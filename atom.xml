<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chen RuiWen&#39;s Space</title>
  
  <subtitle>Life is real, life is earnest</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.chenruiwen.cn/"/>
  <updated>2018-12-05T16:20:02.362Z</updated>
  <id>https://www.chenruiwen.cn/</id>
  
  <author>
    <name>陈瑞文</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Dubbo路由层之Directory</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-Directory/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-Directory/</id>
    <published>2018-12-05T16:18:33.000Z</published>
    <updated>2018-12-05T16:20:02.362Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/">Dubbo服务引用之ReferenceConfig</a>中看到在引用协议订阅远程服务的过程中涉及到这么一个接口<code>Directory</code>。这个东东是做什么的呢？<a id="more"></a></p><h2 id="回顾时序图"><a href="#回顾时序图" class="headerlink" title="回顾时序图"></a>回顾时序图</h2><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtwlylelwj20ry0jwgo7.jpg" alt="">之前说到了拿到引用配置<code>ReferenceConfig</code>类，并且调用了<code>RegistryProtocol</code>的<code>refer</code>方法，接下来在手撕源码前，先超前的看看后面还要经历哪些环节：<code>Directory</code>,<code>Cluster</code>,<code>Protocol</code>,<code>Invoker</code>。。。(省略)。到这里可以根据源码结构找到关键的接口<code>Directory</code>,<code>Cluster</code>，这俩都是<code>dubbo-cluster</code>下的接口，一起理解会比较方便，在细嚼源码前看看开发者文档有没有给我们一些帮助。</p><p>可以找到官网介绍图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg" alt=""></p><p>从图中大致了解到各个接口的作用，今天要分析的<code>Directory</code>主要作用是服务目录列表。</p><h2 id="Directory"><a href="#Directory" class="headerlink" title="Directory"></a>Directory</h2><p>看下接口设计：</p><pre><code class="java">public interface Directory&lt;T&gt; extends Node {    /**     * get service type.     *     * @return service type.     */    Class&lt;T&gt; getInterface();    /**     * list invokers.     *     * @return invokers     */    List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;}</code></pre><p>就俩方法：</p><ul><li>获取服务类型</li><li>获取invoker列表</li></ul><p>看一下其实现的子类：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw8c5tbt5j21a40eogov.jpg" alt="">再结合官网介绍图可知主要实现有<code>StaticDirectory</code>,<code>RegistryDirectory</code>。模板类是<code>AbstractDirectory</code>.</p><h3 id="AbstractDirectory"><a href="#AbstractDirectory" class="headerlink" title="AbstractDirectory"></a>AbstractDirectory</h3><p>看名便知，提供了抽象的<code>Directory</code>实现，也是模板方法模式的体现。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw8u6e45lj21280fejua.jpg" alt=""><code>doList</code>方法交由具体的子类实现。父类(即此类)实现了模板方法<code>list</code>。</p><p>list方法：</p><pre><code class="java">public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {    if (destroyed) {        throw new RpcException(&quot;Directory already destroyed .url: &quot; + getUrl());    }    // 从子类的实现中获取调用者列表    List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation);    List&lt;Router&gt; localRouters = this.routers; // local reference    // 路由过滤，获取匹配的调用者列表    if (localRouters != null &amp;&amp; !localRouters.isEmpty()) {        for (Router router : localRouters) {            try {                if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) {                    invokers = router.route(invokers, getConsumerUrl(), invocation);                }            } catch (Throwable t) {                logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t);            }        }    }    return invokers;}</code></pre><p>可见主要作用就是找到真的匹配的<code>invoker</code>列表。此处涉及接口<code>Router</code>，之后分析。</p><h3 id="StaticDirectory"><a href="#StaticDirectory" class="headerlink" title="StaticDirectory"></a>StaticDirectory</h3><p>主要还是看<code>doList</code>的实现，这是区分不同<code>Directory</code>的根本方法。</p><p>StaticDirectory#doList:</p><pre><code class="java">@Overrideprotected List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException {    return invokers;}</code></pre><p>惊不惊喜？意不意外？没错，就是这么简单，因此也和这个实现的名称也想对应了，“静态的服务目录”，调用者列表不会动态改变。它的<code>invokers</code>主要还是通过构造器传入：</p><pre><code class="java">public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) {    super(url == null &amp;&amp; invokers != null &amp;&amp; !invokers.isEmpty() ? invokers.get(0).getUrl() : url, routers);    if (invokers == null || invokers.isEmpty())        throw new IllegalArgumentException(&quot;invokers == null&quot;);    this.invokers = invokers;}</code></pre><p>此类的应用本人才疏学浅，暂时没有看到，存在即合理，之后看到再补充吧。</p><h3 id="RegistryDirectory"><a href="#RegistryDirectory" class="headerlink" title="RegistryDirectory"></a>RegistryDirectory</h3><p>这个子类实现应该是应用最广泛的一个了。</p><p>RegistryDirectory#doList:</p><pre><code class="java">public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) {    if (forbidden) {        // 下面这个异常简直不要太熟悉了        // 1. No service provider 2. Service providers are disabled        throw new RpcException(RpcException.FORBIDDEN_EXCEPTION,            &quot;No provider available from registry &quot; + getUrl().getAddress() + &quot; for service &quot; + getConsumerUrl().getServiceKey() + &quot; on consumer &quot; +  NetUtils.getLocalHost()                    + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please check status of providers(disabled, not registered or in blacklist).&quot;);    }    List&lt;Invoker&lt;T&gt;&gt; invokers = null;    Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // local reference    if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) {        String methodName = RpcUtils.getMethodName(invocation); // 获取服务提供者方法名称        Object[] args = RpcUtils.getArguments(invocation); // 获取调用参数        if (args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null                &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) {            invokers = localMethodInvokerMap.get(methodName + &quot;.&quot; + args[0]); // The routing can be enumerated according to the first parameter        }        if (invokers == null) {            invokers = localMethodInvokerMap.get(methodName);        }        if (invokers == null) {            invokers = localMethodInvokerMap.get(Constants.ANY_VALUE);        }        if (invokers == null) {            Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator();            if (iterator.hasNext()) {                invokers = iterator.next();            }        }    }    return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers;}</code></pre><p>工作流程：可以看到主要是从<code>methodInvokerMap</code>中获取。先尝试从map中获取key为<code>方法名.参数0</code>的invokers，没找到再尝试从map中获取key为<code>方法名</code>的invokers。没找到再尝试从map中获取key为<code>*</code>的invokers。都找不到就遍历map找到最后的一个invokers。</p><p>那么问题来了，获取<code>invokers</code>是从<code>methodInvokerMap</code>中获取，那么<code>methodInvokerMap</code>是怎么来的呢。</p><p>借助IDE找到<code>methodInvokerMap</code>的赋值处，是在<code>refreshInvoker</code>方法中。<code>refreshInvoker</code>又是在<code>notify</code>方法里调用。现在问题来了，<code>notify</code>方法何时何地调用？</p><p>我们可以注意到:</p><pre><code class="java">public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener`。</code></pre><p><code>RegistryDirectory</code>实现了<code>NotifyListener</code>，并实现了<code>notify</code>方法。方便起见，利用IDE生成一个类图:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxwadwlcz6j20mi0i2js5.jpg" alt=""></p><p>关于在哪里调用又借助一下IDE：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxwaplqiw6j20vm09876h.jpg" alt="">可以确定的是在注册服务处调用的，这里先不细看。</p><p>到这里再细看一下<code>notify</code>方法:</p><pre><code class="java">public synchronized void notify(List&lt;URL&gt; urls) {    List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;();    List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;();    List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;();    for (URL url : urls) {        String protocol = url.getProtocol();        String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);        if (Constants.ROUTERS_CATEGORY.equals(category)                || Constants.ROUTE_PROTOCOL.equals(protocol)) {            routerUrls.add(url);        } else if (Constants.CONFIGURATORS_CATEGORY.equals(category)                || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {            configuratorUrls.add(url);        } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {            invokerUrls.add(url);        } else {            logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost());        }    }    // configurators    if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) {        this.configurators = toConfigurators(configuratorUrls);    }    // routers    if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) {        List&lt;Router&gt; routers = toRouters(routerUrls);        if (routers != null) { // null - do nothing            setRouters(routers);        }    }    List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference    // merge override parameters    this.overrideDirectoryUrl = directoryUrl;    if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) {        for (Configurator configurator : localConfigurators) {            this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);        }    }    // providers    refreshInvoker(invokerUrls);}</code></pre><pre><code class="java">private void refreshInvoker(List&lt;URL&gt; invokerUrls) {    // 清除不存在注册中心的数据    if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null            &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) {        // 空协议禁止访问        this.forbidden = true; // Forbid to access        this.methodInvokerMap = null; // Set the method invoker map to null        destroyAllInvokers(); // Close all invokers    } else {        this.forbidden = false; // Allow to access        Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference        // invokerUrls为空，因为通知的url可能只改变了router或者configurator，提供者并没有变化，但是对应invoker配置还是需要被更改的        if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) {            invokerUrls.addAll(this.cachedInvokerUrls); // 使用缓存的url        } else {            // 更新缓存            this.cachedInvokerUrls = new HashSet&lt;URL&gt;();            this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison        }        if (invokerUrls.isEmpty()) {            return;        }        Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map        Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // Change method name to map Invoker Map        // state change        // If the calculation is wrong, it is not processed.        if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) {            logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot; + invokerUrls.size() + &quot;, invoker.size :0. urls :&quot; + invokerUrls.toString()));            return;        }        // 是否存在group？是则对method对应的invoker进行cluster伪装        this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;        this.urlInvokerMap = newUrlInvokerMap;        try {            destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker        } catch (Exception e) {            logger.warn(&quot;destroyUnusedInvokers error. &quot;, e);        }    }}</code></pre><p><code>notify</code>方法主要就是对url进行分类处理，分为<code>provider</code>，<code>configurators</code>，<code>routers</code>三类url。然后再使用<code>provider</code>类的url调用<code>refreshInvoker</code>进行增量刷新.</p><p><code>refreshInvoker</code>主要根据url协议过滤不匹配的提供者url，然后对过滤后的提供者url生成远程对等调用invoker，并且这些invoker会利用缓存防止重复创建。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，基本Directory的核心方法都已经研究完，尤其是RegistryDirectory，它涉及动态更新<code>invokerUrls</code>，核心在于注册中心的通知与监听。dubbo的路由层还有<code>Cluster</code>,<code>Router</code>以及<code>LoadBalance</code>。留到明天再看！不知不觉已经凌晨，一看源码就容易上头哈~</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在&lt;a href=&quot;https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/&quot;&gt;Dubbo服务引用之ReferenceConfig&lt;/a&gt;中看到在引用协议订阅远程服务的过程中涉及到这么一个接口&lt;code&gt;Directory&lt;/code&gt;。这个东东是做什么的呢？
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo服务引用之ReferenceConfig</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/</id>
    <published>2018-12-04T15:50:03.000Z</published>
    <updated>2018-12-04T15:42:52.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>开启<code>RTFSC</code>之旅，先拾起来之前未完成的<code>Dubbo</code>源码解析。<code>Dubbo</code>自今年夏天开始也是变化很大，github上的官方文档也变化了不少次，现在来看也是非常的美观了。话不多说，今天研究一下<code>Dubbo引用服务</code>。</p><a id="more"></a><h2 id="开局一张图"><a href="#开局一张图" class="headerlink" title="开局一张图"></a>开局一张图</h2><p>老规矩，从文档入手，看看官网介绍。</p><p>ps:一图千言</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtw1bw0rbj217y0tmasc.jpg" alt=""></p><p>和Dubbo服务调用过程一样，其非常重要的还是<code>Invoker</code></p><p>从图可见，服务调用过程大概经历这两步:</p><ul><li>把引用配置(<code>ReferenceConfig</code>)转化为<code>Invoker</code>实例</li><li>再把<code>Invoker</code>实例转化为客户端需要的接口代理对象</li></ul><p>再补一张时序图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtwlylelwj20ry0jwgo7.jpg" alt=""></p><h2 id="ReferenceConfig"><a href="#ReferenceConfig" class="headerlink" title="ReferenceConfig"></a>ReferenceConfig</h2><p>准备工作，先启动服务提供者，我们将<code>dubbo-demo</code>模块下的<code>dubbo-demo-provider</code>启动起来即可。</p><p>第一个断点打在哪，文档以及告诉你了。即<code>ReferenceConfig</code>类的<code>init</code>方法，重点则是调用<code>Protocol</code>的<code>refer</code>方法。</p><p>代码片段分析，直击<code>init</code>方法:</p><pre><code class="java">private void init() {    // 省略代码，判断是否已初始化过    // get consumer&#39;s global configuration    checkDefault();    appendProperties(this); // 添加config 配置属性(根据xml或者java bean)    // 省略代码，获取到 interfaceClass 以及 检察其属性    String resolve = System.getProperty(interfaceName);    String resolveFile = null;    if (resolve == null || resolve.length() == 0) {        resolveFile = System.getProperty(&quot;dubbo.resolve.file&quot;); // resolveFile 映射路径文件，通常用于开发直连调试        if (resolveFile == null || resolveFile.length() == 0) {            File userResolveFile = new File(new File(System.getProperty(&quot;user.home&quot;)), &quot;dubbo-resolve.properties&quot;); // 默认加载 ${user.home}/dubbo-resolve.properties            if (userResolveFile.exists()) {                resolveFile = userResolveFile.getAbsolutePath();            }        }        if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) {            Properties properties = new Properties();            FileInputStream fis = null;            try {                fis = new FileInputStream(new File(resolveFile));                properties.load(fis);            } catch (IOException e) {                throw new IllegalStateException(&quot;Unload &quot; + resolveFile + &quot;, cause: &quot; + e.getMessage(), e);            } finally {                try {                    if (null != fis) fis.close();                } catch (IOException e) {                    logger.warn(e.getMessage(), e);                }            }            resolve = properties.getProperty(interfaceName); // 获取接口的直连地址        }    }    if (resolve != null &amp;&amp; resolve.length() &gt; 0) {        url = resolve;        if (logger.isWarnEnabled()) {            if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) {                logger.warn(&quot;Using default dubbo resolve file &quot; + resolveFile + &quot; replace &quot; + interfaceName + &quot;&quot; + resolve + &quot; to p2p invoke remote service.&quot;);            } else {                logger.warn(&quot;Using -D&quot; + interfaceName + &quot;=&quot; + resolve + &quot; to p2p invoke remote service.&quot;);            }        }    }    // 获取 应用配置，模块配置，注册中心(多个)配置，监控配置    if (consumer != null) {        if (application == null) {            application = consumer.getApplication();        }        if (module == null) {            module = consumer.getModule();        }        if (registries == null) {            registries = consumer.getRegistries();        }        if (monitor == null) {            monitor = consumer.getMonitor();        }    }    if (module != null) {        if (registries == null) {            registries = module.getRegistries();        }        if (monitor == null) {            monitor = module.getMonitor();        }    }    if (application != null) {        if (registries == null) {            registries = application.getRegistries();        }        if (monitor == null) {            monitor = application.getMonitor();        }    }    checkApplication();    checkStubAndMock(interfaceClass);    // 添加调用信息，用于封装为invoker，side=consumer,dubbo=2.0.0,timestamp=xxxxx,pid=xxx    Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();    Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;();    map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE);    map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));    if (ConfigUtils.getPid() &gt; 0) {        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));    }    if (!isGeneric()) {        String revision = Version.getVersion(interfaceClass, version);        if (revision != null &amp;&amp; revision.length() &gt; 0) {            map.put(&quot;revision&quot;, revision);        }        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();        if (methods.length == 0) {            logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());            map.put(&quot;methods&quot;, Constants.ANY_VALUE);        } else {            map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));        }    }    map.put(Constants.INTERFACE_KEY, interfaceName);    appendParameters(map, application);    appendParameters(map, module);    appendParameters(map, consumer, Constants.DEFAULT_KEY);    appendParameters(map, this);    String prefix = StringUtils.getServiceKey(map);    if (methods != null &amp;&amp; !methods.isEmpty()) {        for (MethodConfig method : methods) {            appendParameters(map, method, method.getName());            String retryKey = method.getName() + &quot;.retry&quot;;            if (map.containsKey(retryKey)) {                String retryValue = map.remove(retryKey);                if (&quot;false&quot;.equals(retryValue)) {                    map.put(method.getName() + &quot;.retries&quot;, &quot;0&quot;);                }            }            appendAttributes(attributes, method, prefix + &quot;.&quot; + method.getName());            checkAndConvertImplicitConfig(method, map, attributes);        }    }    String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY);    if (hostToRegistry == null || hostToRegistry.length() == 0) {        hostToRegistry = NetUtils.getLocalHost();    } else if (isInvalidLocalHost(hostToRegistry)) {        throw new IllegalArgumentException(&quot;Specified invalid registry ip from property:&quot; + Constants.DUBBO_IP_TO_REGISTRY + &quot;, value:&quot; + hostToRegistry);    }    map.put(Constants.REGISTER_IP_KEY, hostToRegistry);    //attributes are stored by system context.    StaticContext.getSystemContext().putAll(attributes);    ref = createProxy(map);    ConsumerModel consumerModel = new ConsumerModel(getUniqueServiceName(), this, ref, interfaceClass.getMethods());    ApplicationModel.initConsumerModel(getUniqueServiceName(), consumerModel); // 实际将消费者模块放入缓存中}</code></pre><p>初始化过程:</p><ol><li>获取消费者配置并初始赋值。</li><li>获取接口类并检查配置中的 interface 属性 和 methods属性。</li><li>获取<code>resolveFile</code>映射路径文件，如果文件存则获取属性将接口的值赋给<code>url</code>属性用于直连使用。(不存在则<code>url</code>属性为null)</li><li>获取应用配置，模块配置，注册中心(多个)配置。</li><li>添加接口调用信息，用于封装为<code>Invoker</code></li><li>创建引用代理(<code>T createProxy(Map&lt;String, String&gt; map)</code>)。</li></ol><p>创建引用代理过程:</p><pre><code class="java">private T createProxy(Map&lt;String, String&gt; map) {    URL tmpUrl = new URL(&quot;temp&quot;, &quot;localhost&quot;, 0, map); // 初始化url  temp://localhost?xxx=xxx    // 判断是否是内部调用    final boolean isJvmRefer;    if (isInjvm() == null) {        if (url != null &amp;&amp; url.length() &gt; 0) { // if a url is specified, don&#39;t do local reference            isJvmRefer = false;        } else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) {            // by default, reference local service if there is            isJvmRefer = true;        } else {            isJvmRefer = false;        }    } else {        isJvmRefer = isInjvm().booleanValue();    }    if (isJvmRefer) {        URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map);        invoker = refprotocol.refer(interfaceClass, url);        if (logger.isInfoEnabled()) {            logger.info(&quot;Using injvm service &quot; + interfaceClass.getName());        }    } else {        // 是否是点对点调用（之前的resolveFile配置和获取）        if (url != null &amp;&amp; url.length() &gt; 0) { // user specified URL, could be peer-to-peer address, or register center&#39;s address.            String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url);            if (us != null &amp;&amp; us.length &gt; 0) {                for (String u : us) {                    URL url = URL.valueOf(u);                    if (url.getPath() == null || url.getPath().length() == 0) {                        url = url.setPath(interfaceName);                    }                    if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) {                        urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));                    } else {                        urls.add(ClusterUtils.mergeUrl(url, map));                    }                }            }        } else { // assemble URL from register center&#39;s configuration            List&lt;URL&gt; us = loadRegistries(false); // 加载注册中心列表            if (us != null &amp;&amp; !us.isEmpty()) {                for (URL u : us) {                    URL monitorUrl = loadMonitor(u);                    if (monitorUrl != null) {                        map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString()));                    }                    urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));                }            }            if (urls == null || urls.isEmpty()) {                throw new IllegalStateException(&quot;No such any registry to reference &quot; + interfaceName + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please config &lt;dubbo:registry address=\&quot;...\&quot; /&gt; to your spring config.&quot;);            }        }        if (urls.size() == 1) {            invoker = refprotocol.refer(interfaceClass, urls.get(0));        } else {            List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;();            URL registryURL = null;            for (URL url : urls) {                invokers.add(refprotocol.refer(interfaceClass, url));                if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) {                    registryURL = url; // use last registry url                }            }            if (registryURL != null) { // registry url is available                // use AvailableCluster only when register&#39;s cluster is available                URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME);                invoker = cluster.join(new StaticDirectory(u, invokers));            } else { // not a registry url                invoker = cluster.join(new StaticDirectory(invokers));            }        }    }    Boolean c = check;    if (c == null &amp;&amp; consumer != null) {        c = consumer.isCheck();    }    if (c == null) {        c = true; // default true    }    if (c &amp;&amp; !invoker.isAvailable()) {        throw new IllegalStateException(&quot;Failed to check the status of the service &quot; + interfaceName + &quot;. No provider available for the service &quot; + (group == null ? &quot;&quot; : group + &quot;/&quot;) + interfaceName + (version == null ? &quot;&quot; : &quot;:&quot; + version) + &quot; from the url &quot; + invoker.getUrl() + &quot; to the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion());    }    if (logger.isInfoEnabled()) {        logger.info(&quot;Refer dubbo service &quot; + interfaceClass.getName() + &quot; from url &quot; + invoker.getUrl());    }    // create service proxy    return (T) proxyFactory.getProxy(invoker);}</code></pre><p>步骤：</p><ol><li>判断是否是内部调用，如果是内部调用，则创建一个内部调用<code>Invoker</code>。比如：injvm://127.0.0.1/interfaceClass?xxx=xxx&amp;xxx=xxx</li><li>判断是否是点对点调用，即通过之前<code>resolveFile</code>文件获取到的映射地址。如果有则执行点对点直连调用。</li><li>如果以上都不是，则加载注册中心url(多个)，获取到<code>注册中心url</code>并赋值属性<code>refer=之前的接口调用url</code>。</li><li><code>注册中心url</code>如果是单个，则直接通过扩展点机制，引用的协议获取此url的<code>Invoker</code>对象。</li><li><code>注册中心url</code>如果是多个，生成多个<code>Invoker</code>对象，遍历urls获取最后一个<code>registryURL</code>。如果<code>registryURL</code>不为null,则有注册中心，用 AvailableCluster获取invoker对象。</li><li>创建服务代理。(这一步之前有介绍过，实际为<code>JavassistProxyFactory.getInvoker</code>通过字节码获取代理对象。)</li></ol><p>关于获取<code>Invoker</code>对象，代码里是这么获取的:</p><pre><code class="java">invoker = refprotocol.refer(interfaceClass, urls.get(0));</code></pre><p>这里的<code>refprotocol</code>又是扩展点机制，在上面这个例子里，他的实现是<code>RegistryProtocol</code>.</p><pre><code class="java">public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException {    // 设置url中的协议，将 registry 换为url中的registry属性，默认为dubbo    url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);    Registry registry = registryFactory.getRegistry(url);    if (RegistryService.class.equals(type)) {        return proxyFactory.getInvoker((T) registry, type, url);    }    // group=&quot;a,b&quot; or group=&quot;*&quot;    Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));    String group = qs.get(Constants.GROUP_KEY);    if (group != null &amp;&amp; group.length() &gt; 0) {        if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1                || &quot;*&quot;.equals(group)) {            return doRefer(getMergeableCluster(), registry, type, url);        }    }    return doRefer(cluster, registry, type, url);}private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) {    RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);    directory.setRegistry(registry);    directory.setProtocol(protocol);    // all attributes of REFER_KEY    Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters());    URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters);    if (!Constants.ANY_VALUE.equals(url.getServiceInterface())            &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) {        registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,                Constants.CHECK_KEY, String.valueOf(false)));    }    directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY,            Constants.PROVIDERS_CATEGORY                    + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY                    + &quot;,&quot; + Constants.ROUTERS_CATEGORY));    Invoker invoker = cluster.join(directory);    ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory);    return invoker;}</code></pre><p>这里的实现涉及的一些内容：</p><ul><li>获取<code>Registry</code>对象</li><li><code>Directory</code>接口</li><li>向注册中心注册。比如本例的<code>ZookeeperRegistry</code></li><li>服务订阅</li><li><code>cluster</code>集群容错</li></ul><p>这里暂时不解释这么多，明天接着按顺序看。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>看了下Dubbo的ReferenceConfig的源码，更深刻体会了那句话:满眼都是<code>Invoker</code>。除此之外，还有很多重要的接口需要理解，比如<code>Directory</code>接口…</p><p>to be contine…</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;开启&lt;code&gt;RTFSC&lt;/code&gt;之旅，先拾起来之前未完成的&lt;code&gt;Dubbo&lt;/code&gt;源码解析。&lt;code&gt;Dubbo&lt;/code&gt;自今年夏天开始也是变化很大，github上的官方文档也变化了不少次，现在来看也是非常的美观了。话不多说，今天研究一下&lt;code&gt;Dubbo引用服务&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
  </entry>
  
  <entry>
    <title>我的反思录</title>
    <link href="https://www.chenruiwen.cn/essay/my-rethink-on-2018/"/>
    <id>https://www.chenruiwen.cn/essay/my-rethink-on-2018/</id>
    <published>2018-12-02T13:09:03.000Z</published>
    <updated>2018-12-02T12:38:42.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>眼瞅着2018要过去了，这一年是有不少收获，但是感觉和自己的计划还有一些差距，简而言之就是没有达到自己的目标。这是一件糟糕的事情，加上已经很久没有写博客了，真的感觉状态不太对，总结一下吧。<a id="more"></a></p><h2 id="回忆问题出在哪"><a href="#回忆问题出在哪" class="headerlink" title="回忆问题出在哪"></a>回忆问题出在哪</h2><p>有哪些问题呢？</p><ul><li>地铁上耗费的时间太长。</li><li>突然的加班导致加班前的正常学习状态被打破。也就是说学习不连贯。</li><li>加班耗费了太多精力，回家就想躺下睡大觉。</li><li>焦虑于未完成的事情。</li></ul><h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><p>看似问题简单，根本原因是<code>时间</code>，然后又巧妙的<code>甩锅</code>给<code>加班</code>。然而真的是这样的吗？</p><p>我看来，根本原因可能是<code>拖延症</code>，或者说是自己的<code>懒</code>。</p><h2 id="解决问题的方法"><a href="#解决问题的方法" class="headerlink" title="解决问题的方法"></a>解决问题的方法</h2><p>基本就是如何解决掉自己<code>懒</code>的特性。</p><ul><li>地铁上的时间可以用来看一下书籍。</li><li>加班问题，其实也没有加班到特别晚过，至少还能留有1小时的时间。</li><li>加班耗费精力的问题，主要还是要集中解决一下效率问题，效率高了就节约加班时间甚至于不用加班。如何提高效率，在日常工作中尽量多的积累工具经验，写优秀简洁的代码，自然而然效率就高了。</li><li>解决了上面的问题也就不焦虑了。</li></ul><h2 id="给自己个小目标"><a href="#给自己个小目标" class="headerlink" title="给自己个小目标"></a>给自己个小目标</h2><p>我的目标最终是要写出高质量简洁高效的代码来提高自己的生产效率，根治加班问题。</p><p>那么，如何一步一步完成这个目标呢？</p><p>答案即是 <code>RTFSC：Read The Fucking Source Code</code>。</p><p>每天坚持看源码，之前<code>dubbo</code>的源码分析还没有写完，我承认是自己懒了，虽然网上也大把的分析<code>dubbo</code>源码的，但是应该有输入也有输出才是正确的学习姿势，应该持之以恒。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>学习之路漫长，走的不快，但是尽量走的远一些，<code>坚持</code>二字确实难但也是一条最正确的路。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;眼瞅着2018要过去了，这一年是有不少收获，但是感觉和自己的计划还有一些差距，简而言之就是没有达到自己的目标。
这是一件糟糕的事情，加上已经很久没有写博客了，真的感觉状态不太对，总结一下吧。
    
    </summary>
    
      <category term="essay" scheme="https://www.chenruiwen.cn/categories/essay/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
  </entry>
  
  <entry>
    <title>小Tips，加速github访问速度</title>
    <link href="https://www.chenruiwen.cn/tips/little-tips-optimize-github-access/"/>
    <id>https://www.chenruiwen.cn/tips/little-tips-optimize-github-access/</id>
    <published>2018-11-17T09:33:22.000Z</published>
    <updated>2018-11-17T09:43:06.837Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>访问<a href="https://github.com/" target="_blank" rel="noopener">github</a>的速度真的太慢了。(尤其微软收购之后。:D)。尤其在<code>git clone</code>等操作上确实影响心情:</p><pre><code>Receiving objects:   8% (497/5635), 2.89 MiB | 15.00 KiB/s</code></pre><p>然而解决的方法非常简单。<a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>慢的原因在哪？其实并不是因为 <code>http://github.com</code> 的这个域名被限制了。而是 <code>http://github.global.ssl.fastly.Net</code> 这个域名被限制了。</p><p>解决方法在于修改<code>hosts</code>文件，增加如下:</p><pre><code>151.101.72.249 global-ssl.fastly.Net192.30.253.112 github.com</code></pre><p>成功解决问题，测速如下:</p><pre><code>Receiving objects: 100% (5635/5635), 46.94 MiB | 2.27 MiB/s, done.</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>国内的编程环境的阻碍还是不少啊~~</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;访问&lt;a href=&quot;https://github.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github&lt;/a&gt;的速度真的太慢了。(尤其微软收购之后。:D)。
尤其在&lt;code&gt;git clone&lt;/code&gt;等操作上确实影响心情:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Receiving objects:   8% (497/5635), 2.89 MiB | 15.00 KiB/s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然而解决的方法非常简单。
    
    </summary>
    
      <category term="tips" scheme="https://www.chenruiwen.cn/categories/tips/"/>
    
    
      <category term="tips" scheme="https://www.chenruiwen.cn/tags/tips/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用性能分析工具</title>
    <link href="https://www.chenruiwen.cn/Linux/Linux-performance-analysis-util/"/>
    <id>https://www.chenruiwen.cn/Linux/Linux-performance-analysis-util/</id>
    <published>2018-11-14T13:19:22.000Z</published>
    <updated>2018-11-14T13:27:05.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上周五公司搞了双十一“大促”，虽然时间紧凑，还是引起了团队上下高度重视，在有限的两天时间里，进行了充分的压测和性能分析，最终的结果也是不错的。对于性能分析工具，又做了一次熟悉的过程，这里结合网上优秀博文做了下整理。</p><a id="more"></a><h2 id="性能监控，要看哪些"><a href="#性能监控，要看哪些" class="headerlink" title="性能监控，要看哪些"></a>性能监控，要看哪些</h2><p>一张表搞定：</p><table><thead><tr><th>检测目标</th><th>指标</th><th>工具</th></tr></thead><tbody><tr><td>cpu</td><td>usr&lt;=70%, sys&lt;=35%, usr+sys&lt;=70%</td><td>top</td></tr><tr><td>memory</td><td>swap in （si） == 0，swap out （so） == 0； 可用空间&gt;=30%；应用程序可用内存/系统物理内存 &lt;= 70%</td><td>vmstat 1;free; /proc/meminfo</td></tr><tr><td>io</td><td>iowait% &lt; 20%</td><td>sar; iostat -x;</td></tr><tr><td>network</td><td>udp：缓冲区不挤压, 无丢包 tcp：重传率</td><td>netstat -lunp; netstat -su; /proc/net/snmp</td></tr></tbody></table><p>良好状态指标:</p><ul><li><p>cpu：</p><ul><li>CPU利用率：User Time &lt;= 70%，System Time &lt;= 35%，User Time + System Time &lt;= 70%</li><li>上下文切换：与CPU利用率相关联，如果CPU利用率状态良好，大量的上下文切换也是可以接受的</li><li>可运行队列：每个处理器的可运行队列&lt;=3个线程</li></ul></li><li><p>memory:swap in(si)==0，swap out(so)==0;应用程序可用内存/系统物理内存 &lt;= 70%</p></li><li>io：<strong>iowait % &lt; 20%</strong> ;提高命中率的一个简单方式就是增大文件缓存区面积，缓存区越大预存的页面就越多，命中率也越高。Linux 内核希望能尽可能产生次缺页中断（从文件缓存区读），并且能尽可能避免主缺页中断（从硬盘读），这样随着次缺页中断的增多，文件缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。</li><li>network：<ul><li>对于UDP，<strong>接收、发送缓冲区不长时间有等待处理的网络包</strong>；</li><li>对于TCP而言，不会出现因为缓存不足而存在丢包的事，因为网络等其他原因，导致丢了包，协议层也会通过重传机制来保证丢的包到达对方。所以，更多的专注<strong>重传率</strong>。</li></ul></li></ul><h2 id="监控工具"><a href="#监控工具" class="headerlink" title="监控工具"></a>监控工具</h2><p>列举一些常用且实用的工具。</p><h3 id="top命令"><a href="#top命令" class="headerlink" title="top命令"></a>top命令</h3><p>最常用的命令，每次压测第一使用率的命令。top命令可以实时监控系统运行状态，它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序。</p><p>命令格式:</p><pre><code>top [参数]</code></pre><p>命令参数:</p><pre><code>-b 批处理-c 显示完整的治命令-I 忽略失效过程-s 保密模式-S 累积模式-i&lt;时间&gt; 设置间隔时间-u&lt;用户名&gt; 指定用户名-p&lt;进程号&gt; 指定进程-n&lt;次数&gt; 循环显示的次数</code></pre><p>使用top命令后，可见如下交互信息：</p><pre><code>top - 22:44:08 up 667 days,  4:15,  9 users,  load average: 4.07, 3.54, 3.30Tasks: 406 total,   1 running, 405 sleeping,   0 stopped,   0 zombieCpu(s): 15.3%us,  0.7%sy,  0.0%ni, 84.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%stMem:  32899876k total, 31996032k used,   903844k free,   337144k buffersSwap: 15624188k total,  1577788k used, 14046400k free,  9132796k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                  47210 staging   20   0 13.6g 743m 6224 S 5204  2.3  5128980h java                                                                                                     35314 staging   20   0 16.6g 830m  11m S    4  2.6 243:11.07 java                                                                                                     32098 staging   20   0 10.1g 524m 9208 S    4  1.6 664:05.61 java                                                                                                     12789 staging   20   0 13.7g 635m  18m S    3  2.0  67:37.08 java                                                                                                      3198 staging   20   0 1193m  38m 5016 S    2  0.1   1942:19 PM2 v2.7.2: God                                                                                          29642 staging   20   0 13.0g 416m 5348 S    2  1.3   1428:13 java                                                                                                     21707 staging   20   0 13.4g 412m  11m S    2  1.3 110:47.28 java                                                                                                     20115 staging   20   0 13.7g 614m  18m S    1  1.9  46:43.89 java                                                                                                     43796 staging   20   0 16.6g 579m  11m S    1  1.8 102:33.21 java                                                                                                     12320 staging   20   0 13.7g 653m  18m S    1  2.0  60:49.53 java                                                                                                     24179 look      20   0 17596 1560  960 R    1  0.0   0:00.16 top                                                                                                      31933 staging   20   0 11.1g 424m 9084 S    1  1.3 208:44.23 java                                                                                                     33717 staging   20   0 1206m  49m 8824 S    1  0.2   3:45.91 node /data/web-                                                                                          40163 staging   20   0 13.5g 534m  15m S    1  1.7  72:56.82 java                                                                                                      7974 staging   20   0 13.0g 435m 8804 S    1  1.4 259:16.18 java                                                                                                     13487 staging   20   0 13.0g 413m 9084 S    1  1.3 188:53.99 java                                                                                                     15855 root      20   0  9.9g 861m 1524 S    1  2.7   1544:16 java                                                                                                     17886 staging   20   0 12.8g 239m 6396 S    1  0.7 692:52.16 java                                                                                                     18725 staging   20   0 13.5g 519m  15m S    1  1.6  39:54.70 java                                                                                                     27444 root      20   0 10.4g 503m 1280 S    1  1.6   2753:21 java                                                                                                     31900 staging   20   0 8991m 422m 9156 S    1  1.3 136:25.31 java                                                                                                     32034 staging   20   0 10.8g 461m 9376 S    1  1.4 152:14.69 java</code></pre><p>上述信息很多，逐个解释。</p><p>第一行，任务队列信息，同 uptime 命令的执行结果</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>22:44:08</td><td>当前系统时间</td></tr><tr><td>up 667 days,  4:15</td><td>已经运行667天4小时15分(未重启过)</td></tr><tr><td>9 users</td><td>当前9个用户登录系统</td></tr><tr><td>load average: 4.07, 3.54, 3.30</td><td>系统负载，后面三个参数分别是一分钟，五分钟和十五分钟；load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</td></tr></tbody></table><p>第二行，Tasks — 任务（进程）：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>406 total</td><td>总进程数，共有206个进程</td></tr><tr><td>1 running</td><td>正在运行进程数，1个</td></tr><tr><td>405 sleeping</td><td>休眠状态进程数，405个</td></tr><tr><td>0 stopped</td><td>停止进程数，0个</td></tr><tr><td>0 zombie</td><td>僵尸进程数（处于无响应状态），0个</td></tr></tbody></table><p>第三行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>15.3%us</td><td>用户空间占用CPU的百分比</td></tr><tr><td>0.7%sy</td><td>内核空间占用CPU的百分比</td></tr><tr><td>0.0%ni</td><td>改变过优先级的进程占用CPU的百分比</td></tr><tr><td>84.0%id</td><td>空闲CPU百分比</td></tr><tr><td>0.0%wa</td><td>IO等待占用CPU的百分比</td></tr><tr><td>0.0%hi</td><td>硬中断（Hardware IRQ）占用CPU的百分比</td></tr><tr><td>0.0%si</td><td>软中断（Software Interrupts）占用CPU的百分比</td></tr><tr><td>0.0%st</td><td>在内存紧张环境下，pagein 强制对不同的页面进行的 steal 操作</td></tr></tbody></table><p>第四行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>32899876k total</td><td>物理内存总量（32GB）</td></tr><tr><td>31996032k used</td><td>使用中的内存总量（31GB）</td></tr><tr><td>903844k free</td><td>空闲内存总量（903M）</td></tr><tr><td>337144k buffers</td><td>缓存的内存量 （337M）</td></tr></tbody></table><p>第五行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>15624188k total</td><td>交换区总量（15.6GB）</td></tr><tr><td>1577788k used</td><td>使用的交换区总量（1.5GB）</td></tr><tr><td>14046400k free</td><td>空闲交换区总量（14GB）</td></tr><tr><td>9132796k cached</td><td>缓冲的交换区总量（9.1GB）</td></tr></tbody></table><p><strong>说明:</strong></p><blockquote><p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</p><p>如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。</p><p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p></blockquote><p>第六行。空行。</p><p>第七行，各进程（任务）的状态监控：PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND<br>参数示例 | 含义—|—PID | 进程idUSER | 进程所有者PR | 进程优先级NI | nice值。负值表示高优先级，正值表示低优先级VIRT | 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES | 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR | 共享内存大小，单位kbS | 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU | 上次更新到现在的CPU时间占用百分比%MEM | 进程使用的物理内存百分比TIME+ | 进程使用的CPU时间总计，单位1/100秒COMMAND | 进程名称（命令名/命令行）</p><p>top命令下，常用交互操作：</p><ul><li><code>h</code>:显示帮助画面</li><li><code>1</code>:显示CPU信息。可监控每个逻辑CPU的状况。(%cpu的值是跟内核数成正比的，如8核cpu的%cpu最大可以800%。)</li><li><code>H</code>:显示线程。</li><li>排序。<ul><li>Cpu ： 在top交互界面按<code>shift+p</code>或<code>P</code>。</li><li>Mem ：在top交互界面按<code>shift+m</code>或<code>M</code>。</li><li>Time ：在top交互界面按<code>shift+t</code>或<code>T</code>。</li></ul></li><li>显示程序名。在top交互界面按c。</li><li>监控进程下的线程。在命令行输入<code>top -H -p pid</code>，其中pid为进程id，进入界面后显示的PID为线程ID；或者使用命令<code>top -H -p pid</code>进入界面之后在按<code>shift+h</code>来显示线程。</li></ul><h3 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h3><p>vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。不足之处是无法对某个进程进行深入分析。vmstat工具提供了一种低开销的系统性能观察方式，适合在高负荷的服务器上控系统的健康情况。</p><p>命令格式：</p><pre><code>vmstat [-a] [-n] [-S unit] [delay [ count]]vmstat [-s] [-n] [-S unit]vmstat [-m] [-n] [delay [ count]]vmstat [-d] [-n] [delay [ count]]vmstat [-p disk partition] [-n] [delay [ count]]vmstat [-f]vmstat [-V]</code></pre><p>命令参数：</p><pre><code>-a：显示活跃和非活跃内存-f：显示从系统启动至今的fork数量 。-m：显示slabinfo-n：只在开始时显示一次各字段名称。-s：显示内存相关统计信息及多种系统活动数量。delay：刷新时间间隔。如果不指定，只显示一条结果。count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。-d：显示磁盘相关统计信息。-p：显示指定磁盘分区统计信息-S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）-V：显示vmstat版本信息。</code></pre><p>使用示例，1秒输出一次，输出20次，单位为MB：</p><pre><code>~$ vmstat 1 20 -S Mprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa 2  0   1540   1079    348   8715    0    0     0     6    0    0  5  0 94  018  0   1540   1078    348   8715    0    0     0    40 11476 16550 32  1 67  0 1  0   1540   1078    348   8715    0    0     0     0 9431 16197 11  0 89  0 0  0   1540   1079    348   8715    0    0     0   244 8325 15550  1  0 99  0 6  0   1540   1079    348   8715    0    0     0     0 8770 15459  5  0 95  0 0  0   1540   1080    348   8715    0    0     0   100 13954 20077 37  1 62  0 0  0   1540   1080    348   8715    0    0     0    36 8661 16188  1  0 98  0 2  0   1540   1080    348   8715    0    0     0     0 8708 16158  1  0 98  0 1  0   1540   1081    348   8715    0    0     0    68 10946 16001 33  0 66  0 1  0   1540   1080    348   8715    0    0     0     0 9380 17035  1  1 98  0 0  0   1540   1080    348   8715    0    0     0   128 8447 15719  1  0 99  020  0   1540   1080    348   8715    0    0     0    44 10066 15924 15  1 84  0 1  0   1540   1081    348   8715    0    0     0     0 11834 16701 41  1 59  0 1  0   1540   1080    348   8715    0    0     0   144 8346 15732  1  1 98  1 2  0   1540   1080    348   8715    0    0     0     0 8378 15545  1  0 98  0 2  0   1540   1080    348   8715    0    0     0   120 16144 21775 36  1 63  0 3  0   1540   1079    348   8715    0    0     0    60 8911 16162  3  1 97  0 1  0   1540   1079    348   8715    0    0     0     0 8645 16013  1  1 99  0 5  0   1540   1079    348   8715    0    0     0   272 9153 15929  6  1 92  1 2  0   1540   1080    348   8715    0    0     0     0 12723 16598 52  1 48  0</code></pre><ul><li><p>procs</p><ul><li>R 列表示运行和等待 CPU 时间片的进程数，这个值如果长期大于系统 CPU 个数，说明CPU 不足，需要增加 CPU。</li><li>B 列表示在等待资源的进程数，比如正在等待 I/O 或者内存交换等。</li></ul></li><li><p>memory</p><ul><li>swpd 列表示切换到内存交换区的内存大小（单位 KB），通俗讲就是虚拟内存的大小。如果 swap 值不为 0 或者比较大， 只要 si、so 的值长期为 0，这种情况一般属于正常情况</li><li>free 列表示当前空闲的物理内存（单位 KB） 。</li><li>buff 列表示 buffers cached 内存大小，也就是缓冲区大小，一般对块设备的读写才需要缓冲。</li><li>cache 列表示 page cached 的内存大小，也就是缓存大小，一般作为文件系统进行缓冲，频繁访问的文件都会被缓存，如果 cache 值非常大说明缓存文件比较多，如果此时 io中的 bi 比较小，说明文件系统效率比较好。</li></ul></li><li><p>swap</p><ul><li>si 列表示由磁盘调入内存，也就是内存进入内存交换区的内存大小。</li><li>so 列表示由内存进入磁盘，也就是有内存交换区进入内存的内存大小。一般情况下，si、so 的值都为 0，如果 si、so 的值长期不为 0，则说明系统内存不足，需要增加系统内存。</li></ul></li><li><p>io</p><ul><li>bi 列表示由块设备读入数据的总量，即读磁盘，单位 kb/s。</li><li>bo 列表示写到块设备数据的总量，即写磁盘，单位 kb/s。如果 bi+bo 值过大，且 wa 值较大，则表示系统磁盘 IO 瓶颈。</li></ul></li><li><p>system</p><ul><li>in 列表示某一时间间隔内观测到的每秒设备中断数。</li><li>cs 列表示每秒产生的上下文切换次数。这 2 个值越大，则由内核消耗的 CPU 就越多。</li></ul></li><li><p>cpu</p><ul><li>us 列表示用户进程消耗的 CPU 时间百分比，us 值越高，说明用户进程消耗 cpu 时间越多，如果长期大于 50%，则需要考虑优化程序或者算法。</li><li>sy 列表示系统内核进程消耗的 CPU 时间百分比，一般来说 us+sy 应该小于 80%，如果大于 80%，说明可能处于 CPU 瓶颈。</li><li>id 列表示 CPU 处在空闲状态的时间百分比。</li><li>wa 列表示 IP 等待所占的 CPU 时间百分比，wa 值越高，说明 I/O 等待越严重，根据经验 wa 的参考值为 20%，如果超过 20%，说明 I/O 等待严重，引起 I/O 等待的原因可能是磁盘大量随机读写造成的， 也可能是磁盘或者此哦按监控器的贷款瓶颈 （主要是块操作）造成的。</li></ul></li></ul><table><thead><tr><th>字段</th><th>含义</th></tr></thead><tbody><tr><td>Procs（进程）</td><td>r: 运行队列中进程数量;b: 等待IO的进程数量</td></tr><tr><td>Memory（内存）</td><td>swpd: 使用虚拟内存大小;free: 可用内存大小;buff: 用作缓冲的内存大小;cache: 用作缓存的内存大小</td></tr><tr><td>Swap</td><td>si: 每秒从交换区写到内存的大小;so: 每秒写入交换区的内存大小</td></tr><tr><td>IO：（现在的Linux版本块的大小为1024bytes）</td><td>bi: 每秒读取的块数; cs: 每秒上下文切换数</td></tr><tr><td>system（系统）</td><td>in: 每秒中断数，包括时钟中断;cs: 每秒上下文切换数</td></tr><tr><td>CPU（以百分比表示）</td><td>us: 用户进程执行时间(user time);sy: 系统进程执行时间(system time);id: 空闲时间(包括IO等待时间),中央处理器的空闲时间,以百分比表示;wa: 等待IO时间</td></tr></tbody></table><p>备注： 如果r经常大于4，且id经常少于40，表示cpu的负荷很重。如果pi，po长期不等于0，表示内存不足。如果disk经常不等于0，且在 b中的队列大于3，表示io性能不好。</p><h3 id="free"><a href="#free" class="headerlink" title="free"></a>free</h3><p>free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。也是经典常用命令之一。</p><p>命令格式：</p><pre><code>free [参数]</code></pre><p>命令参数：</p><pre><code>-b 　以Byte为单位显示内存使用情况。 -k 　以KB为单位显示内存使用情况。 -m 　以MB为单位显示内存使用情况。-g   以GB为单位显示内存使用情况。 -o 　不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 　持续观察内存使用状况。 -t 　显示内存总和列。 -V 　显示版本信息。</code></pre><p>使用实例：</p><pre><code>chenruiwen@ubuntu$ free -m             total       used       free     shared    buffers     cachedMem:         32128      31103       1025          0        348       8739-/+ buffers/cache:      22014      10114Swap:        15257       1540      13717</code></pre><p>字段解释：</p><ul><li>Mem：物理内存大小。</li><li>total：总计物理内存的大小。</li><li>used：已使用多大。</li><li>free：可用有多少。</li><li>shared：多个进程共享的内存总额。</li><li>buffers：缓冲区内存总量。</li><li>cached：交换区缓冲区内存总量。</li><li>第三行(-/+ buffers/cached)：系统的物理内存真实使用量，可通过used-buffers-cached计算得到，因为buffers和cached也是占用物理内存得来，可以通过释放它们来获得这部分内存。</li><li>Swap：交换区总量，也叫虚拟内存。</li></ul><p><strong>第二行(Mem)的used/free与第三行(-/+ buffers/cache) used/free的区别：</strong>  </p><blockquote><p>这两个的区别在于使用的角度来看。</p><p><code>Mem</code>行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是<code>1025MB</code>，已用内存是<code>31103MB</code>，其中包括，内核（OS）使用 + Application(X,oracle,etc)使用的 + buffers + cached.</p><p><code>-/+ buffers/cache</code>行是从应用程序角度来看，对于应用程序来说，buffers/cached是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。</p><p>例如本机的可用内存为：22014MB(<code>-/+ buffers/cache: used</code>) = 1025MB(Mem:free) + 348MB(<code>Mem:buffers</code>) + 8739MB(<code>Mem:cached</code>)</p></blockquote><p><strong>cache 和 buffer的区别：</strong></p><blockquote><p>Cache：高速缓存，是位于CPU与主内存间的一种容量较小但速度很高的存储器。</p><p>由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，Cache中保存着CPU刚用过或循环使用的一部分数据，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。</p><p>Cache又分为一级Cache(L1 Cache)和二级Cache(L2 Cache)，L1 Cache集成在CPU内部，L2 Cache早期一般是焊在主板上,现在也都集成在CPU内部，常见的容量有256KB或512KB L2 Cache。</p><p>Buffer：缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。</p><p>Free中的buffer和cache：（它们都是占用内存）</p><p>buffer : 作为buffer cache的内存，是块设备的读写缓冲区cache: 作为page cache的内存，文件系统的cache</p><p>如果 cache 的值很大，说明cache住的文件数很多。如果频繁访问到的文件都能被cache住，那么磁盘的读IO 必会非常小。</p></blockquote><h3 id="proc-meminfo-文件"><a href="#proc-meminfo-文件" class="headerlink" title="/proc/meminfo 文件"></a>/proc/meminfo 文件</h3><p>/proc/meminfo是了解Linux系统内存使用状况的主要接口，我们最常用的<code>free</code>、<code>vmstat</code>等命令就是通过它获取数据的。此信息最为丰富，但是我个人使用不多。</p><p>使用示例如下，至于各参数的含义，还是留给Google吧:</p><pre><code>~$ cat /proc/meminfoMemTotal:       32899876 kBMemFree:         4919948 kBBuffers:           95612 kBCached:          1170384 kBSwapCached:      1345120 kBActive:         22391896 kBInactive:        4236700 kBActive(anon):   21918324 kBInactive(anon):  3448892 kBActive(file):     473572 kBInactive(file):   787808 kBUnevictable:           0 kBMlocked:               0 kBSwapTotal:      15624188 kBSwapFree:        5905244 kBDirty:              7212 kBWriteback:             0 kBAnonPages:      24023988 kBMapped:            33772 kBShmem:              4408 kBSlab:             764240 kBSReclaimable:     598480 kBSUnreclaim:       165760 kBKernelStack:       70024 kBPageTables:       125652 kBNFS_Unstable:          0 kBBounce:                0 kBWritebackTmp:          0 kBCommitLimit:    32074124 kBCommitted_AS:   52714036 kBVmallocTotal:   34359738367 kBVmallocUsed:      342184 kBVmallocChunk:   34342341604 kBHardwareCorrupted:     0 kBAnonHugePages:         0 kBHugePages_Total:       0HugePages_Free:        0HugePages_Rsvd:        0HugePages_Surp:        0Hugepagesize:       2048 kBDirectMap4k:      271296 kBDirectMap2M:    25896960 kBDirectMap1G:     7340032 kB</code></pre><h3 id="sar"><a href="#sar" class="headerlink" title="sar"></a>sar</h3><p>sar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等，sar命令由sysstat安装包安装。</p><p>sar安装直接<code>yum install -y sysstat</code>，然后先执行<code>sar -o 2 3</code>，来生成所需文件，之后使用就正常啦。</p><p>命令格式:</p><pre><code>sar [选项] [&lt;时间间隔&gt; [&lt;次数&gt;]]</code></pre><p>命令参数:</p><pre><code>-A:所有报告的总和-b:显示I/O和传递速率的统计信息-B:显示换页状态-d:输出每一块磁盘的使用信息-e:设置显示报告的结束时间-f:从制定的文件读取报告-i:设置状态信息刷新的间隔时间-P:报告每个CPU的状态-R:显示内存状态–u:输出cpu使用情况和统计信息–v:显示索引节点、文件和其他内核表的状态-w:显示交换分区的状态-x:显示给定进程的装-r:报告内存利用率的统计信息</code></pre><h4 id="sar监控CPU"><a href="#sar监控CPU" class="headerlink" title="sar监控CPU"></a>sar监控CPU</h4><p>使用示例,输出cpu使用情况和统计信息，每2秒输出一次，输出10次：</p><pre><code>~$ sar -u 2 10Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)13时43分03秒     CPU     %user     %nice   %system   %iowait    %steal     %idle13时43分05秒     all      2.23      0.02      0.93      0.15      0.00     96.6713时43分07秒     all      1.54      0.00      0.65      0.11      0.00     97.7113时43分09秒     all      0.99      0.00      0.65      1.12      0.00     97.2413时43分11秒     all      2.02      0.02      0.92      0.13      0.00     96.9113时43分13秒     all      1.39      0.00      0.63      0.44      0.00     97.5313时43分15秒     all      1.85      0.02      1.01      0.06      0.00     97.0613时43分17秒     all      2.11      0.00      0.70      0.02      0.00     97.1713时43分19秒     all      1.37      0.00      0.51      0.72      0.00     97.4113时43分21秒     all      1.62      0.02      0.93      0.06      0.00     97.3713时43分23秒     all      1.39      0.00      0.59      0.27      0.00     97.75Average:        all      1.65      0.01      0.75      0.31      0.00     97.28</code></pre><p>参数说明:</p><ul><li>%usr：用户进程消耗的 CPU 时间百分比</li><li>%nice: 运行正常进程消耗的 CPU 时间百分比</li><li>%system：系统进程消耗的 CPU 时间百分比</li><li>%iowait：I/O 等待所占 CPU 时间百分比</li><li>%steal：在内存紧张环境下，pagein强制对不同的页面进行的steal操作。虚拟服务占用的CPU时间百分比，这个值一般为0.</li><li>%idle：CPU 空闲状态的时间百分比</li></ul><blockquote><p>在所有的显示中，我们应主要注意<code>%iowait</code> 和<code>%idle</code>。</p><p>%iowait 的值过高，表示硬盘存在I/O瓶颈， %idle值高，表示 CPU 较空闲，如果%idle 值高但系统响应慢时，有可能是 CPU 等待分配内存， 此时应加大内存容量。</p><p>%idle 值如果持续低于 10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p></blockquote><h4 id="sar监控内存"><a href="#sar监控内存" class="headerlink" title="sar监控内存"></a>sar监控内存</h4><p>使用示例,<strong>显示内存使用信息</strong>：</p><pre><code>~$ sar -r 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)14时04分38秒 kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact14时04分40秒   4984120  27915756     84.85    104060   1157104  52363184    107.91  22343076   422716814时04分42秒   4983772  27916104     84.85    104060   1157416  52363184    107.91  22343080   422734414时04分44秒   4983516  27916360     84.85    104072   1157584  52363184    107.91  22343148   4227532Average:      4983803  27916073     84.85    104064   1157368  52363184    107.91  22343101   4227348</code></pre><ul><li>kbmemfree： 空闲的物理内存大小。这个值和 free 命令中的 free 值基本一致,所以它不包括 buffer 和 cache 的空间。</li><li>kbmemused：使用中的物理内存大小。这个值和 free 命令中的 used 值基本一致,所以它包括 buffer 和 cache 的空间。</li><li>%memused：这个值是 kbmemused 和内存总量(不包括 swap)的一个百分比。</li><li>kbbuffers 和 kbcached：这两个值就是 free 命令中的 buffer 和 cache。</li><li>kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)。</li><li>%commit：这个值是 kbcommit 与内存总量(包括 swap)的一个百分比。</li></ul><p>使用示例，<strong>显示系统内存分页状态</strong>：</p><pre><code>~$ sar -B 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)14时17分35秒  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff14时17分37秒      0.00     16.00    135.00      0.00    395.50      0.00      0.00      0.00      0.0014时17分39秒      0.00    168.00     26.00      0.00    435.00      0.00      0.00      0.00      0.0014时17分41秒      0.00   1142.00    517.50      0.00    679.50      0.00      0.00      0.00      0.00Average:         0.00    442.00    226.17      0.00    503.33      0.00      0.00      0.00      0.00</code></pre><ul><li>pgpgin/s：表示每秒从磁盘或 SWAP 置换到内存的字节数(KB)。</li><li>pgpgout/s：表示每秒从内存置换到磁盘或 SWAP 的字节数(KB)。</li><li>fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)。</li><li>majflt/s：每秒钟产生的主缺页数。</li></ul><p>使用示例，<strong>显示系统虚拟内存分页状态</strong>：</p><pre><code>$ sar -W 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)17时08分41秒  pswpin/s pswpout/s17时08分43秒      0.00      0.0017时08分45秒      0.00      0.0017时08分47秒      0.00      0.00Average:         0.00      0.00</code></pre><ul><li>pswpin/s：每秒系统换入的交换页面（swap page）数量。</li><li>pswpout/s：每秒系统换出的交换页面（swap page）数量。</li></ul><h4 id="sar监控负载"><a href="#sar监控负载" class="headerlink" title="sar监控负载"></a>sar监控负载</h4><p>使用示例，<strong>查看平均负载</strong>：</p><pre><code>~$ sar -q 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时36分24秒   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15   blocked21时36分26秒         1      8321      0.92      0.71      0.72         021时36分28秒         0      8321      0.92      0.71      0.72         021时36分30秒         1      8322      0.92      0.71      0.72         0Average:            1      8321      0.92      0.71      0.72         0</code></pre><ul><li>unq-sz：运行队列的长度（等待运行的进程数）</li><li>plist-sz：进程列表中进程（processes）和线程（threads）的数量</li><li>ldavg-1：最后1分钟的系统平均负载</li><li>ldavg-5：过去5分钟的系统平均负载</li><li>ldavg-15：过去15分钟的系统平均负载</li></ul><h4 id="sar监控I-O"><a href="#sar监控I-O" class="headerlink" title="sar监控I/O"></a>sar监控I/O</h4><p>使用示例，<strong>显示缓冲区使用情况</strong>:</p><pre><code>~$ sar -b 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时40分00秒       tps      rtps      wtps   bread/s   bwrtn/s21时40分02秒     18.50      0.00     18.50      0.00    288.0021时40分04秒     15.50      0.00     15.50      0.00    240.0021时40分06秒      5.50      0.00      5.50      0.00     44.00Average:        13.17      0.00     13.17      0.00    190.67</code></pre><ul><li>tps：每秒钟物理设备的 I/O 传输总量。</li><li>rtps：每秒钟从物理设备读入的数据总量。</li><li>wtps：每秒钟向物理设备写入的数据总量。</li><li>bread/s：每秒钟从物理设备读入的数据量，单位为 块/s。</li><li>bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s。</li></ul><p>使用示例，<strong>监控设备使用情况</strong>:</p><pre><code>~$ sar -d 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时50分47秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分49秒    dev8-0     17.50      0.00    868.00     49.60      0.71     40.57      6.17     10.8021时50分49秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分51秒    dev8-0      5.00      0.00     40.00      8.00      0.02      3.60      3.60      1.8021时50分51秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分53秒    dev8-0     53.50      0.00    800.00     14.95      4.70     87.89      3.03     16.20Average:          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %utilAverage:       dev8-0     25.33      0.00    569.33     22.47      1.81     71.45      3.79      9.60</code></pre><ul><li>tps:每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。</li><li>rd_sec/s:每秒读扇区的次数。</li><li>wr_sec/s:每秒写扇区的次数。</li><li>avgrq-sz:平均每次设备 I/O 操作的数据大小(扇区)。</li><li>avgqu-sz:磁盘请求队列的平均长度。</li><li>await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1 秒=1000 毫秒)。</li><li>svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间。</li><li>%util:I/O 请求占 CPU 的百分比,比率越大,说明越饱和。</li><li>avgqu-sz 的值较低时，设备的利用率较高。当%util 的值接近 1% 时，表示设备带宽已经占满。</li><li>await-svctm=io等待时间。</li></ul><h4 id="sar总结"><a href="#sar总结" class="headerlink" title="sar总结"></a>sar总结</h4><p>sar可监控的太多了，这里做个总结。</p><ul><li>要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来</li><li>怀疑 CPU 存在瓶颈，可用 sar -u 和 sar -q 等来查看</li><li>怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看</li><li>怀疑 I/O 存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看</li></ul><h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><p> iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。</p><p> 命令格式：</p><pre><code> iostat[参数][时间][次数]</code></pre><p> 命令参数：</p><pre><code> -C 显示CPU使用情况-d 显示磁盘使用情况-k 以 KB 为单位显示-m 以 M 为单位显示-N 显示磁盘阵列(LVM) 信息-n 显示NFS 使用情况-p[磁盘] 显示磁盘和分区的情况-t 显示终端和CPU的信息-x 显示详细信息-V 显示版本信息</code></pre><h4 id="显示所有磁盘分区的情况"><a href="#显示所有磁盘分区的情况" class="headerlink" title="显示所有磁盘分区的情况"></a>显示所有磁盘分区的情况</h4><pre><code>~$ iostat -xLinux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           2.56    0.01    2.38    0.17    0.00   94.88Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilsda               0.10     6.61    0.61    8.95     6.79   169.04    36.80     0.04    4.44   10.29    4.04   3.64   3.47</code></pre><p> 参数说明:</p><ul><li>rrqm/s：每秒进行 merge 的读操作数目，即 delta(rmerge)/s 。<ul><li>wrqm/s：每秒进行 merge 的写操作数目，即 delta(wmerge)/s 。</li><li>r/s：每秒完成的读 I/O 设备次数，即 delta(rio)/s 。</li><li>w/s： 每秒完成的写 I/O 设备次数，即 delta(wio)/s 。</li><li>rsec/s：每秒读扇区数，即 delta(rsect)/s。</li><li>wsec/s：每秒写扇区数，即 delta(wsect)/s</li><li>rkB/s：每秒读 K 字节数，是 rsect/s 的一半，因为每扇区大小为 512 字节。</li><li>wkB/s：每秒写 K 字节数，是 wsect/s 的一半</li><li>avgrq-sz：平均每次设备 I/O 操作的数据大小 (扇区)，即delta(rsect+wsect)/delta(rio+wio) 。</li><li><strong>avgqu-sz</strong>：平均 I/O 队列长度，即 delta(aveq)/s/1000 (因为 aveq 的单位为毫秒)。</li><li><strong>Await</strong>： 平均每次设备 I/O 操作的等待时间 (毫秒)， 即 delta(ruse+wuse)/delta(rio+wio) 。</li><li><strong>Svctm</strong>：平均每次设备 I/O 操作的服务时间 (毫秒)，即delta(use)/delta(rio+wio) </li><li>%util：一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为 use 的单位为毫秒) 。</li></ul></li></ul><h4 id="显示所有设备负载情况"><a href="#显示所有设备负载情况" class="headerlink" title="显示所有设备负载情况"></a>显示所有设备负载情况</h4><pre><code> ~$ iostatLinux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           2.56    0.01    2.38    0.17    0.00   94.88Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               9.55         6.79       169.04  391806012 9758159776</code></pre><p> 参数说明：</p><ul><li>%user：CPU处在用户模式下的时间百分比。</li><li>%nice：CPU处在带NICE值的用户模式下的时间百分比。</li><li>%system：CPU处在系统模式下的时间百分比。</li><li>%iowait：CPU等待输入输出完成时间的百分比。</li><li>%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</li><li><p>%idle：CPU空闲时间百分比。</p><p><strong>注</strong>：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p></li><li><p>tps：每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。<strong>磁盘的一次读或者写都是一次 I/O 操作</strong></p></li><li>Blk_read/s：每秒读取的数据块数。</li><li>Blk_wrtn/s ：每秒写入的数据块数。</li><li>Blk_read：读取的所有块数。</li><li>Blk_wrtn ：写入的所有块数。</li></ul><h3 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h3><p>netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。</p><p>如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。</p><p>命令格式：</p><pre><code>netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][--ip]</code></pre><p>命令参数：</p><pre><code>-a或–all 显示所有连线中的Socket。-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。-c或–continuous 持续列出网络状态。-C或–cache 显示路由器配置的快取信息。-e或–extend 显示网络其他相关信息。-F或–fib 显示FIB。-g或–groups 显示多重广播功能群组组员名单。-h或–help 在线帮助。-i或–interfaces 显示网络界面信息表单。-l或–listening 显示监控中的服务器的Socket。-M或–masquerade 显示伪装的网络连线。-n或–numeric 直接使用IP地址，而不通过域名服务器。-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。-o或–timers 显示计时器。-p或–programs 显示正在使用Socket的程序识别码和程序名称。-r或–route 显示Routing Table。-s或–statistice 显示网络工作信息统计表。-t或–tcp 显示TCP传输协议的连线状况。-u或–udp 显示UDP传输协议的连线状况。-v或–verbose 显示指令执行过程。-V或–version 显示版本信息。-w或–raw 显示RAW传输协议的连线状况。-x或–unix 此参数的效果和指定”-A unix”参数相同。–ip或–inet 此参数的效果和指定”-A inet”参数相同。</code></pre><p>常用的有两个：<code>netstat -plnt</code>和<code>netstat -i</code>.</p><pre><code>~$ netstat -iKernel Interface tableIface   MTU Met   RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeth1       1500 0  26920306700      0 26842853 0      23410550297      0      0      0 BMRUlo        16436 0  9819751923      0      0 0      9819751923      0      0      0 LRU</code></pre><p>字段说明:</p><ul><li>Iface：表示网络设备的接口名称。</li><li>MTU：表示最大传输单元，单位为字节。</li><li>RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。</li><li>RX-ERR/TX-ERR：表示接收/发送数据包时候产生了多少错误。</li><li>RX-DRP/TX-DRP：表示接收/发送数据包时候丢弃了多少数据包。</li><li>RX-OVR/TX-OVR：表示由于误差而丢失了多少数据包。</li><li>Flg 表示接口标记，其中<ul><li>B 已经设置了一个广播地址。</li><li>L 该接口是一个回送设备。</li><li>M 接收所有数据包（混乱模式） 。</li><li>N 避免跟踪。</li><li>O 在该接口上，禁用 AR P。</li><li>P 这是一个点到点链接。</li><li>R 接口正在运行。</li><li>U 接口处于“活动”状态。</li></ul></li><li>其中 RX-ERR/TX-ERR、 RX-DRP/TX-DRP 和 RX-OVR/TX-OVR 的值应该都为 0，如果不为 0，并且很大，那么网络质量肯定有问题，网络传输性能也一代会下降。</li></ul><pre><code>$  netstat -plnt(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 0.0.0.0:2281            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:18889           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:27017           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:30090           0.0.0.0:*               LISTEN      -               tcp        0      0 10.0.0.114:22122        0.0.0.0:*               LISTEN      -               tcp        0      0 10.0.0.114:22123        0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:1099            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:6379            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:9100            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:30060           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:6380            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:48781           0.0.0.0:*               LISTEN      -       </code></pre><p>字段说明：</p><ul><li>Proto ：协议</li><li>Recv-Q：表示接收队列。</li><li>Send-Q ：表示发送队列。</li><li>LocalAddress ：表示本地机器名、端口</li><li>Foreign Address ：表示远程机器名、端口</li><li>State：表示状态，其中:<ul><li>LISTEN ：在监听状态中。</li><li>ESTABLISHED：已建立联机的联机情况。</li><li>TIME_WAIT：该联机在目前已经是等待的状态。</li></ul></li><li>PID/Program name:进程id/进程名</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Linux的性能分析工具非常多，这里只是总结了冰山一角，也是参考了很多优秀的博文:</p><ul><li><a href="https://cloud.tencent.com/developer/article/1004358" target="_blank" rel="noopener">Linux 性能监控 ： CPU 、Memory 、 IO 、Network</a></li><li><a href="https://www.jianshu.com/p/9e571b2b4971" target="_blank" rel="noopener">linux 服务器性能监控</a></li><li><a href="https://www.cnblogs.com/peida/archive/2012/12/05/2803591.html" target="_blank" rel="noopener">每天一个linux命令</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上周五公司搞了双十一“大促”，虽然时间紧凑，还是引起了团队上下高度重视，在有限的两天时间里，进行了充分的压测和性能分析，最终的结果也是不错的。对于性能分析工具，又做了一次熟悉的过程，这里结合网上优秀博文做了下整理。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://www.chenruiwen.cn/categories/Linux/"/>
    
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/tags/architecture/"/>
    
      <category term="Linux" scheme="https://www.chenruiwen.cn/tags/Linux/"/>
    
      <category term="performance analysis" scheme="https://www.chenruiwen.cn/tags/performance-analysis/"/>
    
  </entry>
  
  <entry>
    <title>记一次jedis连接异常引发的血案</title>
    <link href="https://www.chenruiwen.cn/redis/JedisPool-optimize-record/"/>
    <id>https://www.chenruiwen.cn/redis/JedisPool-optimize-record/</id>
    <published>2018-11-09T15:14:51.000Z</published>
    <updated>2018-11-09T15:48:46.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>每年双十一，各个互联网企业都会搞一些活动来促销自己公司产品，然而今年对于互联网金融领域的企业来说，可能并不好过，本以为今年公司不搞活动了，然而11月7号被告知11月9号上午发售一批双十一产品搞活动，这对于我们技术人员来说即兴奋又担忧，兴奋的是遇到这种类似秒杀场景的机会不多，担忧的是害怕网站会挂掉，而且留给我们的时间只有两天。</p><a id="more"></a><p>去年花了一段时间优化了我们网站，从架构层面到代码层面，也做了充分的全链路压测，花费了不少心思。(然而去年，并没有搞活动。)总之，我们还是对我们的代码有信心。</p><p>虽说如此，我们还是做了2天的全链路压测，压测数据单机qps大概能达到400+，能撑住五分钟左右然后系统性能下降，但是一分钟后qps又能上来，系统并没有挂掉，说明我们的系统还可以，又增加了自信。</p><p>今天上午9点早早到达公司，打开各种监控和日志，实施观察以便处理意外情况。果不其然，产品销售很快，门槛低的产品基本一分钟内卖完，90%的产品八分钟内卖完。我们的系统抗住压力。</p><p>app端请求数:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27hcac7fj20hq061dfx.jpg" alt=""></p><p>app端购买请求数：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27hmjt3mj20hs06sdfx.jpg" alt=""></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>然而还是出现了一些问题。运维的同学反馈，基于redis统计并发在线人数有些不正常，有一个突然间的峰值：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx273xbknaj21di0qm0x3.jpg" alt=""></p><p>老大反馈了一些问题：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27307uojj21cy0l4acm.jpg" alt=""></p><p>总之问题是：</p><ul><li>登录后，PC端在产品可购买的瞬间大量用户登出系统了。</li><li>购买后反馈结果慢。(这个问题老问题了，原因是对接杭州那边系统反应慢。)</li></ul><h2 id="排查问题"><a href="#排查问题" class="headerlink" title="排查问题"></a>排查问题</h2><p>我们主要是排查为什么大量用户登出？</p><p>开始以为是cookie被删除的原因，但是大量用户登出还是有些不正常，我们的服务监控也没有报警，一度觉得很诧异，总之还是先查日志吧，万一日志确实没有报警呢？</p><p>还真是。Dubbo报错：调用用户服务线程池满了，达到上限200，之后的请求全部拒绝了:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27esr9iwj21a605ywez.jpg" alt=""></p><p>到底什么导致了Dubbo线程池满了？接着看日志找到了具体的报错信息:</p><pre><code>Caused by: java.util.NoSuchElementException: Timeout waiting for idle object    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449)    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)    at redis.clients.util.Pool.getResource(Pool.java:49)    ... 16 moreException in thread &quot;pool-4-thread-4074&quot; org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:198)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:345)    at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:129)    at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:92)    at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:79)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:191)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:166)    at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:88)    at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169)    at com.gemantic.wealth.test.controller.RedisController$1.run(RedisController.java:40)    at com.gemantic.wealth.test.controller.MyRunnable.run(RedisController.java:84)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    at java.lang.Thread.run(Thread.java:745)Caused by: redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool    at redis.clients.util.Pool.getResource(Pool.java:51)    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:99)    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:12)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:191)    ... 13 moreCaused by: java.util.NoSuchElementException: Timeout waiting for idle object    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449)    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)    at redis.clients.util.Pool.getResource(Pool.java:49)    ... 16 more</code></pre><p>那么问题就比较明朗了：</p><ul><li>jedis获取资源时等待超时，连接不上报错。</li></ul><p>看了下生产的redis配置：</p><pre><code>spring.redis:    database: 1    host: redis    port: 6379    password:    pool:      max-wait: 3000      max-idle: 20</code></pre><p>问题可能是出在这里，大胆猜测一下：由于没有配置jedisPool的maxTotal，默认连接数为8，当并发数上来时，大量请求过来导致大部分的连接不上redis而直接抛异常了。</p><p>Google了一下，也有我们这种情况的先例，但还是先测试一下：200个并发请求往redis中插入数据，jedis配置与生产一致的情况，发现稳定浮现错误信息。</p><p>对比测试，修改测试用例的jedis配置，大致，最大连接数改为100后测试，发现报错少了90%。那么应该就是这个问题了。</p><p>解决生产问题，修改redis配置:</p><pre><code>spring.redis:    database: 1    host: redis    port: 6379    password:    pool:      max-wait: 500      max-idle: 50      max-active: 50</code></pre><p>解释一下:</p><ul><li>max-wait: 对应连接池连接等待时间，原先是3000毫秒，有些长了，连接不上应该尽早报错不要占用资源。</li><li>max-active：对应<code>JedisPoolConfig</code>的maxTotal，最大连接数，主要改的就是这个。</li><li>max-idle：最大空闲连接数，保持与maxTotal一致，避免连接池伸缩带来的性能干扰。</li></ul><p>以上设置参考了<a href="https://yq.aliyun.com/articles/236383?spm=5176.8091938.0.0.qVO71y" target="_blank" rel="noopener">JedisPool资源池优化</a>。</p><p>最后附一下JedisPoolConfig关键配置，也是参考以上博客哈：</p><table><thead><tr><th>参数名</th><th>含义</th><th>默认值</th><th>使用建议</th></tr></thead><tbody><tr><td>maxTotal</td><td>资源池中最大连接数</td><td>8</td><td>不能太大，连接太多占用客户端和服务器的资源，建议50</td></tr><tr><td>maxIdle</td><td>资源池允许最大空闲的连接数</td><td>8</td><td>与maxTotal一致</td></tr><tr><td>minIdle</td><td>资源池确保最少空闲的连接数</td><td>0</td><td>根据业务，可设置少量</td></tr><tr><td>blockWhenExhausted</td><td>当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效</td><td>true</td><td>建议默认值</td></tr><tr><td>maxWaitMillis</td><td>当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)</td><td>-1 : 表示永不超时</td><td>不建议默认值，我们是500</td></tr><tr><td>testOnBorrow</td><td>向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td>false</td><td>业务量很大时候建议设置为false(多一次ping的开销)。</td></tr><tr><td>testOnReturn</td><td>向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td>false</td><td>业务量很大时候建议设置为false(多一次ping的开销)。</td></tr><tr><td>jmxEnabled</td><td>是否开启jmx监控，可用于监控</td><td>true</td><td>建议开启，但应用本身也要开启</td></tr><tr><td>testWhileIdle</td><td>是否开启空闲资源监测</td><td>false</td><td>true</td></tr><tr><td>timeBetweenEvictionRunsMillis</td><td>空闲资源的检测周期(单位为毫秒)</td><td>-1：不检测</td><td>建议设置，周期自行选择，也可以默认也可以使用下面JedisPoolConfig中的配置</td></tr><tr><td>minEvictableIdleTimeMillis</td><td>资源池中资源最小空闲时间(单位为毫秒)，达到此值后空闲资源将被移除</td><td>1000<em>60</em>30 = 30 min</td><td>可根据自身业务决定，大部分默认值即可，也可以考虑使用下面JeidsPoolConfig中的配置</td></tr><tr><td>numTestsPerEvictionRun</td><td>做空闲资源检测时，每次的采样数</td><td>3</td><td>可根据自身应用连接数进行微调,如果设置为-1，就是对所有连接做空闲监测</td></tr></tbody></table><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>这次的问题属于客户端设置参数的问题，还是要检查一下各个服务的配置为好。</p><p>解决了这个问题，根据监控发现还有更多可优化的地方，其次，我们的这次监控没有加上Jedis的异常报错，监控还有待提高，不过我们以及在测试环境上接上了点评的<a href="https://github.com/dianping/cat" target="_blank" rel="noopener">CAT</a>,非常好用，踩完坑后准备接到生产。</p><p>最后感慨一下解决问题真的很有快感。更感谢帮助我解决问题的这些参考的博文:</p><ul><li><a href="https://blog.csdn.net/qq_39954022/article/details/78488935" target="_blank" rel="noopener">Jedis常见异常汇总</a></li><li><a href="https://yq.aliyun.com/articles/236383?spm=5176.8091938.0.0.qVO71y" target="_blank" rel="noopener">JedisPool资源池优化</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;每年双十一，各个互联网企业都会搞一些活动来促销自己公司产品，然而今年对于互联网金融领域的企业来说，可能并不好过，本以为今年公司不搞活动了，然而11月7号被告知11月9号上午发售一批双十一产品搞活动，这对于我们技术人员来说即兴奋又担忧，兴奋的是遇到这种类似秒杀场景的机会不多，担忧的是害怕网站会挂掉，而且留给我们的时间只有两天。&lt;/p&gt;
    
    </summary>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/categories/redis/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(六)：线程池那些事儿</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-ThreadPoolExecutor/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-ThreadPoolExecutor/</id>
    <published>2018-10-28T10:23:51.000Z</published>
    <updated>2018-10-30T13:30:59.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>创建一个线程，最简单的做法是<code>new</code>一个线程，但是当大量请求过来时(类比窗口卖票的场景)，创建这么多个线程的开销就很大了。今天整理下线程池相关知识，相对于传统做法，线程池的优势还是很明显的：<strong>节省了创建和销毁线程的时间，提高了任务执行效率，也就增加了CPU的吞吐能力</strong><a id="more"></a></p><h2 id="线程池的优势"><a href="#线程池的优势" class="headerlink" title="线程池的优势"></a>线程池的优势</h2><p>引用一下方腾飞的话，合理利用线程池能够带来三个好处。</p><ul><li><strong>降低资源消耗</strong>。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li><strong>提高响应速度</strong>。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li><li><strong>提高线程的可管理性</strong>。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。但是要做到合理的利用线程池，必须对其原理了如指掌。</li></ul><h2 id="Executors中的线程池"><a href="#Executors中的线程池" class="headerlink" title="Executors中的线程池"></a>Executors中的线程池</h2><p>j.u.c的Executors中默认提供了一些方便的线程池创建:</p><table><thead><tr><th>静态方法</th><th>线程池类型</th><th>说明</th><th>返回值的实际实现</th></tr></thead><tbody><tr><td>newCachedThreadPool()</td><td>可缓存的线程池</td><td>如果线程池的大小超过了处理任务所需要的线程,那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。</td><td>ThreadPoolExecutor</td></tr><tr><td>newFixedThreadPool(int)</td><td>固定线程池</td><td>每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。</td><td>ThreadPoolExecutor</td></tr><tr><td>newScheduledThreadPool(int)</td><td>定时及周期性线程池</td><td>此线程池支持定时以及周期性执行任务的需求。</td><td>ScheduledThreadPoolExecutor</td></tr><tr><td>newSingleThreadExecutor()</td><td>单线程的线程池</td><td>这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。</td><td>FinalizableDelegatedExecutorService</td></tr></tbody></table><h3 id="线程池的使用"><a href="#线程池的使用" class="headerlink" title="线程池的使用"></a>线程池的使用</h3><pre><code class="java">public static void main(String[] args) {    //ExecutorService pool = Executors. newSingleThreadExecutor();    //ExecutorService pool = Executors.newFixedThreadPool(2);    ExecutorService pool = Executors.newCachedThreadPool();    for (int i = 0; i &lt; 5; i++) {        pool.execute(() -&gt; System.out.println(Thread.currentThread().getName() + &quot;正在执行...&quot;));    }    pool.shutdown();}</code></pre><p>如上述测试程序，如果<code>ExecutorService</code>的实现pool是<code>newSingleThreadExecutor</code>的时，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...</code></pre><p>如果<code>ExecutorService</code>的实现pool是<code>newFixedThreadPool</code>的时，参数设置大小为2，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-2正在执行...pool-1-thread-1正在执行...pool-1-thread-2正在执行...pool-1-thread-1正在执行...</code></pre><p>如果<code>ExecutorService</code>的实现pool是<code>newCachedThreadPool</code>的时，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-3正在执行...pool-1-thread-2正在执行...pool-1-thread-4正在执行...pool-1-thread-5正在执行...</code></pre><p>如果是<code>newScheduledThreadPool</code>，则使用方法有些不同:</p><pre><code class="java">public static void main(String[] args) {    ScheduledExecutorService exec = Executors.newScheduledThreadPool(2); // 创建一个可定时的线程池    // 每2秒打印一次    exec.scheduleAtFixedRate(() -&gt; System.out.println(System.currentTimeMillis() / 1000), 1, 2, TimeUnit.SECONDS);    // 线程池中某个线程出错    exec.scheduleAtFixedRate(() -&gt; {        System.out.println(&quot;池中一个线程出错了！&quot;);        throw new RuntimeException();    }, 1, 2, TimeUnit.SECONDS);}</code></pre><p>上述程序输出如下,可见池中的线程是隔离的</p><pre><code>1540794708池中一个线程出错了！154079471015407947121540794714</code></pre><h2 id="核心ThreadPoolExecutor"><a href="#核心ThreadPoolExecutor" class="headerlink" title="核心ThreadPoolExecutor"></a>核心ThreadPoolExecutor</h2><p>无论你从上诉任何一种静态方法进去，其最终都是离不开这个类:<code>ThreadPoolExecutor</code></p><p>构造器：</p><pre><code class="java">public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler)</code></pre><p>解释一下这几个参数:</p><ol><li><code>corePoolSize</code>(核心线程池大小):当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的<code>prestartAllCoreThreads</code>方法，线程池会提前创建并启动所有基本线程。</li><li><code>maximumPoolSize</code>(线程池最大大小，其值=核心线程数+其他线程数):线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。</li><li><code>keepAliveTime</code>(线程活动保持时间):线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率。</li><li><code>TimeUnit</code>(线程活动保持时间的单位)：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。</li><li><code>workQueue</code>(任务队列):用于保存等待执行的任务的阻塞队列。关于阻塞队列，可参考之前写的<a href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-BlockingQueue/">浅析java并发包(三)：阻塞队列(BlockingQueue)</a></li><li><code>threadFactory</code>(线程工厂):用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字，Debug和定位问题时非常又帮助。</li><li><code>RejectedExecutionHandler</code>(饱和策略):当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略：<ul><li>AbortPolicy：中止策略，默认。直接抛出异常。</li><li>CallerRunsPolicy：“调用者运行”策略，任务回退到调用者，从而降低了新任务的流量，只用调用者所在线程来运行任务。</li><li>DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。</li><li>DiscardPolicy：不处理，丢弃掉。</li><li>第五种，通过实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。</li></ul></li></ol><h2 id="线程池运行流程"><a href="#线程池运行流程" class="headerlink" title="线程池运行流程"></a>线程池运行流程</h2><p>一图胜前言，直接引用来自方腾飞《聊聊并发》：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwpdng64j1j20dw0850t4.jpg" alt=""></p><p>图码结合，从线程池的执行方法<code>ThreadPoolExecutor.execute</code>分析。分3种，我在代码里用注释标出</p><pre><code class="java">public void execute(Runnable command) {    if (command == null)        throw new NullPointerException();    int c = ctl.get();// 获取线程数    // 1.如果线程数小于核心线程数，则addWorker创建线程执行任务    if (workerCountOf(c) &lt; corePoolSize) {        if (addWorker(command, true))            return;        c = ctl.get();    }    // 2.线程是否RUNNING状态且尝试加入队列    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {        int recheck = ctl.get();        //再检查， 任务队列不在运行且从队列中删除，执行拒绝策略        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        // 运行任务数量为0，则移除核心线程外的线程        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    }    // 3.非RUNNING状态或者加入队列失败，尝试创建非核心线程直到maxPoolSize，如果失败则执行拒绝策略    else if (!addWorker(command, false))        reject(command);}</code></pre><h2 id="配置线程池"><a href="#配置线程池" class="headerlink" title="配置线程池"></a>配置线程池</h2><p>知道了线程池的参数和运行规则，那么如何配置线程池呢?</p><p>一. <strong>线程池的大小</strong>。主要是根据任务类型：计算密集型 or I/O密集型 or 二者皆可？</p><p>计算密集型的任务，通常情况线程池大小=Ncpu+1最优；</p><p>I/O密集型任务，由于线程不会一直执行，通常设置为Ncpu*2。</p><p>混合型，最好因地制宜，拆分为CPU密集型和I/O密集型处理。</p><p>一个通用公式:</p><pre><code>Ncpu:cpu的个数Ucpu:使用cpu的个数W/C:计算时间等待率Nthreads=Ncpu * Ucpu * (1 + W/C)</code></pre><p>二. <strong>阻塞队列的选择</strong>。主要分为3种，有界队列、无界队列、同步移交。</p><p>有界队列有助于避免资源耗尽，大部分情况比较适合。使用有界队列时，队列大小与线程池大小必须一起调节。当线程池较小而队列较大时，有助于减少内存使用量，降低CPU使用率，同时减少上下文切换，但代价是可能会限制吞吐量。</p><p>无界队列可以通过使用SynchronousQueue来避免排队。只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值。</p><p>三.<strong>关于ThreadPoolExecutor的扩展性</strong>。它提供了几个可以在子类改写的方法:<code>beforeExecute</code>,<code>afterExecute</code>,<code>terminated</code>。可以利用这些方法在线程执行前、后、以及销毁时做一些特别操作，比如添加日志、计时、监控、收集统计信息等功能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要参考了：</p><ul><li><a href="https://www.oschina.net/question/565065_86540" target="_blank" rel="noopener">java自带线程池和队列详细讲解</a></li><li><a href="http://ifeve.com/java-threadpool/" target="_blank" rel="noopener">聊聊并发（三）Java线程池的分析和使用</a></li><li>java并发编程实战</li></ul><p>对这些优秀博文书籍进行了一次聚合总结吧，感谢原作者。同时，对java线程池也更加的了解一些。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;创建一个线程，最简单的做法是&lt;code&gt;new&lt;/code&gt;一个线程，但是当大量请求过来时(类比窗口卖票的场景)，
创建这么多个线程的开销就很大了。
今天整理下线程池相关知识，相对于传统做法，线程池的优势还是很明显的：
&lt;strong&gt;节省了创建和销毁线程的时间，提高了任务执行效率，也就增加了CPU的吞吐能力&lt;/strong&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>巴厘岛旅行记</title>
    <link href="https://www.chenruiwen.cn/travel/traveling-all-around-Bali/"/>
    <id>https://www.chenruiwen.cn/travel/traveling-all-around-Bali/</id>
    <published>2018-10-24T15:40:24.000Z</published>
    <updated>2018-10-28T12:23:43.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>过了一个漫长的假期，国庆节七天加上婚假十天，过的都不会上班了。蜜月之行的计划本来打算是去欧洲看看的，但是听说基本都是玩十二天左右，时间太长会很累，其次由于我们第一次出国，很多事情不是很懂，所以跟了个10.09-10.15的七天五晚的旅行团(有出国经验的话建议自由行)，遂主要记录在巴厘岛这几天的行程与游记。<a id="more"></a></p><h2 id="行前准备"><a href="#行前准备" class="headerlink" title="行前准备"></a>行前准备</h2><p>必备：  </p><ul><li>护照</li><li>机票(去机场取，我们坐的从北京直飞登巴萨的东方航空，座位可以从网上提前预约好)</li><li>钱。推荐带美元+印尼盾的组合，各提前准备好。(是可以从当地货币兑换点兑换，但是比较亏。最好提前准备好。)</li><li>打电话与流量(可以直接从支付宝搜索“境外上网”，我们是移动的用户，价格是移动的一半，办了五天流量价格54元。)</li><li>防晒霜(我们是提前在首都机场DFS买好的安耐晒，非常便宜，建议多买)</li><li>户外常用app：google地图，大众点评/飞猪等</li></ul><p>补充一些非必须但是有必要带的物品：</p><ul><li>沙滩裤(毕竟是要沾水的，速干的裤子比较好，巴厘岛那边比较潮湿，棉的衣物在宾馆不容易干)</li><li>泳衣泳裤(不解释)</li><li>拖鞋(不解释，基本告别要穿袜子的鞋)</li><li>沙滩鞋(有些地方比拖鞋好用)</li><li>花露水(防蚊)</li><li>手机防水袋(一些喜欢拍照的朋友请准备好)</li></ul><h2 id="具体行程记录"><a href="#具体行程记录" class="headerlink" title="具体行程记录"></a>具体行程记录</h2><p>行程简记：<br><strong>day0</strong> 首都机场飞到巴厘岛(人家原名叫登巴萨) -&gt; uluwatu的酒店<br><strong>day1</strong> uluwatu的酒店 -&gt; 情人崖 -&gt; 海龟岛 -&gt; 金巴兰海滩 -&gt; uluwatu的酒店<br><strong>day2</strong> uluwatu的酒店 -&gt; 蓝梦岛 -&gt; spa -&gt;  kuta的酒店<br><strong>day3</strong> kuta的酒店 -&gt; 漂流 -&gt; 大秋千 -&gt; 家乐福购物 -&gt; kuta的酒店<br><strong>day4</strong> kuta的酒店 -&gt; kuta沙滩 -&gt; DFS Bali T Galleria -&gt; spa again~ -&gt; kuta的酒店<br><strong>day5</strong> kuta的酒店 -&gt; 海神庙 -&gt; 乌布皇宫，乌布市场 -&gt; 下午茶 -&gt; 洋人街 -&gt; 机场<br><strong>day6</strong> 飞回首都机场</p><h3 id="day0"><a href="#day0" class="headerlink" title="day0"></a>day0</h3><p>由于是4点半的飞机，我们中午就到了首都机场，先是在机场吃了饭(机场的饭价格不用说，一定会贵，但是感谢上帝，这里的全家便利店跟其他地区一样)。然后我们就直接取机票和登机牌，然后办理托运，开开心心去首都机场的DFS了(帮人代购真累:D)。</p><p>4点半飞机起飞，好久没坐过飞机了，再加上第一次出国，着实有些小兴奋。乘坐的是东方航空，之前还担心东方航空的环境不好，其实还可以。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwb884twazj20u01hcthc.jpg" alt="">壮哉我大蚌埠:D，“新中国四大城市”</p><p>飞行七个小时整，晚上11:45到达巴厘岛，巴厘岛与北京没有时差。第一次办理入境，我的方法是，跟着人群走总是对的。好在大部分人是对的。护照盖章和取完托运的行李后便顺利入境了。</p><p>出去后先是找到导游，本来准备在机场办理一张当地的电话卡的，但是很不划算(比首都机场办卡和中国移动还贵)，后来比对了中国移动推出的无忧行app和支付宝的“境外上网”，价格相同，54RMB五天流量不限，所以就采用了支付宝的解决方案。</p><p>与我们一起同行的也是两对来度蜜月的情侣，都是北京本地人，人都很nice，很好相处，社交属性都很max的感觉:D。我们一行人在导游的导航下开了很久，到达离机场比较远的乌鲁瓦图(uluwatu)的酒店——Hillstone Uluwatu Villa。然后洗洗就睡了。</p><p>槽点：住宿虽是独立别墅，并没有想象中的好，唯一的亮点是院内的泳池，其他设施感觉很一般。</p><h3 id="day1"><a href="#day1" class="headerlink" title="day1"></a>day1</h3><p>早上睡到8点就自然醒了，收拾好后，床头放了5RMB的小费(这是必须的，这边的服务都是要收小费的，给大概5~10RMB小费就足够了)。早饭是吃的酒店的自助餐，味道一般，没有国内吃的习惯就是了。</p><p>11点出发去了情人崖。据说那里的小猴子很调皮，会抢游客的东西，如果被抢了东西，需要找当地的人帮忙，大概就是那种一物换一物的样子，也可能换不回来。所以，保护好自己的钱财啊，拍照的时候手机拿紧了。可能因为我们是中午到了，猴子们都比较懒洋洋的。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwb9686np9j23402c0qv7.jpg" alt="">情人崖</p><p>中午的午饭是在黄金咖啡工厂旁边的娘惹私房菜解决，饭馆里面基本都是中国人，问了导游，说本地人在饭店吃饭的很少。关于菜呢，做的虾不错，别的菜就可圈可点了，咖喱味确实吃不习惯。</p><p>我们没有在黄金工厂逗留，听导游说黄金工厂的猫屎咖啡100g大概800块钱(后来对这个导游所言及其不信任，此价格可信度不足5成)。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbh3q7rbej211a0sctd9.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbh408x0jj22c0340npf.jpg" alt="">娘惹私房菜</p><p>然后下一站直接去了金巴兰沙滩。路上听导游介绍了这里一个很奇葩的本地文化。印尼这边女性地位很低，男性地位很高，之前法律可以允许一个男人娶四个老婆，而且男人不干粗活，像搬砖砌瓦这种粗活都是女人来做，男人只多做雕刻等工作。路上有许多可供休息的小亭子，叫发呆亭，专门给男人发呆用的…这里的男人太幸福了…</p><p>我们2点左右到达金巴兰沙滩，首先是去玩一些水上项目，比如飞艇，滑翔伞等。滑翔伞没有想象的那么刺激，但是高度确实可以，看风景真的不错。玩过这些后，我们乘船去了海龟岛。海龟岛上最特色的是大量的海龟，被当地人群圈养着…我以为是沙滩上的，可能我还是太年轻。不止有海龟，还有各种鸟，蜥蜴，蟒蛇，大蝙蝠等…这个岛基本就是小型动物园的样子，不过好玩的是船停在岸边很远，因为还没到雨季的原因，我们沿着海边走了很久，一路上抓了不少寄居蟹和海螺。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj47lsqzj22c0340qva.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj36n4i1j22c0340kjn.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj3h9t4qj22c0340u0z.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj3u80eaj22c03401l1.jpg" alt=""></p><p>玩到四五点我们又回到了金巴兰沙滩看日出，嗯，没错，金巴兰海滩——世界十大最美落日海滩之一。直接上图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjn0pcmlj23402c0kjn.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjmm2gtgj22c0340hdv.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjma0f5bj23402c0u0y.jpg" alt=""></p><p>看着日落，吃着烧烤，金巴兰的玉米据说是必吃的，点了一个微辣，实际上也是很辣了，价格7块5RMB，果然景区很贵。这里的烧烤也是出奇的宰人啊，看了菜单，要想吃饱人均至少200+RMB，巴厘岛的人民也不老实啊。烧烤是旅行团提供了，每人一盘，一盘有三只虾，三串鱿鱼，一个螃蟹，一条鱼，啤酒一瓶。(画外音：想念我大中华的烧烤啤酒。)就这价格明显宰人，不能当傻子(怂了)，我们又去便利店看了看当地的人民都吃些什么。嗯，买了泡面和一些零食回去垫垫了…回酒店游了一圈就休息了。</p><h3 id="day2"><a href="#day2" class="headerlink" title="day2"></a>day2</h3><p>这是一个早起的上午，6点半就吃饭了，七点开始出发，今天的目的地是巴厘岛必玩景点之一——蓝梦岛，所以我们坐车先来到Pantai Mertasari，等到八点十几分左右坐上船开往蓝梦岛(Lembongan)。大概坐了四五十分钟左右的船(有点晕船的小伙伴最好准备好口香糖等缓解手段)，来到另一个船上，这个船上先玩一些水上项目，香蕉船，甜甜圈无限玩，玩到过瘾，浮潜，水上跳床等，还有水底漫步，很多热带鱼很好看。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbkenk1d0j215e0vewhl.jpg" alt="">坐船路线</p><p>中文在蓝梦岛又是吃的自助餐，应该是最难吃的一顿饭了，如果不是饿的厉害，我可能得去买泡面了。</p><p>蓝梦岛最著名的景点是梦幻沙滩和恶魔的眼泪。当时我就想如果是自由行就好了，我一定会在蓝梦岛上住一晚，就住在梦幻沙滩这里。梦幻沙滩必须是住在那个酒店才能进去的。在恶魔的眼泪拍照一定要小心，因为我们是在旱季去的，水位不高，我看网上雨季的巴厘岛水位是可能冲上来的，据说每年能卷走一两百个游客。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwcrigz5rnj23402c0kjo.jpg" alt="">梦幻沙滩</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwcri5z4jxj23402c04qu.jpg" alt="">恶魔的眼泪</p><p>看完恶魔的眼泪，下午4点去做了当地的spa，给幸苦的一天画上一个舒服的句号。晚上的酒店是在库塔(kuta)区的 The Kuta Beach Heritage Hotel 酒店，对面就是库塔沙滩，这条街上基本都是酒吧，沙滩、啤酒与乐队，就会突然感觉很有电影里看到的那种氛围。晚上没事干就去酒店四层(顶层，巴厘岛没有什么高楼大厦，基本最高就四五层)大泳池游了一圈(弥补今夏未游泳之遗憾)。</p><h3 id="day3"><a href="#day3" class="headerlink" title="day3"></a>day3</h3><p>今天是自由行的第一天，我们在昨天晚上一起从飞猪上定了今天的行程(阿勇河漂流和悬崖秋千)，于是一大早便起，七点半吃了酒店的自助餐(吐槽一下，来巴厘岛这几天吃的最好吃的一顿)。八点多坐上了包的车，一路上用中午和师傅谈笑风生大约一个半小时左右，来到目的地，阿勇河漂流。不得不说阿勇河真的是适合团队活动，漂流的时间大概在两个小时左右，漂流是一定会全身湿透的(刚下水就湿透了)，所以要准备泳衣。河水并不深，不必担心掉下水溺水，水流有平缓和湍急之处，有的时候皮划艇还会卡在石头上…至于河里有没有蛇就不知道了，反正看到了树枝上有蛇还有蜥蜴…</p><p>午餐是一如既往的难吃，依旧是景点的自助餐。唯一能让我吃下去的就是依靠当地的辣酱了。</p><p>饭后直接去悬崖秋千。路上经过了一些雕刻和沉香店，下车瞧了瞧，由于并不懂行，并没有买。悬崖秋千，确实是有些刺激的(主要是因为司机路上告诉了我们之前都摔下去摔死的，我心里一直担心绳子会断…)。其次，论拍摄技巧的重要性，被老婆好好教育了一顿，惨痛，有时间一定要系统性学习一下拍摄。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9f6pn6ij23402c0e85.jpg" alt="">坐秋千</p><p>玩完之后又让师傅带着去了当地的一个猫屎咖啡工厂，看了猫屎咖啡的生产过程，尝了尝当地各种品种咖啡和饮料(免费的)，猫屎咖啡是需要付费的(25RMB)，而且喝起来感觉怪怪的，加了两袋白糖喝起来还行。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9jx5j4yj23402c04qr.jpg" alt="">十三种免费饮品</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9jju2tfj22c03407wj.jpg" alt="">制作中的猫屎咖啡豆</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9j92w3gj22c0340u0z.jpg" alt="">磨的猫屎豆</p><p>逛完猫屎咖啡工厂，下一站我们的选择是家乐福…总结一下，家乐福中可带的东西有手工香皂，猫屎咖啡(价格不贵)，当地泡面(难道不想和康师傅汤达人一较高低吗)，Max T奶茶(超级好喝)，Olay空气霜(国内价格的三分之一，这个牌子的基本价格都是国内的一半价格一下)，雕刻手工制品，养乐多才5块钱…总之我们满载而归。</p><h3 id="day4"><a href="#day4" class="headerlink" title="day4"></a>day4</h3><p>自由行的第二天，必须睡到自然醒(其实八点多就醒了)。9点吃了超好吃的早饭，和老婆去酒店对面的库塔沙滩走了走。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9vks2fhj23402c0u0z.jpg" alt=""></p><p>天气又好，浪又大，冲浪的人很多，忍不住的我也跃跃欲试，于是人生中第一次冲浪诞生于巴厘岛了。库塔沙滩旁边都是出租冲浪板和教学了，我和同行的游泳爱好者一起冲的，两个人45W印尼盾(大约一个人115RMB)，各有一个教练带着。tips，切记不要刚吃完饭去冲浪，会吐的。总的来说，冲浪真的是很爽就是了(被一浪一浪排在沙滩上)。</p><p>中午，是女人们的专场，巴厘岛当地的DFS。我们打了当地的出租车，号称蓝鸟(Blue Bird)，上车后听见师傅在听布鲁斯，便用我那蹩脚的英文跟司机师傅瞎侃说我也喜欢布鲁斯，我喜欢Jimi Hendrix。司机师傅表示认同，他说他有个自己的乐队，但平时排练比较少等等。。。</p><p>然而，聊的挺愉快，下车的时候就不愉快了。这儿的出租车挺黑的。我从谷歌地图上看司机带我们绕了个大圈，而且就算绕这个大圈，应该也就四五公里不到的路。下册的时候师傅打的表显示160000，合RMB 80块，这是北京的四五倍价格了。(回去的时候我们问了当地七座的私人车，五个人25就回去了。)</p><p>其次，到了目的地也没想象的那么愉快，因为这里的DFS比国内的贵，一件东西没买上。然后又去了家乐福，还是家乐福好啊，把昨天没上的东西再看看咯。</p><p>晚上又想去spa了，这里的spa毕竟很便宜。从大众点评上(巴厘岛大众点评是可以用的)看了离我们最近的有一个五星好评的“哈巴狗spa”，于是我们一路沿着酒吧街走过去，直到到达目的地后着实让我们失望了，原来是小作坊:)。由于这家spa位置有限以及时间原因问题，换了旁边一家小spa点按了一下全身按摩，感觉很一般，没啥手劲，但是我老婆说这家手劲刚好:)。</p><p>遇到一件很酷的事情，在路边的时候，几个老外在酒吧大声合唱起来，一听让人激动，原来是“英国国歌”：Oasis的Don’t Look Back in Anger。让人想到2005年曼城演唱会上的万人大合唱。</p><h3 id="day5"><a href="#day5" class="headerlink" title="day5"></a>day5</h3><p>早上出发的比较早，一大早就去了海神庙。海神庙的海浪很大…<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwij8zix0hj23402c0hdw.jpg" alt="">看不腻的海</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwij9g6btyj23402c0nph.jpg" alt="">浪花与帅男</p><p>中午那会儿又去了乌布皇宫和乌布市场。乌布皇宫，说是皇宫，但是真的好小啊，跟咱故宫比查太远了，没什么意思。有点意思的是乌布市场，这里能淘一些当地的手工工艺品，当然最需要也是最有意思的就是砍价了。(语言采用中西结合的技法，又不缺失肢体语言与计算器这种神奇的辅助，方能砍得合适的价格)。我自己的战利品是尤克里里一把(75RMB价格，真的很便宜了)。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijipl9l1j22c0340b2c.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwiji66q0lj22c0340hdw.jpg" alt="">乌布市场街景(后面还有很大一片)</p><p>中午的午饭吃的是当地有名的脏鸭餐，说实话，味道一般。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijhqn1r5j22c03401kz.jpg" alt="">脏鸭餐(确实是脏，能感受到上面的毛毛)</p><p>我们吃脏鸭餐的旁边就是Monkey Park，我们出门还碰到几个猴兄，给了一袋薯片一下就抢走了。。。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijmh5kp1j22c03407wk.jpg" alt=""></p><p>下午是休闲的下午茶时光(旅行社安排，对于我来说有点浪费时间)，我们来到 Benoa Bay 海湾这里的 Conard Bali酒店吃的下午茶。下午茶平淡无奇，但是这里的住宿是真的比之前住的好(超大泳池，几乎整个花园都是泳池，这里沙滩也好，还有飞艇等娱乐工具)，妈的，要是自己来一定住这里！</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwjpo7vzuhj22c0340b2e.jpg" alt="">康纳德酒店泳池一角</p><p>晚上去了巴厘岛的洋人街，一听名字就知道很宰人，这里的手工制品比乌布市场的贵将近一半左右，以及商场里的一些品牌比国内的贵。洋人街不适合购物，可以选择去对面的库塔沙滩吹吹海风。</p><p>巴厘岛之行基本上就到这了，晚上我们很早就去了机场，大概11点办理完托运等，第一件事就是再去DFS(万恶的化妆品)再看看。最后1点半坐上回帝都的飞机了。再见，巴厘岛(登巴萨)。</p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>在巴厘岛待的时间不长，一共就5天5晚吧，说实话还是想再多玩几天的，还是有些遗憾的，只能暂时先列一下计划了以后再去补上~~：</p><ul><li>看海豚和海上日出</li><li>去火山和温泉</li><li>蓝梦岛住一晚，一定要冲一次梦幻沙滩的浪</li><li>吃一顿猪排饭</li><li>乌布多待两天</li><li>吉利三岛和龙目岛(脱离巴厘岛的范围了:))玩几天</li></ul><p>对巴厘岛印象最深刻的还是这里的交通，路又窄又弯又起伏，这里的摩托车是主要的交通工具，喜欢摩托车的朋友适合在这生活哈~：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwo7f19fx6j22c0340u0y.jpg" alt=""></p><p>最后，还是想说一句：巴厘岛司机牛逼！巴厘岛司机世界第一！</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;过了一个漫长的假期，国庆节七天加上婚假十天，过的都不会上班了。蜜月之行的计划本来打算是去欧洲看看的，但是听说基本都是玩十二天左右，时间太长会很累，其次由于我们第一次出国，很多事情不是很懂，所以跟了个10.09-10.15的七天五晚的旅行团(有出国经验的话建议自由行)，遂主要记录在巴厘岛这几天的行程与游记。
    
    </summary>
    
      <category term="travel" scheme="https://www.chenruiwen.cn/categories/travel/"/>
    
    
      <category term="travel" scheme="https://www.chenruiwen.cn/tags/travel/"/>
    
      <category term="Bali" scheme="https://www.chenruiwen.cn/tags/Bali/"/>
    
  </entry>
  
  <entry>
    <title>《大型网站技术架构》知识总结</title>
    <link href="https://www.chenruiwen.cn/architecture/large-scale-websites-architecture-note/"/>
    <id>https://www.chenruiwen.cn/architecture/large-scale-websites-architecture-note/</id>
    <published>2018-09-23T15:10:24.000Z</published>
    <updated>2018-09-24T13:04:33.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>又把《大型网站技术架构-核心原理与案例分析》看了一遍，之前走马观花看了一遍，没有体会到精髓。现在具备一定“中型”网站开发经验后再看之，又有些体会，故整理一下这本书的内容。<a id="more"></a></p><h2 id="大型网站架构演化"><a href="#大型网站架构演化" class="headerlink" title="大型网站架构演化"></a>大型网站架构演化</h2><h3 id="大型网站软件的特点"><a href="#大型网站软件的特点" class="headerlink" title="大型网站软件的特点"></a>大型网站软件的特点</h3><ul><li>高并发、大流量</li><li>高可用</li><li>海量数据</li><li>用户分布广泛</li><li>安全环境恶劣</li><li>需求变更快，发布频繁</li><li>渐进式发展</li></ul><h3 id="大型网站架构演化发展历程"><a href="#大型网站架构演化发展历程" class="headerlink" title="大型网站架构演化发展历程"></a>大型网站架构演化发展历程</h3><ol><li><strong>初始阶段的网站架构</strong>：all in one，一台服务器，部署了应用程序，数据库，文件，等所有资源。比如经典的<code>LAMP</code>架构。</li><li><strong>应用和数据服务分离</strong>：应用程序，数据库，文件分别用了3台服务器部署。</li><li><strong>使用缓存改善网站性能</strong>：本地缓存+分布式缓存。</li><li><strong>使用应用服务器集群改善网站并发处理能力</strong>：通过负载均衡调度服务器来将访问请求分发到应用服务器集群中的任何一台机器。</li><li><strong>数据库读写分离</strong>：数据库采用主从热备，写数据在主数据库中，主数据库通过主从复制机制将数据更新同步到从数据库。读数据从从库读取。</li><li><strong>使用反向代理和 CDN 加速网站响应</strong>：这两者基本原理都是缓存。CDN 部署在网络提供商的机房，使用户可从离距离自己最近的提供商机房获取数据;反向代理部署在网站的中心机房，减轻后端负载压力，反向代理服务器命中的静态数据可直接返回。</li><li><strong>使用分布式文件系统和分布式数据库系统</strong>：数据库拆分的最后手段，解决单表特别大的情况。</li><li><strong>使用 NoSQL 和搜索引擎</strong>：对可伸缩的分布式有更好的支持。</li><li><strong>业务拆分</strong>：将整个网站业务拆分成不同的应用，每个应用独立部署维护，应用之间通过超链接建立联系/消息队列进行数据分发/访问同一数据存储系统</li><li><strong>分布式服务</strong>：公共业务提取出来独立部署</li></ol><p>大型网站演化到这里，大多数技术问题都得以解决，如图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fvjtco0bevj20r20e2mxf.jpg" alt=""></p><h3 id="大型网站架构演化的价值观"><a href="#大型网站架构演化的价值观" class="headerlink" title="大型网站架构演化的价值观"></a>大型网站架构演化的价值观</h3><ul><li>大型网站架构的核心价值是随网站所需灵活应对</li><li>驱动大型网站技术发展的主要力量是网站的业务发展</li></ul><h3 id="网站架构设计误区"><a href="#网站架构设计误区" class="headerlink" title="网站架构设计误区"></a>网站架构设计误区</h3><ul><li>一味追随大公司的解决方案</li><li>为了技术而技术</li><li>企图用技术解决所有问题</li></ul><h2 id="大型网站架构模式"><a href="#大型网站架构模式" class="headerlink" title="大型网站架构模式"></a>大型网站架构模式</h2><ul><li>分层:计算机世界无处不在，操作系统与硬件，网络七层，网站应用MVC分层。</li><li>分割：按业务分割</li><li>分布式：<ul><li>分布式应用和服务</li><li>分布式静态资源</li><li>分布式数据和存储</li><li>分布式计算</li></ul></li><li>集群</li><li>缓存：<ul><li>CDN</li><li>反向代理</li><li>本地缓存</li><li>分布式缓存</li></ul></li><li>异步：<ul><li>提供系统可用性</li><li>加快网站响应速度</li><li>消除高并发访问高峰</li></ul></li><li>冗余：服务器冗余运行，数据库冗余备份（冷热备份）</li><li>自动化：自动化代码管理；自动化发布；自动化测试；自动化安全检测；自动化部署；自动化监控；自动化报警；自动化失效转移；自动化失效恢复；自动化降级；自动化分配资源。</li><li>安全：防止XSS攻击、sql注入。</li></ul><h2 id="大型网站核心架构要素"><a href="#大型网站核心架构要素" class="headerlink" title="大型网站核心架构要素"></a>大型网站核心架构要素</h2><ul><li>性能<ol><li>浏览器端:浏览器缓存，页面压缩，合理布局页面，减少Cookie传输</li><li>CDN：静态内容分发到离用户最近的网络服务商机房。</li><li>应用服务器：缓存+异步。</li><li>代码层面：多线程+改善内存等手段优化。</li><li>数据库：索引，缓存，SQL优化等。</li></ol></li><li>可用性：只要手段是冗余<ol><li>应用服务器：负载均衡组成集群。</li><li>数据库：实时备份。</li><li>软件开发质量保证：预发布验证，自动化测试，自动化发布，灰度发布等。</li></ol></li><li>伸缩性：主要标准是是否可以构成集群，是否容易不断地向服务器集群加服务器<ol><li>应用服务器集群：负载均衡设备。</li><li>缓存服务器集群：改进缓存路由算法保证存储数据的可访问性。</li><li>数据库：路由分区等。</li><li>NoSQL数据库：先天良好支持。</li></ol></li><li>扩展性：指业务上是否可以少有改动快速上线。主要手段是事件驱动架构和分布式服务。<ol><li>事件驱动架构：通常用消息队列实现。</li><li>分布式服务：按业务和可复用性将服务分离。</li></ol></li><li>安全性：标准是针对现存和潜在的各种攻击和窃密手段，是否有可靠的应对策略。</li></ul><h2 id="瞬时响应：网站的高性能架构"><a href="#瞬时响应：网站的高性能架构" class="headerlink" title="瞬时响应：网站的高性能架构"></a>瞬时响应：网站的高性能架构</h2><h3 id="网站性能测试"><a href="#网站性能测试" class="headerlink" title="网站性能测试"></a>网站性能测试</h3><ul><li>不同视角下网站的性能 <ul><li>用户视角网站性能：响应时间。</li><li>开发人员视角的网站性能：响应时间、并发量、吞吐量。</li><li>运维人员视角的网站性能：资源。</li></ul></li><li>性能测试指标 <ul><li>响应时间：直观反映系统快慢。</li><li>并发数：反映系统负载特性。</li><li>吞吐量：反映系统整体处理能力。通过qps,tps,hps测量。</li><li>性能计数器：描述服务器或操作系统的数据指标。包括System Load、对象与线程数、内存使用、CPU使用、磁盘与网络I/O等指标。</li></ul></li><li>性能测试方法 <ul><li>性能测试：验证系统在资源可接受范围内。</li><li>负载测试：测试安全临界值。</li><li>压力测试：测试系统最大压力承受能力。</li><li>稳定性测试：模拟生产环境。</li></ul></li><li>性能测试报告</li><li>性能优化策略 <ul><li>性能分析：1.检测请求各环节日志，分析那个环节响应时间不合理。2.检查监控数据。</li><li>性能优化：<ul><li>Web前端性能优化</li><li>应用服务器性能优化</li><li>存储服务器性能优化</li></ul></li></ul></li></ul><h3 id="web前端性能优化"><a href="#web前端性能优化" class="headerlink" title="web前端性能优化"></a>web前端性能优化</h3><ul><li>浏览器访问优化 <ul><li>减少http请求</li><li>使用浏览器缓存</li><li>启用压缩</li><li>css放在网页最上面 js最下面</li><li>减少cookie传输</li></ul></li><li>CDN加速</li><li>反向代理：安全屏障；缓存静态和热点数据；负载均衡。</li></ul><h3 id="应用服务器性能优化"><a href="#应用服务器性能优化" class="headerlink" title="应用服务器性能优化"></a>应用服务器性能优化</h3><p>优化的主要手段还是：缓存，异步，集群。</p><ul><li>分布式缓存 <ul><li>缓存的基本原理</li><li>合理的使用缓存 <ul><li>频繁修改数据：读写比2：1以上缓存才有意义</li><li>没有热点的访问</li><li>数据不一致与脏读</li><li>缓存可用性</li><li>缓存预热</li><li>缓存穿透</li></ul></li><li>分布式缓存架构</li></ul></li><li>异步操作：削峰</li><li>使用集群</li><li>代码优化<ul><li>多线程：<ul><li>将对象设计为无状态对象</li><li>使用局部对象</li><li>并发访问资源加锁</li></ul></li><li>资源复用：单例和对象池</li><li>数据结构</li><li>垃圾回收</li></ul></li></ul><h3 id="存储性能优化"><a href="#存储性能优化" class="headerlink" title="存储性能优化"></a>存储性能优化</h3><ul><li>机械硬盘 vs. 固态硬盘</li><li>B+ 树 vs. LSM 树</li><li>RAID vs. HDFS</li></ul><h2 id="万无一失：网站的高可用架构"><a href="#万无一失：网站的高可用架构" class="headerlink" title="万无一失：网站的高可用架构"></a>万无一失：网站的高可用架构</h2><h3 id="网站可用性的度量和考核"><a href="#网站可用性的度量和考核" class="headerlink" title="网站可用性的度量和考核"></a>网站可用性的度量和考核</h3><ul><li>网站可行性度量<ul><li>网站不可用时间(故障时间) = 故障修复时间点 - 故障发现时间点</li><li>网站年度可用性指标 = (1 - 网站不可用时间/年度总时间) * 100%</li><li>2个9基本可用，3个9较高可用，4个9具有自动恢复能力的高可用，5个9是极高可用性</li></ul></li><li>网站可用性考核:故障分 = 故障时间 * 故障权重</li></ul><h3 id="高可用的网站架构"><a href="#高可用的网站架构" class="headerlink" title="高可用的网站架构"></a>高可用的网站架构</h3><p>分层+分割+集群</p><h3 id="高可用的应用"><a href="#高可用的应用" class="headerlink" title="高可用的应用"></a>高可用的应用</h3><ul><li>通过负载均衡进行无状态服务的失效转移</li><li>应用服务器集群的session管理 <ul><li>session复制：简单，适用于集群规模较小的情况</li><li>session绑定：粘性session</li><li>利用cookie记录 session：简单易用，可用性高，支持线性伸缩，但是每次响应都会传输cookie，影响性能。</li><li>session服务器：利用分布式缓存。</li></ul></li></ul><h3 id="高可用的应用-1"><a href="#高可用的应用-1" class="headerlink" title="高可用的应用"></a>高可用的应用</h3><ul><li>分级管理：核心应用与服务优先使用更好的硬件；部署上进行隔离。</li><li>超时设置</li><li>异步调用</li><li>服务降级：手段有二：拒绝服务及关闭服务。</li><li>幂等性设计：业务代码层面通过有效性校验等。 <h3 id="高可用的数据"><a href="#高可用的数据" class="headerlink" title="高可用的数据"></a>高可用的数据</h3></li><li>CAP原理 <ul><li>数据持久性</li><li>数据可访问性</li><li>数据一致性 <ul><li>数据强一致性</li><li>数据用户一致性</li><li>数据最终一致性</li></ul></li></ul></li><li>数据备份<ul><li>冷备:简单廉价，成本和技术难度低；但不能保证数据最终一致。恢复时间可能会长，一段时间不可用。</li><li>热备：同步和异步方式</li></ul></li><li>失效转移 <ul><li>失效确认</li><li>访问转移</li><li>数据恢复</li></ul></li></ul><h3 id="高可用软件质量保障"><a href="#高可用软件质量保障" class="headerlink" title="高可用软件质量保障"></a>高可用软件质量保障</h3><ul><li><p>网站发布：脚本发布，流程大致如下</p><ol><li>关闭负载均衡服务器上一台或一小批服务器路由</li><li>关闭这些服务器应用</li><li>同步(复制)软件代码包到这些服务器上</li><li>启动这些服务器</li><li>打开负载均衡服务器这些服务器的路由</li><li>集群所有机器发布完成？是则退出：否则继续1.</li></ol></li><li><p>自动化测试</p></li><li>预发布验证</li><li>代码控制 <ul><li>主干开发，分支发布</li><li>分支开发，主干发布</li></ul></li><li>自动化发布</li><li>灰度发布</li></ul><h3 id="网站运行监控"><a href="#网站运行监控" class="headerlink" title="网站运行监控"></a>网站运行监控</h3><ul><li>监控数据采集 <ul><li>用户行为日志收集</li><li>服务器性能检测</li><li>运行数据报告</li></ul></li><li>监控管理 <ul><li>系统报警</li><li>失效转移</li><li>自动优雅降级</li></ul></li></ul><h2 id="永无止尽：网站的伸缩性架构"><a href="#永无止尽：网站的伸缩性架构" class="headerlink" title="永无止尽：网站的伸缩性架构"></a>永无止尽：网站的伸缩性架构</h2><h3 id="网站伸缩性设计"><a href="#网站伸缩性设计" class="headerlink" title="网站伸缩性设计"></a>网站伸缩性设计</h3><ul><li>不同功能进行物理分离实现伸缩<ul><li>纵向分离(分层后分离)</li><li>横向分离(业务分割后分离)</li></ul></li><li>单一功能通过集群实现伸缩</li></ul><h3 id="应用服务器集群伸缩设计"><a href="#应用服务器集群伸缩设计" class="headerlink" title="应用服务器集群伸缩设计"></a>应用服务器集群伸缩设计</h3><ul><li>http重定向负载均衡：简单，但是浏览器需要两次请求服务器。</li><li>Dns域名解析负载均衡：省掉了管理运维负载均衡服务器的麻烦，能支持基于地理位置的域名解析加速访问；但是生效时间较长，以及无法做更多改善和更强大的管理。</li><li>反向代理负载均衡：发生在http协议层，也叫应用层负载均衡。</li><li>ip负载均衡：发生在网络层，修改请求目标地址进行负载均衡。</li><li>数据链路层负载均衡：发生在通信协议的数据链路层，通过修改mac地址进行负载均衡。广泛使用的一种方式，比如：LVS(Linux Virtual Server)</li><li>负载均衡算法 <ul><li>轮询</li><li>加权轮询</li><li>随机</li><li>最少链接</li><li>源地址散列</li></ul></li></ul><h3 id="分布式缓存集群的伸缩性设计"><a href="#分布式缓存集群的伸缩性设计" class="headerlink" title="分布式缓存集群的伸缩性设计"></a>分布式缓存集群的伸缩性设计</h3><ul><li>Memcached分布式缓存集群的访问模型</li><li>Memcached分布式缓存集群的伸缩性挑战</li><li>分布式缓存的一致性hash算法</li></ul><h3 id="数据存储服务器集群的伸缩性设计"><a href="#数据存储服务器集群的伸缩性设计" class="headerlink" title="数据存储服务器集群的伸缩性设计"></a>数据存储服务器集群的伸缩性设计</h3><ul><li>关系数据库集群的伸缩性设计：从业务上回避分布式关系型数据库的各种缺点：避免事务或利用事务补偿机制代替数据库事务；避免JOIN操作等。</li><li>Nosql数据库的伸缩性设计</li></ul><h2 id="随机应变：网站的可扩展性架构"><a href="#随机应变：网站的可扩展性架构" class="headerlink" title="随机应变：网站的可扩展性架构"></a>随机应变：网站的可扩展性架构</h2><h3 id="构建可扩展性的网站架构"><a href="#构建可扩展性的网站架构" class="headerlink" title="构建可扩展性的网站架构"></a>构建可扩展性的网站架构</h3><p>软件架构师的最大价值不在于掌握多少先进的技术，而在于具有将一个大系统切分层N个低耦合的子模块的能力，这些子模块包含横向的业务模块，也包含纵向的基础技术模块。</p><h3 id="利用分布式消息队列降低系统耦合性"><a href="#利用分布式消息队列降低系统耦合性" class="headerlink" title="利用分布式消息队列降低系统耦合性"></a>利用分布式消息队列降低系统耦合性</h3><ul><li>事件驱动架构</li><li>分布式消息队列</li></ul><h3 id="利用分布式服务打造可复用的业务平台"><a href="#利用分布式服务打造可复用的业务平台" class="headerlink" title="利用分布式服务打造可复用的业务平台"></a>利用分布式服务打造可复用的业务平台</h3><ul><li>web service与企业级分布式服务：缺点有臃肿的注册和发现机制，抵消的XML序列化手段，开销相对较高的HTTP远程通信，复杂的部署与维护手段。</li><li>大型网站分布式服务的需求与特点 <ul><li>负载均衡</li><li>失效转移</li><li>高效的远程通信</li><li>整合异构系统</li><li>对应用最少侵入</li><li>版本控制</li><li>实时监控</li></ul></li><li>分布式服务框架设计</li></ul><h3 id="可扩展的数据结构"><a href="#可扩展的数据结构" class="headerlink" title="可扩展的数据结构"></a>可扩展的数据结构</h3><p>利用NoSQL的ColumnFamily(列族)设计。</p><h3 id="利用开放平台建设网站生态圈"><a href="#利用开放平台建设网站生态圈" class="headerlink" title="利用开放平台建设网站生态圈"></a>利用开放平台建设网站生态圈</h3><ul><li>api接口</li><li>协议转移</li><li>安全</li><li>审计</li><li>路由</li><li>流程</li></ul><h2 id="固若金汤：网站的安全架构"><a href="#固若金汤：网站的安全架构" class="headerlink" title="固若金汤：网站的安全架构"></a>固若金汤：网站的安全架构</h2><h3 id="道高一尺魔高一丈的网站应用攻击与防御"><a href="#道高一尺魔高一丈的网站应用攻击与防御" class="headerlink" title="道高一尺魔高一丈的网站应用攻击与防御"></a>道高一尺魔高一丈的网站应用攻击与防御</h3><p>全球70%的web攻击来自XSS攻击和SQL注入。</p><ul><li>xss攻击 <ul><li>消毒：转移html字符</li><li>httponly：避免攻击脚本窃取</li></ul></li><li>注入攻击 <ul><li>开源</li><li>错误回显</li><li>盲注</li><li>消毒</li><li>参数绑定</li></ul></li><li>csrf攻击：防御的主要手段是识别访问者身份。<ul><li>表单token</li><li>验证码</li><li>referer check</li></ul></li><li>其他攻击和漏洞 <ul><li>error code</li><li>html注释</li><li>文件上传</li><li>路径遍历</li></ul></li><li>web应用防火墙</li><li>网站安全漏洞扫描</li></ul><h3 id="信息加密技术及密钥安全管理"><a href="#信息加密技术及密钥安全管理" class="headerlink" title="信息加密技术及密钥安全管理"></a>信息加密技术及密钥安全管理</h3><ul><li>单向散列加密：MD5,SHA等</li><li>对称加密：DES,RC等</li><li>非对称加密：RSA等</li><li>密钥安全管理</li></ul><h3 id="信息过滤与反垃圾"><a href="#信息过滤与反垃圾" class="headerlink" title="信息过滤与反垃圾"></a>信息过滤与反垃圾</h3><ul><li>文本匹配<ul><li>正则表达式匹配：适用于敏感词较少</li><li>Trie树、双数组Trie树：时间和空间复杂度都较好</li><li>多级hash表：速度较快，但浪费部分空间</li></ul></li><li>分类算法：朴素贝叶斯算法。</li><li>黑名单：布隆过滤器。</li></ul><h3 id="电子商务风险控制"><a href="#电子商务风险控制" class="headerlink" title="电子商务风险控制"></a>电子商务风险控制</h3><ul><li>风险 <ul><li>账号风险</li><li>买家风险</li><li>卖家风险</li><li>交易风险</li></ul></li><li>风控<ul><li>规则引擎</li><li>统计模型</li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>大致总结了李智慧老师的<a href="https://book.douban.com/subject/25723064/" target="_blank" rel="noopener">《大型网站技术架构——核心原理与案例分析》</a>一书中的部分知识点的原理部分，又重新加深了架构演进的过程。建议还是需要购买原书看一看。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;又把《大型网站技术架构-核心原理与案例分析》看了一遍，之前走马观花看了一遍，没有体会到精髓。现在具备一定“中型”网站开发经验后再看之，又有些体会，故整理一下这本书的内容。
    
    </summary>
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/categories/architecture/"/>
    
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/tags/architecture/"/>
    
      <category term="read notes" scheme="https://www.chenruiwen.cn/tags/read-notes/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(五)：Callable、Future和FutureTask</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-callable-future-futureTask/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-callable-future-futureTask/</id>
    <published>2018-09-17T14:24:24.000Z</published>
    <updated>2018-09-17T14:21:37.472Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>创建一个线程，最熟悉的做法是集成<code>Thread</code>类或者实现<code>Runnable</code>接口重新<code>run()</code>。但是这两种创建方式在一些场景比如想要获取线程的执行结果时却不那么好用。<code>J.U.C</code>满足了这种需求。今天说一下不得不知的<code>Callable</code>、<code>Future</code>和<code>FutureTask</code><a id="more"></a></p><h2 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h2><p>比对<code>Runnable</code>接口与<code>Callable</code>接口：</p><pre><code class="java">public interface Runnable {    public abstract void run();}public interface Callable&lt;V&gt; {    V call() throws Exception;}</code></pre><p>可以看到，<code>Callable</code>接口代表一种能返回结果并可能引发异常的任务。 实现者只要实现<code>call()</code>并返回任务结果即可。<code>Callable</code>接口类似于Runnable，但是，<code>Runnable</code>不返回结果，也不能抛出被检查的异常。</p><p>一个好的事实是，无论是<code>Callable</code>还是<code>Runnable</code>，都可以很好的与<code>Executor</code>框架结合使用：</p><pre><code class="java">&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task);</code></pre><h2 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h2><p><code>future</code>,单从语义上就知道代表未来，实际上也是如此。先看接口定义：</p><pre><code class="java">public interface Future&lt;V&gt; {    boolean cancel(boolean mayInterruptIfRunning);    boolean isCancelled();    boolean isDone();    V get() throws InterruptedException, ExecutionException;    V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;}</code></pre><p><code>Future</code>提供了5个方法:</p><ul><li>cancel(boolean mayInterruptIfRunning):尝试取消执行此任务。</li><li>isCancelled():如果此任务在正常完成之前被取消，则返回 true 。</li><li>isDone():如果任务已完成返回 true。</li><li>get():一直阻塞直至获取执行结果。</li><li>get(long timeout, TimeUnit unit)：在指定时间内获取执行结果，获取不到抛出TimeoutException</li></ul><h2 id="FutureTask"><a href="#FutureTask" class="headerlink" title="FutureTask"></a>FutureTask</h2><p><code>FutureTask</code>实现了<code>RunnableFuture</code>接口，看下<code>RunnableFuture</code>接口：</p><pre><code class="java">public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; {    void run();}</code></pre><p>可以看到它即实现了<code>Runnable</code>接口，也实现了<code>Future</code>接口，因此<code>FutureTask</code>可以作为<code>Runnable</code>的实现，也可以作为<code>Future</code>来获取<code>Callable</code>的返回。看其构造器便知如何选择：</p><pre><code class="java">public FutureTask(Callable&lt;V&gt; callable) {}public FutureTask(Runnable runnable, V result) {}</code></pre><h2 id="推荐的使用方式"><a href="#推荐的使用方式" class="headerlink" title="推荐的使用方式"></a>推荐的使用方式</h2><p>开发中建议使用线程池+<code>Callable</code>返回<code>Future</code>的方式来获取异步结果,最好给予超时时间：</p><pre><code class="java">ExecutorService es = Executors.newSingleThreadExecutor();Future&lt;Integer&gt; future = es.submit(() -&gt; {    try {        System.out.println(&quot;开始执行计算任务...&quot;);        Thread.sleep(5000L);    } catch (InterruptedException e) {        e.printStackTrace();    }    return 100;});es.shutdown();//        Integer integer = future.get();//        System.out.println(&quot;get() 获取异步任务结果:&quot; + integer);Integer integer;try {    integer = future.get(2, TimeUnit.SECONDS);} catch (TimeoutException e) {    System.out.println(&quot;调用超时，返回错误结果&quot;);    integer = -1;}System.out.println(&quot;get(timeout) 获取异步任务结果:&quot; + integer);}</code></pre><p>返回的结果值:</p><pre><code>开始执行计算任务...调用超时，返回错误结果get(timeout) 获取异步任务结果:-1</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;创建一个线程，最熟悉的做法是集成&lt;code&gt;Thread&lt;/code&gt;类或者实现&lt;code&gt;Runnable&lt;/code&gt;接口重新&lt;code&gt;run()&lt;/code&gt;。
但是这两种创建方式在一些场景比如想要获取线程的执行结果时却不那么好用。&lt;code&gt;J.U.C&lt;/code&gt;满足了这种需求。
今天说一下不得不知的&lt;code&gt;Callable&lt;/code&gt;、&lt;code&gt;Future&lt;/code&gt;和&lt;code&gt;FutureTask&lt;/code&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(四)：闭锁与栅栏</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-latch-and-barrier/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-latch-and-barrier/</id>
    <published>2018-09-10T13:46:24.000Z</published>
    <updated>2018-09-17T13:34:00.207Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>闭锁(<code>CountDownlatch</code>)和栅栏(<code>CyclicBarrier</code>)功能看起来相似，都是同步工具类，看起来都是可以阻塞一个操作，等待其依赖的一组操作完成之后再执行。但是害死有所区别。<a id="more"></a></p><h2 id="闭锁"><a href="#闭锁" class="headerlink" title="闭锁"></a>闭锁</h2><p>闭锁(<code>CountDownlatch</code>)：允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。</p><p>注意这里有两种线程，一种是等待的线程，一种是执行线程。</p><p>它的应用场景比如：</p><ul><li>确保某个计算在其需要的所有资源都初始化后继续执行。即，这个计算依赖于资源初始化，必须等待所有依赖资源初始化后执行。</li><li>确保某个服务在其依赖的所有其他服务启动之后才能启动。</li><li>等待直到某个操作的所有参与者都就绪后再继续执行。</li></ul><h3 id="闭锁示例"><a href="#闭锁示例" class="headerlink" title="闭锁示例"></a>闭锁示例</h3><p>举例说明，比如有三个玩家，游戏开始必须在三个玩家就绪后才能开始。这里用两个类来模拟这种情况，分别是玩家(Player)和游戏(Game).</p><p>玩家：</p><pre><code class="java">public class Player implements Runnable {    private CountDownLatch downLatch;    private String name;    public Player(CountDownLatch downLatch, String name) {        this.downLatch = downLatch;        this.name = name;    }    @Override    public void run() {        System.out.println(&quot;玩家:&quot; + name + &quot;正来赶来游戏场地的路上！&quot;);        try {            Thread.sleep(new Random().nextInt(10000));        } catch (InterruptedException ie) {        }        System.out.println(&quot;玩家:&quot; + name + &quot;已准备就绪！&quot;);        this.downLatch.countDown();    }}</code></pre><p>游戏：</p><pre><code class="java">public class Game implements Runnable {    private CountDownLatch downLatch;    public Game(CountDownLatch downLatch) {        this.downLatch = downLatch;    }    @Override    public void run() {        System.out.println(&quot;游戏尚未开始，正在等待玩家就绪...&quot;);        try {            this.downLatch.await();        } catch (InterruptedException ie) {        }        System.out.println(&quot;所有玩家已就绪，游戏开始&quot;);        this.downLatch.countDown();    }}</code></pre><p>运行测试程序：</p><pre><code class="java">public static void main(String[] args) {    ExecutorService executor = Executors.newCachedThreadPool();    CountDownLatch latch = new CountDownLatch(3);    Player p1 = new Player(latch, &quot;A&quot;);    Player p2 = new Player(latch, &quot;B&quot;);    Player p3 = new Player(latch, &quot;C&quot;);    Game game = new Game(latch);    executor.execute(p1);    executor.execute(p2);    executor.execute(p3);    executor.execute(game);    executor.shutdown();}</code></pre><p>结果：</p><pre><code>玩家:A正来赶来游戏场地的路上！玩家:C正来赶来游戏场地的路上！游戏尚未开始，正在等待玩家就绪...玩家:B正来赶来游戏场地的路上！玩家:C已准备就绪！玩家:A已准备就绪！玩家:B已准备就绪！所有玩家已就绪，游戏开始</code></pre><p>可见，<code>Game</code>线程和所有<code>Player</code>都持有同一把闭锁，<code>Game</code>线程等待所有<code>Player</code>闭锁释放后才能继续执行，否则则一直等待。</p><h3 id="关键方法浅析"><a href="#关键方法浅析" class="headerlink" title="关键方法浅析"></a>关键方法浅析</h3><p>原理分析：<code>CountDownLatch</code>里初始化会存有一个正数计算器，每次做<code>countDown()</code>操作时会把计算器减1，<code>await()</code>需要等待计数器为0时才能释放，否则一直阻塞。</p><p>构造器给定一个初始化的计数值：</p><pre><code class="java">public CountDownLatch(int count) {    if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);    this.sync = new Sync(count);}</code></pre><p><code>Sync</code>是闭锁内部类，继承了<code>AQS</code>，并重写了<code>tryAcquireShared(int acquires)</code>和<code>tryReleaseShared(int releases)</code>方法，可见其采用共享锁实现。</p><p><code>await()</code>内部使用<code>AQS</code>的<code>acquireSharedInterruptibly(int arg)</code>：</p><pre><code class="java">public void await() throws InterruptedException {    sync.acquireSharedInterruptibly(1);}</code></pre><p><code>AQS</code>中的<code>acquireSharedInterruptibly(int arg)</code>：</p><pre><code class="java">public final void acquireSharedInterruptibly(int arg)        throws InterruptedException {    if (Thread.interrupted())        throw new InterruptedException();    if (tryAcquireShared(arg) &lt; 0)        doAcquireSharedInterruptibly(arg);}</code></pre><p>关键点在这个<code>tryAcquireShared</code>方法中，闭锁内部类<code>Sync</code>重写了这个方法：</p><pre><code class="java">protected int tryAcquireShared(int acquires) {    return (getState() == 0) ? 1 : -1;}</code></pre><p>这里的<code>getState</code>就是计数器的个数，当个数为0时可以获取到共享锁。</p><p>再看<code>countDown()</code>，其目的是减少计数器个数。</p><pre><code class="java">public void countDown() {    sync.releaseShared(1);}</code></pre><p>其内部也是调用<code>AQS</code>的<code>releaseShared(int arg)</code>方法来释放共享锁同步状态：</p><pre><code class="java">public final boolean releaseShared(int arg) {    if (tryReleaseShared(arg)) {        doReleaseShared();        return true;    }    return false;}</code></pre><p>这里的<code>tryReleaseShared</code>是内部类<code>Sync</code>重写的：</p><pre><code class="java">protected boolean tryReleaseShared(int releases) {    for (;;) {        int c = getState();        if (c == 0)            return false;        int nextc = c-1;        if (compareAndSetState(c, nextc))            return nextc == 0;    }}</code></pre><p>可见此处计算器进行了减1操作，知道状态为0时释放锁。</p><h2 id="栅栏"><a href="#栅栏" class="headerlink" title="栅栏"></a>栅栏</h2><p>栅栏(<code>CyclicBarrier</code>)类似于闭锁，但其还是不同。</p><p>api中介绍：</p><blockquote><p>允许一组线程全部等待彼此达到共同屏障点的同步辅助。 循环阻塞在涉及固定大小的线程方的程序中很有用，这些线程必须偶尔等待彼此。 屏障被称为循环 ，因为它可以在等待的线程被释放之后重新使用。</p></blockquote><p>再引用<code>java并发编程实战</code>里的解释：</p><blockquote><p>栅栏类似于闭锁，它能阻塞一组线程直到某个事件发生。 栅栏与闭锁的关键区别在于，所有的线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。</p></blockquote><p>所以关注点在于”栅栏”(共同屏障点)这个位置，这一组线程必须都到达栅栏以后才可以都继续执行。</p><h3 id="栅栏示例"><a href="#栅栏示例" class="headerlink" title="栅栏示例"></a>栅栏示例</h3><p>比如三个人共同商议6点钟去麦当劳碰头，等到三个人都到达以后，一起商讨去干什么。这里用栅栏实现，只需要一个Person类：</p><pre><code class="java">public class Persion implements Runnable {    private CyclicBarrier cyclicBarrier;    private String name;    public Persion(CyclicBarrier cyclicBarrier, String name) {        this.name = name;        this.cyclicBarrier = cyclicBarrier;    }    @Override    public void run() {        System.out.println(name + &quot;正来赶来麦当劳的路上...&quot;);        try {            Thread.sleep(new Random().nextInt(10000));            System.out.println(name + &quot;到达麦当劳...&quot;);            cyclicBarrier.await();        } catch (BrokenBarrierException e) {            e.printStackTrace();        } catch (InterruptedException e) {            e.printStackTrace();        }        System.out.println(name + &quot;说：大家都到齐了，开始商量干什么吧！&quot;);    }}</code></pre><p>运行程序：</p><pre><code class="java">public static void main(String[] args) {    ExecutorService executor = Executors.newCachedThreadPool();    CyclicBarrier barrier = new CyclicBarrier(3);    Persion p1 = new Persion(barrier, &quot;A&quot;);    Persion p2 = new Persion(barrier, &quot;B&quot;);    Persion p3 = new Persion(barrier, &quot;C&quot;);    executor.execute(p1);    executor.execute(p2);    executor.execute(p3);    executor.shutdown();}</code></pre><p>运行结果：</p><pre><code>A正来赶来麦当劳的路上...C正来赶来麦当劳的路上...B正来赶来麦当劳的路上...B到达麦当劳...A到达麦当劳...C到达麦当劳...C说：大家都到齐了，开始商量干什么吧！B说：大家都到齐了，开始商量干什么吧！A说：大家都到齐了，开始商量干什么吧！</code></pre><p>可见，所有线程都等到了其栅栏点才可以继续执行。</p><p>可能有时候需要我们的执行线程希望做到类似闭锁的情况，即到达栅栏点时，只执行一次处理。<code>CyclicBarrier</code>有个这么个构造器(<code>public CyclicBarrier(int parties, Runnable barrierAction)</code>)可以实现：</p><p>修改上面的Persion类：</p><pre><code class="java">public class Persion implements Runnable {    private CyclicBarrier cyclicBarrier;    private String name;    public Persion(CyclicBarrier cyclicBarrier, String name) {        this.name = name;        this.cyclicBarrier = cyclicBarrier;    }    @Override    public void run() {        System.out.println(name + &quot;正来赶来麦当劳的路上...&quot;);        try {            Thread.sleep(new Random().nextInt(10000));            System.out.println(name + &quot;到达麦当劳...&quot;);            cyclicBarrier.await();        } catch (BrokenBarrierException e) {            e.printStackTrace();        } catch (InterruptedException e) {            e.printStackTrace();        }    }}</code></pre><p>执行程序：</p><pre><code class="java">public static void main(String[] args) {    ExecutorService executor = Executors.newCachedThreadPool();    CyclicBarrier barrier = new CyclicBarrier(3, new Runnable() {        @Override        public void run() {            System.out.println(&quot;大家都到齐了，开始商量干什么吧！&quot;);        }    });    Persion p1 = new Persion(barrier, &quot;A&quot;);    Persion p2 = new Persion(barrier, &quot;B&quot;);    Persion p3 = new Persion(barrier, &quot;C&quot;);    executor.execute(p1);    executor.execute(p2);    executor.execute(p3);    executor.shutdown();}</code></pre><p>运行结果：</p><pre><code>A正来赶来麦当劳的路上...C正来赶来麦当劳的路上...B正来赶来麦当劳的路上...C到达麦当劳...A到达麦当劳...B到达麦当劳...大家都到齐了，开始商量干什么吧！</code></pre><h3 id="关键方法浅析-1"><a href="#关键方法浅析-1" class="headerlink" title="关键方法浅析"></a>关键方法浅析</h3><p>构造器有两个：</p><pre><code class="java">public CyclicBarrier(int parties, Runnable barrierAction) {    if (parties &lt;= 0) throw new IllegalArgumentException();    this.parties = parties;    this.count = parties;    this.barrierCommand = barrierAction;}public CyclicBarrier(int parties) {    this(parties, null);}</code></pre><p><code>parties</code>是拦截的线程数，当拦截的线程数达到这个值之前，线程会一直等待。<code>barrierAction</code>是当拦截的线程数达到<code>parties</code>时，由最后一个进入的线程执行此操作。</p><p><code>await()</code>方法，所有的参与者在此等待：</p><pre><code class="java">public int await() throws InterruptedException, BrokenBarrierException {    try {        return dowait(false, 0L);//不超时等待    } catch (TimeoutException toe) {        throw new Error(toe); // cannot happen    }}private int dowait(boolean timed, long nanos)    throws InterruptedException, BrokenBarrierException,           TimeoutException {    final ReentrantLock lock = this.lock;    lock.lock();    try {        final Generation g = generation;        if (g.broken)            throw new BrokenBarrierException();        if (Thread.interrupted()) {            breakBarrier();            throw new InterruptedException();        }        // 每次进度的线程，此count值减1，减到0时，触发barrierCommand任务        int index = --count;        if (index == 0) {  // tripped            boolean ranAction = false;            try {                final Runnable command = barrierCommand;                if (command != null)                    command.run();                ranAction = true;                nextGeneration(); // 此处唤醒所有等待线程                return 0;            } finally {                if (!ranAction)                    breakBarrier();            }        }        // loop until tripped, broken, interrupted, or timed out        for (;;) {            try {                if (!timed)                    trip.await();                else if (nanos &gt; 0L)                    nanos = trip.awaitNanos(nanos);            } catch (InterruptedException ie) {                if (g == generation &amp;&amp; ! g.broken) {                    breakBarrier();                    throw ie;                } else {                    // We&#39;re about to finish waiting even if we had not                    // been interrupted, so this interrupt is deemed to                    // &quot;belong&quot; to subsequent execution.                    Thread.currentThread().interrupt();                }            }            if (g.broken)                throw new BrokenBarrierException();            if (g != generation)                return index;            if (timed &amp;&amp; nanos &lt;= 0L) {                breakBarrier();                throw new TimeoutException();            }        }    } finally {        lock.unlock();    }}</code></pre><p>简单的说，<code>dowait</code>方法使得最后一个到达的线程到达之后，<code>index == 0</code>，执行Runnable任务，唤醒所有等待的线程。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>闭锁和栅栏是实现并发同步操作的两把利器，有所相似又各有不同，抓住其原理关键点就很好理解了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;闭锁(&lt;code&gt;CountDownlatch&lt;/code&gt;)和栅栏(&lt;code&gt;CyclicBarrier&lt;/code&gt;)功能看起来相似，都是同步工具类，
看起来都是可以阻塞一个操作，等待其依赖的一组操作完成之后再执行。但是害死有所区别。
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(三)：阻塞队列(BlockingQueue)</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-BlockingQueue/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-BlockingQueue/</id>
    <published>2018-09-08T08:16:24.000Z</published>
    <updated>2018-09-08T16:04:47.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>阻塞队列 (<code>BlockingQueue</code>)是<code>j.u.c</code>下重要的数据结构，<code>BlockingQueue</code>提供了线程安全的队列访问方式：当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。</p><a id="more"></a><h2 id="接口-BlockingQueue"><a href="#接口-BlockingQueue" class="headerlink" title="接口 BlockingQueue"></a>接口 BlockingQueue</h2><h3 id="提供的方法API"><a href="#提供的方法API" class="headerlink" title="提供的方法API"></a>提供的方法API</h3><p>从API文档上看，<code>BlockingQueue</code>定义的方法有四种形式，具有不同的操作方式，不能立即满足，但可能在将来的某个时间点满足：一个抛出异常，第二个返回一个特殊值（ null或false ，具体取决于操作），第三个程序将无限期地阻止当前线程，直到操作成功为止，而第四个程序块在放弃之前只有给定的最大时限。 这些方法总结在下表中：</p><table><thead><tr><th>method\way</th><th>Throws exception</th><th>Special value</th><th>Blocks</th><th>Times out</th></tr></thead><tbody><tr><td>Insert</td><td>add(e)</td><td>offer(e)</td><td>put(e)</td><td>offer(e, time, unit) </td></tr><tr><td>Remove</td><td>remove()</td><td>poll()</td><td>take()</td><td>poll(time, unit)</td></tr><tr><td>Examine</td><td>element()</td><td>peek()</td><td>not applicable</td><td>not applicable</td></tr></tbody></table><p>简单解释一下四种行为方式：</p><ul><li>抛异常(Throws exception)：如果试图的操作无法立即执行，抛一个异常。</li><li>特定值(Special value)：如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。</li><li>阻塞(Blocks)：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。</li><li>超时(Times out)：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是true / false)。</li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><p>阻塞队列的典型使用场景就是生产者 - 消费者场景，它可以安全的与多个生产者和多个消费者一起使用。引用API文档里的例子：</p><pre><code class="java">class Producer implements Runnable {   private final BlockingQueue queue;   Producer(BlockingQueue q) { queue = q; }   public void run() {     try {       while (true) { queue.put(produce()); }     } catch (InterruptedException ex) { ... handle ...}   }   Object produce() { ... } } class Consumer implements Runnable {   private final BlockingQueue queue;   Consumer(BlockingQueue q) { queue = q; }   public void run() {     try {       while (true) { consume(queue.take()); }     } catch (InterruptedException ex) { ... handle ...}   }   void consume(Object x) { ... } } class Setup {   void main() {     BlockingQueue q = new SomeQueueImplementation();     Producer p = new Producer(q);     Consumer c1 = new Consumer(q);     Consumer c2 = new Consumer(q);     new Thread(p).start();     new Thread(c1).start();     new Thread(c2).start();   } }</code></pre><h3 id="其他特性"><a href="#其他特性" class="headerlink" title="其他特性"></a>其他特性</h3><ul><li>不接受null元素。当尝试对一个阻塞队列执行add,put或offer一个null对象时，会抛出NullPointerException。</li><li>BlockingQueue实现是线程安全的。 所有排队方法使用内部锁或其他形式的并发控制在原子上实现其效果。 </li></ul><h2 id="BlockingQueue常见实现类与介绍"><a href="#BlockingQueue常见实现类与介绍" class="headerlink" title="BlockingQueue常见实现类与介绍"></a>BlockingQueue常见实现类与介绍</h2><ul><li>有界阻塞队列：ArrayBlockingQueue,LinkedBlockingQueue…</li><li>无界阻塞队列：PriorityBlockingQueue,DelayQueue…</li><li>优先级阻塞队列：PriorityBlockingQueue</li><li>延迟阻塞队列：DelayQueue</li></ul><h3 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h3><p>有界阻塞队列，FIFO队列，内部是通过数组实现的，大小固定，创建后容量无法修改。尝试put成满的队列的元件将导致在操作阻挡; 尝试take从空队列的元件将类似地阻塞。</p><p>举个栗子：</p><pre><code class="java">public class BlockingQueueTest {    /**     * 实例化一个队列，队列中的容量为10     */    private static BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10);    public static void main(String[] args) {        ScheduledExecutorService product = Executors.newScheduledThreadPool(1);        Random random = new Random();        product.scheduleAtFixedRate(() -&gt; {            int value = random.nextInt(101);            try {                blockingQueue.offer(value);  //offer()方法就是往队列的尾部设置值                System.out.println(&quot;已经往队列里加入数据:&quot; + value);            } catch (Exception ex) {                ex.printStackTrace();            }        }, 0, 100, TimeUnit.MILLISECONDS);  //每100毫秒执行线程        new Thread(() -&gt; {            while (true) {                try {                    Thread.sleep(1000);                    Integer poll = blockingQueue.poll();// 弹出                    System.out.println(&quot;已经从队列里取出数据:&quot; + poll);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }).start();    }}</code></pre><p>以上实现一个固定队列的例子，容量为10，可以通过构造器创建容量大小为n的阻塞队列。</p><h3 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h3><p>有界阻塞队列，FIFO队列，基于链表实现，创建时可以不指定容量，不指定时默认容量Integer.MAX_VALUE。队列的节点可以动态扩展，只是不能超过容量。这一点上与<code>ArrayBlockingQueue</code>区别在于<code>ArrayBlockingQueue</code>创建后不能再扩展队列的元素了。</p><p>使用方式，将上面的<code>BlockingQueueTest</code>里的阻塞队列的实现改为<code>LinkedBlockingQueue</code>即可。</p><h3 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h3><p>无界阻塞队列，优先级排序。<code>PriorityBlockingQueue</code>只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容。所以，虽然这个队列逻辑上无界，但是可能会耗尽资源导致OOM的问题。<code>PriorityBlockingQueue</code>的内部排序默认是自然排序，也可通过<code>omparator</code>指定排序规则，便于自定义优先级逻辑。</p><p><code>PriorityBlockingQueue</code>内部也是通过数组实现，数组的容量可以动态扩展，源码如下：</p><pre><code class="java">/** * Tries to grow array to accommodate at least one more element * (but normally expand by about 50%), giving up (allowing retry) * on contention (which we expect to be rare). Call only while * holding lock. * * @param array the heap array * @param oldCap the length of the array */private void tryGrow(Object[] array, int oldCap) {    lock.unlock(); // must release and then re-acquire main lock    Object[] newArray = null;    if (allocationSpinLock == 0 &amp;&amp;        UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset,                                 0, 1)) {        try {            int newCap = oldCap + ((oldCap &lt; 64) ?                                   (oldCap + 2) : // grow faster if small                                   (oldCap &gt;&gt; 1));            if (newCap - MAX_ARRAY_SIZE &gt; 0) {    // possible overflow                int minCap = oldCap + 1;                if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE)                    throw new OutOfMemoryError();                newCap = MAX_ARRAY_SIZE;            }            if (newCap &gt; oldCap &amp;&amp; queue == array)                newArray = new Object[newCap];        } finally {            allocationSpinLock = 0;        }    }    if (newArray == null) // back off if another thread is allocating        Thread.yield();    lock.lock();    if (newArray != null &amp;&amp; queue == array) {        queue = newArray;        System.arraycopy(array, 0, newArray, 0, oldCap);    }}</code></pre><h3 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h3><p>无界阻塞队列，其元素是一个<code>Delayed</code>元素，其元素只能在其延迟到期时才被使用。在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。</p><p>其使用场景：</p><ul><li>定时任务调度。通过<code>DelayQueue</code>保存执行的任务和执行时间，当从<code>DelayQueue</code>中获取到任务时立即执行，从而实现定时调度。</li><li>缓存有效期。缓存元素的有效期，当循环获取队列的元素时，只要获取到就说明缓存有效期过了。</li></ul><h3 id="其他队列"><a href="#其他队列" class="headerlink" title="其他队列"></a>其他队列</h3><p>除了常用的队列以外，jdk还提供了一些其他的实现，比如：<code>SynchronousQueue</code>，<code>LinkedTransferQueue</code>，<code>LinkedBlockingDeque</code>等，各有特色与其使用场景。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;阻塞队列 (&lt;code&gt;BlockingQueue&lt;/code&gt;)是&lt;code&gt;j.u.c&lt;/code&gt;下重要的数据结构，&lt;code&gt;BlockingQueue&lt;/code&gt;提供了线程安全的队列访问方式：
当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。&lt;/p&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(二)：并发容器类</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-collections/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-collections/</id>
    <published>2018-09-02T08:16:24.000Z</published>
    <updated>2018-09-02T08:03:27.183Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>jdk1.5之前，线程安全的容器类有<code>HashTable</code>,<code>Vector</code>等实现。但是其内部使用的是<code>synchronized</code>内置锁这样重量级的实现，在高并发的情况下大大影响性能。jdk1.5之后，<code>j.u.c</code>中有了基于<code>CAS</code>实现的更加高并发的实现来极大的提高伸缩性。<a id="more"></a></p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p><code>ConcurrentHashMap</code>是当前最常使用的并发容器之一，它同样也实现了<code>AbstractMap</code>接口，所以使用它就像是使用<code>HashMap</code>等线程不安全的容器一样使用。</p><h3 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h3><pre><code class="java">static final class HashEntry&lt;K,V&gt; {    final int hash;    final K key;    volatile V value;    volatile HashEntry&lt;K,V&gt; next;}</code></pre><p>和<code>HashMap</code>类似，也是基于哈希桶的结构，最主要的区别在于，<code>ConcurrentHashMap</code>采用了分段锁<code>Segment</code>来加锁，并不是整个结构都加锁，使得多个线程可以访问不同分段锁上的桶，从而实现更高的并发。</p><p>关于<code>并发等级</code>，即分段锁的个数，在源码里默认的并发等级是16：</p><pre><code class="java">/** * The default concurrency level for this table. Unused but * defined for compatibility with previous versions of this class. */private static final int DEFAULT_CONCURRENCY_LEVEL = 16;</code></pre><p><code>Segment</code>的结构:</p><pre><code class="java">/** * Stripped-down version of helper class used in previous version, * declared for the sake of serialization compatibility */static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable {    private static final long serialVersionUID = 2249069246763182397L;    final float loadFactor;    Segment(float lf) { this.loadFactor = lf; }}</code></pre><p>所以其大致的结构是这样的:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fuv78147kbj20pr0ij0t3.jpg" alt=""></p><h3 id="重要的方法"><a href="#重要的方法" class="headerlink" title="重要的方法"></a>重要的方法</h3><h4 id="put-K-key-V-value"><a href="#put-K-key-V-value" class="headerlink" title="put(K key, V value)"></a>put(K key, V value)</h4><pre><code class="java">public V put(K key, V value) {    return putVal(key, value, false);}</code></pre><p>如果key存在也替换value值：</p><pre><code class="java">/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) {    if (key == null || value == null) throw new NullPointerException();    int hash = spread(key.hashCode());    int binCount = 0;    for (Node&lt;K,V&gt;[] tab = table;;) {        Node&lt;K,V&gt; f; int n, i, fh;        if (tab == null || (n = tab.length) == 0)            tab = initTable();        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {            if (casTabAt(tab, i, null,                         new Node&lt;K,V&gt;(hash, key, value, null)))                break;                   // no lock when adding to empty bin        }        else if ((fh = f.hash) == MOVED)            tab = helpTransfer(tab, f);        else {            V oldVal = null;            synchronized (f) {                if (tabAt(tab, i) == f) {                    if (fh &gt;= 0) {                        binCount = 1;                        for (Node&lt;K,V&gt; e = f;; ++binCount) {                            K ek;                            if (e.hash == hash &amp;&amp;                                ((ek = e.key) == key ||                                 (ek != null &amp;&amp; key.equals(ek)))) {                                oldVal = e.val;                                if (!onlyIfAbsent)                                    e.val = value;                                break;                            }                            Node&lt;K,V&gt; pred = e;                            if ((e = e.next) == null) {                                pred.next = new Node&lt;K,V&gt;(hash, key,                                                          value, null);                                break;                            }                        }                    }                    else if (f instanceof TreeBin) {                        Node&lt;K,V&gt; p;                        binCount = 2;                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,                                                       value)) != null) {                            oldVal = p.val;                            if (!onlyIfAbsent)                                p.val = value;                        }                    }                }            }            if (binCount != 0) {                if (binCount &gt;= TREEIFY_THRESHOLD)                    treeifyBin(tab, i);                if (oldVal != null)                    return oldVal;                break;            }        }    }    addCount(1L, binCount);    return null;}</code></pre><p>简诉以上代码逻辑：</p><ol><li>判断key,value均不能为null。</li><li>计算key的hash值。</li><li>开始遍历整个table。<ol><li>table为null时初始化table</li><li>计算节点位置，如果该位置没有别的节点则直接插入，不需要加锁</li><li><code>(fh = f.hash) == MOVED</code>，如果有线程正在扩容，则先帮助扩容4 如果该节点位置有别的节点，加锁处理。<ol><li>如果该节点位置上目前<code>fh &gt;= 0</code>，则为链表结构，遍历链表，如果key节点相同则替换value，否则插入链表尾部。</li><li>如果该位置节点上是<code>TreeBin</code>类型，则以红黑树的方式赠加节点。</li></ol></li></ol></li><li>ConcurrentHashMap 的 size + 1。</li></ol><h4 id="get-Object-key"><a href="#get-Object-key" class="headerlink" title="get(Object key)"></a>get(Object key)</h4><pre><code class="java">public V get(Object key) {    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;    int h = spread(key.hashCode());    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;        (e = tabAt(tab, (n - 1) &amp; h)) != null) {        if ((eh = e.hash) == h) {            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))                return e.val;        }        else if (eh &lt; 0)            return (p = e.find(h, key)) != null ? p.val : null;        while ((e = e.next) != null) {            if (e.hash == h &amp;&amp;                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))                return e.val;        }    }    return null;}</code></pre><p>简诉以上代码逻辑：</p><ol><li>计算key的hash值。</li><li>判断table是否有值，没值直接返回null。</li><li>获取table中的node节点，如果是链表则遍历查找到相同key的value，如果是红黑树则调用<code>e.find(h, key)</code>找到value。</li></ol><h4 id="size"><a href="#size" class="headerlink" title="size()"></a>size()</h4><p>size()操作是一个费劲的操作，在1.7以及之前的版本中，size()是需要获取每个<code>Segment</code>中的count值累加获取的，由于可能存在size的同时有线程正在put或者remove操作，所以其返回的值可能不精确。</p><p>而1.8之后，ConcurrentHashMap提供了<code>baseCount</code>、<code>counterCells</code>两个辅助变量和一个<code>CounterCell</code>辅助内部类来计算size()。</p><p>具体代码暂不展示了，在实际操作中实际上很少用到<code>size()</code>方法。</p><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p><code>CopyOnWriteArrayList</code>是用于替代同步List,它提供了更好的并发性。同理的<code>CopyOnWriteArrayList</code>是替代同步Set。</p><p><code>写入时复制(Copy-On-Write)</code>，这一类容器的特点是，访问该对象时不需要再进行一次同步，但每次修改时都会创建并重新发布一个新的容器副本从而实现可变性。</p><p>读写分离，写在一个新的副本数组上执行，此处需加锁；读操作直接读原始数组。写操作完成后会把原始数组指向新数组：</p><pre><code class="java">public boolean add(E e) {    final ReentrantLock lock = this.lock;    lock.lock();    try {        Object[] elements = getArray();        int len = elements.length;        Object[] newElements = Arrays.copyOf(elements, len + 1);        newElements[len] = e;        setArray(newElements);        return true;    } finally {        lock.unlock();    }}final void setArray(Object[] a) {    array = a;}</code></pre><p>因此，增删元素等都是花费很大的开销，典型的空间换时间的方式，只有当迭代操作远远多于修改操作时，才应当使用<code>Copy-On-Write</code>容器。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>除此之外，还有一些有各自应用场景的并发集合类比如<code>ConcurrentSkipListMap</code>和<code>ConcurrentSkipListSet</code>。最主要的重点集合类便是<code>ConcurrentHashMap</code>了，其代码在jdk1.7和1.8之间还有不同。建议阅读源码顺序：<code>1.7的HashMap</code>-&gt;<code>1.7的ConcurrentHashMap</code>-&gt;<code>1.8的HashMap</code>-&gt;<code>1.8的ConcurrentHashMap</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;jdk1.5之前，线程安全的容器类有&lt;code&gt;HashTable&lt;/code&gt;,&lt;code&gt;Vector&lt;/code&gt;等实现。但是其内部使用的是&lt;code&gt;synchronized&lt;/code&gt;内置锁这样重量级的实现，在高并发的情况下大大影响性能。
jdk1.5之后，&lt;code&gt;j.u.c&lt;/code&gt;中有了基于&lt;code&gt;CAS&lt;/code&gt;实现的更加高并发的实现来极大的提高伸缩性。
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(一)：原子类和锁</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-atomic-and-locks/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-atomic-and-locks/</id>
    <published>2018-08-20T15:16:24.000Z</published>
    <updated>2018-08-21T13:14:37.736Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><code>jdk 1.5</code>开始，新增了<code>java.util.concurrent</code>包（以下简称<code>j.u.c</code>），是一系列关于并发的工具类，是java并发编程必知必会的内容。今儿准备简单介绍一些常用的工具类。</p><a id="more"></a><h2 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h2><p><code>java.util.concurrent.atomic</code>包提供了一些专门为线程安全设计的java操作原子类。见名知意，类名基本以 <code>Atomic</code> 开头，表示这些类都是线程安全的。</p><p>明明提供线程安全的锁，为什么还要提供这些基础的类呢？</p><p>这就必须说明，这些原子类与通过<code>synchronized</code>加锁实现的对象不同，以往通过<code>synchronized</code>等加锁的实现我们认为是一种悲观锁的体现，即不论谁来操作，都假设最坏的情况，必须加锁独占，让其他需要操作的线程挂起等待锁释放。这种情况是具有比较大的开销的，线程抢占锁的花费的时间代价非常高。</p><p>所以这里就体现了原子类存在的强大意义。原子类的底层代码是利用了现代CPU的<code>CAS</code>指令来完成赋值操作的。<code>CAS</code>是乐观锁技术，原称:<code>Compare and Swap</code>,比较并交换。操作之前会比较内存值V与预期值A是否一致，并且仅当V == A时，才会把V赋值为新值B。</p><p>举个例子，<code>AtomicInteger</code>的<code>incrementAndGet</code>操作:</p><pre><code class="java">public final int incrementAndGet() {    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;}</code></pre><p>其调用了<code>sun.misc.Unsafe</code>的方法，这里的<code>compareAndSwapInt</code>是一个本地方法，起调用了CPU的CAS指令。</p><pre><code class="java">public final int getAndAddInt(Object var1, long var2, int var4) {    int var5;    do {        var5 = this.getIntVolatile(var1, var2);    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));    return var5;}</code></pre><h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p><code>java.util.concurrent.locks</code>包下提供了很方方便加锁的工具。其下最知名的应该是<code>ReentrantLock</code>，但是提到<code>ReentrantLock</code>之前，最需要提的是<code>AbstractQueuedSynchronizer</code>。</p><h3 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h3><p><code>AbstractQueuedSynchronizer</code>简称<code>AQS</code>，见名知意，抽象的基于队列的同步器，本质上是提供并定义了一套多线程访问共享资源的模板。这个模板应用广泛，大部分锁的实现都基于此：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fud1ftyagjj21kc0eoq7u.jpg" alt=""></p><p>源码中的描述:</p><blockquote><p>The wait queue is a variant of a “CLH” (Craig, Landin, and Hagersten) lock queue.</p></blockquote><p><code>CLH</code>是一种自旋锁，提供先来先服务的公平性，其基于链表，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。</p><p><code>AQS</code>提供了两种资源共享方式:<code>Exclusive</code>(独占) 和 <code>Shared</code>(共享)。</p><p>我们开发中自定义队列同步器很少，更多的实现都在jdk中。</p><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p><code>ReentrantLock</code>是开发中比较常用的显示锁。其性能在jdk1.5的时候是比<code>synchronized</code>关键字高出许多的，但是jdk1.6之后二者实际上不分伯仲。但是<code>ReentrantLock</code>还是有其独特的特性：轮询锁、定时锁、可中断锁、公平锁等，并且使用更加灵活。</p><p>其基本使用方式:</p><pre><code class="java">Lock lock = new ReentrantLock();...lock.lock(); // 上锁try {    // 处理共享资源} finally {    lock.unlock(); // 解锁} </code></pre><h4 id="轮询锁与定时锁"><a href="#轮询锁与定时锁" class="headerlink" title="轮询锁与定时锁"></a>轮询锁与定时锁</h4><p>轮询锁与定时锁是由<code>tryLock</code>方法实现的，与无条件的锁获取方式相比，它具有跟完善的错误回复机制。</p><h5 id="轮询锁之转账问题"><a href="#轮询锁之转账问题" class="headerlink" title="轮询锁之转账问题"></a>轮询锁之转账问题</h5><p>假设在银行系统把账户A的钱转给账户B，必须保证多线程并发安全，加锁是必不可少的，但是在获取多个锁的情况下，如果通过内置锁，很可能发生死锁问题。</p><p>解决方式：通过<code>tryLock</code>尝试同时获取多个锁，如果不能同时获取，就回退重试。</p><p>账户类，每个账户都持有一把锁：</p><pre><code class="java">@Data@Builderclass Account {    private BigDecimal balance; // 账户余额    private String name; // 账户名称    public Lock lock;    void debit(BigDecimal amount) {        balance = balance.subtract(amount);    }    void credit(BigDecimal amount) {        balance = balance.add(amount);    }    @Override    public String toString() {        return new StringBuilder(name).append(&quot;的余额为:&quot;).append(balance).toString();    }}</code></pre><p>使用<code>tryLock</code>尝试获取锁，进行两个账户的转账:</p><pre><code class="java">public class TransferService {    public boolean transferAccount(Account fromAcct, Account toAcct, BigDecimal amount, long timeout) throws InterruptedException {        long stopTime = System.currentTimeMillis() + timeout;        while (true) {            if (fromAcct.lock.tryLock()) {                try {                    if (toAcct.lock.tryLock()) {                        try {                            if (fromAcct.getBalance().compareTo(amount) &lt; 0) {                                throw new RuntimeException(&quot;转账账户余额不足&quot;);                            } else {                                fromAcct.debit(amount);                                toAcct.credit(amount);                                System.out.println(&quot;转账人:&quot; + fromAcct.toString());                                System.out.println(&quot;被转账人:&quot; + toAcct.toString());                                return true;                            }                        } finally {                            toAcct.lock.unlock();                        }                    } else {                        System.out.println(&quot;toAcct.lock.tryLock() false&quot;);                    }                } finally {                    fromAcct.lock.unlock();                }            } else {                System.out.println(&quot;fromAcct.lock.tryLock() false&quot;);            }            if (System.currentTimeMillis() &gt; stopTime) {                return false;            }            Thread.sleep(1000L);        }    }    public static void main(String[] args) {        Lock lock1 = new ReentrantLock();        Lock lock2 = new ReentrantLock();        final Account fromAcct = Account.builder().lock(lock1).name(&quot;老王&quot;).balance(new BigDecimal(1000)).build();        final Account toAcct = Account.builder().lock(lock2).name(&quot;老李&quot;).balance(new BigDecimal(1000)).build();        TransferService service = new TransferService();        Runnable runnable = new Runnable() {            @Override            public void run() {                try {                    service.transferAccount(fromAcct, toAcct, new BigDecimal(50), 1000);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        };        for (int i = 0; i &lt; 10; i++) {            new Thread(runnable).start();        }    }}</code></pre><p>如下运行结果，可以看到尝试获取锁多次。如果修改调用参数里的timeout 值，可能会出现转账失败的情况。</p><pre><code>fromAcct.lock.tryLock() false转账人:老王的余额为:950被转账人:老李的余额为:1050转账人:老王的余额为:900fromAcct.lock.tryLock() false被转账人:老李的余额为:1100转账人:老王的余额为:850被转账人:老李的余额为:1150fromAcct.lock.tryLock() false转账人:老王的余额为:800被转账人:老李的余额为:1200fromAcct.lock.tryLock() false转账人:老王的余额为:750被转账人:老李的余额为:1250fromAcct.lock.tryLock() falsefromAcct.lock.tryLock() false转账人:老王的余额为:700被转账人:老李的余额为:1300fromAcct.lock.tryLock() falsefromAcct.lock.tryLock() false转账人:老王的余额为:650被转账人:老李的余额为:1350fromAcct.lock.tryLock() falsefromAcct.lock.tryLock() false转账人:老王的余额为:600被转账人:老李的余额为:1400fromAcct.lock.tryLock() false转账人:老王的余额为:550被转账人:老李的余额为:1450转账人:老王的余额为:500被转账人:老李的余额为:1500</code></pre><h5 id="定时锁的使用"><a href="#定时锁的使用" class="headerlink" title="定时锁的使用"></a>定时锁的使用</h5><p>关键方法<code>tryLock(long timeout, TimeUtil unit)</code>，即申请获取锁设置等待时间，在此等待时间内尝试获取锁，如果锁被其他线程占有，则返回false.这种方式可以有效的避免死锁的发生。</p><pre><code class="java">public class Service {    public ReentrantLock lock = new ReentrantLock();    public void waitMethod() {        try {            if (lock.tryLock(3, TimeUnit.SECONDS)) {                System.out.println(Thread.currentThread().getName() + &quot;获得锁的时间:&quot; + System.currentTimeMillis());                Thread.sleep(10000);            } else {                System.out.println(Thread.currentThread().getName() + &quot;没有获得锁&quot;);            }        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            if (lock.isHeldByCurrentThread()) {                lock.unlock();            }        }    }}public class Run_tryLock_param {    public static void main(String[] args) {        final Service service = new Service();        Runnable runnable = new Runnable() {            public void run() {                System.out.println(Thread.currentThread().getName() + &quot; 调用waitMethod时间:&quot; + System.currentTimeMillis());                service.waitMethod();            }        };        Thread threadA = new Thread(runnable);        threadA.setName(&quot;A&quot;);        threadA.start();        Thread threadB = new Thread(runnable);        threadB.setName(&quot;B&quot;);        threadB.start();    }}</code></pre><p>如上所示，运行结果:</p><pre><code>A 调用waitMethod时间:1534690399458B 调用waitMethod时间:1534690399458A获得锁的时间:1534690399459B没有获得锁</code></pre><h4 id="可中断锁"><a href="#可中断锁" class="headerlink" title="可中断锁"></a>可中断锁</h4><p>java的内置锁<code>synchronized</code>就是不可中断的锁，其不可中断的阻塞机制使得实现可取消的任务变得复杂。</p><p><code>Lock</code>是可中断锁，<code>lockInterruptibly</code>可以使得在获得锁的同时保持对中断的响应。</p><p><code>lockInterruptibly</code>基本使用方式:</p><pre><code class="java">public void method() throws InterruptedException {    lock.lockInterruptibly();    try {       //do something    }    finally {        lock.unlock();    }  }</code></pre><h3 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a>读写锁</h3><p><code>ReentrantReadWriteLock</code>读写锁，它除了实现了<code>Lock</code>接口外，同时也实现了<code>ReadWriteLock</code>接口。</p><pre><code class="java">public interface ReadWriteLock {    /**     * Returns the lock used for reading.     *     * @return the lock used for reading     */    Lock readLock();    /**     * Returns the lock used for writing.     *     * @return the lock used for writing     */    Lock writeLock();}</code></pre><p>总所周知，<code>ReentrantLock</code>是排它锁，无论什么操作（read or write），其同一时间只能一个线程访问。但是实际应用中，读操作往往是占据最多的场景，那么绝大部分读取的场景能否采用共享锁呢？<code>ReentrantReadWriteLock</code>就能满足这一点，它允许读读共享，但是读写，写写是排他的操作。</p><p>应用场景，见<a href="https://docs.oracle.com/javase/8/docs/api/" target="_blank" rel="noopener">java doc api</a>提供了一个读写锁的生动的使用范例：</p><blockquote><p> Here is a code sketch showing how to perform lock downgrading after updating a cache (exception handling is particularly tricky when handling multiple locks in a non-nested fashion):<code>`</code>javaclass CachedData {   Object data;   volatile boolean cacheValid;   final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();</p></blockquote><p>   void processCachedData() {     rwl.readLock().lock(); // 1.加读锁     if (!cacheValid) {       // Must release read lock before acquiring write lock       rwl.readLock().unlock(); // 2.释放读锁，因为要加写锁，不支持锁升级，只能先解读锁再加写锁       rwl.writeLock().lock();// 3.加写锁       try {         // Recheck state because another thread might have         // acquired write lock and changed state before we did.         if (!cacheValid) { // 见上面英文解释，简单的说避免重复写入数据           data = …           cacheValid = true;         }         // Downgrade by acquiring read lock before releasing write lock         rwl.readLock().lock();// 4.锁降级，写锁变读锁       } finally {         rwl.writeLock().unlock(); // Unlock write, still hold read  5.见英文，解写锁，仍然能读       }     }</p><pre><code> try {   use(data); } finally {   rwl.readLock().unlock(); // 6.最终释放读锁 }</code></pre><p>   } }<code>`</code>为什么要有锁降级？<br>因为锁降级的过程能避免在写锁释放，加读锁的过程中，此时读取的数据不会被其他线程竞争到写锁更新数据导致脏读问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>j.u.c</code>是实现java高并发必知必会的重要内容。在很多web相关框架中都有体现，也是java程序猿进阶的必备技能之一，多学多用。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;code&gt;jdk 1.5&lt;/code&gt;开始，新增了&lt;code&gt;java.util.concurrent&lt;/code&gt;包（以下简称&lt;code&gt;j.u.c&lt;/code&gt;），是一系列关于并发的工具类，是java并发编程必知必会的内容。今儿准备简单介绍一些常用的工具类。&lt;/p&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>再见，艾泽拉斯</title>
    <link href="https://www.chenruiwen.cn/essay/Goodbye-Azeroth/"/>
    <id>https://www.chenruiwen.cn/essay/Goodbye-Azeroth/</id>
    <published>2018-08-13T13:24:03.000Z</published>
    <updated>2018-08-13T15:19:33.583Z</updated>
    
    <content type="html"><![CDATA[<h2 id="再见"><a href="#再见" class="headerlink" title="再见"></a>再见</h2><p>终于，这一刻还是来了。2018年8月13日开始，彻底AFK了。虽然玩的菜，但好歹是玩的最久的游戏，就此告别，很开心有生之年去过艾泽拉斯。</p><a id="more"></a><h2 id="AFK的原因"><a href="#AFK的原因" class="headerlink" title="AFK的原因"></a>AFK的原因</h2><p>直接原因，是月卡的推出的这两年。官方公告：</p><blockquote><p>《魔兽世界》已于2016年8月4日从分钟付费模式转为包月畅玩模式。此后的两年内，账号里仍有剩余分钟时间的玩家可以选择继续消耗分钟进行游戏，也可通过游戏内的兑换功能，按以下比例将分钟换为包月模式下的天数：</p><p>150分钟=1天；不足150分钟的部分按150分钟计算</p><p>自2018年8月4日起，玩家将无法使用分钟时间继续登录游戏。我们将通过专题网站为这部分玩家提供如下的兑换选项：</p><p>150分钟=1天；不足150分钟的部分按150分钟计算</p><p>或以90分钟=1点的比例退还暴雪游戏点数至游戏账号关联的暴雪游戏通行证，小数部分向上取整，如7.1点计为8点。</p><p>注：账号冻结期间不能参与兑换；而通过战友招募等途径获取的免费时间将无法转为暴雪游戏点数，仅可换成包月天数。</p></blockquote><p>2016年的8月4日之前得到了官方公告，2016年8月4日后将不再支持点卡。于是乎大批休闲玩家(没时间一直玩)的玩家大批量囤游戏时间。没错，包括我，我囤了十张点卡。时间过得真的飞快，得到官方公告后才发现自那以后居然已经过了两年时间了…这两年的时间总共的游戏时间还不到24小时。</p><p>根本原因，则是时间。</p><p>今天，又重新把时间兑换成了战网点数。感觉青春突然又走了一些。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fu8exz3bf7j21ui1407fa.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fu8eybjlzej21uo13qk29.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fu8eyi1f1qj21ug13sgw6.jpg" alt=""></p><h2 id="初识艾泽拉斯"><a href="#初识艾泽拉斯" class="headerlink" title="初识艾泽拉斯"></a>初识艾泽拉斯</h2><p>那是2008年的夏天，那年初中刚毕业，和磊少顺子去常州找好哥们猴子玩。猴子算是我对电脑的”启蒙老师”，他教会了我电脑是如何用来玩游戏的。。。猴子初中的时候离开了我们。。。不是永久的那种，跟他父母移居到常州去了，每年还是能回蚌埠来玩几天的。</p><p>在常州度过了难忘的几天，我们宅在家里玩游戏，第一次接触魔兽是那时候看猴子和他朋友打22竞技场，他们是战德组合，猴子就是德，所以就打德。炫酷的界面，复杂的技能栏，各种监控插件，最重要的是种族好多啊，牛头人真的很可爱，仅次于兽人妹纸。</p><p>后来上了高一后，上网吧成了周末的必备活动，好孩子表示周一到周五不能上网吧，原因是没时间。</p><p>那时候的周末总是那么美好，周六上午包个早机，中午回家吃饭后上一会儿网接着去打球，简单而充实的快乐。高一那年，认识了鸣鸣，一个活逗比。那会儿开号也是要花一张大卡的，我俩分表练了侏儒盗贼和侏儒法师。为什么玩侏儒，可能是比较符合我们猥琐的气质吧。</p><p>那会儿印象最深的是艾尔文森林的鱼人族们，嗯，让我们跑尸的那群哇啦啦们。</p><p>然后是杀霍格，第一个小BOSS，年轻的我以为同级的怪都能打过，没想到是还得靠磊少的大号SS带了把。吐槽一下磊少的术士， ID:囡囡不坏。嗯，非常接地气。</p><p>第一个FB，西部荒野的地下矿井。还是靠磊少的SS。套用磊少一句话：火石法杖，极品。</p><p>后来记得很清楚，17级的时候，号被盗了。那时候的盗号还是非常疯狂的，用密保吧太费事，不用密保稳被盗，没想到的是我的不到20级的号都能被盗。于是乎，我的第一个侏儒贼算是折戟了。</p><h2 id="再识艾泽拉斯"><a href="#再识艾泽拉斯" class="headerlink" title="再识艾泽拉斯"></a>再识艾泽拉斯</h2><p>很长一段时间没有玩了，后来猴子给了个号，44级人类盗贼，又让我重新回到艾泽拉斯。不得不说，人类盗贼潜行的样子真的很猥琐。</p><p>第一次荣誉击杀，是在塔纳瑞斯，野外遇到一个部落的猎人，第一反应，潜行。嗯，盗贼就得有盗贼的样子。悄悄潜过去，偷袭，背刺，肾击。总之就是一顿技能上去追着干。职业优势了也是，拿下艾泽拉斯一血。</p><p>【得睡觉了，未完待续…】</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;再见&quot;&gt;&lt;a href=&quot;#再见&quot; class=&quot;headerlink&quot; title=&quot;再见&quot;&gt;&lt;/a&gt;再见&lt;/h2&gt;&lt;p&gt;终于，这一刻还是来了。2018年8月13日开始，彻底AFK了。虽然玩的菜，但好歹是玩的最久的游戏，就此告别，很开心有生之年去过艾泽拉斯。&lt;/p&gt;
    
    </summary>
    
      <category term="essay" scheme="https://www.chenruiwen.cn/categories/essay/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
  </entry>
  
  <entry>
    <title>MacOS解决pycurl安装的坑</title>
    <link href="https://www.chenruiwen.cn/python/macos-fix-problem-about-pycurl-install/"/>
    <id>https://www.chenruiwen.cn/python/macos-fix-problem-about-pycurl-install/</id>
    <published>2018-08-11T02:20:07.000Z</published>
    <updated>2018-08-14T14:12:02.744Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>记录<code>macos</code>安装<code>pycurl</code>过程中的爬坑过程。</p><a id="more"></a><h2 id="爬坑过程记录"><a href="#爬坑过程记录" class="headerlink" title="爬坑过程记录"></a>爬坑过程记录</h2><p>本来目的是安装<code>pyspider</code>的, 安装<code>pyspider</code>必须依赖<code>pycurl</code>。</p><p>本人环境：</p><ul><li>Python 3.6.4</li><li>MacOS 10.12 Sierra</li></ul><h3 id="初次安装-pycurl"><a href="#初次安装-pycurl" class="headerlink" title="初次安装 pycurl"></a>初次安装 pycurl</h3><p>第一次安装pycurl。直接 <code>pip</code> 安装</p><pre><code>pip install pycurl</code></pre><p>可是安装并不顺利。安装报错:</p><pre><code>    ...  File &quot;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-y_b53n5l/pycurl/setup.py&quot;, line 316, in configure_unix    specify the SSL backend manually.&#39;&#39;&#39;)__main__.ConfigurationError: Curl is configured to use SSL, but we have not been able to determine which SSL backend it is using. Please see PycURL documentation for how to specify the SSL backend manually.----------------------------------------Command &quot;python setup.py egg_info&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-y_b53n5l/pycurl/</code></pre><p>可以看到报错应该是因为 使用ssl配置的原因。查看<a href="https://pycurl.io/docs/latest/install.html" target="_blank" rel="noopener">官方PycURL Installation¶</a>，可以不使用ssl安装。</p><h3 id="第二次安装-pycurl"><a href="#第二次安装-pycurl" class="headerlink" title="第二次安装 pycurl"></a>第二次安装 pycurl</h3><p>第二次安装，配置不使用ssl安装。</p><pre><code># upgrade pip if necessarypip install --upgrade pip# remove current pycurlpip uninstall pycurl# set PYCURL_SSL_LIBRARYexport PYCURL_SSL_LIBRARY=nss# recompile and install pycurlpip install --compile pycurl</code></pre><p>可是还是报错:</p><pre><code>...build/temp.macosx-10.12-x86_64-3.6/src/stringcompat.o build/temp.macosx-10.12-x86_64-3.6/src/threadsupport.o build/temp.macosx-10.12-x86_64-3.6/src/util.o -lssl3 -lcurl -o build/lib.macosx-10.12-x86_64-3.6/pycurl.cpython-36m-darwin.so    ld: library not found for -lssl3    clang: error: linker command failed with exit code 1 (use -v to see invocation)    error: command &#39;clang&#39; failed with exit status 1    ----------------------------------------Command &quot;/Users/chenruiwen/.pyenv/versions/3.6.4/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&#39;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-syesb72n/pycurl/setup.py&#39;;f=getattr(tokenize, &#39;open&#39;, open)(__file__);code=f.read().replace(&#39;\r\n&#39;, &#39;\n&#39;);f.close();exec(compile(code, __file__, &#39;exec&#39;))&quot; install --record /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-record-ch2zxgp5/install-record.txt --single-version-externally-managed --compile&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-syesb72n/pycurl/</code></pre><p>二次吐血。</p><h3 id="第三次安装pycurl"><a href="#第三次安装pycurl" class="headerlink" title="第三次安装pycurl"></a>第三次安装pycurl</h3><p>还是根据官网，<code>nss</code>不可以，配置成<code>openssl</code>试试吧。</p><pre><code>pip uninstall pycurlexport PYCURL_SSL_LIBRARY=opensslpip install --compile pycurl</code></pre><p>还是那个熟悉的味道:</p><pre><code>...clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Cellar/openssl/1.0.2o_1/include -DPYCURL_VERSION=&quot;7.43.0.2&quot; -DHAVE_CURL_SSL=1 -DHAVE_CURL_OPENSSL=1 -DHAVE_CURL_SSL=1 -I/Users/chenruiwen/.pyenv/versions/3.6.4/include/python3.6m -c src/docstrings.c -o build/temp.macosx-10.12-x86_64-3.6/src/docstrings.o    In file included from src/docstrings.c:4:    src/pycurl.h:164:13: fatal error: &#39;openssl/ssl.h&#39; file not found    #   include &lt;openssl/ssl.h&gt;                ^~~~~~~~~~~~~~~    1 error generated.    error: command &#39;clang&#39; failed with exit status 1    ----------------------------------------Command &quot;/Users/chenruiwen/.pyenv/versions/3.6.4/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&#39;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-aavrg23s/pycurl/setup.py&#39;;f=getattr(tokenize, &#39;open&#39;, open)(__file__);code=f.read().replace(&#39;\r\n&#39;, &#39;\n&#39;);f.close();exec(compile(code, __file__, &#39;exec&#39;))&quot; install --record /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-record-l0npewt_/install-record.txt --single-version-externally-managed --compile&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-aavrg23s/pycurl/</code></pre><p>三次吐血。可以看到引入 <code>openssl/ssl.h</code>失败了。继续google解决一下。</p><h3 id="第四次安装pycurl"><a href="#第四次安装pycurl" class="headerlink" title="第四次安装pycurl"></a>第四次安装pycurl</h3><p>从 <code>stackoverflow</code> 搜到一个<a href="https://stackoverflow.com/questions/21096436/ssl-backend-error-when-using-openssl" target="_blank" rel="noopener">解决方案</a>,准备尝试一下。</p><pre><code>pip uninstall pycurlexport PYCURL_SSL_LIBRARY=opensslexport LDFLAGS=-L/usr/local/opt/openssl/libexport CPPFLAGS=-I/usr/local/opt/openssl/includepip install pycurl --compile --no-cache-dir</code></pre><p>果然安装成功了！可喜可贺！可是我们用python导入pycurl试试：</p><pre><code>&gt;&gt;&gt; import pycurlTraceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ImportError: pycurl: libcurl link-time ssl backend (none/other) is different from compile-time ssl backend (openssl)</code></pre><p>四次吐血。 不过这次的问题应该是系统版本问题，刚刚 <code>stackoverflow</code>上的解决方案要求是系统<code>OSX 10.13</code>，于是乎备份系统，升级到<code>macOS 10.13 High Sierra</code>。大胆的童鞋可以不备份升级，比如我(:D)。</p><p>升级完成后尝试一下导入pycurl:</p><pre><code>&gt;&gt;&gt; import pycurl&gt;&gt;&gt;</code></pre><p>成功解决问题。吐血完毕。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;记录&lt;code&gt;macos&lt;/code&gt;安装&lt;code&gt;pycurl&lt;/code&gt;过程中的爬坑过程。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="https://www.chenruiwen.cn/categories/python/"/>
    
    
      <category term="python" scheme="https://www.chenruiwen.cn/tags/python/"/>
    
      <category term="pycurl" scheme="https://www.chenruiwen.cn/tags/pycurl/"/>
    
  </entry>
  
  <entry>
    <title>redis“冷门”知识点：HyperLogLog</title>
    <link href="https://www.chenruiwen.cn/redis/redis-hyperloglog/"/>
    <id>https://www.chenruiwen.cn/redis/redis-hyperloglog/</id>
    <published>2018-08-05T07:08:24.000Z</published>
    <updated>2018-08-13T14:23:20.831Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前几天，我司大牛分享redis知识点，讲到redis数据结构的时候，抛出一个问题：如果要统计网站uv，你准备怎么实现？</p><p>和大多数普通开发人员一样，想到的第一个想法是存到set集合里。可是这样真的好吗？</p><p>后来找到了更好的方式，redis“冷门”数据结构:<code>HyperLogLog</code>。（说是“冷门”，可能只是我不知道罢了:D）</p><a id="more"></a><h2 id="问题回顾"><a href="#问题回顾" class="headerlink" title="问题回顾"></a>问题回顾</h2><blockquote><p>你准备如何实现统计大型网站的网页UV数据？</p></blockquote><p>uv数据不像pv数据，pv可能只需要在redis中使用一个计数器，每次访问<code>incrby</code>一次即可。uv数据需要根据用户id来标识唯一来统计，集合中的数据需要去重，那么<code>set</code>是一个最容易想到的数据结构。现在的问题是，大型网站，可能这是一个爆款商品的秒杀页面，用户访问量非常大，假如有上千万的uv估计，那么占用的空间就非常大，而我仅仅只是想要一个<code>set</code>的<code>size</code>，岂不是杀鸡用了宰牛刀了？而且，uv数据一定要精确吗？uv数据存在一些误差可不可以？有没有更好的解决方案？</p><p>uv数据当然可以存在误差，更好的解决方案当然有。那就是redis的<code>HyperLogLog</code>。</p><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>本文主角<code>HyperLogLog</code>，redis的一种数据结构，可能不被大多数人知道，但却是非常有用的数据。</p><h3 id="HyperLogLog是什么"><a href="#HyperLogLog是什么" class="headerlink" title="HyperLogLog是什么"></a>HyperLogLog是什么</h3><p>Redis 在 <code>2.8.9</code> 版本添加了HyperLogLog结构。</p><p>Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。</p><p>但是，因为HyperLogLog只会根据输入元素来计算基数，而不会储存输入元素本身，所以HyperLogLog 不能像集合那样，返回输入的各个元素。</p><p>可见，专业的人做专业的事，HyperLogLog在做基数统计方面是一流的。</p><h3 id="HyperLogLog怎么玩"><a href="#HyperLogLog怎么玩" class="headerlink" title="HyperLogLog怎么玩"></a>HyperLogLog怎么玩</h3><h4 id="HyperLogLog的三个指令"><a href="#HyperLogLog的三个指令" class="headerlink" title="HyperLogLog的三个指令:"></a><code>HyperLogLog</code>的三个指令:</h4><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>PFADD key element [element …]</td><td>添加指定元素到 HyperLogLog 中。</td></tr><tr><td>PFCOUNT key [key …]</td><td>返回给定 HyperLogLog 的基数估算值。</td></tr><tr><td>PFMERGE destkey sourcekey [sourcekey …]</td><td>将多个 HyperLogLog 合并为一个 HyperLogLog</td></tr></tbody></table><h4 id="小试牛刀"><a href="#小试牛刀" class="headerlink" title="小试牛刀"></a>小试牛刀</h4><p>以计算uv为例，假如统计网站首页uv人数，路径<code>/index</code>，我们使用<code>pfadd</code>增加计数，<code>pfcount</code>统计人数。使用方式类似于<code>set</code>集合的<code>sadd</code>和<code>scard</code>。</p><pre><code>127.0.0.1:6379[1]&gt; pfadd /index user_1(integer) 1127.0.0.1:6379[1]&gt; pfadd /index user_2(integer) 1127.0.0.1:6379[1]&gt; pfcount /index(integer) 2127.0.0.1:6379[1]&gt; pfadd /index user_3(integer) 1127.0.0.1:6379[1]&gt; pfcount /index(integer) 3127.0.0.1:6379[1]&gt; pfadd /index user_4(integer) 1127.0.0.1:6379[1]&gt; pfcount /index(integer) 4127.0.0.1:6379[1]&gt; pfadd /index user_1(integer) 0127.0.0.1:6379[1]&gt; pfcount /index(integer) 4127.0.0.1:6379[1]&gt; pfadd /index user_5 user_6 user_7(integer) 1127.0.0.1:6379[1]&gt; pfcount /index(integer) 7</code></pre><p>目前看数值都是正确的，我们用程序加大user数据看看精确度怎么样。</p><p>此处用Python实现吧，你懂的，毕竟人生苦短。</p><pre><code># coding: utf-8import redisdef start_test():    r = redis.Redis(host=&#39;localhost&#39;, port=6379, decode_responses=True)    client = redis.StrictRedis()    for i in range(100000):        client.pfadd(&quot;/index&quot;, &quot;user%d&quot; % i)    print(&quot;用户真实人数:&quot;, 100000, &quot;,统计uv数:&quot; , client.pfcount(&quot;/index&quot;))if __name__ == &#39;__main__&#39;:    start_test();</code></pre><p>输出结果:</p><pre><code>用户真实人数: 100000 ,统计uv数: 99723</code></pre><p>可见正确率有<code>99.723%</code>，误差可以接受的范围</p><h3 id="HyperLogLog的底层原理"><a href="#HyperLogLog的底层原理" class="headerlink" title="HyperLogLog的底层原理"></a>HyperLogLog的底层原理</h3><p>建议阅读文章：<a href="https://blog.csdn.net/firenet1/article/details/77247649" target="_blank" rel="noopener">神奇的HyperLogLog算法</a></p><p>其底层的实现原理还是比较复杂，感兴趣的童鞋可以多多了解。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在统计不是很要求精确的统计计数时，可以考虑使用redis的<code>HyperLogLog</code>数据结构。它的占用内存非常小，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。当数值非常大时，它的优势就越发明显。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前几天，我司大牛分享redis知识点，讲到redis数据结构的时候，抛出一个问题：如果要统计网站uv，你准备怎么实现？&lt;/p&gt;
&lt;p&gt;和大多数普通开发人员一样，想到的第一个想法是存到set集合里。可是这样真的好吗？&lt;/p&gt;
&lt;p&gt;后来找到了更好的方式，redis“冷门”数据结构:&lt;code&gt;HyperLogLog&lt;/code&gt;。（说是“冷门”，可能只是我不知道罢了:D）&lt;/p&gt;
    
    </summary>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/categories/redis/"/>
    
    
      <category term="redis" scheme="https://www.chenruiwen.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>Java SE1.6中的Synchronized</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-concurrency-se-16-synchronized/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-concurrency-se-16-synchronized/</id>
    <published>2018-07-29T08:40:24.000Z</published>
    <updated>2018-07-29T09:38:51.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ww1.sinaimg.cn/large/87faef88ly1ftquomgo3sj20m80ciq4e.jpg" alt=""></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>多线程并发，你最先想到的加锁使用方式是什么？我想几乎百分百会想到这个关键字:<code>Synchronized</code>。</p><p>关于<code>Synchronized</code>的底层原理，可能大部分java程序猿都没有太多的了解。本文将洞悉<code>Synchronized</code>那些小细节。</p><p>本文摘自 <a href="https://www.infoq.com/" target="_blank" rel="noopener">infoq</a> 上阿里巴巴的技术专家<a href="https://www.infoq.com/cn/profile/%E6%96%B9%E8%85%BE%E9%A3%9E" target="_blank" rel="noopener">方腾飞</a>老师的文章。</p><p>原文地址：<a href="https://www.infoq.com/cn/articles/java-se-16-synchronized" target="_blank" rel="noopener">聊聊并发（二）Java SE1.6中的Synchronized</a></p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，有些情况下它并不那么重了，本文详细介绍了Java SE1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。</p><h2 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a>术语定义</h2><table><thead><tr><th>术语</th><th>英文</th><th>说明 </th></tr></thead><tbody><tr><td>CAS</td><td>Compare and Swap</td><td>比较并设置。用于在硬件层面上提供原子性操作。在 Intel 处理器中，比较并交换通过指令cmpxchg实现。比较是否和给定的数值一致，如果一致则修改，不一致则不修改。</td></tr></tbody></table><h2 id="同步的基础"><a href="#同步的基础" class="headerlink" title="同步的基础"></a>同步的基础</h2><p>Java中的每一个对象都可以作为锁。</p><ul><li>对于同步方法，锁是当前实例对象。</li><li>对于静态同步方法，锁是当前对象的Class对象。</li><li>对于同步方法块，锁是Synchonized括号里配置的对象。</li></ul><p>当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁存在哪里呢？锁里面会存储什么信息呢？</p><h2 id="同步的原理"><a href="#同步的原理" class="headerlink" title="同步的原理"></a>同步的原理</h2><p>JVM规范规定JVM基于进入和退出<code>Monitor</code>对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用<code>monitorenter</code>和<code>monitorexit</code>指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。<code>monitorenter</code>指令是在编译后插入到同步代码块的开始位置，而<code>monitorexit</code>是插入到方法结束处和异常处， JVM要保证每个<code>monitorenter</code>必须有对应的<code>monitorexit</code>与之配对。任何对象都有一个 <code>monitor</code> 与之关联，当且一个<code>monitor</code> 被持有后，它将处于锁定状态。线程执行到 <code>monitorenter</code> 指令时，将会尝试获取对象所对应的 <code>monitor</code> 的所有权，即尝试获得对象的锁。</p><h3 id="Java对象头"><a href="#Java对象头" class="headerlink" title="Java对象头"></a>Java对象头</h3><p>锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。</p><table><thead><tr><th>长度</th><th>内容</th><th>说明 </th></tr></thead><tbody><tr><td>32/64bit</td><td>Mark Word</td><td>存储对象的hashCode或锁信息等。</td></tr><tr><td>32/64bit</td><td>Class Metadata Address</td><td>存储到对象类型数据的指针</td></tr><tr><td>32/64bit</td><td>Array length</td><td>数组的长度（如果当前对象是数组）</td></tr></tbody></table><p>Java对象头里的<code>Mark Word</code>里默认存储对象的<code>HashCode</code>，分代年龄和锁标记位。32位JVM的<code>Mark Word</code>的默认存储结构如下：</p><table>    <tr>        <th></th>        <th>25 bit</th>        <th>4bit</th>        <th>1bit是否是偏向锁</th>        <th>2bit锁标志位</th>    </tr>    <tr>        <th>无锁状态</th>        <th>对象的hashCode</th>        <th>对象分代年龄</th>        <th>0</th>        <th>01</th>    </tr></table><p>在运行期间<code>Mark Word</code>里存储的数据会随着锁标志位的变化而变化。<code>Mark Word</code>可能变化为存储以下4种数据：</p><table>    <tr>        <th rowspan="2">锁状态</th>        <th colspan="2">25 bit</th>        <th rowspan="2">4bit</th>        <th>1bit</th>        <th>2bit</th>    </tr>    <tr>        <th>23bit</th>        <th>2bit</th>        <th>是否是偏向锁</th>        <th>锁标志位</th>    </tr>    <tr>        <th>轻量级锁</th>        <th colspan="4">指向栈中锁记录的指针</th>        <th>00</th>    </tr>    <tr>        <th>重量级锁</th>        <th colspan="4">指向互斥量（重量级锁）的指针</th>        <th>10</th>    </tr>    <tr>        <th>GC标记</th>        <th colspan="4">空</th>        <th>11</th>    </tr>    <tr>        <th>偏向锁</th>        <th>线程ID</th>        <th>Epoch</th>        <th>对象分代年龄</th>        <th>1</th>        <th>01</th>    </tr></table><p>在64位虚拟机下，<code>Mark Word</code>是64bit大小的，其存储结构如下： </p><table>    <tr>        <th rowspan="2">锁状态</th>        <th>25 bit</th>        <th>31bit</th>        <th>1bit</th>        <th>4bit</th>        <th>1bit</th>        <th>2bit</th>    </tr>    <tr>        <th></th>        <th></th>        <th>cms_free</th>        <th>分代年龄</th>        <th>偏向锁</th>        <th>锁标志位</th>    </tr>    <tr>        <th>无锁</th>        <th>unused</th>        <th>hashCode</th>        <th></th>        <th></th>        <th>0</th>        <th>01</th>    </tr>    <tr>        <th>偏向锁</th>        <th colspan="2">ThreadID(54bit) Epoch(2bit)</th>        <th></th>        <th></th>        <th>1</th>        <th>01</th>    </tr></table><h3 id="锁的升级"><a href="#锁的升级" class="headerlink" title="锁的升级"></a>锁的升级</h3><p>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，<code>无锁状态</code>，<code>偏向锁状态</code>，<code>轻量级锁状态</code>和<code>重量级锁状态</code>，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1ftqrb6oxy3j20ol03w74r.jpg" alt=""></p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。</p><p>偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1ftqrib054vj20o10qxjx1.jpg" alt=""></p><p>关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟<code>-XX:BiasedLockingStartupDelay=0</code>。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁<code>-XX:-UseBiasedLocking=false</code>，那么默认会进入轻量级锁状态。</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为<code>Displaced Mark Word</code>。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p><p>轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将<code>Displaced Mark Word</code>替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1ftqroqob22j20o10ncgs6.jpg" alt=""></p><p>因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。</p><h2 id="锁的优缺点对比"><a href="#锁的优缺点对比" class="headerlink" title="锁的优缺点对比"></a>锁的优缺点对比</h2><table>    <tr>        <th>锁</th>        <th>优点</th>        <th>缺点</th>        <th>适用场景</th>    </tr>    <tr>        <th>偏向锁</th>        <th>加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。</th>        <th>如果线程间存在锁竞争，会带来额外的锁撤销的消耗。</th>        <th>适用于只有一个线程访问同步块场景。</th>    </tr>    <tr>        <th>轻量级锁</th>        <th>竞争的线程不会阻塞，提高了程序的响应速度。</th>        <th>如果始终得不到锁竞争的线程使用自旋会消耗CPU。</th>        <th>追求响应时间。<br>同步块执行速度非常快。</th>    </tr>    <tr>        <th>重量级锁</th>        <th>线程竞争不使用自旋，不会消耗CPU。</th>        <th>线程阻塞，响应时间缓慢。</th>        <th>追求吞吐量。<br>同步块执行速度较长。</th>    </tr></table><h2 id="参考源码"><a href="#参考源码" class="headerlink" title="参考源码"></a>参考源码</h2><p>本文一些内容参考了<a href="https://hg.openjdk.java.net/jdk/jdk/file/2ce72467c4e8/src/hotspot/share" target="_blank" rel="noopener">HotSpot</a>源码 。对象头源码<code>markOop.hpp</code>。偏向锁源码<code>biasedLocking.cpp</code>。以及其他源码<code>ObjectMonitor.cpp</code>和<code>BasicLock.cpp</code>。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.oracle.com/technetwork/java/javase/tech/biasedlocking-oopsla2006-preso-150106.pdf" target="_blank" rel="noopener">偏向锁</a></li><li><a href="https://pdffinder.net/Java-Overview-and-Java-SE-6-What&#39;s-New.html" target="_blank" rel="noopener">java-overview-and-java-se6</a> Synchronization Optimization章节</li><li>Dave Dice <a href="https://home.comcast.net/~pjbishop/Dave/MustangSync.pdf" target="_blank" rel="noopener"> “Synchronization in Java SE 6”</a></li><li><a href="https://java.sun.com/performance/reference/whitepapers/6_performance.html#2.1.3" target="_blank" rel="noopener">Java SE 6 Performance White Paper </a> 2.1章节</li><li><a href="https://docs.oracle.com/javase/specs/jvms/se7/html/index.html" target="_blank" rel="noopener">JVM规范（Java SE 7）</a></li><li><a href="https://docs.oracle.com/javase/specs/jls/se7/html/" target="_blank" rel="noopener">Java语言规范（JAVA SE7）</a></li><li><a href="https://book.douban.com/subject/6522893/" target="_blank" rel="noopener">周志明的《深入理解Java虚拟机》</a></li><li><a href="https://kenwublog.com/theory-of-java-biased-locking" target="_blank" rel="noopener">Java偏向锁实现原理</a></li><li><a href="https://wikis.oracle.com/display/HotSpotInternals/Synchronization" target="_blank" rel="noopener">hotspot Synchronization</a></li></ul><h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><p>java中锁的四种状态:无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态。各有千秋，并且锁会随着竞争情况逐渐升级，且不会降级，好处是提高获得锁和释放锁的效率。</p><p>关于四种锁的使用，还是要分场景和尽量多的测试性能。</p><p>关于<code>synchronized</code>，早起的版本效率很低，从java6开始有了较多的优化。如果生成环境的jdk版本较低,低于1.5，建议尽量少使用，同步尽量使用<code>ReentrantLock</code>。如果jdk版本比较高，java8以后还是可以考虑<code>synchronized</code>的，效率并不差。</p><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>最后，还是非常感谢本文的原创作者:</p><p><strong>方腾飞</strong>，阿里巴巴资深软件开发工程师，致力于高性能网络和并发编程，目前在公司从事询盘管理和长连接服务器OpenComet的开发工作。</p><ul><li>博客地址：<a href="https://ifeve.com" target="_blank" rel="noopener">https://ifeve.com</a> </li><li>微博地址：<a href="https://weibo.com/kirals" target="_blank" rel="noopener">https://weibo.com/kirals</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://ww1.sinaimg.cn/large/87faef88ly1ftquomgo3sj20m80ciq4e.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;多线程并发，你最先想到的加锁使用方式是什么？我想几乎百分百会想到这个关键字:&lt;code&gt;Synchronized&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;关于&lt;code&gt;Synchronized&lt;/code&gt;的底层原理，可能大部分java程序猿都没有太多的了解。本文将洞悉&lt;code&gt;Synchronized&lt;/code&gt;那些小细节。&lt;/p&gt;
&lt;p&gt;本文摘自 &lt;a href=&quot;https://www.infoq.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;infoq&lt;/a&gt; 上阿里巴巴的技术专家&lt;a href=&quot;https://www.infoq.com/cn/profile/%E6%96%B9%E8%85%BE%E9%A3%9E&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;方腾飞&lt;/a&gt;老师的文章。&lt;/p&gt;
&lt;p&gt;原文地址：&lt;a href=&quot;https://www.infoq.com/cn/articles/java-se-16-synchronized&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;聊聊并发（二）Java SE1.6中的Synchronized&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="转载摘抄" scheme="https://www.chenruiwen.cn/tags/%E8%BD%AC%E8%BD%BD%E6%91%98%E6%8A%84/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>spring-boot优雅使用redis集中式缓存</title>
    <link href="https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-redis/"/>
    <id>https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-redis/</id>
    <published>2018-07-25T12:26:10.000Z</published>
    <updated>2018-07-25T12:40:59.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ws1.sinaimg.cn/large/87faef88ly1ftmdpcaqwwj20dw08cq2w.jpg" alt=""></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前的文章<a href="https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-guava/">spring-boot优雅的使用缓存</a>介绍了使用spring3开始的cache功能，并使用<code>guava</code>实现完成一次示例。但是在分布式环境下，进程内的本地缓存是独立的，在一些场景并不使用。</p><p>在现在互联网企业中广泛使用了一些中间件比如<code>memcache</code>,<code>redis</code>等来实现分布式环境下的集中式缓存。本文将介绍spring-boot下集成redis做缓存的实现细节。</p><a id="more"></a><h2 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h2><p><a href="https://redis.io/" target="_blank" rel="noopener">redis</a>是开源免费的、高性能key-value数据库。它的特点主要有：</p><ul><li>高性能，基于内存内的数据结构，读写性能都很好</li><li>支持持久化，数据支持写进磁盘</li><li>数据结构有五种形式，string,list，set，zset，hash，各有特点，使用场景广泛。</li><li>高可用，支持集群</li><li>支持发布/订阅</li></ul><p>现如今大多公司使用<code>redis</code>，大有替代<code>memcache</code>的意思(具体根据业务场景选型)。</p><h2 id="集成redis"><a href="#集成redis" class="headerlink" title="集成redis"></a>集成redis</h2><p>依旧三步完成redis缓存：</p><ul><li>maven依赖</li><li>配置redis和缓存</li><li>代码使用及测试</li></ul><h3 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h3><p><code>1.4.x</code>版本的spring-boot可依赖如下:</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>但是从<code>1.5.x</code>开始已经被废弃，请依赖如下:</p><pre><code>&lt;!-- redis --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h3 id="配置文件application-yml添加redis相关配置，以及缓存开启为redis"><a href="#配置文件application-yml添加redis相关配置，以及缓存开启为redis" class="headerlink" title="配置文件application.yml添加redis相关配置，以及缓存开启为redis."></a>配置文件<code>application.yml</code>添加<code>redis</code>相关配置，以及缓存开启为<code>redis</code>.</h3><pre><code>spring:# redis  redis:    database: 2    host: 127.0.0.1    port: 6379    password:    pool:      max-active: 8      max-wait: -1      max-idle: 8      min-idle: 0    timeout: 0# cache  cache:    type: redis</code></pre><h3 id="代码使用及单元测试"><a href="#代码使用及单元测试" class="headerlink" title="代码使用及单元测试"></a>代码使用及单元测试</h3><h4 id="redis的配置类"><a href="#redis的配置类" class="headerlink" title="redis的配置类"></a>redis的配置类</h4><p>在<code>spring-boot-autoconfigure</code>包中的<code>RedisAutoConfiguration</code>类中有自动装配了<code>RedisConnectionFactory</code>,<code>RedisTemplate</code>,无需多配置即可完成直接调用即可。</p><p>但是此处我们想要定制<code>RedisTemplate</code>,因为默认的<code>RedisTemplate</code>的<code>keySerializer</code>和<code>valueSerializer</code>都是默认的<code>JdkSerializationRedisSerializer</code>。由于业务的需要(强迫症+颜控)，我们希望<code>key</code>是字符串类型，<code>value</code>是json格式。如下修改<code>RedisTemplate</code>的序列化格式即可:</p><pre><code class="java">@Beanpublic RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) {    RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();    redisTemplate.setConnectionFactory(redisConnectionFactory);    // 使用Jackson2JsonRedisSerialize 替换默认序列化    Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);    ObjectMapper objectMapper = new ObjectMapper();    objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);    objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);    jackson2JsonRedisSerializer.setObjectMapper(objectMapper);    // 设置value的序列化规则和 key的序列化规则    redisTemplate.setKeySerializer(new StringRedisSerializer());    redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);    redisTemplate.afterPropertiesSet();    return redisTemplate;}</code></pre><h4 id="cache配置使用redis"><a href="#cache配置使用redis" class="headerlink" title="cache配置使用redis"></a>cache配置使用redis</h4><p>当<code>application.yml</code>指定为<code>spring.cache.type=redis</code>时，即已经会自动加载<code>spring-boot-autoconfigure</code>包中的<code>RedisCacheConfiguration</code>,从源码中可以看到它自动装配了<code>RedisCacheManager</code>，原则上无需配置直接使用即可。</p><p>但是此处默认的<code>RedisCacheManager</code>不没有设置过期时间，即不过期。这显然不合理。因此需要自定义<code>RedisCacheManager</code>。</p><p>有两种方式自定义<code>RedisCacheManager</code>:</p><ul><li>直接装配<code>RedisCacheManager</code></li><li>装配<code>CacheManagerCustomizer</code></li></ul><p>方式一. 直接手动装配<code>RedisCacheManager</code>方式如下:</p><pre><code class="java">@Beanpublic CacheManager redisCacheManager(RedisTemplate redisTemplate) {    RedisCacheManager redisCacheManager = new RedisCacheManager(redisTemplate);    redisCacheManager.setDefaultExpiration(60L); // 默认缓存 1 分钟    redisCacheManager.setUsePrefix(true);    Map&lt;String, Long&gt; expires = new ConcurrentHashMap&lt;String, Long&gt;(2);    expires.put(&quot;userCache&quot;, 90L); // 指定 cacheName 缓存时间    redisCacheManager.setExpires(expires);    return redisCacheManager;}</code></pre><p>方式二. spring boot添加了可扩展<code>RedisCacheManager</code>的方式，即<code>CacheManagerCustomizer</code>接口。可通过装配<code>CacheManagerCustomizer</code>的实现，实现其<code>customize(T cacheManager)</code>方法即可实现自定义：</p><pre><code class="java">@Beanpublic CacheManagerCustomizer redisCacheManagerCustomizer() {    return (CacheManagerCustomizer&lt;RedisCacheManager&gt;) cacheManager -&gt; {        cacheManager.setDefaultExpiration(60L);// 默认过期时间，单位秒        Map&lt;String, Long&gt; expires = new ConcurrentHashMap&lt;&gt;(2);        expires.put(&quot;userCache&quot;, 2000L); // 指定 cacheName 缓存时间        cacheManager.setExpires(expires);    };}</code></pre><h4 id="测试redis操作"><a href="#测试redis操作" class="headerlink" title="测试redis操作"></a>测试redis操作</h4><p>首先测试通过<code>redisTemplate</code>来操作redis。测试用例:</p><pre><code>@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = App.class)public class RedisTemplateTest {    @Autowired    private StringRedisTemplate redisTemplate;    @Test    public void test() {        redisTemplate.opsForValue().set(&quot;key1&quot;, &quot;value1&quot;);        String value1 = redisTemplate.opsForValue().get(&quot;key1&quot;);        Assert.assertEquals(&quot;value1&quot;, value1);    }}</code></pre><p>调用正常结束，查看redis库中有此缓存。</p><h4 id="测试redis缓存"><a href="#测试redis缓存" class="headerlink" title="测试redis缓存"></a>测试redis缓存</h4><p>比如我们有个User服务，代码如下:</p><pre><code class="java">@Service@CacheConfig(cacheNames = &quot;userCache&quot;)public class SbpUserServiceImpl implements SbpUserService {    @Resource    private SbpUserMapper sbpUserMapper;    @Override    @CachePut(key = &quot;&#39;id:&#39;+ #p0.id&quot;)    public SbpUser insert(SbpUser user) {        sbpUserMapper.insert(user);        return user;    }    @Override    @CachePut(key = &quot;&#39;id:&#39;+ #p0.id&quot;)    public SbpUser update(SbpUser user) {        sbpUserMapper.updateByPrimaryKey(user);        return user;    }    @Override    @CacheEvict(allEntries = true, beforeInvocation = true)// 清空 userCache 缓存    public int insertList(List&lt;SbpUser&gt; list) {        return sbpUserMapper.insertList(list);    }    @Override    public Page&lt;SbpUser&gt; getListPageInfo(int pageNo, int pageSize) {        // 开启分页        Page&lt;SbpUser&gt; page = PageHelper.startPage(pageNo, pageSize);        sbpUserMapper.getAll();        return page;    }    @Override    @CacheEvict(key = &quot;&#39;id:&#39;+#id&quot;, beforeInvocation = true)    public boolean deleteById(Long id) {        return sbpUserMapper.deleteByPrimaryKey(id) &gt; 0;    }    @Override    @Cacheable(key = &quot;&#39;id:&#39;+ #id&quot;)    public SbpUser getObjectById(Long id) {        return sbpUserMapper.selectByPrimaryKey(id);    }}</code></pre><p>说明:</p><ul><li><code>@CacheConfig(cacheNames = &quot;userCache&quot;)</code>注解表示<code>SbpUserServiceImpl</code>服务下的所有缓存的前缀加上了”userCache”。注意前提是<code>RedisCacheManager</code>配置的<code>usePrefix</code>为<code>true</code>时才生效。</li><li><code>@CachePut</code>注解使得数据更新时放入缓存，此处在<code>insert</code>和<code>update</code>方法时都使用了此注解更新缓存。</li><li><code>@CacheEvict</code>注解用在<code>delete</code>方法上，并配置了删除时清空”userCache”里的缓存。</li><li><code>@Cacheable</code>设置了查询缓存。</li></ul><p>单元测试用例:</p><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = App.class)@Slf4jpublic class SbpUserServiceTest {    @Autowired    private SbpUserService sbpUserService;    @Autowired    private RedisTemplate redisTemplate;    @Test    public void testRedisCache() {        long now = System.currentTimeMillis();        SbpUser user1 = SbpUser.builder().id(666L).mobile(&quot;11100006666&quot;)                .nickName(&quot;老A&quot;).password(&quot;111111&quot;)                .createAt(now).updateAt(now).build();        sbpUserService.insert(user1);        log.info(&quot;~~~~~~~~~~~~~insert data~~~~~~~~~~~~~~~~~~~~~~&quot;);        log.info(&quot;=============first select start===============&quot;);        SbpUser user2 = sbpUserService.getObjectById(666L);        log.info(&quot;=============first select end=================,user:{}&quot;, user2);        user2.setNickName(&quot;老B&quot;);        sbpUserService.update(user2);        log.info(&quot;~~~~~~~~~~~~~update data~~~~~~~~~~~~~~~~~~~~~~&quot;);        log.info(&quot;=============second select start===============&quot;);        SbpUser user3 = sbpUserService.getObjectById(666L);        log.info(&quot;=============second select end=================,user:{}&quot;, user3);        sbpUserService.deleteById(666L);        log.info(&quot;~~~~~~~~~~~~~delete data~~~~~~~~~~~~~~~~~~~~~~&quot;);        log.info(&quot;=============third select start===============&quot;);        SbpUser user4 = sbpUserService.getObjectById(666L);        log.info(&quot;=============third select end=================,user:{}&quot;, user4);        assert 666L == sbpUserService.insert(SbpUser.builder().id(666L).mobile(&quot;11100006666&quot;)                .nickName(&quot;老A&quot;).password(&quot;111111&quot;)                .createAt(now).updateAt(now).build()).getId();        redisTemplate.delete(&quot;userCache:id:666&quot;); // 手动删除redis缓存        log.info(&quot;~~~~~~~~~~~~~insert data and delete cache~~~~~~~~~~~~~~~~~~~~~~&quot;);        log.info(&quot;=============fourth select start===============&quot;);        SbpUser user5 = sbpUserService.getObjectById(666L);        log.info(&quot;=============fourth select end=================,user:{}&quot;, user5);    }}</code></pre><p>控制台输出:</p><pre><code>JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: insert into sbp_user (id, nick_name, password, mobile, create_at, update_at ) values (?, ?, ?, ?, ?, ? ) ==&gt; Parameters: 666(Long), 老A(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long)&lt;==    Updates: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@552ffa44]2018-07-24 21:45:02.196 [main] INFO  com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~insert data~~~~~~~~~~~~~~~~~~~~~~2018-07-24 21:45:02.199 [main] INFO  com.crw.service.SbpUserServiceTest - =============first select start===============2018-07-24 21:45:02.280 [main] INFO  com.crw.service.SbpUserServiceTest - =============first select end=================,user:SbpUser(id=666, nickName=老A, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401)Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@578198d9] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: update sbp_user set nick_name = ?, password = ?, mobile = ?, create_at = ?, update_at = ? where id = ? ==&gt; Parameters: 老B(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long), 666(Long)&lt;==    Updates: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@578198d9]2018-07-24 21:45:02.286 [main] INFO  com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~update data~~~~~~~~~~~~~~~~~~~~~~2018-07-24 21:45:02.287 [main] INFO  com.crw.service.SbpUserServiceTest - =============second select start===============2018-07-24 21:45:02.289 [main] INFO  com.crw.service.SbpUserServiceTest - =============second select end=================,user:SbpUser(id=666, nickName=老B, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401)Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3ff53704] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: delete from sbp_user where id = ? ==&gt; Parameters: 666(Long)&lt;==    Updates: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3ff53704]2018-07-24 21:45:02.298 [main] INFO  com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~delete data~~~~~~~~~~~~~~~~~~~~~~2018-07-24 21:45:02.298 [main] INFO  com.crw.service.SbpUserServiceTest - =============third select start===============Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@31b289da] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: select id, nick_name, password, mobile, create_at, update_at from sbp_user where id = ? ==&gt; Parameters: 666(Long)&lt;==      Total: 0Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@31b289da]2018-07-24 21:45:02.326 [main] INFO  com.crw.service.SbpUserServiceTest - =============third select end=================,user:nullCreating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58a7ca42] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: insert into sbp_user (id, nick_name, password, mobile, create_at, update_at ) values (?, ?, ?, ?, ?, ? ) ==&gt; Parameters: 666(Long), 老A(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long)&lt;==    Updates: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58a7ca42]2018-07-24 21:45:02.332 [main] INFO  com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~insert data and delete cache~~~~~~~~~~~~~~~~~~~~~~2018-07-24 21:45:02.332 [main] INFO  com.crw.service.SbpUserServiceTest - =============fourth select start===============Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@16890f00] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring==&gt;  Preparing: select id, nick_name, password, mobile, create_at, update_at from sbp_user where id = ? ==&gt; Parameters: 666(Long)&lt;==    Columns: id, nick_name, password, mobile, create_at, update_at&lt;==        Row: 666, 老A, 111111, 11100006666, 1532439901401, 1532439901401&lt;==      Total: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@16890f00]2018-07-24 21:45:02.338 [main] INFO  com.crw.service.SbpUserServiceTest - =============fourth select end=================,user:SbpUser(id=666, nickName=老A, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401)2018-07-24 21:45:02.343 [Thread-4] INFO  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@1556f2dd: startup date [Tue Jul 24 21:44:55 CST 2018]; root of context hierarchyDisconnected from the target VM, address: &#39;127.0.0.1:51531&#39;, transport: &#39;socket&#39;Process finished with exit code 0</code></pre><p>输出结果分析：</p><ol><li>第一次查询在插入数据之后，并没有打印查询sql表明是从缓存查询。即<code>insert</code>操作的<code>@CachePut</code>注解其效果。</li><li>第二次查询在修改数据之后，也没有打印查询sql表明从缓存查询。继续观察输出的<code>user</code>对象，nickName已经从“老A”变为“老B”了。即<code>update</code>操作的<code>@CachePut</code>注解其效果。</li><li>第三次查询在删除数据之后，打印sql说明未从缓存查询。继续观察输出的<code>user</code>对象为null,说明<code>delete</code>操作的<code>@CacheEvict</code>注解其效果。</li><li>第四次查询在插入数据并删除缓存的情况下，打印sql了说明从数据库查询。再连接redis可以看到：<img src="https://ws1.sinaimg.cn/large/87faef88ly1ftlbyqd2wjj20vk0d841c.jpg" alt="">图上，redis已有缓存，说明<code>select</code>操作也会增加redis缓存。并且输出格式正如<code>RedisTemplate</code>配置的那样，<code>key</code>为字符串,<code>value</code>为json格式。同时设置的缓存时间为2000秒。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/87faef88ly1ftmdpcaqwwj20dw08cq2w.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前的文章&lt;a href=&quot;https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-guava/&quot;&gt;spring-boot优雅的使用缓存&lt;/a&gt;介绍了使用spring3开始的cache功能，
并使用&lt;code&gt;guava&lt;/code&gt;实现完成一次示例。但是在分布式环境下，进程内的本地缓存是独立的，在一些场景并不使用。&lt;/p&gt;
&lt;p&gt;在现在互联网企业中广泛使用了一些中间件比如&lt;code&gt;memcache&lt;/code&gt;,&lt;code&gt;redis&lt;/code&gt;等来实现分布式环境下的集中式缓存。
本文将介绍spring-boot下集成redis做缓存的实现细节。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="https://www.chenruiwen.cn/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="https://www.chenruiwen.cn/tags/spring-boot/"/>
    
      <category term="cache" scheme="https://www.chenruiwen.cn/tags/cache/"/>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>spring-boot优雅的使用缓存</title>
    <link href="https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-guava/"/>
    <id>https://www.chenruiwen.cn/spring-boot/spring-boot-use-cache-guava/</id>
    <published>2018-07-22T14:45:10.000Z</published>
    <updated>2018-07-23T08:50:04.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://ww1.sinaimg.cn/large/87faef88ly1ftj1n4e5e2j20iz075q2y.jpg" alt=""></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如果说如何优化你的网站或者应用，大部分同学第一的反应可能就是<code>缓存</code>。缓存不是万能的，但是当用户和访问量加大的情况下，缓存是提高应用吞吐量非常有效的手段。</p><p>本文主要介绍如果通过spring-boot使用本地缓存，以<code>guava cache</code>为例。其实从spring3开始就已经提供了基于注解的缓存支持，其原理还是基于<code>aop</code>的思想，降低了缓存代码对我们应用代码的侵入。</p><a id="more"></a><h2 id="spring-cache相关接口及注解"><a href="#spring-cache相关接口及注解" class="headerlink" title="spring cache相关接口及注解"></a>spring cache相关接口及注解</h2><p>从spring3开始，spring支持基于注解的缓存组件。其核心接口俩个，在<code>spring-context</code>包中:</p><ul><li>Cache</li><li>CacheManager</li></ul><p>spring中实现优雅使用缓存的方式还是基于注解的方式，其中常用的一些注解也是在<code>spring-context</code>包中。</p><p>接下来分别看下这些接口。</p><h3 id="Cache-接口"><a href="#Cache-接口" class="headerlink" title="Cache 接口"></a>Cache 接口</h3><p><code>Cache</code>接口，提供操作缓存的定义(比如放入、读取、清理等。</p><p>其中<code>Cache</code>接口Spring也提供了很多默认的实现，它们在<code>spring-context</code>包和<code>spring-context-support</code>包中:<img src="https://ww1.sinaimg.cn/large/87faef88ly1ftinmijpmuj21cw0pkjzh.jpg" alt=""></p><p><code>Cache</code>接口:</p><pre><code class="java">public interface Cache {    // cacheName，缓存的名字，默认实现中一般是CacheManager创建Cache的bean时传入cacheName    String getName();    // 获取实际使用的缓存，如：RedisTemplate、com.github.benmanes.caffeine.cache.Cache&lt;Object, Object&gt;。暂时没发现实际用处，可能只是提供获取原生缓存的bean，以便需要扩展一些缓存操作或统计之类的东西    Object getNativeCache();    // 通过key获取缓存值，注意返回的是ValueWrapper，为了兼容存储空值的情况，将返回值包装了一层，通过get方法获取实际值    ValueWrapper get(Object key);    // 通过key获取缓存值，返回的是实际值，即方法的返回值类型    &lt;T&gt; T get(Object key, Class&lt;T&gt; type);    // 通过key获取缓存值，可以使用valueLoader.call()来调使用@Cacheable注解的方法。当@Cacheable注解的sync属性配置为true时使用此方法。因此方法内需要保证回源到数据库的同步性。避免在缓存失效时大量请求回源到数据库    &lt;T&gt; T get(Object key, Callable&lt;T&gt; valueLoader);    // 将@Cacheable注解方法返回的数据放入缓存中    void put(Object key, Object value);    // 当缓存中不存在key时才放入缓存。返回值是当key存在时原有的数据    ValueWrapper putIfAbsent(Object key, Object value);    // 删除缓存    void evict(Object key);    // 删除缓存中的所有数据。需要注意的是，具体实现中只删除使用@Cacheable注解缓存的所有数据，不要影响应用内的其他缓存    void clear();    // 缓存返回值的包装    interface ValueWrapper {        // 返回实际缓存的对象        Object get();    }    // 当{@link #get(Object, Callable)}抛出异常时，会包装成此异常抛出    @SuppressWarnings(&quot;serial&quot;)    class ValueRetrievalException extends RuntimeException {        private final Object key;        public ValueRetrievalException(Object key, Callable&lt;?&gt; loader, Throwable ex) {            super(String.format(&quot;Value for key &#39;%s&#39; could not be loaded using &#39;%s&#39;&quot;, key, loader), ex);            this.key = key;        }        public Object getKey() {            return this.key;        }    }}</code></pre><h3 id="CacheManager-接口"><a href="#CacheManager-接口" class="headerlink" title="CacheManager 接口"></a>CacheManager 接口</h3><p>主要负责缓存<code>Cache</code>接口的管理，提供了根据<code>cacheName</code>获取缓存的接口以及获取所有<code>cacheName</code>的接口。</p><pre><code class="java">public interface CacheManager {    // 通过cacheName创建Cache的实现bean，具体实现中需要存储已创建的Cache实现bean，避免重复创建，也避免内存缓存对象（如Caffeine）重新创建后原来缓存内容丢失的情况    Cache getCache(String name);    // 返回所有的cacheName    Collection&lt;String&gt; getCacheNames();}</code></pre><h3 id="cache-相关注解"><a href="#cache-相关注解" class="headerlink" title="cache 相关注解"></a>cache 相关注解</h3><h4 id="EnableCaching"><a href="#EnableCaching" class="headerlink" title="@EnableCaching"></a>@EnableCaching</h4><p>启用Cache注解支持的总开关。</p><h4 id="CachePut"><a href="#CachePut" class="headerlink" title="@CachePut"></a>@CachePut</h4><p>应用到写数据的方法上，如新增/修改方法，调用方法时会自动把相应的数据放入缓存。</p><pre><code class="java">Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface CachePut {    // cacheNames，CacheManager就是通过这个名称创建对应的Cache实现bean    @AliasFor(&quot;cacheNames&quot;)    String[] value() default {};    // 含义与`cacheNames`别名一样，等价于value()    @AliasFor(&quot;value&quot;)    String[] cacheNames() default {};    // 缓存的key，支持SpEL表达式。默认是使用所有参数及其计算的hashCode包装后的对象（SimpleKey）    String key() default &quot;&quot;;    // 缓存key生成器，spring4开始默认实现是SimpleKeyGenerator    String keyGenerator() default &quot;&quot;;    // 指定使用的cacheManager    String cacheManager() default &quot;&quot;;    // 缓存解析器    String cacheResolver() default &quot;&quot;;    // 缓存的条件，支持SpEL表达式，当达到满足的条件时才缓存数据。在调用方法前后都会判断    String condition() default &quot;&quot;;    // 满足条件时不更新缓存，支持SpEL表达式，只在调用方法后判断    String unless() default &quot;&quot;;}</code></pre><h4 id="CacheEvict"><a href="#CacheEvict" class="headerlink" title="@CacheEvict"></a>@CacheEvict</h4><p>应用到移除数据的方法上，如删除方法，调用方法时会从缓存中移除相应的数据。</p><p>大部分定义可参考上面<code>@CachePut</code>注解，新增了2个属性:</p><pre><code class="java">@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface CacheEvict {    // 此处省略大部分与CachePut相同的属性...    // 是否要清除所有缓存的数据，为false时调用的是Cache.evict(key)方法；为true时调用的是Cache.clear()方法    boolean allEntries() default false;    // 是否在调用方法之前清除缓存    boolean beforeInvocation() default false;}</code></pre><h4 id="Cacheable"><a href="#Cacheable" class="headerlink" title="@Cacheable"></a>@Cacheable</h4><p>应用到读取数据的方法上，即可缓存的方法，如查找方法：先从缓存中读取，如果没有再调用方法获取数据，然后把数据添加到缓存中。</p><p>大部分定义可参考上面<code>@CachePut</code>注解，新增了1个属性:</p><pre><code class="java">@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Cacheable {    // 此处省略大部分与CachePut相同的属性...    // 回源到实际方法获取数据时，是否要保持同步，如果为false，调用的是Cache.get(key)方法；如果为true，调用的是Cache.get(key, Callable)方法    boolean sync() default false;}</code></pre><h4 id="Caching"><a href="#Caching" class="headerlink" title="@Caching"></a>@Caching</h4><p>提供了注解的组合模式，可以在此注解中配置多个Cache注解。</p><pre><code class="java">@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Caching {    // @Cacheable 数组，可以配置多个Cacheable注解，实现同时查询多个缓存    Cacheable[] cacheable() default {};    // @CachePut 数组，可以配置多个CachePut注解，实现同时存放多个缓存    CachePut[] put() default {};    // @CacheEvict 数组，可以配置多个CacheEvict注解，实现同时删除多个缓存    CacheEvict[] evict() default {};}</code></pre><h2 id="guava-cache"><a href="#guava-cache" class="headerlink" title="guava cache"></a>guava cache</h2><p><code>guava</code>是Google提供的开源的java核心工具类库。其中包含很多好用的工具类，我们这里主要使用<code>guava</code>中的<code>cache</code>包。</p><p><em>为什么要使用guava的cache而不是简单的使用ConcurrentMap呢？或者说这二者的区别在哪？</em></p><p>答：Guava Cache与ConcurrentMap很相似，它们之间的一个根本区别在于缓存可以回收存储的元素。</p><p>guava提供了不同方式的缓存回收策略：</p><ul><li>基于容量的回收</li><li>定时回收</li><li>基于引用的回收</li></ul><h2 id="在spring-boot中使用guava-cache"><a href="#在spring-boot中使用guava-cache" class="headerlink" title="在spring-boot中使用guava cache"></a>在spring-boot中使用guava cache</h2><p>三步完成在spring-boot中使用guava cache:</p><ul><li>maven依赖</li><li>配置缓存类型</li><li>代码中使用guava cache并单元测试</li></ul><h3 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h3><p>maven依赖特别少，由于<code>spring-boot-starter</code>默认并没有依赖上<code>spring-context-support</code>包，所以我们需要依赖上它。如下，引入<code>spring-boot-starter-cache</code>即可。以及引入本地缓存要用到的<code>guava</code>。</p><pre><code>&lt;!-- cache --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- guava --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;    &lt;artifactId&gt;guava&lt;/artifactId&gt;    &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="配置缓存类型"><a href="#配置缓存类型" class="headerlink" title="配置缓存类型"></a>配置缓存类型</h3><p>由于我们使用guava作为缓存，只需要指明缓存类型为 guava即可。</p><pre><code>spring:  cache:    type: guava</code></pre><h3 id="使用guava-cache"><a href="#使用guava-cache" class="headerlink" title="使用guava cache"></a>使用guava cache</h3><p>一. 配置 CacheManager，并开启缓存功能。</p><pre><code class="java">@EnableCaching@Configurationpublic class CacheConfig {    @Bean    public CacheManager cacheManager() {        GuavaCacheManager cacheManager = new GuavaCacheManager();        cacheManager.setCacheBuilder(CacheBuilder.newBuilder()                .expireAfterWrite(10, TimeUnit.SECONDS).maximumSize(1000));        return cacheManager;    }}</code></pre><p>如上，我配置了缓存写入后保持10秒</p><p>二. 使用注解优雅给接口加上缓存。在访问接口上加上注解。</p><pre><code class="java">@Service@CacheConfig(cacheNames = &quot;product&quot;)public class ProductServiceImpl implements ProductService {    @Resource    private ProductMapper productMapper;    @Override    @Cacheable    public Product getObjectById(Long id) {        return productMapper.selectByPrimaryKey(id);    }}</code></pre><p>三. 测试本地缓存。首先开启<code>mybatis</code>的sql输出打印，修改<code>application.yml</code>的配置，增加如下:</p><pre><code>mybatis:  configuration:    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl</code></pre><p>测试本地缓存是否起效，以及缓存时间是否其效果。</p><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = App.class)@Slf4jpublic class SbpProductServiceTest {    @Autowired    private ProductService productService;    @Test    @Rollback    public void getObjectById() throws InterruptedException {        Product product1 = productService.getObjectById(1L);        log.info(&quot;time:{} , first get product:{}&quot;, System.currentTimeMillis(), product1);        Product product2 = productService.getObjectById(1L);        log.info(&quot;time:{} , second get product:{}&quot;, System.currentTimeMillis(), product2);        Thread.sleep(15000);        Product product3 = productService.getObjectById(1L);        log.info(&quot;time:{} , third get product:{}&quot;, System.currentTimeMillis(), product3);    }}</code></pre><p>输出如下：</p><pre><code>==&gt;  Preparing: select id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at from sbp_product where id = ? ==&gt; Parameters: 1(Long)&lt;==    Columns: id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at&lt;==        Row: 1, BK100001, 1, java编程思想, thinking in java, 86.00, 75.00, 300, 1532260305712, 1532260305712&lt;==      Total: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@25791d40]2018-07-22 19:53:05.534 [main] INFO  com.crw.service.SbpProductServiceTest - time:1532260385532 , first get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712)2018-07-22 19:53:05.537 [main] INFO  com.crw.service.SbpProductServiceTest - time:1532260385537 , second get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712)Creating a new SqlSessionSqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6812c8cc] was not registered for synchronization because synchronization is not activeJDBC Connection [com.mysql.jdbc.JDBC4Connection@6075b369] will not be managed by Spring==&gt;  Preparing: select id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at from sbp_product where id = ? ==&gt; Parameters: 1(Long)&lt;==    Columns: id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at&lt;==        Row: 1, BK100001, 1, java编程思想, thinking in java, 86.00, 75.00, 300, 1532260305712, 1532260305712&lt;==      Total: 1Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6812c8cc]2018-07-22 19:53:20.547 [main] INFO  com.crw.service.SbpProductServiceTest - time:1532260400547 , third get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712)2018-07-22 19:53:20.553 [Thread-4] INFO  org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@6853425f: startup date [Sun Jul 22 19:53:01 CST 2018]; root of context hierarchy</code></pre><p>可以看到结果:</p><ol><li>第一次调用打印了sql，此时还没有缓存。</li><li>第二次调用没打印sql，此时有本地缓存了。</li><li>第三次调用又打印sql，此时本地缓存失效。</li></ol><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>再来回顾一下，本文介绍了：</p><ul><li>spring cache的使用，它是AOP理念的一个很好的应用</li><li>guava的使用。by the way,从Spring5开始变不再支持guava的实现了，从spring-boot 1.5.x版本你就可以看到<code>autoconfgure</code>包下的<code>GuavaCacheConfiguration</code>以及被注解为<code>@Deprecated</code>了。推荐更好的实现是<a href="https://github.com/ben-manes/caffeine" target="_blank" rel="noopener">caffeine</a>。</li><li>spring-boot使用哦cache非常方便，三步完成。</li></ul><p>本文参考了：</p><ul><li><a href="http://jinnianshilongnian.iteye.com/blog/2001040" target="_blank" rel="noopener">Spring Cache抽象详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://ww1.sinaimg.cn/large/87faef88ly1ftj1n4e5e2j20iz075q2y.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;如果说如何优化你的网站或者应用，大部分同学第一的反应可能就是&lt;code&gt;缓存&lt;/code&gt;。缓存不是万能的，但是当用户和访问量加大的情况下，缓存是提高应用吞吐量非常有效的手段。&lt;/p&gt;
&lt;p&gt;本文主要介绍如果通过spring-boot使用本地缓存，以&lt;code&gt;guava cache&lt;/code&gt;为例。其实从spring3开始就已经提供了基于注解的缓存支持，其原理还是基于&lt;code&gt;aop&lt;/code&gt;的思想，降低了缓存代码对我们应用代码的侵入。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="https://www.chenruiwen.cn/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="https://www.chenruiwen.cn/tags/spring-boot/"/>
    
      <category term="cache" scheme="https://www.chenruiwen.cn/tags/cache/"/>
    
      <category term="guava" scheme="https://www.chenruiwen.cn/tags/guava/"/>
    
  </entry>
  
</feed>
