<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chen RuiWen&#39;s Space</title>
  
  <subtitle>Life is real, life is earnest</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.chenruiwen.cn/"/>
  <updated>2020-02-03T12:40:45.232Z</updated>
  <id>https://www.chenruiwen.cn/</id>
  
  <author>
    <name>陈瑞文</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一分钟看清Netty的工作流程</title>
    <link href="https://www.chenruiwen.cn/Netty/netty-workflow/"/>
    <id>https://www.chenruiwen.cn/Netty/netty-workflow/</id>
    <published>2020-02-03T12:36:24.000Z</published>
    <updated>2020-02-03T12:40:45.232Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前摸清了 Reactor 线程模型及其演变，最近看了下相关文章和代码，也熟悉了netty的工作模型，记录之。<a id="more"></a></p><h2 id="netty工作模型"><a href="#netty工作模型" class="headerlink" title="netty工作模型"></a>netty工作模型</h2><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1gbjhmtam7jj227818sgtv.jpg" alt="netty模型.png"></p><ul><li>Netty 抽象出两组线程池：BossGroup、WorkerGroup。BossGroup专门负责接受客户端的连接，相当于 mainReactor;WorkerGroup专门负责网络的读写，相当于subReactor。</li><li>BossGroup、WorkerGroup 类型都是 NioEventLoopGroup.</li><li>NioEventLoopGroup 即事件循环组，里面含有多个事件循环（NioEventLoop），即 一个 NioEventLoopGroup 对应多个 NioEventLoop</li><li>NioEventLoop 表示一个不断循环的执行处理任务的线程，每个 NioEventLoop 都有一个 selector ，用于监听绑定在其上的 socket 的网络通信。</li><li>每个 boss 的 NioEventLoopGroup 循环执行的步骤：<ol><li>轮询 accept 事件</li><li>处理 accept 事件，与 client 建立连接，生产 NioSocketChannel，并将其注册到某个 woker 的 NioEventLoop 上的 selector</li><li>处理任务队列，即 runAllTasks</li></ol></li><li><p>每个 worker 的 NioEventLoopGroup 循环执行的步骤：</p><ol><li>轮询 read,write 事件</li><li>处理I/O事件，即 read,write 事件，在对应的 NioSocketChannel 处理。</li><li>处理任务队列，即 runAllTasks</li></ol></li><li><p>每个 worker 的 NioEventLoopGroup 处理业务时，会使用 ChannelPipeline ，即通道。ChannelPipeline 中包含了 channel ， ChannelPipeline 中也有各种处理器（编码、解码、业务处理…）</p></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>之后准备用netty写一个IM项目练练手，代码会比较简单，非常适合熟悉netty。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前摸清了 Reactor 线程模型及其演变，最近看了下相关文章和代码，也熟悉了netty的工作模型，记录之。
    
    </summary>
    
      <category term="Netty" scheme="https://www.chenruiwen.cn/categories/Netty/"/>
    
    
      <category term="Netty" scheme="https://www.chenruiwen.cn/tags/Netty/"/>
    
  </entry>
  
  <entry>
    <title>R.I.P Kobe Bryant, Mamba Never Out</title>
    <link href="https://www.chenruiwen.cn/essay/mamba-never-out/"/>
    <id>https://www.chenruiwen.cn/essay/mamba-never-out/</id>
    <published>2020-01-27T04:19:24.000Z</published>
    <updated>2020-02-02T12:08:58.189Z</updated>
    
    <content type="html"><![CDATA[<h2 id="R-I-P-Kobe-Bryant"><a href="#R-I-P-Kobe-Bryant" class="headerlink" title="R.I.P Kobe Bryant"></a>R.I.P Kobe Bryant</h2><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1gbi6idtfsvj20hs0a0q3f.jpg" alt="">今天上午6点半，被噩梦惊醒，醒来打开手机准备刷刷新闻看一看今天的全国疫情情况的，结果看到老姐发来的微信：科比坠机死亡。我心想又是恶心的标题党吧，然后打开朋友圈，oh, fk!这不可能！又去微博、头条等新闻媒体看新闻，才确定这是真的，那一刻的感觉，真的是心碎，仿佛亲人离去的感觉。那可是科比啊。<a id="more"></a></p><p>真的说不出的感受，一个好强的不屈的生命就这样结束了，记得曾经你退役后说过，“在我的人生中最成功的 事情是篮球，那么我就是失败者。” 我想，这样的你将来还会做出怎样让人惊叹的成就啊。</p><p>上学打球的时候，你也正是巅峰的年龄，那时候，我们喜欢麦迪，艾弗森，加内特，纳什，白巧克力，打球时候喜欢黑你“打铁”，“不传球”，作为曾经的凯尔特人球迷，纳什球迷，也“讨厌”过你夺走过总冠军，1-3逆转太阳等。初高中那会让，身边一些不太懂球的同学，都说喜欢你，是你粉丝，嘴上说着科比牛逼。我不喜欢跟风，虽然知道NBA中最接近乔丹的就是你了，但也没喜欢上你。再后来，渐渐的打球少了，熟悉的球星一个一个也退役了，才越发珍惜那年群星聚萃的景象，我会支持每一个学生时代的偶像，当然有你，科比。在你跟腱断裂的那一天，我看的直播，那一刻，心碎难受，尤其你好强的罚了制胜的关键两球，尊敬，这就是老大。2016.4.14日，无数球迷翘班也要看球的日子，那一天你退役了，最后一句“Mamba out”，全场欢呼、流泪，青春真的感觉到不在了。</p><p>直到今天真正的失去了你，我们才发现，这些年内心深处对你是真正喜欢。</p><p>今天，一看到你的报道，球迷做的你的视频，就忍不住点进去，但每个视频都没有看完过就退出来了，真的看不下去了。</p><p>Rest in peace, Kobe, Mamba never out!</p><h2 id="Mamba-Never-Out"><a href="#Mamba-Never-Out" class="headerlink" title="Mamba Never Out"></a>Mamba Never Out</h2><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1gbiaykh355j20u00jyq63.jpg" alt="">科比那些激励一代又一代年轻人的经典语录，Thank you , Kobe，曼巴精神将被人们传承。</p><ul><li>总有一个人要赢，为什么不能是我呢？</li><li>如果创造历史轻而易举，那又何苦如此费尽心力。</li><li>如果你害怕失败，你就会失败！</li><li>我宁愿30投0中，也不愿9投0中，因为9投0中意味着你被自己打败了！</li><li>第二名只能说明你是头号输家！</li><li>你见过凌晨洛杉矶四点的样子吗？</li><li>朋友来来往往，但冠军之旗永不落。</li><li>嘘声又不能盖掉我！</li><li>24，就是24小时都全力以赴。</li></ul><h2 id="by-the-way-fuck-那些炒鞋的鞋贩子"><a href="#by-the-way-fuck-那些炒鞋的鞋贩子" class="headerlink" title="by the way, fuck 那些炒鞋的鞋贩子"></a>by the way, fuck 那些炒鞋的鞋贩子</h2><p>fuck 那些炒鞋的鞋贩子，你们不配。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;R-I-P-Kobe-Bryant&quot;&gt;&lt;a href=&quot;#R-I-P-Kobe-Bryant&quot; class=&quot;headerlink&quot; title=&quot;R.I.P Kobe Bryant&quot;&gt;&lt;/a&gt;R.I.P Kobe Bryant&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/87faef88ly1gbi6idtfsvj20hs0a0q3f.jpg&quot; alt=&quot;&quot;&gt;
今天上午6点半，被噩梦惊醒，醒来打开手机准备刷刷新闻看一看今天的全国疫情情况的，结果看到老姐发来的微信：
科比坠机死亡。我心想又是恶心的标题党吧，然后打开朋友圈，oh, fk!这不可能！又去微博、头条等新闻媒体看新闻，
才确定这是真的，那一刻的感觉，真的是心碎，仿佛亲人离去的感觉。那可是科比啊。
    
    </summary>
    
      <category term="essay" scheme="https://www.chenruiwen.cn/categories/essay/"/>
    
    
      <category term="Kobe Bryant" scheme="https://www.chenruiwen.cn/tags/Kobe-Bryant/"/>
    
      <category term="basketball" scheme="https://www.chenruiwen.cn/tags/basketball/"/>
    
  </entry>
  
  <entry>
    <title>Reactor模型的三种实现</title>
    <link href="https://www.chenruiwen.cn/Netty/reactor-thread-model/"/>
    <id>https://www.chenruiwen.cn/Netty/reactor-thread-model/</id>
    <published>2020-01-03T07:19:24.000Z</published>
    <updated>2020-02-02T12:07:49.864Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Netty，一个无法拒绝的基于java语言编写的网络通信框架，其线程模型是最为复杂，也是面试官最爱考的问题之一。Netty的线程模型是基于Reactor模型发展来的，所以有必要了解Reactor模型的发展历程。<a id="more"></a></p><h2 id="经典模式"><a href="#经典模式" class="headerlink" title="经典模式"></a>经典模式</h2><p>最开始的网络服务设计，即传统BIO JAVA网络服务那样，一个客户端请求过来，服务端分配一个hander处理read-&gt;biz-&gt;send等所有工作。如图：<img src="http://ww1.sinaimg.cn/large/87faef88ly1gakx62tbgrj219g0v2q9g.jpg" alt="传统BIO网络模式.png"></p><h2 id="Reactor-模式"><a href="#Reactor-模式" class="headerlink" title="Reactor 模式"></a>Reactor 模式</h2><p>与传统BIO服务不同，Reactor模式是基于事件驱动的。对每个IO事件，Reactor通过分发(dispatch)给不同的hander处理各自的业务请求。简单的说，就是IO复用+线程池的组合，如图：<img src="http://ww1.sinaimg.cn/large/87faef88ly1gakxgmha3jj21900vywkj.jpg" alt="Reactor模式基础架构.png">解释：</p><ol><li>客户端发起请求事件到Reactor，Reactor通过IO复用接受请求事件。</li><li>Reactor不处理业务操作，而是把业务处理操作分配给工作线程池处理。</li><li>工作线程完成业务操作后再将结果返回给客户端。</li></ol><h2 id="单Reactor单线程"><a href="#单Reactor单线程" class="headerlink" title="单Reactor单线程"></a>单Reactor单线程</h2><p>即通过一个main线程处理接受请求事件-&gt;read-&gt;handle biz-&gt;send 一系列的操作。<img src="http://ww1.sinaimg.cn/large/87faef88ly1gakxuiti33j21860r0jx5.jpg" alt="单Reactor单线程.png">这种方式的缺点非常明显，只用一个线程处理，非常容易出现瓶颈，而且无法充分利用现代计算机多核CPU的优势；低可靠性，一旦main线程意外，则整个系统通信模块就会故障，节点不可用。</p><p>优点：模型简单，没有多线程、多进程通信，不存在竞争问题。</p><h2 id="单Reactor多线程"><a href="#单Reactor多线程" class="headerlink" title="单Reactor多线程"></a>单Reactor多线程</h2><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1gaky2oo37cj21920xsdmp.jpg" alt="单Reactor多线程.png">解释：</p><ol><li>Reactor通过acceptor接受客户端请求事件。</li><li>Reactor接受到事件后，把相应的业务分发出给相应的hander处理，hander负责read和send响应数据。</li><li>hander只负责响应事件，不做具体业务处理，通过read读取数据后，会把业务交给线程池的某个worker线程处理业务。</li><li>线程处理完业务后，会把响应返回给hander，再由hander响应，通过send发送给客户端。</li></ol><ul><li>优点：相较于单Reactor单线程模式，它把业务操作放在线程池里处理，能充分利用CPU多核处理能力</li><li>缺点：多线程数据共享和访问比较复杂，Reactor处理所有事件监听和响应，Reactor还是单线程的，高并发场景还是容易出现性能瓶颈。</li></ul><h2 id="主从多线程"><a href="#主从多线程" class="headerlink" title="主从多线程"></a>主从多线程</h2><p>针对单Reactor多线程模型中，Reactor只有一个线程，在高并发场景下很容易出现性能瓶颈，因此可以使Reactor在多线程中运行，如图。<img src="http://ww1.sinaimg.cn/large/87faef88ly1gamzuh18j6j219a0zc7bw.jpg" alt="主从多线程模式.png"></p><p>针对单Reactor多线程模型中，Reactor只有一个线程，在高并发场景下很容易出现性能瓶颈，因此可以使Reactor在多线程中运行，如图。</p><p>解释：</p><ol><li>Reactor主线程通过 mainReactor 对象通过select监听连接事件，收到事件交给 acceptor 处理连接事件。</li><li>acceptor 处理连接事件后，mainReactor 将连接分配给一个 subReactor。</li><li>subReactor 将连接键入连接队列进行监听，并创建 handler 进行事件处理。</li><li>handler 在 read 操作后再将连接交给工作线程池(worker thread pool)处理业务，由线程池分配独立线程进行业务操作。</li><li>线程处理完业务后，会把响应返回给hander，再由hander响应，通过send发送给客户端。</li><li>mainReactor 可以对于多个 subReactor ，因此称此模型为主从多线程模型。</li></ol><ul><li>优点：父线程和子线程的数据交互简单，职责明确，父线程只需要接受新连接，而子线程只需完成业务处理，子线程也无须返回数据。</li><li>缺点：复杂度高</li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>参考资料:《Scalable IO In Java》,是java.util.concurrent包的作者，大师Doug Lea关于分析与构建可伸缩的高性能IO服务的一篇经典文章。本文的图片截图均截自此书，建议先阅读大师的经典文章。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Netty，一个无法拒绝的基于java语言编写的网络通信框架，其线程模型是最为复杂，也是面试官最爱考的问题之一。Netty的线程模型是基于Reactor模型发展来的，所以有必要了解Reactor模型的发展历程。
    
    </summary>
    
      <category term="Netty" scheme="https://www.chenruiwen.cn/categories/Netty/"/>
    
    
      <category term="Netty" scheme="https://www.chenruiwen.cn/tags/Netty/"/>
    
      <category term="Reactor" scheme="https://www.chenruiwen.cn/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>从DelayQueue到 Leader-follower线程模型</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/delayqueue-leaderfollower/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/delayqueue-leaderfollower/</id>
    <published>2019-05-06T12:16:24.000Z</published>
    <updated>2019-05-06T12:50:37.867Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天看源码，从 <code>DelayQueue</code>中发现了一些有意思的事情： Leader-follower线程模型。顺便记录一下源码解析和Leader-follower线程模型的思想。<a id="more"></a></p><h2 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h2><h3 id="主要成员"><a href="#主要成员" class="headerlink" title="主要成员"></a>主要成员</h3><p>如下四个：</p><pre><code>// 一把可重入锁private final transient ReentrantLock lock = new ReentrantLock();// 优先级队列，根据Delay排序private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;();// Leader-follower线程模型的 leaderprivate Thread leader = null;// 条件，用于阻塞通知private final Condition available = lock.newCondition();</code></pre><h3 id="Delayed接口"><a href="#Delayed接口" class="headerlink" title="Delayed接口"></a>Delayed接口</h3><p>能放入延迟队列的元素必须实现<code>Delayed</code>接口，其设计也比较明显。实现<code>Delayed</code>接口的对象必须实现：</p><ul><li><code>getDelay</code>方法：此对象的剩余时间</li><li><p><code>compareTo</code>方法：用于排序，而且要与<code>getDelay</code>方法一致的排序</p><pre><code class="java">public interface Delayed extends Comparable&lt;Delayed&gt; {  long getDelay(TimeUnit unit);}</code></pre></li></ul><h3 id="总体思路"><a href="#总体思路" class="headerlink" title="总体思路"></a>总体思路</h3><ol><li>优先级无界队列<code>PriorityQueue</code>当做容器。</li><li>入队的元素必须实现<code>Delayed</code>接口.</li><li>出队时获取队列头的元素，队列头的元素是根据<code>Delayed</code>排序获取的最先过期的元素。</li></ol><h3 id="核心方法"><a href="#核心方法" class="headerlink" title="核心方法"></a>核心方法</h3><p>主要是入队<code>offer</code>方法和出队<code>take</code>方法。</p><h4 id="offer-E-e"><a href="#offer-E-e" class="headerlink" title="offer(E e)"></a>offer(E e)</h4><pre><code class="java">public boolean offer(E e) {    final ReentrantLock lock = this.lock;    lock.lock();    try {        q.offer(e); // 插入优先级队列        if (q.peek() == e) { // 如果队首元素是当前元素            leader = null; // leader置空            available.signal(); // 唤醒等待线程        }        return true;    } finally {        lock.unlock();    }}</code></pre><h4 id="take"><a href="#take" class="headerlink" title="take()"></a>take()</h4><p>等待直到有一个过期的元素可用，获取并删除队首元素。</p><pre><code class="java">public E take() throws InterruptedException {    final ReentrantLock lock = this.lock;    lock.lockInterruptibly();    try {        for (;;) {            E first = q.peek(); // 获取队首元素            // 如果队首元素为空，则等待唤醒            if (first == null)                available.await();            else {                // 获取超时时间                long delay = first.getDelay(NANOSECONDS);                // 已过期即 delay&lt;=0，直接从队列中出队并返回                if (delay &lt;= 0)                    return q.poll();                // 下面这个很关键                first = null; // don&#39;t retain ref while waiting                // 如果leader不为null,说明有其他线程在操作，则等待唤醒                if (leader != null)                    available.await();                else {                    Thread thisThread = Thread.currentThread();                    // leader设置为当前线程                    leader = thisThread;                    try {                        // 超时等待                        available.awaitNanos(delay);                    } finally {                        // 释放leader                        if (leader == thisThread)                            leader = null;                    }                }            }        }    } finally {        // 最终还是需要判断释放leader已被释放，并唤醒        if (leader == null &amp;&amp; q.peek() != null)            available.signal();        lock.unlock();    }}</code></pre><p>简单明了：</p><ol><li>首先是获取队首元素，如果队首元素已过期 ，则直接出队。</li><li>否则设置 <code>first = null</code>，这里设置为null的主要目的是为了避免内存泄漏。如果 leader != null 则表示当前有线程占用，则阻塞。</li><li>否则设置leader为当前线程，然后调用awaitNanos()方法超时等待。</li></ol><p><strong>注：</strong><code>first = null</code>的作用是避免其他线程持有 first 的引用并且不会被回收，避免了线程多的情况造成内存泄漏的可能。</p><h2 id="Leader-follower线程模型"><a href="#Leader-follower线程模型" class="headerlink" title="Leader-follower线程模型"></a>Leader-follower线程模型</h2><p>前面<code>DelayQueue</code>里涉及到的<code>leader</code>有些摸不清楚为啥要这样，于是补充了一下Leader-follower线程模型知识，如下一图胜千言：</p><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1g2redf0l7qj20g205uaai.jpg" alt=""></p><p>如图，涉及三种状态：</p><ul><li><code>leading</code>:<code>leader</code>线程负责监听事件。</li><li><code>following</code>:<code>follower</code>为其他线程，处于等待状态。</li><li><code>processing</code>:<code>leader</code>处理事件时状态轮转为<code>processing</code>状态。</li></ul><p>过程如下:</p><ol><li>一个新的事件到来时:<code>leader</code>线程监听到此事件，<code>follower</code>线程们等待。</li><li><code>leader</code>线程接受请求: <code>leader</code>线程轮转为<code>processing</code>状态，<code>leader</code>线程会释放自己<code>leader</code>的角色，<code>follower</code>线程们里会挑选出一个新的线程作为<code>leader</code>线程，其余的<code>follower</code>则会继续等待。</li><li><code>leader</code>线程处理请求：之前的<code>leader</code>线程(<code>processing</code>状态)会开始处理事件，处理完成以后变成一个<code>follower</code>角色进行等待唤醒。</li></ol><p><strong>优势</strong>：  </p><ul><li>接受请求和进行处理使用的是同一个线程，这避免了线程上下文切换和线程通讯数据拷贝。</li><li>不需要消息队列。</li></ul><p><strong>适用场景</strong>：线程可以快速的完成工作任务的情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从延迟队列<code>DelayQueue</code>的源码分析，了解到了Leader-follower线程模型。</p><ul><li><code>DelayQueue</code>实现还是比较简单的，只是增加了只获取过期任务的条件。</li><li><code>DelayQueue</code>源码里涉及避免内存泄漏的代码，再今后自己写高并发代码的情况下提供了一种思路。</li><li>Leader-follower线程模型，它的优势与适用场景，也提供了多线程任务的一种思路。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;今天看源码，从 &lt;code&gt;DelayQueue&lt;/code&gt;中发现了一些有意思的事情： Leader-follower线程模型。
顺便记录一下源码解析和Leader-follower线程模型的思想。
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>事件驱动SpringEvent与EventBus</title>
    <link href="https://www.chenruiwen.cn/event-driven/event-driven-design-and-demo/"/>
    <id>https://www.chenruiwen.cn/event-driven/event-driven-design-and-demo/</id>
    <published>2019-02-23T06:13:13.000Z</published>
    <updated>2019-02-23T05:59:17.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近公司内部准备搞消息驱动，即在订单系统上使用消息/事件驱动的设计，这里研究了一下进程内的事件驱动设计，主要分析了业内常用的<code>Spring Event</code>和<code>EventBus</code>，本篇博文目的如下：</p><ul><li>熟悉事件驱动的设计思想</li><li>会在项目中使用事件驱动(spring event和 eventbus)</li><li>spring event和 eventbus 的异同点</li></ul><a id="more"></a><h2 id="QucikStart"><a href="#QucikStart" class="headerlink" title="QucikStart"></a>QucikStart</h2><h3 id="Spring-Event"><a href="#Spring-Event" class="headerlink" title="Spring Event"></a>Spring Event</h3><p><a href="https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/core.html#context-functionality-events" target="_blank" rel="noopener">spring event官方文档索引</a></p><p>三要素：</p><ul><li><code>Event</code>(事件)</li><li><code>Publisher</code>(发布者)</li><li><code>Listener</code>(监听者)</li></ul><h4 id="举例场景"><a href="#举例场景" class="headerlink" title="举例场景"></a>举例场景</h4><p>用户下订单，推送发短信通知，发微信通知。</p><h4 id="创建一个-Event"><a href="#创建一个-Event" class="headerlink" title="创建一个 Event"></a>创建一个 <code>Event</code></h4><p>直接继承<code>ApplicationEvent</code>即可。</p><p>示例代码:</p><pre><code class="java">public class CreateOrderEvent extends ApplicationEvent {    public CreateOrderEvent(Object source) {        super(source);    }    public Order getOrder() {        return (Order) this.source;    }}</code></pre><p>补充：这里事件也可以不继承<code>ApplicationEvent</code>，因为发布接口有提供<code>void publishEvent(Object event);</code></p><h4 id="创建一个-Publisher"><a href="#创建一个-Publisher" class="headerlink" title="创建一个 Publisher"></a>创建一个 <code>Publisher</code></h4><p>使用<code>ApplicationEventPublisher</code>发布即可。</p><p>示例代码:</p><pre><code class="java">@Slf4j@Componentpublic class EventPublisher {    @Autowired    private ApplicationEventPublisher applicationEventPublisher;    public void publishCreateOrderEvent(CreateOrderEvent createOrderEvent) {        log.info(&quot;发布了一个[订单创建]事件：{}&quot;, createOrderEvent);        applicationEventPublisher.publishEvent(createOrderEvent);    }}</code></pre><h4 id="监听事件"><a href="#监听事件" class="headerlink" title="监听事件"></a>监听事件</h4><p>监听者的创建可以使用两种方式：</p><ul><li>实现<code>ApplicationListener</code>接口</li><li>基于注解式的监听(推荐，要求 Spring 4.2 + )</li></ul><p>使用实现<code>ApplicationListener</code>接口的方式示例：</p><pre><code class="java">@Slf4j@Componentpublic class DuanXinNoticeListener implements ApplicationListener&lt;CreateOrderEvent&gt; {    @Override    public void onApplicationEvent(CreateOrderEvent event) {        log.info(&quot;实现接口方式：收到[创建订单]事件。[短信通知]：亲爱的{}，您的订单[{}]已被创建&quot;, event.getOrder().getUserName(), event.getOrder().getOrderName());    }}</code></pre><p>这种方式不太优雅，每次都要实现一次接口不太爽。那么推荐使用使用注解式监听器。</p><p>注解式监听只需要在监听方法逻辑上使用注解<code>@EventListener</code>即可，而且注解支持spel表达式。</p><p>注解式示例：</p><pre><code class="java">@Slf4j@Componentpublic class CreateOrderListener {    @EventListener(condition = &quot;#createOrderEvent.order.status == 1&quot;)    public void processCreateOrderEvent(CreateOrderEvent createOrderEvent) {        log.info(&quot;注解式 spring event 收到消息，订单名称:{} ; 订单状态为：{} ; 开始处理相应的事件。&quot;, createOrderEvent.getOrder().getOrderName(), createOrderEvent.getOrder().getStatus());    }    @EventListener(condition = &quot;#createOrderEvent.order.status == 2&quot;)    public void processCreateOrderEvent2(CreateOrderEvent createOrderEvent) {        log.info(&quot;注解式 spring event 收到消息，订单名称:{} ; 订单状态为：{} ; 开始处理相应的事件。&quot;, createOrderEvent.getOrder().getOrderName(), createOrderEvent.getOrder().getStatus());    }}</code></pre><h4 id="使用事件发布"><a href="#使用事件发布" class="headerlink" title="使用事件发布"></a>使用事件发布</h4><p>事件在控制器里使用：</p><pre><code class="java">@Slf4j@RestController@RequestMapping(&quot;/event&quot;)public class EventDemoController {    @Autowired    private EventPublisher createOrderEventPublisher;    @PostMapping(&quot;/spring/createOrder&quot;)    public String createOrder(Order order) {        createOrderEventPublisher.publishCreateOrderEvent(new CreateOrderEvent(order));        return &quot;ok&quot;;    }}</code></pre><h4 id="测试创建订单事件"><a href="#测试创建订单事件" class="headerlink" title="测试创建订单事件"></a>测试创建订单事件</h4><p>发送请求：</p><pre><code>curl -X POST \  http://localhost:9090/event/spring/createOrder \  -H &#39;cache-control: no-cache&#39; \  -H &#39;content-type: application/x-www-form-urlencoded&#39; \  -H &#39;postman-token: a632443a-b7b2-40df-6bc3-3881babd15e3&#39; \  -d &#39;id=1&amp;orderName=53%E5%BA%A62018%E9%A3%9E%E5%A4%A9%E8%8C%85%E5%8F%B0&amp;status=1&amp;userName=%E5%BC%A0%E4%B8%89&#39;</code></pre><p>可以看到控制台打印：</p><pre><code>2019-02-21 10:53:20.750  INFO 24168 --- [nio-9090-exec-3] c.gemantic.wealth.spring.EventPublisher  : 发布了一个[订单创建]事件：CreateOrderEvent(order=Order(id=1, orderName=53度2018飞天茅台, status=1, userName=张三))2019-02-21 10:53:20.750  INFO 24168 --- [nio-9090-exec-3] c.g.wealth.spring.CreateOrderListener    : 注解式 spring event 收到消息，订单名称:53度2018飞天茅台 ; 订单状态为：1 ; 开始处理相应的事件。2019-02-21 10:53:20.750  INFO 24168 --- [nio-9090-exec-3] c.g.wealth.spring.DuanXinNoticeListener  : 实现接口方式：收到[创建订单]事件。[短信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建2019-02-21 10:53:20.750  INFO 24168 --- [nio-9090-exec-3] c.g.wealth.spring.WeiXinNoticeListener   : 实现接口方式：收到[创建订单]事件。[微信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建</code></pre><p>事件已被执行，把<code>status</code>改为2：</p><pre><code>2019-02-21 10:55:51.951  INFO 24168 --- [nio-9090-exec-5] c.gemantic.wealth.spring.EventPublisher  : 发布了一个[订单创建]事件：CreateOrderEvent(order=Order(id=1, orderName=53度2018飞天茅台, status=2, userName=张三))2019-02-21 10:55:51.951  INFO 24168 --- [nio-9090-exec-5] c.g.wealth.spring.CreateOrderListener    : 注解式 spring event 收到消息，订单名称:53度2018飞天茅台 ; 订单状态为：2 ; 开始处理相应的事件。2019-02-21 10:55:51.951  INFO 24168 --- [nio-9090-exec-5] c.g.wealth.spring.DuanXinNoticeListener  : 实现接口方式：收到[创建订单]事件。[短信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建2019-02-21 10:55:51.951  INFO 24168 --- [nio-9090-exec-5] c.g.wealth.spring.WeiXinNoticeListener   : 实现接口方式：收到[创建订单]事件。[微信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建</code></pre><p>可见可以很方便的根据条件执行监听。</p><h4 id="补充1-使用异步事件处理"><a href="#补充1-使用异步事件处理" class="headerlink" title="补充1: 使用异步事件处理"></a>补充1: 使用异步事件处理</h4><p>可以在监听方法上使用注解<code>@Async</code>，前提是需要spring应用启动异步功能：<code>@EnableAsync</code></p><h4 id="补充2-TransactionalEventListener实现事务监控"><a href="#补充2-TransactionalEventListener实现事务监控" class="headerlink" title="补充2: TransactionalEventListener实现事务监控"></a>补充2: TransactionalEventListener实现事务监控</h4><p>我们知道，比如如上“发送短信”，“发送微信”等通知是需要在“订单入库”的基础上才能执行，也就是说“订单入库”完成，才能处理执行相应的监听器的逻辑。</p><p>使用<code>@TransactionalEventListener</code>即可完成如上控制，可参考：<a href="https://docs.spring.io/spring-framework/docs/current/spring-framework-reference/data-access.html#transaction-event" target="_blank" rel="noopener">spring官方文档 Transaction-bound Events</a></p><p>注意一点，官方文档中有提出：</p><blockquote><p>If no transaction is running, the listener is not invoked at all, since we cannot honor the required semantics. You can, however, override that behavior by setting the fallbackExecution attribute of the annotation to true.</p></blockquote><p>也就是说，实现事务控制必须<code>开启事务</code>并且处于一个事务中，<strong>否者该监听器不会被调用</strong>。(不过可以设置<code>fallbackExecution=true</code>)</p><p>前提条件：</p><ul><li>开启事务管理：<code>@EnableTransactionManagement</code></li><li>配置事务管理器: <code>PlatformTransactionManager</code>(这一步<code>@EnableTransactionManagement</code>已默认实现，如须按需配置可手动配置)</li><li>使用<code>@Transactional</code>处理一个事务</li></ul><p>示例代码如下（前提已开启事务）：</p><p>订单服务-“订单入库”：</p><pre><code class="java">@Slf4j@Servicepublic class OrderService {    @Autowired    private EventPublisher createOrderEventPublisher;    /**     * 插入订单表操作     */    @Transactional(rollbackFor = Exception.class)    public void insert(Order order) {        log.info(&quot;[订单入库] start&quot;);        createOrderEventPublisher.publishCreateOrderEvent(new CreateOrderEvent(order));        try {            Thread.sleep(5000);        } catch (InterruptedException e) {            e.printStackTrace();        }        log.info(&quot;[订单入库] end&quot;);    }}</code></pre><p>两个新的监听器，一个不是事务的，一个是事务的做对比：</p><pre><code class="java">@EventListener(condition = &quot;#createOrderEvent.order.status == 3&quot;)public void processCreateOrderEvent3(CreateOrderEvent createOrderEvent) {    log.info(&quot;[EventListener] 注解式 spring event 收到消息，订单名称:{} ; 订单状态为：{} ; 开始处理相应的事件。&quot;, createOrderEvent.getOrder().getOrderName(), createOrderEvent.getOrder().getStatus());}@TransactionalEventListener(condition = &quot;#createOrderEvent.order.status == 3&quot;, phase = TransactionPhase.AFTER_COMMIT)public void processCreateOrderEvent4(CreateOrderEvent createOrderEvent) {    log.info(&quot;[TransactionalEventListener] 注解式 spring event 收到消息，订单名称:{} ; 订单状态为：{} ; 开始处理相应的事件。&quot;, createOrderEvent.getOrder().getOrderName(), createOrderEvent.getOrder().getStatus());}</code></pre><p>控制器里的事务调用请求处理：</p><pre><code class="java">@PostMapping(&quot;/spring/createOrder_transaction&quot;)public String createOrder_transaction(Order order) {    orderService.insert(order);    return &quot;ok&quot;;}</code></pre><p>开启服务发请求测试:</p><pre><code>curl -X POST \  http://localhost:9090/event/spring/createOrder_transaction \  -H &#39;cache-control: no-cache&#39; \  -H &#39;content-type: application/x-www-form-urlencoded&#39; \  -H &#39;postman-token: 1e9d2357-ba51-6aa6-156b-6fe2559cdb06&#39; \  -d &#39;id=1&amp;orderName=53%E5%BA%A62018%E9%A3%9E%E5%A4%A9%E8%8C%85%E5%8F%B0&amp;status=3&amp;userName=%E5%BC%A0%E4%B8%89&#39;</code></pre><p>结果如下：</p><pre><code>2019-02-21 14:07:31.467  INFO 24496 --- [nio-9090-exec-1] c.gemantic.wealth.service.OrderService   : [订单入库] start2019-02-21 14:07:31.468  INFO 24496 --- [nio-9090-exec-1] c.gemantic.wealth.spring.EventPublisher  : 发布了一个[订单创建]事件：CreateOrderEvent(order=Order(id=1, orderName=53度2018飞天茅台, status=3, userName=张三))2019-02-21 14:07:31.482  INFO 24496 --- [nio-9090-exec-1] c.g.wealth.spring.CreateOrderListener    : [EventListener] 注解式 spring event 收到消息，订单名称:53度2018飞天茅台 ; 订单状态为：3 ; 开始处理相应的事件。2019-02-21 14:07:31.483  INFO 24496 --- [nio-9090-exec-1] c.g.wealth.spring.DuanXinNoticeListener  : 实现接口方式：收到[创建订单]事件。[短信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建2019-02-21 14:07:31.483  INFO 24496 --- [nio-9090-exec-1] c.g.wealth.spring.WeiXinNoticeListener   : 实现接口方式：收到[创建订单]事件。[微信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建2019-02-21 14:07:36.483  INFO 24496 --- [nio-9090-exec-1] c.gemantic.wealth.service.OrderService   : [订单入库] end2019-02-21 14:07:36.484  INFO 24496 --- [nio-9090-exec-1] c.g.wealth.spring.CreateOrderListener    : [TransactionalEventListener] 注解式 spring event 收到消息，订单名称:53度2018飞天茅台 ; 订单状态为：3 ; 开始处理相应的事件。</code></pre><p>请求大约5秒后返回，可以看到控制台，<code>EventListener</code>是直接处理的，<code>TransactionalEventListener</code>是在订单<code>insert</code>方法调用后再处理。这是因为<code>TransactionalEventListener</code>默认的处理是事务<code>commit</code>之后处理的，这里可以改注解的<code>phase</code>属性。参考枚举类：<code>TransactionPhase</code>。</p><pre><code class="java">public enum TransactionPhase {    BEFORE_COMMIT,    AFTER_COMMIT,    AFTER_ROLLBACK,    AFTER_COMPLETION}</code></pre><h4 id="补充3-事件的父类监听"><a href="#补充3-事件的父类监听" class="headerlink" title="补充3: 事件的父类监听"></a>补充3: 事件的父类监听</h4><p>如果事件继承了某一父类，此父类也有监听，则每次发布事件，父类子类的监听器都会执行。</p><h3 id="Guava-EventBus"><a href="#Guava-EventBus" class="headerlink" title="Guava EventBus"></a>Guava EventBus</h3><p>Google的进程内的发布订阅模式的实现，轻量级消息系统。可参考：</p><ul><li><a href="https://github.com/google/guava/wiki/EventBusExplained" target="_blank" rel="noopener">github上一分钟概览</a></li></ul><p>那么场景依然是订单与通知场景，下面示例代码为集成在spring中的示例。</p><h4 id="依赖guava包"><a href="#依赖guava包" class="headerlink" title="依赖guava包"></a>依赖guava包</h4><p>maven引入：</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;    &lt;artifactId&gt;guava&lt;/artifactId&gt;    &lt;version&gt;22.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="创建一个-Event-1"><a href="#创建一个-Event-1" class="headerlink" title="创建一个 Event"></a>创建一个 <code>Event</code></h4><p>普通类即可以。</p><pre><code class="java">@Data@AllArgsConstructorpublic class CreateOrderEvent {    private Order order;}</code></pre><h4 id="创建一个-Publisher-1"><a href="#创建一个-Publisher-1" class="headerlink" title="创建一个 Publisher"></a>创建一个 <code>Publisher</code></h4><p>发布者即 <code>EventBus</code>类，因为<code>EventBus</code>不是单例的，我们使用中又想用单例，创建一个事件管理器类。</p><pre><code class="java">/** * 事件管理器：统一管理所有事件 */public class EventBusManager {    /**     * 创建订单     */    public final static EventBus CREATE_ORDER = new EventBus();}</code></pre><h4 id="监听事件-1"><a href="#监听事件-1" class="headerlink" title="监听事件"></a>监听事件</h4><p>可以优雅的使用<code>@Subscribe</code>表示监听某一事件，这个注解没有其他属性。</p><p>除此之外，监听器需要手动注册到<code>EventBus</code>中类如:<code>EventBus.register(listener)</code>。</p><p>方便起见，我们可以在<code>spring</code>容器初始化时注册监听器，并抽象之。</p><pre><code class="java">/** * 抽象的监听器 */public abstract class AbstractBusListener {    /**     * 统一在spring启动时注册事件     */    @PostConstruct    public void init() {        registerEventBus();    }    private void registerEventBus() {        getEventBus().register(this);    }    protected abstract EventBus getEventBus();}@Slf4j@Componentpublic class CreateOrderBusListener extends AbstractBusListener {    /**     * 订单创建事件：短信通知     */    @Subscribe    public void onCreateOrderEvent2DuanxinNotice(CreateOrderEvent event) {        log.info(&quot;收到[创建订单]事件。[短信通知]：亲爱的{}，您的订单[{}]已被创建&quot;, event.getOrder().getUserName(), event.getOrder().getOrderName());    }    /**     * 订单创建事件：微信通知     */    @Subscribe    public void onCreateOrderEvent2WeixinNotice(CreateOrderEvent event) {        log.info(&quot;收到[创建订单]事件。[微信通知]：亲爱的{}，您的订单[{}]已被创建&quot;, event.getOrder().getUserName(), event.getOrder().getOrderName());    }    /**     * 注册的为订单创建事件     */    @Override    protected EventBus getEventBus() {        return EventBusManager.CREATE_ORDER;    }}</code></pre><h4 id="发布事件"><a href="#发布事件" class="headerlink" title="发布事件"></a>发布事件</h4><p>发布事件也是通过<code>EventBus</code>发布，通过其<code>post(event)</code>方法发布。</p><p>示例：</p><pre><code class="java">@PostMapping(&quot;/eventbus/createOrder&quot;)public String createOrderByEventBus(Order order) {    EventBusManager.CREATE_ORDER.post(new com.gemantic.wealth.eventbus.CreateOrderEvent(order));    return &quot;ok&quot;;}</code></pre><h4 id="测试创建订单事件-1"><a href="#测试创建订单事件-1" class="headerlink" title="测试创建订单事件"></a>测试创建订单事件</h4><p>发送请求：</p><pre><code>curl -X POST \  http://localhost:9090/event/eventbus/createOrder \  -H &#39;cache-control: no-cache&#39; \  -H &#39;content-type: application/x-www-form-urlencoded&#39; \  -H &#39;postman-token: 6b5255d5-2b1d-e9c1-7ef3-a5678f7a73ad&#39; \  -d &#39;id=1&amp;orderName=53%E5%BA%A62018%E9%A3%9E%E5%A4%A9%E8%8C%85%E5%8F%B0&amp;status=1&amp;userName=%E5%BC%A0%E4%B8%89&#39;</code></pre><p>看控制台打印：</p><pre><code>2019-02-21 17:34:04.276  INFO 24556 --- [nio-9090-exec-1] c.g.w.eventbus.CreateOrderBusListener    : 收到[创建订单]事件。[微信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建2019-02-21 17:34:04.276  INFO 24556 --- [nio-9090-exec-1] c.g.w.eventbus.CreateOrderBusListener    : 收到[创建订单]事件。[短信通知]：亲爱的张三，您的订单[53度2018飞天茅台]已被创建</code></pre><h4 id="补充1：使用异步事件处理"><a href="#补充1：使用异步事件处理" class="headerlink" title="补充1：使用异步事件处理"></a>补充1：使用异步事件处理</h4><p><code>EventBus</code>实现上改为<code>AsyncEventBus</code>即可，构造器内需要再配一个线程池。举例:</p><pre><code class="java">public final static EventBus CREATE_ORDER = new AsyncEventBus(Executors.newFixedThreadPool(5));</code></pre><h4 id="补充2：DeadEvent"><a href="#补充2：DeadEvent" class="headerlink" title="补充2：DeadEvent"></a>补充2：DeadEvent</h4><p>介绍：</p><blockquote><p>Wraps an event that was posted, but which had no subscribers and thus could not be delivered.Registering a DeadEvent subscriber is useful for debugging or logging, as it can detect misconfigurations in a system’s event distribution.</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/87faef88ly1g0eyfgwartj20sm05wt98.jpg" alt="">所有没被监听的事件都会被包装成一个<code>DeadEvent</code>。这种情况，只需要提供一个监听<code>DeadEvent</code>事件的监听器即可统一处理</p><h4 id="补充3-事件的父类监听-1"><a href="#补充3-事件的父类监听-1" class="headerlink" title="补充3: 事件的父类监听"></a>补充3: 事件的父类监听</h4><p>如果事件继承了某一父类，此父类也有监听，则每次发布事件，父类子类的监听器都会执行。</p><h4 id="补充4-AllowConcurrentEvents"><a href="#补充4-AllowConcurrentEvents" class="headerlink" title="补充4: @AllowConcurrentEvents"></a>补充4: @AllowConcurrentEvents</h4><p>描述：</p><blockquote><p>Marks an event subscriber method as being thread-safe. This annotation indicates that EventBus may invoke the event subscriber simultaneously from multiple threads.This does not mark the method, and so should be used in combination with Subscribe.</p></blockquote><p>创建监听器时会根据此注解判断创建普通监听者还是同步的监听者：</p><pre><code class="java">class Subscriber {  /**   * Creates a {@code Subscriber} for {@code method} on {@code listener}.   */  static Subscriber create(EventBus bus, Object listener, Method method) {    return isDeclaredThreadSafe(method)        ? new Subscriber(bus, listener, method)        : new SynchronizedSubscriber(bus, listener, method);  }  private static boolean isDeclaredThreadSafe(Method method) {    return method.getAnnotation(AllowConcurrentEvents.class) != null;  }  ...}</code></pre><p>同步的监听者则会加锁同步调用订阅方法:</p><pre><code class="java">  @VisibleForTesting  static final class SynchronizedSubscriber extends Subscriber {    private SynchronizedSubscriber(EventBus bus, Object target, Method method) {      super(bus, target, method);    }    @Override    void invokeSubscriberMethod(Object event) throws InvocationTargetException {      synchronized (this) {        super.invokeSubscriberMethod(event);      }    }  }</code></pre><p>加锁会有一定的开销，所以如果是同步的<code>EventBus</code>监听者或者是你确认线程安全的<code>AsyncEventBus</code>监听者，最好标注注解<code>@AllowConcurrentEvents</code></p><h2 id="事件处理异常"><a href="#事件处理异常" class="headerlink" title="事件处理异常"></a>事件处理异常</h2><table><thead><tr><th>–</th><th>Spring Event</th><th>Guava EventBus</th></tr></thead><tbody><tr><td>同步</td><td>会对其他监听器有影响</td><td>不影响其他监听器的处理</td></tr><tr><td>异步</td><td>不影响其他监听器的处理</td><td>不影响其他监听器的处理</td></tr></tbody></table><p>针对同步的情况单独说下。</p><h3 id="EventBus"><a href="#EventBus" class="headerlink" title="EventBus"></a>EventBus</h3><p>事件处理逻辑，无论同步异步都是用线程执行，区别在于同步的情况使用的是同一个线程执行。</p><pre><code class="java">final void dispatchEvent(final Object event) {        this.executor.execute(new Runnable() {            public void run() {                try {                    Subscriber.this.invokeSubscriberMethod(event);                } catch (InvocationTargetException var2) {                    Subscriber.this.bus.handleSubscriberException(var2.getCause(), Subscriber.this.context(event));                }            }        });    }</code></pre><p>this.executor是：</p><pre><code class="java">public static Executor directExecutor() {    return MoreExecutors.DirectExecutor.INSTANCE;}</code></pre><p>可以看到<code>EventBus</code>把异常都统一catch了，异常不上抛，别的监听器依然正常处理。</p><h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><p>Spring调用的时候的异常都是往外抛的：</p><pre><code class="java">protected Object doInvoke(Object... args) {    Object bean = getTargetBean();    ReflectionUtils.makeAccessible(this.bridgedMethod);    try {        return this.bridgedMethod.invoke(bean, args);    }    catch (IllegalArgumentException ex) {        assertTargetBean(this.bridgedMethod, bean, args);        throw new IllegalStateException(getInvocationErrorMessage(bean, ex.getMessage(), args), ex);    }    catch (IllegalAccessException ex) {        throw new IllegalStateException(getInvocationErrorMessage(bean, ex.getMessage(), args), ex);    }    catch (InvocationTargetException ex) {        // Throw underlying exception        Throwable targetException = ex.getTargetException();        if (targetException instanceof RuntimeException) {            throw (RuntimeException) targetException;        }        else {            String msg = getInvocationErrorMessage(bean, &quot;Failed to invoke event listener method&quot;, args);            throw new UndeclaredThrowableException(targetException, msg);        }    }}</code></pre><h3 id="分别适合的场景"><a href="#分别适合的场景" class="headerlink" title="分别适合的场景"></a>分别适合的场景</h3><p>异步情况下，都是多线程处理，无差异。</p><p>同步情况下，同一线程处理，由于Spring会抛出异常，适合事件有依赖的情况，而EventBus适合事件互不依赖的场景。</p><p>举个栗子：</p><ul><li>下订单场景一。订单已经创建，那么会发送短信通知，微信通知，此二者之间无依赖，适合EventBus.</li><li>下订单场景二。如果创建订单也作为事件，那么微信短信通知需依赖订单事件已完成，如果创建订单异常失败则不需要发送通知，适合Spring Event</li></ul><h2 id="异步实现的区别"><a href="#异步实现的区别" class="headerlink" title="异步实现的区别"></a>异步实现的区别</h2><h3 id="EventBus的异步实现"><a href="#EventBus的异步实现" class="headerlink" title="EventBus的异步实现"></a>EventBus的异步实现</h3><p>EventBus的异步实现是依赖于线程池的，在创建的时候确定，实际上是在监听器调用方法的时候采用的异步，同一个<code>EventBus</code>都是同一种处理方式(同步or异步)。<img src="http://ww1.sinaimg.cn/large/87faef88ly1g0f66qorovj20tw075dgg.jpg" alt=""></p><h3 id="Spring的异步实现"><a href="#Spring的异步实现" class="headerlink" title="Spring的异步实现"></a>Spring的异步实现</h3><p>Spring是通过拦截器的机制，被<code>@Async</code>的方法都会被<code>AsyncExecutionInterceptor</code>拦截，然后采用多线程的方式调用：</p><pre><code class="java">public Object invoke(final MethodInvocation invocation) throws Throwable {    Class&lt;?&gt; targetClass = invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null;    Method specificMethod = ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass);    final Method userDeclaredMethod = BridgeMethodResolver.findBridgedMethod(specificMethod);    AsyncTaskExecutor executor = this.determineAsyncExecutor(userDeclaredMethod);    if (executor == null) {        throw new IllegalStateException(&quot;No executor specified and no default executor set on AsyncExecutionInterceptor either&quot;);    } else {        Callable&lt;Object&gt; task = new Callable&lt;Object&gt;() {            public Object call() throws Exception {                try {                    Object result = invocation.proceed();                    if (result instanceof Future) {                        return ((Future)result).get();                    }                } catch (ExecutionException var2) {                    AsyncExecutionInterceptor.this.handleError(var2.getCause(), userDeclaredMethod, invocation.getArguments());                } catch (Throwable var3) {                    AsyncExecutionInterceptor.this.handleError(var3, userDeclaredMethod, invocation.getArguments());                }                return null;            }        };        // 异步调用        return this.doSubmit(task, executor, invocation.getMethod().getReturnType());    }}</code></pre><h3 id="异步方式小结"><a href="#异步方式小结" class="headerlink" title="异步方式小结"></a>异步方式小结</h3><p>综上，还是<code>Spring Event</code>更加灵活多变，适用场景更多。</p><h2 id="Spring-Event与-Guava-EventBus的比较"><a href="#Spring-Event与-Guava-EventBus的比较" class="headerlink" title="Spring Event与 Guava EventBus的比较"></a>Spring Event与 Guava EventBus的比较</h2><table><thead><tr><th>–</th><th>Spring Event</th><th>Guava EventBus</th></tr></thead><tbody><tr><td>Event</td><td>任意对象</td><td>任意对象</td></tr><tr><td>Publisher</td><td>EventBus</td><td>ApplicationEventPublisher</td></tr><tr><td>Subscriber</td><td>@EventListener</td><td>@Subscribe </td></tr><tr><td>发布方法</td><td>ApplicationEventPublisher#publishEvent</td><td>EventBus#post</td></tr><tr><td>注册方法</td><td>spring自动注册</td><td>手动注册：EventBus#register</td></tr><tr><td>是否支持异步</td><td>支持。@Async</td><td>支持。AsyncEventBus</td></tr><tr><td>是否支持事务</td><td>支持。@TransactionalEventListener</td><td>不支持。</td></tr><tr><td>是否支持条件过滤</td><td>支持。</td><td>不支持。</td></tr><tr><td>是否支持DeadEvent</td><td>不支持。</td><td>支持。</td></tr><tr><td>是否支持事件继承</td><td>支持。</td><td>支持。</td></tr><tr><td>同步时是否支持排序</td><td>支持。</td><td>不支持。</td></tr><tr><td>事件异常处理</td><td>异常上抛</td><td>捕获异常并不上抛</td></tr><tr><td>复杂度</td><td>复杂</td><td>轻量</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>Spring Event</code>与<code>Guava EventBus</code>在设计上略有不同，可根据业务场景按需使用，总的来说<code>Guava EventBus</code>比较轻量一些，适合大多数业务场景，而<code>Spring Event</code>稍微重了，但也开箱可用，与Spring天然一体，多了很多花哨的功能也适合更多的复杂场景。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近公司内部准备搞消息驱动，即在订单系统上使用消息/事件驱动的设计，这里研究了一下进程内的
事件驱动设计，主要分析了业内常用的&lt;code&gt;Spring Event&lt;/code&gt;和&lt;code&gt;EventBus&lt;/code&gt;，本篇博文目的如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;熟悉事件驱动的设计思想&lt;/li&gt;
&lt;li&gt;会在项目中使用事件驱动(spring event和 eventbus)&lt;/li&gt;
&lt;li&gt;spring event和 eventbus 的异同点&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="event driven" scheme="https://www.chenruiwen.cn/categories/event-driven/"/>
    
    
      <category term="event driven" scheme="https://www.chenruiwen.cn/tags/event-driven/"/>
    
      <category term="Spring" scheme="https://www.chenruiwen.cn/tags/Spring/"/>
    
      <category term="Guava" scheme="https://www.chenruiwen.cn/tags/Guava/"/>
    
      <category term="SpringEvent" scheme="https://www.chenruiwen.cn/tags/SpringEvent/"/>
    
      <category term="EventBus" scheme="https://www.chenruiwen.cn/tags/EventBus/"/>
    
  </entry>
  
  <entry>
    <title>再见2018，你好2019</title>
    <link href="https://www.chenruiwen.cn/essay/year-end-summary-2018/"/>
    <id>https://www.chenruiwen.cn/essay/year-end-summary-2018/</id>
    <published>2018-12-31T13:58:13.000Z</published>
    <updated>2018-12-31T14:32:27.995Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天是2018年的最后一天，是时候需要做一个年终总结了。总体来看今年做了很多，也有很多计划没有完成很遗憾，从各个方面总结吧，为了2019过的更有意义一些。</p><a id="more"></a><h2 id="我的2018"><a href="#我的2018" class="headerlink" title="我的2018"></a>我的2018</h2><p>2018年，这是一个波荡起伏的一年(可能更多的是“伏”:))，简单的整理如下，我的2018事件：</p><ul><li>结婚（最大的一件事了）</li><li>工作业务改动(公司新产品从0到1完成了多个项目)</li><li>技术升级(服务化的报警、监控、分布式配置等技术调研与升级，与公司一起成长)</li></ul><h3 id="结婚"><a href="#结婚" class="headerlink" title="结婚"></a>结婚</h3><p>结婚是今年最大的一件事，从年初就开始准备了，也就是去年的元旦，去我媳妇儿老家提了婚，经过媳妇儿爷爷掐指一算，定在10.3号，嗯，玄学就是让人很忙碌。于是乎开启今年的结婚筹备工作了。</p><ul><li>一月：预约婚纱摄影</li><li>二月：定婚庆公司，定酒店</li><li>三月：婚博会上买了三金和钻戒</li><li>四月：双发父母第一次见面</li><li>五月：双发父母第二次见面</li><li>六月：回家试婚纱，试装等</li><li>七月至九月：N次沟通婚庆公司(婚庆公司有些服务不到位，店大欺客，体验不好)，九月底约见了司仪，准备婚礼紧张的准备。</li><li>十月：结婚，度蜜月，完成了人生上的一件大事。</li></ul><p>关于结婚，一个字：累。不过还是最终很有感触，也是建立了自己的家庭，从职责上来看，更要担起一个男人的责任。</p><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><p>作为一名在互联网金融行业工作的员工，可以说今年公司的业务上也是“坎坎坷坷”。众说周知，今年的p2p暴雷事件也是轰动全国，感觉从那开始便是国家经济下行开始，公司各种裁员，员工各种失业，人民群众各种消费降级…2018年也是会载入史册的一年…</p><p>扯的有点远，虽说是互金行业，但是我们公司并不是p2p公司，我们公司只是做互联网金融服务，所以影响不是很大…在领导的英明指挥下，我们公司也是在主业务稳定的情况下发展了并产出了to B端的企业服务产品以及to C端的电商产品。</p><p>从技术人员的角度上看，今年更是参与从0到1快速迭代开发新产品，更加深刻理解了敏捷开发的流程与实践。除此之外作为一个以java为主开发语言的后端从业人员，在dubbo服务化的基础上，调研并集成了主流的调用链监控框架(美团点评的<code>cat</code>)，分布式配置中心(携程的<code>Apollo</code>)，流量监控框架(阿里的<code>sentinel</code>)，更深刻的理解了分布式服务化以及微服务的设计思想，这些使得我们的系统更加的高性能，系统问题处理更加快速(甚至都能抢答了)，这是最有成就感的事情。</p><h3 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h3><p>技术是一个以技术为核心的开发人员最重要的一项技能，我这里的技术专指开发技术。</p><p>工作中学习到的：</p><ul><li>限流神器：<code>Sentinel</code></li><li>链路跟踪与性能监控：<code>cat</code></li><li>分布式配置中心：<code>Apollo</code></li><li>分布式调度任务：<code>elastic job</code></li><li><code>python</code></li><li>java性能测试：<code>JMH</code></li></ul><p>业余:</p><ul><li>开始写博客</li><li>spring cloud全家桶</li><li>netty</li><li>dubbo源码分析</li></ul><p>阅读，今年买了不少书，但是大部分没看完，不过看一些还是有一些收获：</p><ul><li>浪潮之巅：目前看了第三版上册的一部分，吴军博士的书都有的一看。</li><li>大型网站技术架构：架构入门，够绝大部分中小型公司的架构设计了</li><li>java并发编程实战：经典中的经典，必读</li><li>thinking in java: 圣经。</li><li>微服务设计：未看完，偏方法论，对微服务架构这里有不错的启发</li><li>财富自由之路：李笑来今年也是颇受争议，书籍有些鸡汤的味道，也能让自己审视总结过去一些“不正确”的学习方法，从而改善之。（未看完）</li><li>数据结构与算法分析：短板之一，大学的时候学习不认真，现在只能补了。（未看完）</li></ul><h2 id="展望2019"><a href="#展望2019" class="headerlink" title="展望2019"></a>展望2019</h2><p>2019，应该也是对我来说不平凡的一年。我对2019的计划也是有的。</p><p>2019备考2020考研！目标北邮！</p><p>也是出于个人发展与对知识的渴望，确实对机器学习有些兴趣，因为好奇，所以想去了解。这意味着需要重新拾起一些知识：</p><ul><li>英语：计划背单词和做阅读</li><li>数学：硬东西，大部分时间将交给数学了</li><li>专业课：不解释，经次于数学</li><li>政治：最后背</li></ul><p>考研是个漫长的备考过程，终于也是避免不了体验考研的感觉了，希望自己通过坚持能考上。(学习时间真的没有在学校的时候多呀，可能博客会更新的慢了)</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;今天是2018年的最后一天，是时候需要做一个年终总结了。总体来看今年做了很多，也有很多计划没有完成很遗憾，从各个方面总结吧，为了2019过的更有意义一些。&lt;/p&gt;
    
    </summary>
    
      <category term="essay" scheme="https://www.chenruiwen.cn/categories/essay/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之Cluster</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-Cluster/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-Cluster/</id>
    <published>2018-12-23T15:11:13.000Z</published>
    <updated>2018-12-23T15:07:18.375Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg" alt="">前面把路由层的重要接口都看了一遍，接下来就回到最初的起点，该看<code>Cluster</code>接口了。<a id="more"></a></p><h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p>一看官网对<code>Cluster</code>的描述：</p><blockquote><p><code>Cluster</code>将<code>Directory</code>中的多个<code>Invoker</code> 伪装成一个<code>Invoker</code>，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个</p></blockquote><p>简而言之就是<code>容错的策略</code>。</p><p>二看接口定义：</p><pre><code class="java">@SPI(FailoverCluster.NAME)public interface Cluster {    /**     * Merge the directory invokers to a virtual invoker.     *     * @param &lt;T&gt;     * @param directory     * @return cluster invoker     * @throws RpcException     */    @Adaptive    &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException;}</code></pre><p>很简单的一个接口，看注释知道是将<code>Directory</code>中获取到的调用者集合中合并出一个虚拟调用者。而且我们还在知其默认实现是<code>FailoverCluster</code>。</p><p>三看继承结构图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fyh0xufzi0j222i0e6di7.jpg" alt="">默认提供了很多策略，接下来主要分析常用策略</p><h3 id="FailoverCluster"><a href="#FailoverCluster" class="headerlink" title="FailoverCluster"></a>FailoverCluster</h3><p><code>join</code>方法：</p><pre><code>public &lt;T&gt; Invoker&lt;T&gt; join(Directory&lt;T&gt; directory) throws RpcException {    return new FailoverClusterInvoker&lt;T&gt;(directory);}</code></pre><p>可见join方法实际是只负责创建实现<code>Invoker</code>接口的具体实现策略。</p><p>再看<code>FailoverClusterInvoker</code>，其继承并实现了<code>AbstractClusterInvoker</code>了<code>doInvoke</code>方法，其余的策略的具体实现也是<code>doInvoke</code>的实现里具体处理。</p><p>官网描述：</p><blockquote><p>失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2” 来设置重试次数(不含第一次)。</p></blockquote><p>贴代码:</p><pre><code class="java">@SuppressWarnings({&quot;unchecked&quot;, &quot;rawtypes&quot;})public Result doInvoke(Invocation invocation, final List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    List&lt;Invoker&lt;T&gt;&gt; copyinvokers = invokers;    checkInvokers(copyinvokers, invocation); // 检查服务提供者是否有可用的    // 获取 retries 属性，默认 2 次，此处调用len = 2+1 = 3 次    int len = getUrl().getMethodParameter(invocation.getMethodName(), Constants.RETRIES_KEY, Constants.DEFAULT_RETRIES) + 1;    if (len &lt;= 0) {        len = 1;    }    // retry loop.    RpcException le = null; // last exception.    List&lt;Invoker&lt;T&gt;&gt; invoked = new ArrayList&lt;Invoker&lt;T&gt;&gt;(copyinvokers.size()); // invoked invokers.    Set&lt;String&gt; providers = new HashSet&lt;String&gt;(len);    for (int i = 0; i &lt; len; i++) {        //Reselect before retry to avoid a change of candidate `invokers`.        //NOTE: if `invokers` changed, then `invoked` also lose accuracy.        if (i &gt; 0) {            checkWhetherDestroyed();            copyinvokers = list(invocation);            // check again            checkInvokers(copyinvokers, invocation);        }        Invoker&lt;T&gt; invoker = select(loadbalance, invocation, copyinvokers, invoked); // 从注册中心获取一个可用的服务提供者        invoked.add(invoker);        RpcContext.getContext().setInvokers((List) invoked);        try {            Result result = invoker.invoke(invocation); // 远程调用            if (le != null &amp;&amp; logger.isWarnEnabled()) { // 远程调用出现rpc异常，打印异常日志                logger.warn(&quot;Although retry the method &quot; + invocation.getMethodName()                        + &quot; in the service &quot; + getInterface().getName()                        + &quot; was successful by the provider &quot; + invoker.getUrl().getAddress()                        + &quot;, but there have been failed providers &quot; + providers                        + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size()                        + &quot;) from the registry &quot; + directory.getUrl().getAddress()                        + &quot; on the consumer &quot; + NetUtils.getLocalHost()                        + &quot; using the dubbo version &quot; + Version.getVersion() + &quot;. Last error is: &quot;                        + le.getMessage(), le);            }            return result;        } catch (RpcException e) {            if (e.isBiz()) { // biz exception.                throw e;            }            le = e;        } catch (Throwable e) {            le = new RpcException(e.getMessage(), e);        } finally {            providers.add(invoker.getUrl().getAddress());        }    }    // 所有重试次数都调用完还是失败，抛异常    throw new RpcException(le != null ? le.getCode() : 0, &quot;Failed to invoke the method &quot;            + invocation.getMethodName() + &quot; in the service &quot; + getInterface().getName()            + &quot;. Tried &quot; + len + &quot; times of the providers &quot; + providers            + &quot; (&quot; + providers.size() + &quot;/&quot; + copyinvokers.size()            + &quot;) from the registry &quot; + directory.getUrl().getAddress()            + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; using the dubbo version &quot;            + Version.getVersion() + &quot;. Last error is: &quot;            + (le != null ? le.getMessage() : &quot;&quot;), le != null &amp;&amp; le.getCause() != null ? le.getCause() : le);}</code></pre><p>这也是刚开始使用<code>dubbo</code>时踩过的坑。记得当时一些修改类型的接口比如重要的<code>购买</code>等接口，超时了，导致购买了3次，这便是那个问题的原因，修改cluster策略为<code>failfast</code>即可。</p><h3 id="FailfastCluster"><a href="#FailfastCluster" class="headerlink" title="FailfastCluster"></a>FailfastCluster</h3><p>先看官网描述:</p><blockquote><p>快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。</p></blockquote><p><em>ps:非常适合之前踩坑的购买等情景哈。</em></p><p>再直接看<code>FailfastClusterInvoker</code>的<code>doInvoke</code>:</p><pre><code class="java">public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    checkInvokers(invokers, invocation); // 检查服务提供者是否有可用的    Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null);    try {        return invoker.invoke(invocation);    } catch (Throwable e) {        // 出错便抛异常        if (e instanceof RpcException &amp;&amp; ((RpcException) e).isBiz()) { // biz exception.            throw (RpcException) e;        }        throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, &quot;Failfast invoke providers &quot; + invoker.getUrl() + &quot; &quot; + loadbalance.getClass().getSimpleName() + &quot; select from all providers &quot; + invokers + &quot; for service &quot; + getInterface().getName() + &quot; method &quot; + invocation.getMethodName() + &quot; on consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e.getCause() != null ? e.getCause() : e);    }}</code></pre><p>非常直接。</p><h3 id="FailsafeCluster"><a href="#FailsafeCluster" class="headerlink" title="FailsafeCluster"></a>FailsafeCluster</h3><p>官方描述:</p><blockquote><p>失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。</p></blockquote><p><code>FailsafeClusterInvoker</code>的<code>doInvoke</code>方法：</p><pre><code class="java">public Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    try {        checkInvokers(invokers, invocation);        Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null);        return invoker.invoke(invocation);    } catch (Throwable e) {        // 嗯，直接无视        logger.error(&quot;Failsafe ignore exception: &quot; + e.getMessage(), e);        return new RpcResult(); // ignore    }}</code></pre><p>直接无视异常。</p><h3 id="FailbackCluster"><a href="#FailbackCluster" class="headerlink" title="FailbackCluster"></a>FailbackCluster</h3><p>官方描述:</p><blockquote><p>失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。</p></blockquote><p><code>FailbackClusterInvoker</code>的<code>doInovke</code>方法：</p><pre><code class="java">protected Result doInvoke(Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    try {        checkInvokers(invokers, invocation);        Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, null);        return invoker.invoke(invocation);    } catch (Throwable e) {        logger.error(&quot;Failback to invoke method &quot; + invocation.getMethodName() + &quot;, wait for retry in background. Ignored exception: &quot;                + e.getMessage() + &quot;, &quot;, e);        addFailed(invocation, this); // 添加到失败恢复线程队列中        return new RpcResult(); // ignore    }}</code></pre><p><code>addFailed</code>方法也很简单：</p><pre><code class="java">private void addFailed(Invocation invocation, AbstractClusterInvoker&lt;?&gt; router) {    if (retryFuture == null) {        synchronized (this) {            if (retryFuture == null) {                retryFuture = scheduledExecutorService.scheduleWithFixedDelay(new Runnable() {                    public void run() {                        // collect retry statistics                        try {                            retryFailed(); // 重试逻辑                        } catch (Throwable t) { // Defensive fault tolerance                            logger.error(&quot;Unexpected error occur at collect statistic&quot;, t);                        }                    }                }, RETRY_FAILED_PERIOD, RETRY_FAILED_PERIOD, TimeUnit.MILLISECONDS); // 5秒重试一次            }        }    }    failed.put(invocation, router);}void retryFailed() {    if (failed.size() == 0) {        return;    }    for (Map.Entry&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt; entry : new HashMap&lt;Invocation, AbstractClusterInvoker&lt;?&gt;&gt;(            failed).entrySet()) {        Invocation invocation = entry.getKey();        Invoker&lt;?&gt; invoker = entry.getValue();        try {            invoker.invoke(invocation);            failed.remove(invocation); // 重试成功后，从队列中出去了        } catch (Throwable e) {            logger.error(&quot;Failed retry to invoke method &quot; + invocation.getMethodName() + &quot;, waiting again.&quot;, e);        }    }}</code></pre><p>这里看样子适合处理一些消息类比如购买成功后发送短信、微信等通知场景，不过考虑到一致性，可以自定义cluster继承<code>FailbackCluster</code>，重新实现.</p><h3 id="ForkingCluster"><a href="#ForkingCluster" class="headerlink" title="ForkingCluster"></a>ForkingCluster</h3><p>官方描述:</p><blockquote><p>并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2” 来设置最大并行数。</p></blockquote><p><code>ForkingClusterInvoker</code>的<code>doInvoke</code>:</p><pre><code class="java">public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    checkInvokers(invokers, invocation);    final List&lt;Invoker&lt;T&gt;&gt; selected;    final int forks = getUrl().getParameter(Constants.FORKS_KEY, Constants.DEFAULT_FORKS); // 获取 forks 属性，默认为 2    final int timeout = getUrl().getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); // 获取 timeout 属性， 默认 1000    if (forks &lt;= 0 || forks &gt;= invokers.size()) {        selected = invokers;    } else {        selected = new ArrayList&lt;Invoker&lt;T&gt;&gt;();        // 分配给不同的机器        for (int i = 0; i &lt; forks; i++) {            // TODO. Add some comment here, refer chinese version for more details.            Invoker&lt;T&gt; invoker = select(loadbalance, invocation, invokers, selected);            if (!selected.contains(invoker)) {//Avoid add the same invoker several times.                selected.add(invoker);            }        }    }    RpcContext.getContext().setInvokers((List) selected);    final AtomicInteger count = new AtomicInteger();    final BlockingQueue&lt;Object&gt; ref = new LinkedBlockingQueue&lt;Object&gt;();    // 多线程处理，并将结果放入阻塞队列    for (final Invoker&lt;T&gt; invoker : selected) {        executor.execute(new Runnable() {            public void run() {                try {                    Result result = invoker.invoke(invocation);                    ref.offer(result);                } catch (Throwable e) {                    int value = count.incrementAndGet();                    if (value &gt;= selected.size()) {                        ref.offer(e);                    }                }            }        });    }    try {        Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS); // 获取队列头的值        if (ret instanceof Throwable) {            Throwable e = (Throwable) ret;            throw new RpcException(e instanceof RpcException ? ((RpcException) e).getCode() : 0, &quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e.getCause() != null ? e.getCause() : e);        }        return (Result) ret;    } catch (InterruptedException e) {        throw new RpcException(&quot;Failed to forking invoke provider &quot; + selected + &quot;, but no luck to perform the invocation. Last error is: &quot; + e.getMessage(), e);    }}</code></pre><p>将请求分配给不同的机器处理，在超时时间内获取最先返回的请求结果。太浪费资源了，大部分情况还是用不到的。</p><h3 id="BroadcastCluster"><a href="#BroadcastCluster" class="headerlink" title="BroadcastCluster"></a>BroadcastCluster</h3><p>官方描述:</p><blockquote><p>广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。</p></blockquote><p><code>BroadcastClusterInvoker</code>的<code>doInvoke</code>方法:</p><pre><code class="java">public Result doInvoke(final Invocation invocation, List&lt;Invoker&lt;T&gt;&gt; invokers, LoadBalance loadbalance) throws RpcException {    checkInvokers(invokers, invocation);    RpcContext.getContext().setInvokers((List) invokers);    RpcException exception = null;    Result result = null;    // 调用所有服务提供者    for (Invoker&lt;T&gt; invoker : invokers) {        try {            result = invoker.invoke(invocation);        } catch (RpcException e) {            exception = e;            logger.warn(e.getMessage(), e);        } catch (Throwable e) {            exception = new RpcException(e.getMessage(), e);            logger.warn(e.getMessage(), e);        }    }    // 任意一台有报错则报错    if (exception != null) {        throw exception;    }    return result;}</code></pre><p>果然还是仅适合于通知所有提供者必须都一致的情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>Cluster</code>就是工厂+策略的方式，创造了<code>Invoker</code>对象，并实现了不同的容错策略。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg&quot; alt=&quot;&quot;&gt;
前面把路由层的重要接口都看了一遍，接下来就回到最初的起点，该看&lt;code&gt;Cluster&lt;/code&gt;接口了。
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
      <category term="LoadBalance" scheme="https://www.chenruiwen.cn/tags/LoadBalance/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之ConsistentHashLoadBalance</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-ConsistentHashLoadBalance/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-ConsistentHashLoadBalance/</id>
    <published>2018-12-18T13:50:13.000Z</published>
    <updated>2018-12-18T13:56:01.316Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文回顾，之前介绍了：</p><ul><li><a href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-one/">RandomLoadBalance和RoundRobinLoadBalance</a></li><li><a href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-LeastActiveLoadBalance/">LeastActiveLoadBalance</a></li></ul><p>今天分析一下最后一个负载均衡器<code>ConsistentHashLoadBalance</code>.<a id="more"></a></p><h3 id="ConsistentHashLoadBalance"><a href="#ConsistentHashLoadBalance" class="headerlink" title="ConsistentHashLoadBalance"></a>ConsistentHashLoadBalance</h3><p>一致性Hash负载均衡器. 看一下官方的介绍：</p><blockquote><ul><li>一致性 Hash，相同参数的请求总是发到同一提供者。</li><li>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。</li><li>算法参见：<a href="http://en.wikipedia.org/wiki/Consistent_hashing" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Consistent_hashing</a></li><li>缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=”hash.arguments” value=”0,1” /&gt;</li><li>缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=”hash.nodes” value=”320” /&gt;</li></ul></blockquote><h3 id="一致性hash原理"><a href="#一致性hash原理" class="headerlink" title="一致性hash原理"></a>一致性hash原理</h3><p>在理解一致性hash原理之前，先看一看传统的hash算法。</p><h4 id="hash算法"><a href="#hash算法" class="headerlink" title="hash算法"></a>hash算法</h4><p>hash算法最初的目的是来解决缓存问题。举个例子，分布式场景，假设有3台redis服务器做缓存，我们如何合理分配这3台redis的资源呢？</p><p>答案很简单，使用hash算法。<code>hash(userId) % 3</code>来获取到路由的服务器即可。如图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya2fh4iiyj212o0tijtq.jpg" alt=""></p><p>但是以上算法看似能解决问题，但是如果其中一台redis挂掉了，或者需要动态增加一台redis服务器，那么原先的hash算法就不适用了！</p><p>既然hash算法是无法解决上述问题，那么如何解决呢？一致性hash算法即可。</p><h4 id="一致性hash算法"><a href="#一致性hash算法" class="headerlink" title="一致性hash算法"></a>一致性hash算法</h4><p>基本原理：$$\begin{gather}a + b\end{gather}$$</p><p>\(a + b\)</p><p>将哈希空间 [0, 2^n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。</p><p>初始话一个 0 ~ 2^32 -1 的hash环：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya3f2bn6qj20qi0oq3z5.jpg" alt=""></p><p>假设初始化有3个节点，根据ip进行hash分配到不同的位置如下：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya3k3876cj20no0lst9i.jpg" alt=""></p><p>hash到服务器算法：将数据<code>key</code>使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。</p><p>假设有数据data1,data2,data3，那么如下数据将会分别落在NodeC,NodeA,NodeB上:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya3uq6yp4j20s40nyq48.jpg" alt=""></p><p>如果此时动态增加一个节点NodeD,那么如下所示，只会影响到data3数据的，其他数据并未影响：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya41dgy80j20qm0qawg4.jpg" alt=""></p><p>这样就是一致性hash算法，只影响一小部分数据。</p><p>依然有一个问题，即如果节点数量太小，将会由于数据节点分布不均匀导致数据倾斜问题。如下图所示：落在节点NodeA上的数据远大于NodeB上的数据。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya466egk5j20o80lqt9g.jpg" alt=""></p><p>如何解决这个问题呢，将<code>引入虚拟节点机制</code>：通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。</p><p>如下所示：NodeA,NodeB各虚拟出 n 个节点均匀分布在hash环上，这样通过虚拟节点到实际节点的映射来解决数据倾斜问题。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fya4atw7d4j20po0m4q4a.jpg" alt=""></p><h3 id="再看源码"><a href="#再看源码" class="headerlink" title="再看源码"></a>再看源码</h3><p>涉及到的配置：</p><blockquote><ul><li>缺省只对第一个参数 Hash，如果要修改，请配置 &lt;dubbo:parameter key=”hash.arguments” value=”0,1” /&gt;</li><li>缺省用 160 份虚拟节点，如果要修改，请配置 &lt;dubbo:parameter key=”hash.nodes” value=”320” /&gt;</li></ul></blockquote><p>先看<code>doSelect</code>方法：</p><pre><code class="java">@Overrideprotected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {    String key = invokers.get(0).getUrl().getServiceKey() + &quot;.&quot; + invocation.getMethodName(); // 获取方法调用名    int identityHashCode = System.identityHashCode(invokers); // 生成调用列表hashcode    ConsistentHashSelector&lt;T&gt; selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key); // 从缓存中获取此方法的一致性哈希选择器    if (selector == null || selector.identityHashCode != identityHashCode) {        // 缓存 key -&gt; selector        selectors.put(key, new ConsistentHashSelector&lt;T&gt;(invokers, invocation.getMethodName(), identityHashCode));        selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key);    }    return selector.select(invocation); // 选择节点实现由内部类selector完成}</code></pre><p>可以得出结论，核心负载均衡操作都交给了其静态内部类<code>ConsistentHashSelector</code>选择器.</p><p>内部选择器的成员与构造器：</p><pre><code class="java">private static final class ConsistentHashSelector&lt;T&gt; {    private final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers; // 虚拟节点    private final int replicaNumber; // 副本数    private final int identityHashCode; // hashcode    private final int[] argumentIndex; // 参数索引数组    ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) {        // 1.初始化属性        this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;(); // 虚拟节点用TreeMap结构        this.identityHashCode = identityHashCode; // hashcode取调用列表hashcode        URL url = invokers.get(0).getUrl();        this.replicaNumber = url.getMethodParameter(methodName, &quot;hash.nodes&quot;, 160); // 获取 url 上 hash.nodes属性，默认160        String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, &quot;hash.arguments&quot;, &quot;0&quot;)); // 获取 url 上 hash.arguments属性，默认&quot;0&quot;        // 获取 hash.arguments 数组        argumentIndex = new int[index.length];        for (int i = 0; i &lt; index.length; i++) {            argumentIndex[i] = Integer.parseInt(index[i]);        }        // 2.开始创建虚拟结点        // 对每个invoker生成replicaNumber个虚拟结点，并存放于TreeMap中        for (Invoker&lt;T&gt; invoker : invokers) {            String address = invoker.getUrl().getAddress();            for (int i = 0; i &lt; replicaNumber / 4; i++) {                byte[] digest = md5(address + i);                for (int h = 0; h &lt; 4; h++) {                    long m = hash(digest, h);                    virtualInvokers.put(m, invoker);                }            }        }    }}</code></pre><p>可见，在构造器内主要是</p><ul><li>初始化属性</li><li>创建虚拟节点(也算是初始化属性的一部分)</li></ul><p>核心方法，<code>ConsistentHashSelector</code>的<code>select</code>方法:</p><pre><code class="java">public Invoker&lt;T&gt; select(Invocation invocation) {    String key = toKey(invocation.getArguments()); // 根据调用参数获取 key    byte[] digest = md5(key); // 生成消息摘要    // 将消息摘要转换为hashCode，这里仅取0-31位来生成HashCode    // 调用sekectForKey方法选择结点。    return selectForKey(hash(digest, 0));}</code></pre><p>此方法具体可以拆分为</p><ul><li>md5() 生成消息摘要</li><li>hash() 获取hash值</li><li>selectForKey() 根据hash值寻址</li></ul><p>md5和hash方法就不说了，hash方法的位操作先不深究，主要的方法还是<code>ConsistentHashSelector</code>的<code>selectForKey</code>方法:</p><pre><code class="java">private Invoker&lt;T&gt; selectForKey(long hash) {    // 1.找到一个该hash值得尾节点，然后获取其上一个节点    Map.Entry&lt;Long, Invoker&lt;T&gt;&gt; entry = virtualInvokers.tailMap(hash, true).firstEntry();    // 2.如果该节点不存在，即表示落在环上最后一个和第一个之间的位置，那么直接返回最小值(第一个点)，这样就形成了逻辑环    if (entry == null) {        entry = virtualInvokers.firstEntry();    }    return entry.getValue();}</code></pre><p>这里解释下，如图所示，</p><ul><li>如果hash值落在了<code>【2】</code>的位置，那么就直接返回<code>NodeA#1</code>即可。</li><li>如果hash值落在<code>【1】</code>的位置，由于<code>【1】</code>后面已经没有虚拟节点，因此返回<code>TreeMap</code>的最小值，即首节点<code>NodeB#3</code>，这样就形成了一个逻辑环。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fyb8awlu1uj20ty0oa75s.jpg" alt=""></li></ul><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>参考:</p><ul><li><a href="https://blog.csdn.net/cywosp/article/details/23397179" target="_blank" rel="noopener">五分钟理解一致性哈希算法(consistent hashing)</a></li></ul><p>这样<code>LoadBalance</code>基本完成，最后再回到最初的起点<code>Cluster</code>接口。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前文回顾，之前介绍了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-one/&quot;&gt;RandomLoadBalance和RoundRobinLoadBalance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-LeastActiveLoadBalance/&quot;&gt;LeastActiveLoadBalance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今天分析一下最后一个负载均衡器&lt;code&gt;ConsistentHashLoadBalance&lt;/code&gt;.
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
      <category term="LoadBalance" scheme="https://www.chenruiwen.cn/tags/LoadBalance/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之LeastActiveLoadBalance</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-LeastActiveLoadBalance/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-LeastActiveLoadBalance/</id>
    <published>2018-12-10T14:13:13.000Z</published>
    <updated>2018-12-10T14:15:06.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前介绍了负载均衡器之<code>RandomLoadBalance</code>和<code>RoundRobinLoadBalance</code>,今天分析一下<code>LeastActiveLoadBalance</code>。<a id="more"></a></p><h2 id="LeastActiveLoadBalance"><a href="#LeastActiveLoadBalance" class="headerlink" title="LeastActiveLoadBalance"></a>LeastActiveLoadBalance</h2><p>最少活跃调用数负载均衡，根据文档描述：</p><blockquote><ul><li>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。</li><li>使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</li></ul></blockquote><p>举个栗子说明一下流程：比如有三个服务{a,b,c}，每个服务都有一个活跃计数，初始化为0。a处理请求时，计数器+1为1，请求处理完后计数器-1为0。如果此时同时b,c也在处理请求，但是b,c的处理慢，计数器分别为1和2，那么此时a的活跃计数器最少为0，新的请求来时将由a来处理。</p><pre><code class="java">protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {    int length = invokers.size(); // 提供者数量    int leastActive = -1; // 提供者中的最小活跃数    int leastCount = 0; // 相同最小活跃数的数量    int[] leastIndexs = new int[length]; // 相同最小活跃数的索引    int totalWeight = 0; // 总权重    int firstWeight = 0; // 第一个权重，用于比较权重是否相同    boolean sameWeight = true; // 权重是否都相同    for (int i = 0; i &lt; length; i++) {        Invoker&lt;T&gt; invoker = invokers.get(i);        int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 活跃数        int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // 权重        if (leastActive == -1 || active &lt; leastActive) { // 发现最小活跃数重新开始            leastActive = active; // 记录当前最小活跃数            leastCount = 1; // 重置相同最小活跃数的个数            leastIndexs[0] = i; // 重置最小活跃数索引            totalWeight = weight; // 重置总权重            firstWeight = weight; // 记录第一个权重            sameWeight = true; // 重置标识        } else if (active == leastActive) { // 累计相同最小活跃数            leastIndexs[leastCount++] = i; // 记录索引            totalWeight += weight; // 累计总权重            // 判断所有权重是否相同            if (sameWeight &amp;&amp; i &gt; 0                    &amp;&amp; weight != firstWeight) {                sameWeight = false;            }        }    }    // assert(leastCount &gt; 0)    if (leastCount == 1) {        // 如果相同最小活跃数的数量只有1个，直接返回        return invokers.get(leastIndexs[0]);    }    if (!sameWeight &amp;&amp; totalWeight &gt; 0) {        // 如果权重不相同且权重大于0,则按总权重数获取一个随机值        int offsetWeight = random.nextInt(totalWeight);        // 根据权重随机返回一个invoker        for (int i = 0; i &lt; leastCount; i++) {            int leastIndex = leastIndexs[i];            offsetWeight -= getWeight(invokers.get(leastIndex), invocation);            if (offsetWeight &lt;= 0)                return invokers.get(leastIndex);        }    }    // 如果权重相同或权重为0则随机获取一个    return invokers.get(leastIndexs[random.nextInt(leastCount)]);}</code></pre><p>源码中的这个算法注释还是很详细的，鄙人就简单的翻译为中文方便观察…这个算法过程还是比较明显的，大致过程分为两种步骤：</p><ol><li>记录活跃数相关信息(最小活跃数，最小活跃数数量，相同活跃数索引，权重是否相同)</li><li>根据活跃数信息获取invokers。<ul><li>只有一个最小活跃数数量，直接返回该invoker</li><li>权重相同，则根据最小活跃数数量随机获取invoker</li><li>权重不相同，则根据权重获取invoker（此算法与<code>RoundRobinLoadBalance</code>中的权重获取有异曲同工之妙）</li></ul></li></ol><p>还有一个问题：<strong>那么何时修改活跃数呢？</strong></p><p>答案是在<code>com.alibaba.dubbo.rpc.filter.ActiveLimitFilter</code>中。</p><p>我们可以看到<code>ActiveLimitFilter</code>中是如何拦截的，代码片段如下：</p><pre><code class="java">public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException {    // 省略部分代码...    try {        long begin = System.currentTimeMillis();        RpcStatus.beginCount(url, methodName); // 活跃数+1        try {            Result result = invoker.invoke(invocation);            RpcStatus.endCount(url, methodName, System.currentTimeMillis() - begin, true); // 活跃数-1            return result;        } catch (RuntimeException t) {            RpcStatus.endCount(url, methodName, System.currentTimeMillis() - begin, false);            throw t;        }    } finally {        // 省略部分代码    }}</code></pre><p>可见，正如算法介绍那样，调用前活跃数+1,调用完成后活跃数-1。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>大概最小活跃数就是这样的，算法是不是很简单~</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前介绍了负载均衡器之&lt;code&gt;RandomLoadBalance&lt;/code&gt;和&lt;code&gt;RoundRobinLoadBalance&lt;/code&gt;,今天分析一下&lt;code&gt;LeastActiveLoadBalance&lt;/code&gt;。
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
      <category term="LoadBalance" scheme="https://www.chenruiwen.cn/tags/LoadBalance/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之LoadBalance随机与轮询</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-one/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-LoadBalance-one/</id>
    <published>2018-12-09T10:31:33.000Z</published>
    <updated>2018-12-10T14:09:01.606Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg" alt="">经过分析了<code>Directory</code>以及<code>Router</code>，接下来是到了负载均衡器<code>LoadBalance</code>了。</p><a id="more"></a><h2 id="简述负载均衡"><a href="#简述负载均衡" class="headerlink" title="简述负载均衡"></a>简述负载均衡</h2><p>搞后端web的同学一定不会陌生，负载均衡在各个层级都有相应的应用。由于单机应用的性能局限性，在负载高的情况下，通常都会采用增加服务器的形式来横向扩展，通过<code>集群</code>和<code>负载均衡</code>来提高整个系统处理能力。</p><p>负载均衡在反向代理层、站点层、服务层、数据层等层级上都有不同的解决方案。<code>dubbo</code>框架就具备解决服务层负载均衡的功能。</p><h2 id="dubbo的负载均衡——LoadBalance"><a href="#dubbo的负载均衡——LoadBalance" class="headerlink" title="dubbo的负载均衡——LoadBalance"></a>dubbo的负载均衡——LoadBalance</h2><p>LoadBalance家族继承图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fy0a1ntdrej21fe0j8763.jpg" alt=""></p><p>典型的<code>模板方法</code>模式和<code>策略</code>模式。</p><p>提供了四种负载均衡实现：</p><ul><li>RandomLoadBalance</li><li>RoundRobinLoadBalance</li><li>LeastActiveLoadBalance</li><li>ConsistentHashLoadBalance</li></ul><p>关于<code>LoadBalance</code>的接口定义:</p><pre><code class="java">@SPI(RandomLoadBalance.NAME)public interface LoadBalance {    /**     * select one invoker in list.     *     * @param invokers   invokers.     * @param url        refer url     * @param invocation invocation.     * @return selected invoker.     */    @Adaptive(&quot;loadbalance&quot;)    &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;}</code></pre><p>简单明了：从提供者列表里获取一个提供者。还可以看到，默认的负载均衡器是<code>RandomLoadBalance</code>。</p><h3 id="基类-AbstractLoadBalance"><a href="#基类-AbstractLoadBalance" class="headerlink" title="基类 AbstractLoadBalance"></a>基类 AbstractLoadBalance</h3><p><code>AbstractLoadBalance</code>是所有负载均衡器的基类，它提供了通用的模板方法<code>select</code>。</p><pre><code class="java">public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {    if (invokers == null || invokers.isEmpty())        return null;    if (invokers.size() == 1)        return invokers.get(0);    return doSelect(invokers, url, invocation);}</code></pre><p>其中<code>doSelect</code>是又具体子类实现的。</p><p>并且其提供了一个通用的获取<code>权重</code>的方法。<code>权重</code>是数学中的一种概念，比如初中学过的<code>加权平均数</code>就是一种体现。</p><h3 id="RandomLoadBalance"><a href="#RandomLoadBalance" class="headerlink" title="RandomLoadBalance"></a>RandomLoadBalance</h3><p>随机负载均衡。根据文档描述：</p><blockquote><ul><li>随机，按权重设置随机概率。</li><li>在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。</li></ul></blockquote><p>源码如下:</p><pre><code class="java">protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {    int length = invokers.size(); // Number of invokers    int totalWeight = 0; // The sum of weights    boolean sameWeight = true; // Every invoker has the same weight?    // 1.判断是否权重都相同    for (int i = 0; i &lt; length; i++) {        int weight = getWeight(invokers.get(i), invocation);        totalWeight += weight; // Sum        if (sameWeight &amp;&amp; i &gt; 0                &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) {            sameWeight = false;        }    }    // 2.权重不是都相等，则根据权重获取随机invoker    if (totalWeight &gt; 0 &amp;&amp; !sameWeight) {        // If (not every invoker has the same weight &amp; at least one invoker&#39;s weight&gt;0), select randomly based on totalWeight.        int offset = random.nextInt(totalWeight);        // Return a invoker based on the random value.        for (int i = 0; i &lt; length; i++) {            offset -= getWeight(invokers.get(i), invocation); // 随机数与权重相减获取调用节点            if (offset &lt; 0) {                return invokers.get(i);            }        }    }    // If all invokers have the same weight value or totalWeight=0, return evenly.    // 3.所有权重都相同的情况或者权重为0，则随机获取invoker    return invokers.get(random.nextInt(length));}</code></pre><p>代码比较简单：<br>判断是否权重都相同，相同则随机数获取调用者，否则则根据权重和随机数来获取一个调用者。算法是根据总权重获取一个随机数，然后与各个调用者的权重相减直到随机数的值小与0，则使用此节点。</p><h3 id="RoundRobinLoadBalance"><a href="#RoundRobinLoadBalance" class="headerlink" title="RoundRobinLoadBalance"></a>RoundRobinLoadBalance</h3><p>轮询负载均衡。根据文档描述：</p><blockquote><ul><li>轮循，按公约后的权重设置轮循比率。</li><li>存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</li></ul></blockquote><p>源码如下:</p><pre><code class="java">protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {    String key = invokers.get(0).getUrl().getServiceKey() + &quot;.&quot; + invocation.getMethodName();    int length = invokers.size(); // Number of invokers    int maxWeight = 0; // The maximum weight    int minWeight = Integer.MAX_VALUE; // The minimum weight    final LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; invokerToWeightMap = new LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt;();    int weightSum = 0;    for (int i = 0; i &lt; length; i++) {        int weight = getWeight(invokers.get(i), invocation);        maxWeight = Math.max(maxWeight, weight); // Choose the maximum weight 1.获取最大权重        minWeight = Math.min(minWeight, weight); // Choose the minimum weight 2.获取最小权重        if (weight &gt; 0) {            invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight)); // 3.invoker和权重大小的映射            weightSum += weight; // 4.获取总权重        }    }    AtomicPositiveInteger sequence = sequences.get(key); // 此方法的调用序列号    if (sequence == null) {        sequences.putIfAbsent(key, new AtomicPositiveInteger()); // 存储方法调用的序列号        sequence = sequences.get(key);    }    int currentSequence = sequence.getAndIncrement(); // 序列号+1    if (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) { // 如果权重不一样        int mod = currentSequence % weightSum;        for (int i = 0; i &lt; maxWeight; i++) {            for (Map.Entry&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; each : invokerToWeightMap.entrySet()) {                final Invoker&lt;T&gt; k = each.getKey();                final IntegerWrapper v = each.getValue();                if (mod == 0 &amp;&amp; v.getValue() &gt; 0) {                    return k;                }                if (v.getValue() &gt; 0) {                    v.decrement();                    mod--;                }            }        }    }    // Round robin    // 权重相同，则直接轮询即可    return invokers.get(currentSequence % length);}</code></pre><p><strong>控制台设置负载均衡算法：</strong><img src="https://ws1.sinaimg.cn/large/87faef88ly1fy0fnfql03j221g12479m.jpg" alt=""></p><p>debug界面：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fy0flwp64mj220w12qwsh.jpg" alt=""></p><p>这个加权算法过程(即代码注释权重不同情况)看着有点懵，大致是:</p><ol><li>获取最大权重、计算权重和</li><li>调用序列号对权重和取余获取到mod值</li><li>mod值为0且invoker对象权重大于0满足条件返回</li><li>如果mod值大于0且invoker对象权重大于0则mod值递减，权重值递减</li><li>重复3，4过程。</li></ol><p>还是很懵，举例演示一下过程。假设提供service{a,b,c}三台，权重分别为{1,2,3}，那么情况如下：</p><p>最大权重 = 3，总权重和 = 6。</p><table><thead><tr><th>调用序列号</th><th>mod值</th><th>返回服务名称</th><th>各服务权重</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>a</td><td>a:1, b:2, c:3</td></tr><tr><td>2</td><td>1,再进行1次递减</td><td>b</td><td>a:0, b:2, c:3</td></tr><tr><td>3</td><td>2,再进行2次递减</td><td>c</td><td>a:0, b:1, c:3</td></tr><tr><td>4</td><td>3,再进行3次递减</td><td>b</td><td>a:0, b:1, c:2</td></tr><tr><td>5</td><td>4,再进行4次递减</td><td>c</td><td>a:0, b:0, c:2</td></tr><tr><td>6</td><td>5,再进行5次递减</td><td>c</td><td>a:0, b:0, c:1</td></tr><tr><td>7</td><td>0</td><td>a</td><td>a:1, b:2, c:3</td></tr><tr><td>…</td><td>…</td><td>…</td><td>…</td></tr></tbody></table><p>运行算法过程如上，细心的你一定会发现这个算法很不合理，不合理的地方在于调用次数很大时，调用序列号达到假如一千万次，那么获取到的<code>mod</code>值则会非常大，那么<code>doSelect</code>方法循环的次数也会这么大，时间复杂度O(N)，再加上最大权重数<code>maxWeight</code>如果也设置很大，那么性能很受影响。</p><p>这个问题被dubbo关注者指出了，详见<a href="https://github.com/apache/incubator-dubbo/issues/2578" target="_blank" rel="noopener">issue#2578</a>，新的版本也修复了这个问题，具体详见新版本的代码。</p><p>除此之外，dubbo官方也指出了这个这种负载的缺点，即：<code>存在慢的提供者累积请求的问题</code>。如果选择此种负载均衡，需要把性能差的机器权重设置低一些。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>负载均衡的算法比较通用，包括nginx等算法是大致相通的。还有最少活跃调用以及一致性哈希，准备留到改日再分析。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg&quot; alt=&quot;&quot;&gt;
经过分析了&lt;code&gt;Directory&lt;/code&gt;以及&lt;code&gt;Router&lt;/code&gt;，接下来是到了负载均衡器&lt;code&gt;LoadBalance&lt;/code&gt;了。&lt;/p&gt;
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
      <category term="LoadBalance" scheme="https://www.chenruiwen.cn/tags/LoadBalance/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之Router</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-Router/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-Router/</id>
    <published>2018-12-08T10:12:33.000Z</published>
    <updated>2018-12-08T10:19:46.343Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前分析了Dubbo路由层的Directory，它的工作主要是负责获取服务提供者列表。回忆一下dubbo官网介绍的图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg" alt="">下一步的操作是在<code>Router</code>接口这里，今天来看一下它主要做哪些工作。</p><a id="more"></a><h2 id="Router"><a href="#Router" class="headerlink" title="Router"></a>Router</h2><p>先看官方文档怎么说：</p><blockquote><p><code>Router</code> 负责从多个 <code>Invoker</code> 中按路由规则选出子集，比如读写分离，应用隔离等</p></blockquote><p>之前<code>Directory</code>获取了当前可用的服务提供者，<code>Router</code>则再从里按规则过滤获取需要的提供者。</p><p>读写分离，应用隔离，很容易就想到管理dubbo服务相关操作，即我们在管理后台里的禁用等功能可能就是这里做了文章。</p><p>看一下接口设计：</p><pre><code class="java">public interface Router extends Comparable&lt;Router&gt; {    /**     * get the router url.     *     * @return url     */    URL getUrl();    /**     * route.     *     * @param invokers     * @param url        refer url     * @param invocation     * @return routed invokers     * @throws RpcException     */    &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;}</code></pre><p>就俩方法：</p><ul><li>获取url</li><li>路由</li></ul><p>再看其实现的子类有哪些：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxxc8rax7cj211w090gnp.jpg" alt=""></p><p>以及<code>Router</code>家族谱：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxxchb7o9yj217q0i2abo.jpg" alt=""></p><p>三个实现：</p><ul><li>ScriptRouter</li><li>ConditionRouter</li><li>MockInvokersSelector</li></ul><h3 id="MockInvokersSelector"><a href="#MockInvokersSelector" class="headerlink" title="MockInvokersSelector"></a>MockInvokersSelector</h3><p>先看这个类，看名称就知道跟降级有关。</p><p>实现的两个方法之<code>getUrl</code>：</p><pre><code class="java">public URL getUrl() {    return null;}</code></pre><p>可以说根本用不到这个方法。</p><p>实现的两个方法之<code>route</code>：</p><pre><code class="java">public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(final List&lt;Invoker&lt;T&gt;&gt; invokers,                                  URL url, final Invocation invocation) throws RpcException {    if (invocation.getAttachments() == null) {        return getNormalInvokers(invokers); // 获取正常的提供者    } else {        String value = invocation.getAttachments().get(Constants.INVOCATION_NEED_MOCK);        if (value == null)            return getNormalInvokers(invokers); // 获取正常的提供者        else if (Boolean.TRUE.toString().equalsIgnoreCase(value)) {            return getMockedInvokers(invokers); // 获取降级的提供者，即协议是mock        }    }    return invokers;}</code></pre><p>这也正如注释所说：</p><blockquote><p>A specific Router designed to realize mock feature.</p><p>If a request is configured to use mock, then this router guarantees that only the invokers with protocol MOCK appear in final the invoker list, all other invokers will be excluded.</p></blockquote><p>如果url请求被配置为<code>mock</code>，那么只有协议是<code>mock</code>会被保留到服务提供者列表，其他都被排除。代码如下:</p><pre><code class="java">private &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; getMockedInvokers(final List&lt;Invoker&lt;T&gt;&gt; invokers) {    if (!hasMockProviders(invokers)) {        return null;    }    List&lt;Invoker&lt;T&gt;&gt; sInvokers = new ArrayList&lt;Invoker&lt;T&gt;&gt;(1);    for (Invoker&lt;T&gt; invoker : invokers) {        if (invoker.getUrl().getProtocol().equals(Constants.MOCK_PROTOCOL)) {            sInvokers.add(invoker);        }    }    return sInvokers;}</code></pre><h3 id="ConditionRouter"><a href="#ConditionRouter" class="headerlink" title="ConditionRouter"></a>ConditionRouter</h3><p>条件路由。</p><p>基于条件表达式的路由规则，如：<code>host = 10.20.153.10 =&gt; host = 10.20.153.11</code></p><p>关于<code>规则</code>以及<code>表达式</code>写法介绍，请参考<a href="https://dubbo.gitbooks.io/dubbo-user-book/content/demos/routing-rule.html" target="_blank" rel="noopener">dubbo用户文档手册</a>。</p><h4 id="管理控制台使用示例"><a href="#管理控制台使用示例" class="headerlink" title="管理控制台使用示例"></a>管理控制台使用示例</h4><p><strong>准备工作</strong>：启动两个<code>provider</code>(本地单机模拟，仅修改端口号，生产需要两个节点上部署)，控制台显示如下：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxyky1wanrj21pu0i0tas.jpg" alt=""></p><p>再启动<code>consumer</code>可见控制台：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxyfu4t1u6j20mo07k0v0.jpg" alt=""></p><p><strong>管理控制台添加路由规则</strong>:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxym0xibnpj21880zk778.jpg" alt="">这个规则的意义是把 <code>192.168.99.243</code>添加到黑名单host中。</p><p>保存后此时看<code>consumer</code>日志：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxym0nlyknj22340aadp7.jpg" alt="">可以看到注册中心发起通知给所有消费者，将该Host的服务添加到黑名单中，由于本地开发机只有该Host的两个服务，于是都被加入黑名单后没有可用的提供者，于是报错。</p><h4 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h4><p>根据日志和debug工具，我们很容易定位到何时触发通知，即之前分析过的<code>RegistryDirectory</code>类的<code>notify</code>方法。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxym14y97vj21g410kgv7.jpg" alt=""></p><p>如上图所示，这里看到标注的<code>toRouters</code> 方法，将url转成<code>Router</code>对象。</p><pre><code class="java">private List&lt;Router&gt; toRouters(List&lt;URL&gt; urls) {    List&lt;Router&gt; routers = new ArrayList&lt;Router&gt;();    if (urls == null || urls.isEmpty()) {        return routers;    }    if (urls != null &amp;&amp; !urls.isEmpty()) {        for (URL url : urls) {            if (Constants.EMPTY_PROTOCOL.equals(url.getProtocol())) {                continue;            }            String routerType = url.getParameter(Constants.ROUTER_KEY);            if (routerType != null &amp;&amp; routerType.length() &gt; 0) {                url = url.setProtocol(routerType);            }            try {                Router router = routerFactory.getRouter(url); // 将url转为Router对象                if (!routers.contains(router))                    routers.add(router);            } catch (Throwable t) {                logger.error(&quot;convert router url to router error, url: &quot; + url, t);            }        }    }    return routers;}</code></pre><p>这里的<code>routerFactory</code>工厂为<code>ConditionRouterFactory</code>，所以这里获取的Router对象为<code>ConditionRouterFactory</code>.其创造的对象是构造器创建：</p><pre><code class="java">public ConditionRouter(URL url) {    this.url = url;    this.priority = url.getParameter(Constants.PRIORITY_KEY, 0);    this.force = url.getParameter(Constants.FORCE_KEY, false);    try {        String rule = url.getParameterAndDecoded(Constants.RULE_KEY);        if (rule == null || rule.trim().length() == 0) {            throw new IllegalArgumentException(&quot;Illegal route rule!&quot;);        }        rule = rule.replace(&quot;consumer.&quot;, &quot;&quot;).replace(&quot;provider.&quot;, &quot;&quot;);        int i = rule.indexOf(&quot;=&gt;&quot;);        String whenRule = i &lt; 0 ? null : rule.substring(0, i).trim();        String thenRule = i &lt; 0 ? rule.trim() : rule.substring(i + 2).trim();        Map&lt;String, MatchPair&gt; when = StringUtils.isBlank(whenRule) || &quot;true&quot;.equals(whenRule) ? new HashMap&lt;String, MatchPair&gt;() : parseRule(whenRule);        Map&lt;String, MatchPair&gt; then = StringUtils.isBlank(thenRule) || &quot;false&quot;.equals(thenRule) ? null : parseRule(thenRule);        // NOTE: It should be determined on the business level whether the `When condition` can be empty or not.        this.whenCondition = when;        this.thenCondition = then;    } catch (ParseException e) {        throw new IllegalStateException(e.getMessage(), e);    }}</code></pre><p>可见这里针对url做了解析，可见<code>url</code>在dubbo中是多么核心的存在。具体的解析在方法<code>parseRule(String rule)</code>中，就不贴代码了。其次，根据debug工具可见其调用栈，直接截图：</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxyng6490xj21g00neahy.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxyngyuveij21g20vek0i.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxynh56yr3j21aq0betbo.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxynha4oqtj21ci0lcq94.jpg" alt=""></p><p>解释下，画个时序图方便整理：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxzhgs45yej227w0i2420.jpg" alt=""></p><p>步骤解析：</p><ol><li>当我们在控制台动态增加一条路由规则时，将会触发<code>RegistryDirectory</code>的<code>notify()</code>方法。</li><li>在<code>notify()</code>内调用<code>setRouter()</code>方法，将通过<code>ConditionRouterFactory</code>获取<code>ConditionRouter</code>路由对象并添加到路由列表。</li><li>继续调用<code>refreshInvoker()</code>方法，这个方法之前介绍过，关键步骤在于<code>toMethodInvokers()</code>获取一个方法名与提供者列表的映射列表。</li><li>调用内部<code>route()</code>方法开始获取可用提供者列表。</li><li><code>RegistryDirectory</code>的<code>notify()</code>方法内部实际上是调用了<code>ConditionRouter</code>对象的<code>route</code>方法过滤获取最终可用提供者列表。</li></ol><h3 id="ScriptRouter"><a href="#ScriptRouter" class="headerlink" title="ScriptRouter"></a>ScriptRouter</h3><p>脚本路由规则，这个使用的不是很多，这里引用官网截图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxzej0y7m4j219q10cwkb.jpg" alt=""></p><p>可以简单看一下源码里:</p><pre><code class="java">public &lt;T&gt; List&lt;Invoker&lt;T&gt;&gt; route(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException {    try {        List&lt;Invoker&lt;T&gt;&gt; invokersCopy = new ArrayList&lt;Invoker&lt;T&gt;&gt;(invokers);        Compilable compilable = (Compilable) engine;        Bindings bindings = engine.createBindings();        bindings.put(&quot;invokers&quot;, invokersCopy);        bindings.put(&quot;invocation&quot;, invocation);        bindings.put(&quot;context&quot;, RpcContext.getContext());        CompiledScript function = compilable.compile(rule);        Object obj = function.eval(bindings);        if (obj instanceof Invoker[]) {            invokersCopy = Arrays.asList((Invoker&lt;T&gt;[]) obj);        } else if (obj instanceof Object[]) {            invokersCopy = new ArrayList&lt;Invoker&lt;T&gt;&gt;();            for (Object inv : (Object[]) obj) {                invokersCopy.add((Invoker&lt;T&gt;) inv);            }        } else {            invokersCopy = (List&lt;Invoker&lt;T&gt;&gt;) obj;        }        return invokersCopy;    } catch (ScriptException e) {        //fail then ignore rule .invokers.        logger.error(&quot;route error , rule has been ignored. rule: &quot; + rule + &quot;, method:&quot; + invocation.getMethodName() + &quot;, url: &quot; + RpcContext.getContext().getUrl(), e);        return invokers;    }}</code></pre><p>其通过一个<code>ScriptEngine</code>对象，编译了规则获取一个<code>function</code>脚本，其可支持执行<code>eval</code>方法过滤获得提供者列表。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>Router的过程不算复杂，可以发现比较核心的地方还是在之前分析<code>Directory</code>时的<code>notify</code>方法，一切路由规则都是从这触发的。</p><p>ps:这次整理的有些慢了，还是不太熟悉画图的过程，画图比较慢，mac上推荐使用OmniGraffle画图，提供的模板还是比较强大的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前分析了Dubbo路由层的Directory，它的工作主要是负责获取服务提供者列表。回忆一下dubbo官网介绍的图：
&lt;img src=&quot;https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg&quot; alt=&quot;&quot;&gt;
下一步的操作是在&lt;code&gt;Router&lt;/code&gt;接口这里，今天来看一下它主要做哪些工作。&lt;/p&gt;
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo路由层之Directory</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-cluster-Directory/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-cluster-Directory/</id>
    <published>2018-12-05T16:18:33.000Z</published>
    <updated>2018-12-06T13:13:35.585Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/">Dubbo服务引用之ReferenceConfig</a>中看到在引用协议订阅远程服务的过程中涉及到这么一个接口<code>Directory</code>。这个东东是做什么的呢？<a id="more"></a></p><h2 id="回顾时序图"><a href="#回顾时序图" class="headerlink" title="回顾时序图"></a>回顾时序图</h2><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtwlylelwj20ry0jwgo7.jpg" alt="">之前说到了拿到引用配置<code>ReferenceConfig</code>类，并且调用了<code>RegistryProtocol</code>的<code>refer</code>方法，接下来在手撕源码前，先超前的看看后面还要经历哪些环节：<code>Directory</code>,<code>Cluster</code>,<code>Protocol</code>,<code>Invoker</code>。。。(省略)。到这里可以根据源码结构找到关键的接口<code>Directory</code>,<code>Cluster</code>，这俩都是<code>dubbo-cluster</code>下的接口，一起理解会比较方便，在细嚼源码前看看开发者文档有没有给我们一些帮助。</p><p>可以找到官网介绍图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw7vtprhej20ze0hsak3.jpg" alt=""></p><p>从图中大致了解到各个接口的作用，今天要分析的<code>Directory</code>主要作用是服务目录列表。</p><h2 id="Directory"><a href="#Directory" class="headerlink" title="Directory"></a>Directory</h2><p>先看官方文档怎么说：</p><blockquote><p><code>Directory</code> 代表多个 <code>Invoker</code>，可以把它看成 <code>List&lt;Invoker&gt;</code> ，但与 <code>List</code> 不同的是，它的值可能是动态变化的，比如注册中心推送变更</p></blockquote><p>看下接口设计：</p><pre><code class="java">public interface Directory&lt;T&gt; extends Node {    /**     * get service type.     *     * @return service type.     */    Class&lt;T&gt; getInterface();    /**     * list invokers.     *     * @return invokers     */    List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException;}</code></pre><p>就俩方法：</p><ul><li>获取服务类型</li><li>获取invoker列表</li></ul><p>看一下其实现的子类：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw8c5tbt5j21a40eogov.jpg" alt="">再结合官网介绍图可知主要实现有<code>StaticDirectory</code>,<code>RegistryDirectory</code>。模板类是<code>AbstractDirectory</code>.</p><h3 id="AbstractDirectory"><a href="#AbstractDirectory" class="headerlink" title="AbstractDirectory"></a>AbstractDirectory</h3><p>看名便知，提供了抽象的<code>Directory</code>实现，也是模板方法模式的体现。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxw8u6e45lj21280fejua.jpg" alt=""><code>doList</code>方法交由具体的子类实现。父类(即此类)实现了模板方法<code>list</code>。</p><p>list方法：</p><pre><code class="java">public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException {    if (destroyed) {        throw new RpcException(&quot;Directory already destroyed .url: &quot; + getUrl());    }    // 从子类的实现中获取调用者列表    List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation);    List&lt;Router&gt; localRouters = this.routers; // local reference    // 路由过滤，获取匹配的调用者列表    if (localRouters != null &amp;&amp; !localRouters.isEmpty()) {        for (Router router : localRouters) {            try {                if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) {                    invokers = router.route(invokers, getConsumerUrl(), invocation);                }            } catch (Throwable t) {                logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t);            }        }    }    return invokers;}</code></pre><p>可见主要作用就是找到真的匹配的<code>invoker</code>列表。此处涉及接口<code>Router</code>，之后分析。</p><h3 id="StaticDirectory"><a href="#StaticDirectory" class="headerlink" title="StaticDirectory"></a>StaticDirectory</h3><p>主要还是看<code>doList</code>的实现，这是区分不同<code>Directory</code>的根本方法。</p><p>StaticDirectory#doList:</p><pre><code class="java">@Overrideprotected List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException {    return invokers;}</code></pre><p>惊不惊喜？意不意外？没错，就是这么简单，因此也和这个实现的名称也想对应了，“静态的服务目录”，调用者列表不会动态改变。它的<code>invokers</code>主要还是通过构造器传入：</p><pre><code class="java">public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) {    super(url == null &amp;&amp; invokers != null &amp;&amp; !invokers.isEmpty() ? invokers.get(0).getUrl() : url, routers);    if (invokers == null || invokers.isEmpty())        throw new IllegalArgumentException(&quot;invokers == null&quot;);    this.invokers = invokers;}</code></pre><p>此类的应用本人才疏学浅，暂时没有看到，存在即合理，之后看到再补充吧。</p><h3 id="RegistryDirectory"><a href="#RegistryDirectory" class="headerlink" title="RegistryDirectory"></a>RegistryDirectory</h3><p>这个子类实现应该是应用最广泛的一个了。</p><p>RegistryDirectory#doList:</p><pre><code class="java">public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) {    if (forbidden) {        // 下面这个异常简直不要太熟悉了        // 1. No service provider 2. Service providers are disabled        throw new RpcException(RpcException.FORBIDDEN_EXCEPTION,            &quot;No provider available from registry &quot; + getUrl().getAddress() + &quot; for service &quot; + getConsumerUrl().getServiceKey() + &quot; on consumer &quot; +  NetUtils.getLocalHost()                    + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please check status of providers(disabled, not registered or in blacklist).&quot;);    }    List&lt;Invoker&lt;T&gt;&gt; invokers = null;    Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // local reference    if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) {        String methodName = RpcUtils.getMethodName(invocation); // 获取服务提供者方法名称        Object[] args = RpcUtils.getArguments(invocation); // 获取调用参数        if (args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null                &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) {            invokers = localMethodInvokerMap.get(methodName + &quot;.&quot; + args[0]); // The routing can be enumerated according to the first parameter        }        if (invokers == null) {            invokers = localMethodInvokerMap.get(methodName);        }        if (invokers == null) {            invokers = localMethodInvokerMap.get(Constants.ANY_VALUE);        }        if (invokers == null) {            Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator();            if (iterator.hasNext()) {                invokers = iterator.next();            }        }    }    return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers;}</code></pre><p>工作流程：可以看到主要是从<code>methodInvokerMap</code>中获取。先尝试从map中获取key为<code>方法名.参数0</code>的invokers，没找到再尝试从map中获取key为<code>方法名</code>的invokers。没找到再尝试从map中获取key为<code>*</code>的invokers。都找不到就遍历map找到最后的一个invokers。</p><p>那么问题来了，获取<code>invokers</code>是从<code>methodInvokerMap</code>中获取，那么<code>methodInvokerMap</code>是怎么来的呢。</p><p>借助IDE找到<code>methodInvokerMap</code>的赋值处，是在<code>refreshInvoker</code>方法中。<code>refreshInvoker</code>又是在<code>notify</code>方法里调用。现在问题来了，<code>notify</code>方法何时何地调用？</p><p>我们可以注意到:</p><pre><code class="java">public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener`。</code></pre><p><code>RegistryDirectory</code>实现了<code>NotifyListener</code>，并实现了<code>notify</code>方法。方便起见，利用IDE生成一个类图:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxwadwlcz6j20mi0i2js5.jpg" alt=""></p><p>关于在哪里调用又借助一下IDE：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxwaplqiw6j20vm09876h.jpg" alt="">可以确定的是在注册服务处调用的，这里先不细看。</p><p>到这里再细看一下<code>notify</code>方法:</p><pre><code class="java">public synchronized void notify(List&lt;URL&gt; urls) {    List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;();    List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;();    List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;();    for (URL url : urls) {        String protocol = url.getProtocol();        String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY);        if (Constants.ROUTERS_CATEGORY.equals(category)                || Constants.ROUTE_PROTOCOL.equals(protocol)) {            routerUrls.add(url);        } else if (Constants.CONFIGURATORS_CATEGORY.equals(category)                || Constants.OVERRIDE_PROTOCOL.equals(protocol)) {            configuratorUrls.add(url);        } else if (Constants.PROVIDERS_CATEGORY.equals(category)) {            invokerUrls.add(url);        } else {            logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost());        }    }    // configurators    if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) {        this.configurators = toConfigurators(configuratorUrls);    }    // routers    if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) {        List&lt;Router&gt; routers = toRouters(routerUrls);        if (routers != null) { // null - do nothing            setRouters(routers);        }    }    List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference    // merge override parameters    this.overrideDirectoryUrl = directoryUrl;    if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) {        for (Configurator configurator : localConfigurators) {            this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);        }    }    // providers    refreshInvoker(invokerUrls);}</code></pre><pre><code class="java">private void refreshInvoker(List&lt;URL&gt; invokerUrls) {    // 清除不存在注册中心的数据    if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null            &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) {        // 空协议禁止访问        this.forbidden = true; // Forbid to access        this.methodInvokerMap = null; // Set the method invoker map to null        destroyAllInvokers(); // Close all invokers    } else {        this.forbidden = false; // Allow to access        Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference        // invokerUrls为空，因为通知的url可能只改变了router或者configurator，提供者并没有变化，但是对应invoker配置还是需要被更改的        if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) {            invokerUrls.addAll(this.cachedInvokerUrls); // 使用缓存的url        } else {            // 更新缓存            this.cachedInvokerUrls = new HashSet&lt;URL&gt;();            this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison        }        if (invokerUrls.isEmpty()) {            return;        }        Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map        Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // Change method name to map Invoker Map        // state change        // If the calculation is wrong, it is not processed.        if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) {            logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot; + invokerUrls.size() + &quot;, invoker.size :0. urls :&quot; + invokerUrls.toString()));            return;        }        // 是否存在group？是则对method对应的invoker进行cluster伪装        this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap;        this.urlInvokerMap = newUrlInvokerMap;        try {            destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker        } catch (Exception e) {            logger.warn(&quot;destroyUnusedInvokers error. &quot;, e);        }    }}</code></pre><p><code>notify</code>方法主要就是对url进行分类处理，分为<code>provider</code>，<code>configurators</code>，<code>routers</code>三类url。然后再使用<code>provider</code>类的url调用<code>refreshInvoker</code>进行增量刷新.</p><p><code>refreshInvoker</code>主要根据url协议过滤不匹配的提供者url，然后对过滤后的提供者url生成远程对等调用invoker，并且这些invoker会利用缓存防止重复创建。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里，基本Directory的核心方法都已经研究完，尤其是RegistryDirectory，它涉及动态更新<code>invokerUrls</code>，核心在于注册中心的通知与监听。dubbo的路由层还有<code>Cluster</code>,<code>Router</code>以及<code>LoadBalance</code>。留到明天再看！不知不觉已经凌晨，一看源码就容易上头哈~</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在&lt;a href=&quot;https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/&quot;&gt;Dubbo服务引用之ReferenceConfig&lt;/a&gt;中看到在引用协议订阅远程服务的过程中涉及到这么一个接口&lt;code&gt;Directory&lt;/code&gt;。这个东东是做什么的呢？
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo服务引用之ReferenceConfig</title>
    <link href="https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/"/>
    <id>https://www.chenruiwen.cn/dubbo/dubbo-ReferenceConfig/</id>
    <published>2018-12-04T15:50:03.000Z</published>
    <updated>2018-12-04T15:42:52.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>开启<code>RTFSC</code>之旅，先拾起来之前未完成的<code>Dubbo</code>源码解析。<code>Dubbo</code>自今年夏天开始也是变化很大，github上的官方文档也变化了不少次，现在来看也是非常的美观了。话不多说，今天研究一下<code>Dubbo引用服务</code>。</p><a id="more"></a><h2 id="开局一张图"><a href="#开局一张图" class="headerlink" title="开局一张图"></a>开局一张图</h2><p>老规矩，从文档入手，看看官网介绍。</p><p>ps:一图千言</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtw1bw0rbj217y0tmasc.jpg" alt=""></p><p>和Dubbo服务调用过程一样，其非常重要的还是<code>Invoker</code></p><p>从图可见，服务调用过程大概经历这两步:</p><ul><li>把引用配置(<code>ReferenceConfig</code>)转化为<code>Invoker</code>实例</li><li>再把<code>Invoker</code>实例转化为客户端需要的接口代理对象</li></ul><p>再补一张时序图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fxtwlylelwj20ry0jwgo7.jpg" alt=""></p><h2 id="ReferenceConfig"><a href="#ReferenceConfig" class="headerlink" title="ReferenceConfig"></a>ReferenceConfig</h2><p>准备工作，先启动服务提供者，我们将<code>dubbo-demo</code>模块下的<code>dubbo-demo-provider</code>启动起来即可。</p><p>第一个断点打在哪，文档以及告诉你了。即<code>ReferenceConfig</code>类的<code>init</code>方法，重点则是调用<code>Protocol</code>的<code>refer</code>方法。</p><p>代码片段分析，直击<code>init</code>方法:</p><pre><code class="java">private void init() {    // 省略代码，判断是否已初始化过    // get consumer&#39;s global configuration    checkDefault();    appendProperties(this); // 添加config 配置属性(根据xml或者java bean)    // 省略代码，获取到 interfaceClass 以及 检察其属性    String resolve = System.getProperty(interfaceName);    String resolveFile = null;    if (resolve == null || resolve.length() == 0) {        resolveFile = System.getProperty(&quot;dubbo.resolve.file&quot;); // resolveFile 映射路径文件，通常用于开发直连调试        if (resolveFile == null || resolveFile.length() == 0) {            File userResolveFile = new File(new File(System.getProperty(&quot;user.home&quot;)), &quot;dubbo-resolve.properties&quot;); // 默认加载 ${user.home}/dubbo-resolve.properties            if (userResolveFile.exists()) {                resolveFile = userResolveFile.getAbsolutePath();            }        }        if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) {            Properties properties = new Properties();            FileInputStream fis = null;            try {                fis = new FileInputStream(new File(resolveFile));                properties.load(fis);            } catch (IOException e) {                throw new IllegalStateException(&quot;Unload &quot; + resolveFile + &quot;, cause: &quot; + e.getMessage(), e);            } finally {                try {                    if (null != fis) fis.close();                } catch (IOException e) {                    logger.warn(e.getMessage(), e);                }            }            resolve = properties.getProperty(interfaceName); // 获取接口的直连地址        }    }    if (resolve != null &amp;&amp; resolve.length() &gt; 0) {        url = resolve;        if (logger.isWarnEnabled()) {            if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) {                logger.warn(&quot;Using default dubbo resolve file &quot; + resolveFile + &quot; replace &quot; + interfaceName + &quot;&quot; + resolve + &quot; to p2p invoke remote service.&quot;);            } else {                logger.warn(&quot;Using -D&quot; + interfaceName + &quot;=&quot; + resolve + &quot; to p2p invoke remote service.&quot;);            }        }    }    // 获取 应用配置，模块配置，注册中心(多个)配置，监控配置    if (consumer != null) {        if (application == null) {            application = consumer.getApplication();        }        if (module == null) {            module = consumer.getModule();        }        if (registries == null) {            registries = consumer.getRegistries();        }        if (monitor == null) {            monitor = consumer.getMonitor();        }    }    if (module != null) {        if (registries == null) {            registries = module.getRegistries();        }        if (monitor == null) {            monitor = module.getMonitor();        }    }    if (application != null) {        if (registries == null) {            registries = application.getRegistries();        }        if (monitor == null) {            monitor = application.getMonitor();        }    }    checkApplication();    checkStubAndMock(interfaceClass);    // 添加调用信息，用于封装为invoker，side=consumer,dubbo=2.0.0,timestamp=xxxxx,pid=xxx    Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();    Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;();    map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE);    map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion());    map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis()));    if (ConfigUtils.getPid() &gt; 0) {        map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid()));    }    if (!isGeneric()) {        String revision = Version.getVersion(interfaceClass, version);        if (revision != null &amp;&amp; revision.length() &gt; 0) {            map.put(&quot;revision&quot;, revision);        }        String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames();        if (methods.length == 0) {            logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName());            map.put(&quot;methods&quot;, Constants.ANY_VALUE);        } else {            map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;));        }    }    map.put(Constants.INTERFACE_KEY, interfaceName);    appendParameters(map, application);    appendParameters(map, module);    appendParameters(map, consumer, Constants.DEFAULT_KEY);    appendParameters(map, this);    String prefix = StringUtils.getServiceKey(map);    if (methods != null &amp;&amp; !methods.isEmpty()) {        for (MethodConfig method : methods) {            appendParameters(map, method, method.getName());            String retryKey = method.getName() + &quot;.retry&quot;;            if (map.containsKey(retryKey)) {                String retryValue = map.remove(retryKey);                if (&quot;false&quot;.equals(retryValue)) {                    map.put(method.getName() + &quot;.retries&quot;, &quot;0&quot;);                }            }            appendAttributes(attributes, method, prefix + &quot;.&quot; + method.getName());            checkAndConvertImplicitConfig(method, map, attributes);        }    }    String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY);    if (hostToRegistry == null || hostToRegistry.length() == 0) {        hostToRegistry = NetUtils.getLocalHost();    } else if (isInvalidLocalHost(hostToRegistry)) {        throw new IllegalArgumentException(&quot;Specified invalid registry ip from property:&quot; + Constants.DUBBO_IP_TO_REGISTRY + &quot;, value:&quot; + hostToRegistry);    }    map.put(Constants.REGISTER_IP_KEY, hostToRegistry);    //attributes are stored by system context.    StaticContext.getSystemContext().putAll(attributes);    ref = createProxy(map);    ConsumerModel consumerModel = new ConsumerModel(getUniqueServiceName(), this, ref, interfaceClass.getMethods());    ApplicationModel.initConsumerModel(getUniqueServiceName(), consumerModel); // 实际将消费者模块放入缓存中}</code></pre><p>初始化过程:</p><ol><li>获取消费者配置并初始赋值。</li><li>获取接口类并检查配置中的 interface 属性 和 methods属性。</li><li>获取<code>resolveFile</code>映射路径文件，如果文件存则获取属性将接口的值赋给<code>url</code>属性用于直连使用。(不存在则<code>url</code>属性为null)</li><li>获取应用配置，模块配置，注册中心(多个)配置。</li><li>添加接口调用信息，用于封装为<code>Invoker</code></li><li>创建引用代理(<code>T createProxy(Map&lt;String, String&gt; map)</code>)。</li></ol><p>创建引用代理过程:</p><pre><code class="java">private T createProxy(Map&lt;String, String&gt; map) {    URL tmpUrl = new URL(&quot;temp&quot;, &quot;localhost&quot;, 0, map); // 初始化url  temp://localhost?xxx=xxx    // 判断是否是内部调用    final boolean isJvmRefer;    if (isInjvm() == null) {        if (url != null &amp;&amp; url.length() &gt; 0) { // if a url is specified, don&#39;t do local reference            isJvmRefer = false;        } else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) {            // by default, reference local service if there is            isJvmRefer = true;        } else {            isJvmRefer = false;        }    } else {        isJvmRefer = isInjvm().booleanValue();    }    if (isJvmRefer) {        URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map);        invoker = refprotocol.refer(interfaceClass, url);        if (logger.isInfoEnabled()) {            logger.info(&quot;Using injvm service &quot; + interfaceClass.getName());        }    } else {        // 是否是点对点调用（之前的resolveFile配置和获取）        if (url != null &amp;&amp; url.length() &gt; 0) { // user specified URL, could be peer-to-peer address, or register center&#39;s address.            String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url);            if (us != null &amp;&amp; us.length &gt; 0) {                for (String u : us) {                    URL url = URL.valueOf(u);                    if (url.getPath() == null || url.getPath().length() == 0) {                        url = url.setPath(interfaceName);                    }                    if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) {                        urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));                    } else {                        urls.add(ClusterUtils.mergeUrl(url, map));                    }                }            }        } else { // assemble URL from register center&#39;s configuration            List&lt;URL&gt; us = loadRegistries(false); // 加载注册中心列表            if (us != null &amp;&amp; !us.isEmpty()) {                for (URL u : us) {                    URL monitorUrl = loadMonitor(u);                    if (monitorUrl != null) {                        map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString()));                    }                    urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map)));                }            }            if (urls == null || urls.isEmpty()) {                throw new IllegalStateException(&quot;No such any registry to reference &quot; + interfaceName + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please config &lt;dubbo:registry address=\&quot;...\&quot; /&gt; to your spring config.&quot;);            }        }        if (urls.size() == 1) {            invoker = refprotocol.refer(interfaceClass, urls.get(0));        } else {            List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;();            URL registryURL = null;            for (URL url : urls) {                invokers.add(refprotocol.refer(interfaceClass, url));                if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) {                    registryURL = url; // use last registry url                }            }            if (registryURL != null) { // registry url is available                // use AvailableCluster only when register&#39;s cluster is available                URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME);                invoker = cluster.join(new StaticDirectory(u, invokers));            } else { // not a registry url                invoker = cluster.join(new StaticDirectory(invokers));            }        }    }    Boolean c = check;    if (c == null &amp;&amp; consumer != null) {        c = consumer.isCheck();    }    if (c == null) {        c = true; // default true    }    if (c &amp;&amp; !invoker.isAvailable()) {        throw new IllegalStateException(&quot;Failed to check the status of the service &quot; + interfaceName + &quot;. No provider available for the service &quot; + (group == null ? &quot;&quot; : group + &quot;/&quot;) + interfaceName + (version == null ? &quot;&quot; : &quot;:&quot; + version) + &quot; from the url &quot; + invoker.getUrl() + &quot; to the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion());    }    if (logger.isInfoEnabled()) {        logger.info(&quot;Refer dubbo service &quot; + interfaceClass.getName() + &quot; from url &quot; + invoker.getUrl());    }    // create service proxy    return (T) proxyFactory.getProxy(invoker);}</code></pre><p>步骤：</p><ol><li>判断是否是内部调用，如果是内部调用，则创建一个内部调用<code>Invoker</code>。比如：injvm://127.0.0.1/interfaceClass?xxx=xxx&amp;xxx=xxx</li><li>判断是否是点对点调用，即通过之前<code>resolveFile</code>文件获取到的映射地址。如果有则执行点对点直连调用。</li><li>如果以上都不是，则加载注册中心url(多个)，获取到<code>注册中心url</code>并赋值属性<code>refer=之前的接口调用url</code>。</li><li><code>注册中心url</code>如果是单个，则直接通过扩展点机制，引用的协议获取此url的<code>Invoker</code>对象。</li><li><code>注册中心url</code>如果是多个，生成多个<code>Invoker</code>对象，遍历urls获取最后一个<code>registryURL</code>。如果<code>registryURL</code>不为null,则有注册中心，用 AvailableCluster获取invoker对象。</li><li>创建服务代理。(这一步之前有介绍过，实际为<code>JavassistProxyFactory.getInvoker</code>通过字节码获取代理对象。)</li></ol><p>关于获取<code>Invoker</code>对象，代码里是这么获取的:</p><pre><code class="java">invoker = refprotocol.refer(interfaceClass, urls.get(0));</code></pre><p>这里的<code>refprotocol</code>又是扩展点机制，在上面这个例子里，他的实现是<code>RegistryProtocol</code>.</p><pre><code class="java">public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException {    // 设置url中的协议，将 registry 换为url中的registry属性，默认为dubbo    url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY);    Registry registry = registryFactory.getRegistry(url);    if (RegistryService.class.equals(type)) {        return proxyFactory.getInvoker((T) registry, type, url);    }    // group=&quot;a,b&quot; or group=&quot;*&quot;    Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY));    String group = qs.get(Constants.GROUP_KEY);    if (group != null &amp;&amp; group.length() &gt; 0) {        if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1                || &quot;*&quot;.equals(group)) {            return doRefer(getMergeableCluster(), registry, type, url);        }    }    return doRefer(cluster, registry, type, url);}private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) {    RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url);    directory.setRegistry(registry);    directory.setProtocol(protocol);    // all attributes of REFER_KEY    Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters());    URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters);    if (!Constants.ANY_VALUE.equals(url.getServiceInterface())            &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) {        registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY,                Constants.CHECK_KEY, String.valueOf(false)));    }    directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY,            Constants.PROVIDERS_CATEGORY                    + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY                    + &quot;,&quot; + Constants.ROUTERS_CATEGORY));    Invoker invoker = cluster.join(directory);    ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory);    return invoker;}</code></pre><p>这里的实现涉及的一些内容：</p><ul><li>获取<code>Registry</code>对象</li><li><code>Directory</code>接口</li><li>向注册中心注册。比如本例的<code>ZookeeperRegistry</code></li><li>服务订阅</li><li><code>cluster</code>集群容错</li></ul><p>这里暂时不解释这么多，明天接着按顺序看。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>看了下Dubbo的ReferenceConfig的源码，更深刻体会了那句话:满眼都是<code>Invoker</code>。除此之外，还有很多重要的接口需要理解，比如<code>Directory</code>接口…</p><p>to be contine…</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;开启&lt;code&gt;RTFSC&lt;/code&gt;之旅，先拾起来之前未完成的&lt;code&gt;Dubbo&lt;/code&gt;源码解析。&lt;code&gt;Dubbo&lt;/code&gt;自今年夏天开始也是变化很大，github上的官方文档也变化了不少次，现在来看也是非常的美观了。话不多说，今天研究一下&lt;code&gt;Dubbo引用服务&lt;/code&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="https://www.chenruiwen.cn/tags/dubbo/"/>
    
      <category term="RTFSC" scheme="https://www.chenruiwen.cn/tags/RTFSC/"/>
    
  </entry>
  
  <entry>
    <title>我的反思录</title>
    <link href="https://www.chenruiwen.cn/essay/my-rethink-on-2018/"/>
    <id>https://www.chenruiwen.cn/essay/my-rethink-on-2018/</id>
    <published>2018-12-02T13:09:03.000Z</published>
    <updated>2018-12-02T12:38:42.581Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>眼瞅着2018要过去了，这一年是有不少收获，但是感觉和自己的计划还有一些差距，简而言之就是没有达到自己的目标。这是一件糟糕的事情，加上已经很久没有写博客了，真的感觉状态不太对，总结一下吧。<a id="more"></a></p><h2 id="回忆问题出在哪"><a href="#回忆问题出在哪" class="headerlink" title="回忆问题出在哪"></a>回忆问题出在哪</h2><p>有哪些问题呢？</p><ul><li>地铁上耗费的时间太长。</li><li>突然的加班导致加班前的正常学习状态被打破。也就是说学习不连贯。</li><li>加班耗费了太多精力，回家就想躺下睡大觉。</li><li>焦虑于未完成的事情。</li></ul><h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><p>看似问题简单，根本原因是<code>时间</code>，然后又巧妙的<code>甩锅</code>给<code>加班</code>。然而真的是这样的吗？</p><p>我看来，根本原因可能是<code>拖延症</code>，或者说是自己的<code>懒</code>。</p><h2 id="解决问题的方法"><a href="#解决问题的方法" class="headerlink" title="解决问题的方法"></a>解决问题的方法</h2><p>基本就是如何解决掉自己<code>懒</code>的特性。</p><ul><li>地铁上的时间可以用来看一下书籍。</li><li>加班问题，其实也没有加班到特别晚过，至少还能留有1小时的时间。</li><li>加班耗费精力的问题，主要还是要集中解决一下效率问题，效率高了就节约加班时间甚至于不用加班。如何提高效率，在日常工作中尽量多的积累工具经验，写优秀简洁的代码，自然而然效率就高了。</li><li>解决了上面的问题也就不焦虑了。</li></ul><h2 id="给自己个小目标"><a href="#给自己个小目标" class="headerlink" title="给自己个小目标"></a>给自己个小目标</h2><p>我的目标最终是要写出高质量简洁高效的代码来提高自己的生产效率，根治加班问题。</p><p>那么，如何一步一步完成这个目标呢？</p><p>答案即是 <code>RTFSC：Read The Fucking Source Code</code>。</p><p>每天坚持看源码，之前<code>dubbo</code>的源码分析还没有写完，我承认是自己懒了，虽然网上也大把的分析<code>dubbo</code>源码的，但是应该有输入也有输出才是正确的学习姿势，应该持之以恒。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>学习之路漫长，走的不快，但是尽量走的远一些，<code>坚持</code>二字确实难但也是一条最正确的路。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;眼瞅着2018要过去了，这一年是有不少收获，但是感觉和自己的计划还有一些差距，简而言之就是没有达到自己的目标。
这是一件糟糕的事情，加上已经很久没有写博客了，真的感觉状态不太对，总结一下吧。
    
    </summary>
    
      <category term="essay" scheme="https://www.chenruiwen.cn/categories/essay/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
  </entry>
  
  <entry>
    <title>小Tips，加速github访问速度</title>
    <link href="https://www.chenruiwen.cn/tips/little-tips-optimize-github-access/"/>
    <id>https://www.chenruiwen.cn/tips/little-tips-optimize-github-access/</id>
    <published>2018-11-17T09:33:22.000Z</published>
    <updated>2018-11-17T09:43:06.837Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>访问<a href="https://github.com/" target="_blank" rel="noopener">github</a>的速度真的太慢了。(尤其微软收购之后。:D)。尤其在<code>git clone</code>等操作上确实影响心情:</p><pre><code>Receiving objects:   8% (497/5635), 2.89 MiB | 15.00 KiB/s</code></pre><p>然而解决的方法非常简单。<a id="more"></a></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>慢的原因在哪？其实并不是因为 <code>http://github.com</code> 的这个域名被限制了。而是 <code>http://github.global.ssl.fastly.Net</code> 这个域名被限制了。</p><p>解决方法在于修改<code>hosts</code>文件，增加如下:</p><pre><code>151.101.72.249 global-ssl.fastly.Net192.30.253.112 github.com</code></pre><p>成功解决问题，测速如下:</p><pre><code>Receiving objects: 100% (5635/5635), 46.94 MiB | 2.27 MiB/s, done.</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>国内的编程环境的阻碍还是不少啊~~</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;访问&lt;a href=&quot;https://github.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;github&lt;/a&gt;的速度真的太慢了。(尤其微软收购之后。:D)。
尤其在&lt;code&gt;git clone&lt;/code&gt;等操作上确实影响心情:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Receiving objects:   8% (497/5635), 2.89 MiB | 15.00 KiB/s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然而解决的方法非常简单。
    
    </summary>
    
      <category term="tips" scheme="https://www.chenruiwen.cn/categories/tips/"/>
    
    
      <category term="tips" scheme="https://www.chenruiwen.cn/tags/tips/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用性能分析工具</title>
    <link href="https://www.chenruiwen.cn/Linux/Linux-performance-analysis-util/"/>
    <id>https://www.chenruiwen.cn/Linux/Linux-performance-analysis-util/</id>
    <published>2018-11-14T13:19:22.000Z</published>
    <updated>2018-11-14T13:27:05.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上周五公司搞了双十一“大促”，虽然时间紧凑，还是引起了团队上下高度重视，在有限的两天时间里，进行了充分的压测和性能分析，最终的结果也是不错的。对于性能分析工具，又做了一次熟悉的过程，这里结合网上优秀博文做了下整理。</p><a id="more"></a><h2 id="性能监控，要看哪些"><a href="#性能监控，要看哪些" class="headerlink" title="性能监控，要看哪些"></a>性能监控，要看哪些</h2><p>一张表搞定：</p><table><thead><tr><th>检测目标</th><th>指标</th><th>工具</th></tr></thead><tbody><tr><td>cpu</td><td>usr&lt;=70%, sys&lt;=35%, usr+sys&lt;=70%</td><td>top</td></tr><tr><td>memory</td><td>swap in （si） == 0，swap out （so） == 0； 可用空间&gt;=30%；应用程序可用内存/系统物理内存 &lt;= 70%</td><td>vmstat 1;free; /proc/meminfo</td></tr><tr><td>io</td><td>iowait% &lt; 20%</td><td>sar; iostat -x;</td></tr><tr><td>network</td><td>udp：缓冲区不挤压, 无丢包 tcp：重传率</td><td>netstat -lunp; netstat -su; /proc/net/snmp</td></tr></tbody></table><p>良好状态指标:</p><ul><li><p>cpu：</p><ul><li>CPU利用率：User Time &lt;= 70%，System Time &lt;= 35%，User Time + System Time &lt;= 70%</li><li>上下文切换：与CPU利用率相关联，如果CPU利用率状态良好，大量的上下文切换也是可以接受的</li><li>可运行队列：每个处理器的可运行队列&lt;=3个线程</li></ul></li><li><p>memory:swap in(si)==0，swap out(so)==0;应用程序可用内存/系统物理内存 &lt;= 70%</p></li><li>io：<strong>iowait % &lt; 20%</strong> ;提高命中率的一个简单方式就是增大文件缓存区面积，缓存区越大预存的页面就越多，命中率也越高。Linux 内核希望能尽可能产生次缺页中断（从文件缓存区读），并且能尽可能避免主缺页中断（从硬盘读），这样随着次缺页中断的增多，文件缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。</li><li>network：<ul><li>对于UDP，<strong>接收、发送缓冲区不长时间有等待处理的网络包</strong>；</li><li>对于TCP而言，不会出现因为缓存不足而存在丢包的事，因为网络等其他原因，导致丢了包，协议层也会通过重传机制来保证丢的包到达对方。所以，更多的专注<strong>重传率</strong>。</li></ul></li></ul><h2 id="监控工具"><a href="#监控工具" class="headerlink" title="监控工具"></a>监控工具</h2><p>列举一些常用且实用的工具。</p><h3 id="top命令"><a href="#top命令" class="headerlink" title="top命令"></a>top命令</h3><p>最常用的命令，每次压测第一使用率的命令。top命令可以实时监控系统运行状态，它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序。</p><p>命令格式:</p><pre><code>top [参数]</code></pre><p>命令参数:</p><pre><code>-b 批处理-c 显示完整的治命令-I 忽略失效过程-s 保密模式-S 累积模式-i&lt;时间&gt; 设置间隔时间-u&lt;用户名&gt; 指定用户名-p&lt;进程号&gt; 指定进程-n&lt;次数&gt; 循环显示的次数</code></pre><p>使用top命令后，可见如下交互信息：</p><pre><code>top - 22:44:08 up 667 days,  4:15,  9 users,  load average: 4.07, 3.54, 3.30Tasks: 406 total,   1 running, 405 sleeping,   0 stopped,   0 zombieCpu(s): 15.3%us,  0.7%sy,  0.0%ni, 84.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%stMem:  32899876k total, 31996032k used,   903844k free,   337144k buffersSwap: 15624188k total,  1577788k used, 14046400k free,  9132796k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                  47210 staging   20   0 13.6g 743m 6224 S 5204  2.3  5128980h java                                                                                                     35314 staging   20   0 16.6g 830m  11m S    4  2.6 243:11.07 java                                                                                                     32098 staging   20   0 10.1g 524m 9208 S    4  1.6 664:05.61 java                                                                                                     12789 staging   20   0 13.7g 635m  18m S    3  2.0  67:37.08 java                                                                                                      3198 staging   20   0 1193m  38m 5016 S    2  0.1   1942:19 PM2 v2.7.2: God                                                                                          29642 staging   20   0 13.0g 416m 5348 S    2  1.3   1428:13 java                                                                                                     21707 staging   20   0 13.4g 412m  11m S    2  1.3 110:47.28 java                                                                                                     20115 staging   20   0 13.7g 614m  18m S    1  1.9  46:43.89 java                                                                                                     43796 staging   20   0 16.6g 579m  11m S    1  1.8 102:33.21 java                                                                                                     12320 staging   20   0 13.7g 653m  18m S    1  2.0  60:49.53 java                                                                                                     24179 look      20   0 17596 1560  960 R    1  0.0   0:00.16 top                                                                                                      31933 staging   20   0 11.1g 424m 9084 S    1  1.3 208:44.23 java                                                                                                     33717 staging   20   0 1206m  49m 8824 S    1  0.2   3:45.91 node /data/web-                                                                                          40163 staging   20   0 13.5g 534m  15m S    1  1.7  72:56.82 java                                                                                                      7974 staging   20   0 13.0g 435m 8804 S    1  1.4 259:16.18 java                                                                                                     13487 staging   20   0 13.0g 413m 9084 S    1  1.3 188:53.99 java                                                                                                     15855 root      20   0  9.9g 861m 1524 S    1  2.7   1544:16 java                                                                                                     17886 staging   20   0 12.8g 239m 6396 S    1  0.7 692:52.16 java                                                                                                     18725 staging   20   0 13.5g 519m  15m S    1  1.6  39:54.70 java                                                                                                     27444 root      20   0 10.4g 503m 1280 S    1  1.6   2753:21 java                                                                                                     31900 staging   20   0 8991m 422m 9156 S    1  1.3 136:25.31 java                                                                                                     32034 staging   20   0 10.8g 461m 9376 S    1  1.4 152:14.69 java</code></pre><p>上述信息很多，逐个解释。</p><p>第一行，任务队列信息，同 uptime 命令的执行结果</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>22:44:08</td><td>当前系统时间</td></tr><tr><td>up 667 days,  4:15</td><td>已经运行667天4小时15分(未重启过)</td></tr><tr><td>9 users</td><td>当前9个用户登录系统</td></tr><tr><td>load average: 4.07, 3.54, 3.30</td><td>系统负载，后面三个参数分别是一分钟，五分钟和十五分钟；load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。</td></tr></tbody></table><p>第二行，Tasks — 任务（进程）：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>406 total</td><td>总进程数，共有206个进程</td></tr><tr><td>1 running</td><td>正在运行进程数，1个</td></tr><tr><td>405 sleeping</td><td>休眠状态进程数，405个</td></tr><tr><td>0 stopped</td><td>停止进程数，0个</td></tr><tr><td>0 zombie</td><td>僵尸进程数（处于无响应状态），0个</td></tr></tbody></table><p>第三行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>15.3%us</td><td>用户空间占用CPU的百分比</td></tr><tr><td>0.7%sy</td><td>内核空间占用CPU的百分比</td></tr><tr><td>0.0%ni</td><td>改变过优先级的进程占用CPU的百分比</td></tr><tr><td>84.0%id</td><td>空闲CPU百分比</td></tr><tr><td>0.0%wa</td><td>IO等待占用CPU的百分比</td></tr><tr><td>0.0%hi</td><td>硬中断（Hardware IRQ）占用CPU的百分比</td></tr><tr><td>0.0%si</td><td>软中断（Software Interrupts）占用CPU的百分比</td></tr><tr><td>0.0%st</td><td>在内存紧张环境下，pagein 强制对不同的页面进行的 steal 操作</td></tr></tbody></table><p>第四行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>32899876k total</td><td>物理内存总量（32GB）</td></tr><tr><td>31996032k used</td><td>使用中的内存总量（31GB）</td></tr><tr><td>903844k free</td><td>空闲内存总量（903M）</td></tr><tr><td>337144k buffers</td><td>缓存的内存量 （337M）</td></tr></tbody></table><p>第五行，cpu状态信息：</p><table><thead><tr><th>参数示例</th><th>含义</th></tr></thead><tbody><tr><td>15624188k total</td><td>交换区总量（15.6GB）</td></tr><tr><td>1577788k used</td><td>使用的交换区总量（1.5GB）</td></tr><tr><td>14046400k free</td><td>空闲交换区总量（14GB）</td></tr><tr><td>9132796k cached</td><td>缓冲的交换区总量（9.1GB）</td></tr></tbody></table><p><strong>说明:</strong></p><blockquote><p>第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。</p><p>如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。</p><p>对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。</p></blockquote><p>第六行。空行。</p><p>第七行，各进程（任务）的状态监控：PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND<br>参数示例 | 含义—|—PID | 进程idUSER | 进程所有者PR | 进程优先级NI | nice值。负值表示高优先级，正值表示低优先级VIRT | 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES | 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR | 共享内存大小，单位kbS | 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU | 上次更新到现在的CPU时间占用百分比%MEM | 进程使用的物理内存百分比TIME+ | 进程使用的CPU时间总计，单位1/100秒COMMAND | 进程名称（命令名/命令行）</p><p>top命令下，常用交互操作：</p><ul><li><code>h</code>:显示帮助画面</li><li><code>1</code>:显示CPU信息。可监控每个逻辑CPU的状况。(%cpu的值是跟内核数成正比的，如8核cpu的%cpu最大可以800%。)</li><li><code>H</code>:显示线程。</li><li>排序。<ul><li>Cpu ： 在top交互界面按<code>shift+p</code>或<code>P</code>。</li><li>Mem ：在top交互界面按<code>shift+m</code>或<code>M</code>。</li><li>Time ：在top交互界面按<code>shift+t</code>或<code>T</code>。</li></ul></li><li>显示程序名。在top交互界面按c。</li><li>监控进程下的线程。在命令行输入<code>top -H -p pid</code>，其中pid为进程id，进入界面后显示的PID为线程ID；或者使用命令<code>top -H -p pid</code>进入界面之后在按<code>shift+h</code>来显示线程。</li></ul><h3 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h3><p>vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。不足之处是无法对某个进程进行深入分析。vmstat工具提供了一种低开销的系统性能观察方式，适合在高负荷的服务器上控系统的健康情况。</p><p>命令格式：</p><pre><code>vmstat [-a] [-n] [-S unit] [delay [ count]]vmstat [-s] [-n] [-S unit]vmstat [-m] [-n] [delay [ count]]vmstat [-d] [-n] [delay [ count]]vmstat [-p disk partition] [-n] [delay [ count]]vmstat [-f]vmstat [-V]</code></pre><p>命令参数：</p><pre><code>-a：显示活跃和非活跃内存-f：显示从系统启动至今的fork数量 。-m：显示slabinfo-n：只在开始时显示一次各字段名称。-s：显示内存相关统计信息及多种系统活动数量。delay：刷新时间间隔。如果不指定，只显示一条结果。count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。-d：显示磁盘相关统计信息。-p：显示指定磁盘分区统计信息-S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）-V：显示vmstat版本信息。</code></pre><p>使用示例，1秒输出一次，输出20次，单位为MB：</p><pre><code>~$ vmstat 1 20 -S Mprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa 2  0   1540   1079    348   8715    0    0     0     6    0    0  5  0 94  018  0   1540   1078    348   8715    0    0     0    40 11476 16550 32  1 67  0 1  0   1540   1078    348   8715    0    0     0     0 9431 16197 11  0 89  0 0  0   1540   1079    348   8715    0    0     0   244 8325 15550  1  0 99  0 6  0   1540   1079    348   8715    0    0     0     0 8770 15459  5  0 95  0 0  0   1540   1080    348   8715    0    0     0   100 13954 20077 37  1 62  0 0  0   1540   1080    348   8715    0    0     0    36 8661 16188  1  0 98  0 2  0   1540   1080    348   8715    0    0     0     0 8708 16158  1  0 98  0 1  0   1540   1081    348   8715    0    0     0    68 10946 16001 33  0 66  0 1  0   1540   1080    348   8715    0    0     0     0 9380 17035  1  1 98  0 0  0   1540   1080    348   8715    0    0     0   128 8447 15719  1  0 99  020  0   1540   1080    348   8715    0    0     0    44 10066 15924 15  1 84  0 1  0   1540   1081    348   8715    0    0     0     0 11834 16701 41  1 59  0 1  0   1540   1080    348   8715    0    0     0   144 8346 15732  1  1 98  1 2  0   1540   1080    348   8715    0    0     0     0 8378 15545  1  0 98  0 2  0   1540   1080    348   8715    0    0     0   120 16144 21775 36  1 63  0 3  0   1540   1079    348   8715    0    0     0    60 8911 16162  3  1 97  0 1  0   1540   1079    348   8715    0    0     0     0 8645 16013  1  1 99  0 5  0   1540   1079    348   8715    0    0     0   272 9153 15929  6  1 92  1 2  0   1540   1080    348   8715    0    0     0     0 12723 16598 52  1 48  0</code></pre><ul><li><p>procs</p><ul><li>R 列表示运行和等待 CPU 时间片的进程数，这个值如果长期大于系统 CPU 个数，说明CPU 不足，需要增加 CPU。</li><li>B 列表示在等待资源的进程数，比如正在等待 I/O 或者内存交换等。</li></ul></li><li><p>memory</p><ul><li>swpd 列表示切换到内存交换区的内存大小（单位 KB），通俗讲就是虚拟内存的大小。如果 swap 值不为 0 或者比较大， 只要 si、so 的值长期为 0，这种情况一般属于正常情况</li><li>free 列表示当前空闲的物理内存（单位 KB） 。</li><li>buff 列表示 buffers cached 内存大小，也就是缓冲区大小，一般对块设备的读写才需要缓冲。</li><li>cache 列表示 page cached 的内存大小，也就是缓存大小，一般作为文件系统进行缓冲，频繁访问的文件都会被缓存，如果 cache 值非常大说明缓存文件比较多，如果此时 io中的 bi 比较小，说明文件系统效率比较好。</li></ul></li><li><p>swap</p><ul><li>si 列表示由磁盘调入内存，也就是内存进入内存交换区的内存大小。</li><li>so 列表示由内存进入磁盘，也就是有内存交换区进入内存的内存大小。一般情况下，si、so 的值都为 0，如果 si、so 的值长期不为 0，则说明系统内存不足，需要增加系统内存。</li></ul></li><li><p>io</p><ul><li>bi 列表示由块设备读入数据的总量，即读磁盘，单位 kb/s。</li><li>bo 列表示写到块设备数据的总量，即写磁盘，单位 kb/s。如果 bi+bo 值过大，且 wa 值较大，则表示系统磁盘 IO 瓶颈。</li></ul></li><li><p>system</p><ul><li>in 列表示某一时间间隔内观测到的每秒设备中断数。</li><li>cs 列表示每秒产生的上下文切换次数。这 2 个值越大，则由内核消耗的 CPU 就越多。</li></ul></li><li><p>cpu</p><ul><li>us 列表示用户进程消耗的 CPU 时间百分比，us 值越高，说明用户进程消耗 cpu 时间越多，如果长期大于 50%，则需要考虑优化程序或者算法。</li><li>sy 列表示系统内核进程消耗的 CPU 时间百分比，一般来说 us+sy 应该小于 80%，如果大于 80%，说明可能处于 CPU 瓶颈。</li><li>id 列表示 CPU 处在空闲状态的时间百分比。</li><li>wa 列表示 IP 等待所占的 CPU 时间百分比，wa 值越高，说明 I/O 等待越严重，根据经验 wa 的参考值为 20%，如果超过 20%，说明 I/O 等待严重，引起 I/O 等待的原因可能是磁盘大量随机读写造成的， 也可能是磁盘或者此哦按监控器的贷款瓶颈 （主要是块操作）造成的。</li></ul></li></ul><table><thead><tr><th>字段</th><th>含义</th></tr></thead><tbody><tr><td>Procs（进程）</td><td>r: 运行队列中进程数量;b: 等待IO的进程数量</td></tr><tr><td>Memory（内存）</td><td>swpd: 使用虚拟内存大小;free: 可用内存大小;buff: 用作缓冲的内存大小;cache: 用作缓存的内存大小</td></tr><tr><td>Swap</td><td>si: 每秒从交换区写到内存的大小;so: 每秒写入交换区的内存大小</td></tr><tr><td>IO：（现在的Linux版本块的大小为1024bytes）</td><td>bi: 每秒读取的块数; cs: 每秒上下文切换数</td></tr><tr><td>system（系统）</td><td>in: 每秒中断数，包括时钟中断;cs: 每秒上下文切换数</td></tr><tr><td>CPU（以百分比表示）</td><td>us: 用户进程执行时间(user time);sy: 系统进程执行时间(system time);id: 空闲时间(包括IO等待时间),中央处理器的空闲时间,以百分比表示;wa: 等待IO时间</td></tr></tbody></table><p>备注： 如果r经常大于4，且id经常少于40，表示cpu的负荷很重。如果pi，po长期不等于0，表示内存不足。如果disk经常不等于0，且在 b中的队列大于3，表示io性能不好。</p><h3 id="free"><a href="#free" class="headerlink" title="free"></a>free</h3><p>free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。也是经典常用命令之一。</p><p>命令格式：</p><pre><code>free [参数]</code></pre><p>命令参数：</p><pre><code>-b 　以Byte为单位显示内存使用情况。 -k 　以KB为单位显示内存使用情况。 -m 　以MB为单位显示内存使用情况。-g   以GB为单位显示内存使用情况。 -o 　不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 　持续观察内存使用状况。 -t 　显示内存总和列。 -V 　显示版本信息。</code></pre><p>使用实例：</p><pre><code>chenruiwen@ubuntu$ free -m             total       used       free     shared    buffers     cachedMem:         32128      31103       1025          0        348       8739-/+ buffers/cache:      22014      10114Swap:        15257       1540      13717</code></pre><p>字段解释：</p><ul><li>Mem：物理内存大小。</li><li>total：总计物理内存的大小。</li><li>used：已使用多大。</li><li>free：可用有多少。</li><li>shared：多个进程共享的内存总额。</li><li>buffers：缓冲区内存总量。</li><li>cached：交换区缓冲区内存总量。</li><li>第三行(-/+ buffers/cached)：系统的物理内存真实使用量，可通过used-buffers-cached计算得到，因为buffers和cached也是占用物理内存得来，可以通过释放它们来获得这部分内存。</li><li>Swap：交换区总量，也叫虚拟内存。</li></ul><p><strong>第二行(Mem)的used/free与第三行(-/+ buffers/cache) used/free的区别：</strong>  </p><blockquote><p>这两个的区别在于使用的角度来看。</p><p><code>Mem</code>行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是<code>1025MB</code>，已用内存是<code>31103MB</code>，其中包括，内核（OS）使用 + Application(X,oracle,etc)使用的 + buffers + cached.</p><p><code>-/+ buffers/cache</code>行是从应用程序角度来看，对于应用程序来说，buffers/cached是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。</p><p>例如本机的可用内存为：22014MB(<code>-/+ buffers/cache: used</code>) = 1025MB(Mem:free) + 348MB(<code>Mem:buffers</code>) + 8739MB(<code>Mem:cached</code>)</p></blockquote><p><strong>cache 和 buffer的区别：</strong></p><blockquote><p>Cache：高速缓存，是位于CPU与主内存间的一种容量较小但速度很高的存储器。</p><p>由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，Cache中保存着CPU刚用过或循环使用的一部分数据，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。</p><p>Cache又分为一级Cache(L1 Cache)和二级Cache(L2 Cache)，L1 Cache集成在CPU内部，L2 Cache早期一般是焊在主板上,现在也都集成在CPU内部，常见的容量有256KB或512KB L2 Cache。</p><p>Buffer：缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。</p><p>Free中的buffer和cache：（它们都是占用内存）</p><p>buffer : 作为buffer cache的内存，是块设备的读写缓冲区cache: 作为page cache的内存，文件系统的cache</p><p>如果 cache 的值很大，说明cache住的文件数很多。如果频繁访问到的文件都能被cache住，那么磁盘的读IO 必会非常小。</p></blockquote><h3 id="proc-meminfo-文件"><a href="#proc-meminfo-文件" class="headerlink" title="/proc/meminfo 文件"></a>/proc/meminfo 文件</h3><p>/proc/meminfo是了解Linux系统内存使用状况的主要接口，我们最常用的<code>free</code>、<code>vmstat</code>等命令就是通过它获取数据的。此信息最为丰富，但是我个人使用不多。</p><p>使用示例如下，至于各参数的含义，还是留给Google吧:</p><pre><code>~$ cat /proc/meminfoMemTotal:       32899876 kBMemFree:         4919948 kBBuffers:           95612 kBCached:          1170384 kBSwapCached:      1345120 kBActive:         22391896 kBInactive:        4236700 kBActive(anon):   21918324 kBInactive(anon):  3448892 kBActive(file):     473572 kBInactive(file):   787808 kBUnevictable:           0 kBMlocked:               0 kBSwapTotal:      15624188 kBSwapFree:        5905244 kBDirty:              7212 kBWriteback:             0 kBAnonPages:      24023988 kBMapped:            33772 kBShmem:              4408 kBSlab:             764240 kBSReclaimable:     598480 kBSUnreclaim:       165760 kBKernelStack:       70024 kBPageTables:       125652 kBNFS_Unstable:          0 kBBounce:                0 kBWritebackTmp:          0 kBCommitLimit:    32074124 kBCommitted_AS:   52714036 kBVmallocTotal:   34359738367 kBVmallocUsed:      342184 kBVmallocChunk:   34342341604 kBHardwareCorrupted:     0 kBAnonHugePages:         0 kBHugePages_Total:       0HugePages_Free:        0HugePages_Rsvd:        0HugePages_Surp:        0Hugepagesize:       2048 kBDirectMap4k:      271296 kBDirectMap2M:    25896960 kBDirectMap1G:     7340032 kB</code></pre><h3 id="sar"><a href="#sar" class="headerlink" title="sar"></a>sar</h3><p>sar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等，sar命令由sysstat安装包安装。</p><p>sar安装直接<code>yum install -y sysstat</code>，然后先执行<code>sar -o 2 3</code>，来生成所需文件，之后使用就正常啦。</p><p>命令格式:</p><pre><code>sar [选项] [&lt;时间间隔&gt; [&lt;次数&gt;]]</code></pre><p>命令参数:</p><pre><code>-A:所有报告的总和-b:显示I/O和传递速率的统计信息-B:显示换页状态-d:输出每一块磁盘的使用信息-e:设置显示报告的结束时间-f:从制定的文件读取报告-i:设置状态信息刷新的间隔时间-P:报告每个CPU的状态-R:显示内存状态–u:输出cpu使用情况和统计信息–v:显示索引节点、文件和其他内核表的状态-w:显示交换分区的状态-x:显示给定进程的装-r:报告内存利用率的统计信息</code></pre><h4 id="sar监控CPU"><a href="#sar监控CPU" class="headerlink" title="sar监控CPU"></a>sar监控CPU</h4><p>使用示例,输出cpu使用情况和统计信息，每2秒输出一次，输出10次：</p><pre><code>~$ sar -u 2 10Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)13时43分03秒     CPU     %user     %nice   %system   %iowait    %steal     %idle13时43分05秒     all      2.23      0.02      0.93      0.15      0.00     96.6713时43分07秒     all      1.54      0.00      0.65      0.11      0.00     97.7113时43分09秒     all      0.99      0.00      0.65      1.12      0.00     97.2413时43分11秒     all      2.02      0.02      0.92      0.13      0.00     96.9113时43分13秒     all      1.39      0.00      0.63      0.44      0.00     97.5313时43分15秒     all      1.85      0.02      1.01      0.06      0.00     97.0613时43分17秒     all      2.11      0.00      0.70      0.02      0.00     97.1713时43分19秒     all      1.37      0.00      0.51      0.72      0.00     97.4113时43分21秒     all      1.62      0.02      0.93      0.06      0.00     97.3713时43分23秒     all      1.39      0.00      0.59      0.27      0.00     97.75Average:        all      1.65      0.01      0.75      0.31      0.00     97.28</code></pre><p>参数说明:</p><ul><li>%usr：用户进程消耗的 CPU 时间百分比</li><li>%nice: 运行正常进程消耗的 CPU 时间百分比</li><li>%system：系统进程消耗的 CPU 时间百分比</li><li>%iowait：I/O 等待所占 CPU 时间百分比</li><li>%steal：在内存紧张环境下，pagein强制对不同的页面进行的steal操作。虚拟服务占用的CPU时间百分比，这个值一般为0.</li><li>%idle：CPU 空闲状态的时间百分比</li></ul><blockquote><p>在所有的显示中，我们应主要注意<code>%iowait</code> 和<code>%idle</code>。</p><p>%iowait 的值过高，表示硬盘存在I/O瓶颈， %idle值高，表示 CPU 较空闲，如果%idle 值高但系统响应慢时，有可能是 CPU 等待分配内存， 此时应加大内存容量。</p><p>%idle 值如果持续低于 10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p></blockquote><h4 id="sar监控内存"><a href="#sar监控内存" class="headerlink" title="sar监控内存"></a>sar监控内存</h4><p>使用示例,<strong>显示内存使用信息</strong>：</p><pre><code>~$ sar -r 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)14时04分38秒 kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact14时04分40秒   4984120  27915756     84.85    104060   1157104  52363184    107.91  22343076   422716814时04分42秒   4983772  27916104     84.85    104060   1157416  52363184    107.91  22343080   422734414时04分44秒   4983516  27916360     84.85    104072   1157584  52363184    107.91  22343148   4227532Average:      4983803  27916073     84.85    104064   1157368  52363184    107.91  22343101   4227348</code></pre><ul><li>kbmemfree： 空闲的物理内存大小。这个值和 free 命令中的 free 值基本一致,所以它不包括 buffer 和 cache 的空间。</li><li>kbmemused：使用中的物理内存大小。这个值和 free 命令中的 used 值基本一致,所以它包括 buffer 和 cache 的空间。</li><li>%memused：这个值是 kbmemused 和内存总量(不包括 swap)的一个百分比。</li><li>kbbuffers 和 kbcached：这两个值就是 free 命令中的 buffer 和 cache。</li><li>kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)。</li><li>%commit：这个值是 kbcommit 与内存总量(包括 swap)的一个百分比。</li></ul><p>使用示例，<strong>显示系统内存分页状态</strong>：</p><pre><code>~$ sar -B 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)14时17分35秒  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff14时17分37秒      0.00     16.00    135.00      0.00    395.50      0.00      0.00      0.00      0.0014时17分39秒      0.00    168.00     26.00      0.00    435.00      0.00      0.00      0.00      0.0014时17分41秒      0.00   1142.00    517.50      0.00    679.50      0.00      0.00      0.00      0.00Average:         0.00    442.00    226.17      0.00    503.33      0.00      0.00      0.00      0.00</code></pre><ul><li>pgpgin/s：表示每秒从磁盘或 SWAP 置换到内存的字节数(KB)。</li><li>pgpgout/s：表示每秒从内存置换到磁盘或 SWAP 的字节数(KB)。</li><li>fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)。</li><li>majflt/s：每秒钟产生的主缺页数。</li></ul><p>使用示例，<strong>显示系统虚拟内存分页状态</strong>：</p><pre><code>$ sar -W 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)17时08分41秒  pswpin/s pswpout/s17时08分43秒      0.00      0.0017时08分45秒      0.00      0.0017时08分47秒      0.00      0.00Average:         0.00      0.00</code></pre><ul><li>pswpin/s：每秒系统换入的交换页面（swap page）数量。</li><li>pswpout/s：每秒系统换出的交换页面（swap page）数量。</li></ul><h4 id="sar监控负载"><a href="#sar监控负载" class="headerlink" title="sar监控负载"></a>sar监控负载</h4><p>使用示例，<strong>查看平均负载</strong>：</p><pre><code>~$ sar -q 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时36分24秒   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15   blocked21时36分26秒         1      8321      0.92      0.71      0.72         021时36分28秒         0      8321      0.92      0.71      0.72         021时36分30秒         1      8322      0.92      0.71      0.72         0Average:            1      8321      0.92      0.71      0.72         0</code></pre><ul><li>unq-sz：运行队列的长度（等待运行的进程数）</li><li>plist-sz：进程列表中进程（processes）和线程（threads）的数量</li><li>ldavg-1：最后1分钟的系统平均负载</li><li>ldavg-5：过去5分钟的系统平均负载</li><li>ldavg-15：过去15分钟的系统平均负载</li></ul><h4 id="sar监控I-O"><a href="#sar监控I-O" class="headerlink" title="sar监控I/O"></a>sar监控I/O</h4><p>使用示例，<strong>显示缓冲区使用情况</strong>:</p><pre><code>~$ sar -b 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时40分00秒       tps      rtps      wtps   bread/s   bwrtn/s21时40分02秒     18.50      0.00     18.50      0.00    288.0021时40分04秒     15.50      0.00     15.50      0.00    240.0021时40分06秒      5.50      0.00      5.50      0.00     44.00Average:        13.17      0.00     13.17      0.00    190.67</code></pre><ul><li>tps：每秒钟物理设备的 I/O 传输总量。</li><li>rtps：每秒钟从物理设备读入的数据总量。</li><li>wtps：每秒钟向物理设备写入的数据总量。</li><li>bread/s：每秒钟从物理设备读入的数据量，单位为 块/s。</li><li>bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s。</li></ul><p>使用示例，<strong>监控设备使用情况</strong>:</p><pre><code>~$ sar -d 2 3Linux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)21时50分47秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分49秒    dev8-0     17.50      0.00    868.00     49.60      0.71     40.57      6.17     10.8021时50分49秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分51秒    dev8-0      5.00      0.00     40.00      8.00      0.02      3.60      3.60      1.8021时50分51秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util21时50分53秒    dev8-0     53.50      0.00    800.00     14.95      4.70     87.89      3.03     16.20Average:          DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %utilAverage:       dev8-0     25.33      0.00    569.33     22.47      1.81     71.45      3.79      9.60</code></pre><ul><li>tps:每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。</li><li>rd_sec/s:每秒读扇区的次数。</li><li>wr_sec/s:每秒写扇区的次数。</li><li>avgrq-sz:平均每次设备 I/O 操作的数据大小(扇区)。</li><li>avgqu-sz:磁盘请求队列的平均长度。</li><li>await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1 秒=1000 毫秒)。</li><li>svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间。</li><li>%util:I/O 请求占 CPU 的百分比,比率越大,说明越饱和。</li><li>avgqu-sz 的值较低时，设备的利用率较高。当%util 的值接近 1% 时，表示设备带宽已经占满。</li><li>await-svctm=io等待时间。</li></ul><h4 id="sar总结"><a href="#sar总结" class="headerlink" title="sar总结"></a>sar总结</h4><p>sar可监控的太多了，这里做个总结。</p><ul><li>要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来</li><li>怀疑 CPU 存在瓶颈，可用 sar -u 和 sar -q 等来查看</li><li>怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看</li><li>怀疑 I/O 存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看</li></ul><h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><p> iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。</p><p> 命令格式：</p><pre><code> iostat[参数][时间][次数]</code></pre><p> 命令参数：</p><pre><code> -C 显示CPU使用情况-d 显示磁盘使用情况-k 以 KB 为单位显示-m 以 M 为单位显示-N 显示磁盘阵列(LVM) 信息-n 显示NFS 使用情况-p[磁盘] 显示磁盘和分区的情况-t 显示终端和CPU的信息-x 显示详细信息-V 显示版本信息</code></pre><h4 id="显示所有磁盘分区的情况"><a href="#显示所有磁盘分区的情况" class="headerlink" title="显示所有磁盘分区的情况"></a>显示所有磁盘分区的情况</h4><pre><code>~$ iostat -xLinux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           2.56    0.01    2.38    0.17    0.00   94.88Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %utilsda               0.10     6.61    0.61    8.95     6.79   169.04    36.80     0.04    4.44   10.29    4.04   3.64   3.47</code></pre><p> 参数说明:</p><ul><li>rrqm/s：每秒进行 merge 的读操作数目，即 delta(rmerge)/s 。<ul><li>wrqm/s：每秒进行 merge 的写操作数目，即 delta(wmerge)/s 。</li><li>r/s：每秒完成的读 I/O 设备次数，即 delta(rio)/s 。</li><li>w/s： 每秒完成的写 I/O 设备次数，即 delta(wio)/s 。</li><li>rsec/s：每秒读扇区数，即 delta(rsect)/s。</li><li>wsec/s：每秒写扇区数，即 delta(wsect)/s</li><li>rkB/s：每秒读 K 字节数，是 rsect/s 的一半，因为每扇区大小为 512 字节。</li><li>wkB/s：每秒写 K 字节数，是 wsect/s 的一半</li><li>avgrq-sz：平均每次设备 I/O 操作的数据大小 (扇区)，即delta(rsect+wsect)/delta(rio+wio) 。</li><li><strong>avgqu-sz</strong>：平均 I/O 队列长度，即 delta(aveq)/s/1000 (因为 aveq 的单位为毫秒)。</li><li><strong>Await</strong>： 平均每次设备 I/O 操作的等待时间 (毫秒)， 即 delta(ruse+wuse)/delta(rio+wio) 。</li><li><strong>Svctm</strong>：平均每次设备 I/O 操作的服务时间 (毫秒)，即delta(use)/delta(rio+wio) </li><li>%util：一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为 use 的单位为毫秒) 。</li></ul></li></ul><h4 id="显示所有设备负载情况"><a href="#显示所有设备负载情况" class="headerlink" title="显示所有设备负载情况"></a>显示所有设备负载情况</h4><pre><code> ~$ iostatLinux 3.2.0-23-generic (localhost)   2018年11月12日  _x86_64_        (24 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           2.56    0.01    2.38    0.17    0.00   94.88Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtnsda               9.55         6.79       169.04  391806012 9758159776</code></pre><p> 参数说明：</p><ul><li>%user：CPU处在用户模式下的时间百分比。</li><li>%nice：CPU处在带NICE值的用户模式下的时间百分比。</li><li>%system：CPU处在系统模式下的时间百分比。</li><li>%iowait：CPU等待输入输出完成时间的百分比。</li><li>%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</li><li><p>%idle：CPU空闲时间百分比。</p><p><strong>注</strong>：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。</p></li><li><p>tps：每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。<strong>磁盘的一次读或者写都是一次 I/O 操作</strong></p></li><li>Blk_read/s：每秒读取的数据块数。</li><li>Blk_wrtn/s ：每秒写入的数据块数。</li><li>Blk_read：读取的所有块数。</li><li>Blk_wrtn ：写入的所有块数。</li></ul><h3 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h3><p>netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。</p><p>如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。</p><p>命令格式：</p><pre><code>netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][--ip]</code></pre><p>命令参数：</p><pre><code>-a或–all 显示所有连线中的Socket。-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。-c或–continuous 持续列出网络状态。-C或–cache 显示路由器配置的快取信息。-e或–extend 显示网络其他相关信息。-F或–fib 显示FIB。-g或–groups 显示多重广播功能群组组员名单。-h或–help 在线帮助。-i或–interfaces 显示网络界面信息表单。-l或–listening 显示监控中的服务器的Socket。-M或–masquerade 显示伪装的网络连线。-n或–numeric 直接使用IP地址，而不通过域名服务器。-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。-o或–timers 显示计时器。-p或–programs 显示正在使用Socket的程序识别码和程序名称。-r或–route 显示Routing Table。-s或–statistice 显示网络工作信息统计表。-t或–tcp 显示TCP传输协议的连线状况。-u或–udp 显示UDP传输协议的连线状况。-v或–verbose 显示指令执行过程。-V或–version 显示版本信息。-w或–raw 显示RAW传输协议的连线状况。-x或–unix 此参数的效果和指定”-A unix”参数相同。–ip或–inet 此参数的效果和指定”-A inet”参数相同。</code></pre><p>常用的有两个：<code>netstat -plnt</code>和<code>netstat -i</code>.</p><pre><code>~$ netstat -iKernel Interface tableIface   MTU Met   RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flgeth1       1500 0  26920306700      0 26842853 0      23410550297      0      0      0 BMRUlo        16436 0  9819751923      0      0 0      9819751923      0      0      0 LRU</code></pre><p>字段说明:</p><ul><li>Iface：表示网络设备的接口名称。</li><li>MTU：表示最大传输单元，单位为字节。</li><li>RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。</li><li>RX-ERR/TX-ERR：表示接收/发送数据包时候产生了多少错误。</li><li>RX-DRP/TX-DRP：表示接收/发送数据包时候丢弃了多少数据包。</li><li>RX-OVR/TX-OVR：表示由于误差而丢失了多少数据包。</li><li>Flg 表示接口标记，其中<ul><li>B 已经设置了一个广播地址。</li><li>L 该接口是一个回送设备。</li><li>M 接收所有数据包（混乱模式） 。</li><li>N 避免跟踪。</li><li>O 在该接口上，禁用 AR P。</li><li>P 这是一个点到点链接。</li><li>R 接口正在运行。</li><li>U 接口处于“活动”状态。</li></ul></li><li>其中 RX-ERR/TX-ERR、 RX-DRP/TX-DRP 和 RX-OVR/TX-OVR 的值应该都为 0，如果不为 0，并且很大，那么网络质量肯定有问题，网络传输性能也一代会下降。</li></ul><pre><code>$  netstat -plnt(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program nametcp        0      0 0.0.0.0:2281            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:18889           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:27017           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:30090           0.0.0.0:*               LISTEN      -               tcp        0      0 10.0.0.114:22122        0.0.0.0:*               LISTEN      -               tcp        0      0 10.0.0.114:22123        0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:1099            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:6379            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:9100            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:30060           0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:6380            0.0.0.0:*               LISTEN      -               tcp        0      0 0.0.0.0:48781           0.0.0.0:*               LISTEN      -       </code></pre><p>字段说明：</p><ul><li>Proto ：协议</li><li>Recv-Q：表示接收队列。</li><li>Send-Q ：表示发送队列。</li><li>LocalAddress ：表示本地机器名、端口</li><li>Foreign Address ：表示远程机器名、端口</li><li>State：表示状态，其中:<ul><li>LISTEN ：在监听状态中。</li><li>ESTABLISHED：已建立联机的联机情况。</li><li>TIME_WAIT：该联机在目前已经是等待的状态。</li></ul></li><li>PID/Program name:进程id/进程名</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Linux的性能分析工具非常多，这里只是总结了冰山一角，也是参考了很多优秀的博文:</p><ul><li><a href="https://cloud.tencent.com/developer/article/1004358" target="_blank" rel="noopener">Linux 性能监控 ： CPU 、Memory 、 IO 、Network</a></li><li><a href="https://www.jianshu.com/p/9e571b2b4971" target="_blank" rel="noopener">linux 服务器性能监控</a></li><li><a href="https://www.cnblogs.com/peida/archive/2012/12/05/2803591.html" target="_blank" rel="noopener">每天一个linux命令</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上周五公司搞了双十一“大促”，虽然时间紧凑，还是引起了团队上下高度重视，在有限的两天时间里，进行了充分的压测和性能分析，最终的结果也是不错的。对于性能分析工具，又做了一次熟悉的过程，这里结合网上优秀博文做了下整理。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://www.chenruiwen.cn/categories/Linux/"/>
    
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/tags/architecture/"/>
    
      <category term="Linux" scheme="https://www.chenruiwen.cn/tags/Linux/"/>
    
      <category term="performance analysis" scheme="https://www.chenruiwen.cn/tags/performance-analysis/"/>
    
  </entry>
  
  <entry>
    <title>记一次jedis连接异常引发的血案</title>
    <link href="https://www.chenruiwen.cn/redis/JedisPool-optimize-record/"/>
    <id>https://www.chenruiwen.cn/redis/JedisPool-optimize-record/</id>
    <published>2018-11-09T15:14:51.000Z</published>
    <updated>2018-11-09T15:48:46.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>每年双十一，各个互联网企业都会搞一些活动来促销自己公司产品，然而今年对于互联网金融领域的企业来说，可能并不好过，本以为今年公司不搞活动了，然而11月7号被告知11月9号上午发售一批双十一产品搞活动，这对于我们技术人员来说即兴奋又担忧，兴奋的是遇到这种类似秒杀场景的机会不多，担忧的是害怕网站会挂掉，而且留给我们的时间只有两天。</p><a id="more"></a><p>去年花了一段时间优化了我们网站，从架构层面到代码层面，也做了充分的全链路压测，花费了不少心思。(然而去年，并没有搞活动。)总之，我们还是对我们的代码有信心。</p><p>虽说如此，我们还是做了2天的全链路压测，压测数据单机qps大概能达到400+，能撑住五分钟左右然后系统性能下降，但是一分钟后qps又能上来，系统并没有挂掉，说明我们的系统还可以，又增加了自信。</p><p>今天上午9点早早到达公司，打开各种监控和日志，实施观察以便处理意外情况。果不其然，产品销售很快，门槛低的产品基本一分钟内卖完，90%的产品八分钟内卖完。我们的系统抗住压力。</p><p>app端请求数:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27hcac7fj20hq061dfx.jpg" alt=""></p><p>app端购买请求数：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27hmjt3mj20hs06sdfx.jpg" alt=""></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>然而还是出现了一些问题。运维的同学反馈，基于redis统计并发在线人数有些不正常，有一个突然间的峰值：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx273xbknaj21di0qm0x3.jpg" alt=""></p><p>老大反馈了一些问题：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27307uojj21cy0l4acm.jpg" alt=""></p><p>总之问题是：</p><ul><li>登录后，PC端在产品可购买的瞬间大量用户登出系统了。</li><li>购买后反馈结果慢。(这个问题老问题了，原因是对接杭州那边系统反应慢。)</li></ul><h2 id="排查问题"><a href="#排查问题" class="headerlink" title="排查问题"></a>排查问题</h2><p>我们主要是排查为什么大量用户登出？</p><p>开始以为是cookie被删除的原因，但是大量用户登出还是有些不正常，我们的服务监控也没有报警，一度觉得很诧异，总之还是先查日志吧，万一日志确实没有报警呢？</p><p>还真是。Dubbo报错：调用用户服务线程池满了，达到上限200，之后的请求全部拒绝了:<img src="https://ws1.sinaimg.cn/large/87faef88ly1fx27esr9iwj21a605ywez.jpg" alt=""></p><p>到底什么导致了Dubbo线程池满了？接着看日志找到了具体的报错信息:</p><pre><code>Caused by: java.util.NoSuchElementException: Timeout waiting for idle object    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449)    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)    at redis.clients.util.Pool.getResource(Pool.java:49)    ... 16 moreException in thread &quot;pool-4-thread-4074&quot; org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:198)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:345)    at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:129)    at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:92)    at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:79)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:191)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:166)    at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:88)    at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169)    at com.gemantic.wealth.test.controller.RedisController$1.run(RedisController.java:40)    at com.gemantic.wealth.test.controller.MyRunnable.run(RedisController.java:84)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    at java.lang.Thread.run(Thread.java:745)Caused by: redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool    at redis.clients.util.Pool.getResource(Pool.java:51)    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:99)    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:12)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:191)    ... 13 moreCaused by: java.util.NoSuchElementException: Timeout waiting for idle object    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449)    at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)    at redis.clients.util.Pool.getResource(Pool.java:49)    ... 16 more</code></pre><p>那么问题就比较明朗了：</p><ul><li>jedis获取资源时等待超时，连接不上报错。</li></ul><p>看了下生产的redis配置：</p><pre><code>spring.redis:    database: 1    host: redis    port: 6379    password:    pool:      max-wait: 3000      max-idle: 20</code></pre><p>问题可能是出在这里，大胆猜测一下：由于没有配置jedisPool的maxTotal，默认连接数为8，当并发数上来时，大量请求过来导致大部分的连接不上redis而直接抛异常了。</p><p>Google了一下，也有我们这种情况的先例，但还是先测试一下：200个并发请求往redis中插入数据，jedis配置与生产一致的情况，发现稳定浮现错误信息。</p><p>对比测试，修改测试用例的jedis配置，大致，最大连接数改为100后测试，发现报错少了90%。那么应该就是这个问题了。</p><p>解决生产问题，修改redis配置:</p><pre><code>spring.redis:    database: 1    host: redis    port: 6379    password:    pool:      max-wait: 500      max-idle: 50      max-active: 50</code></pre><p>解释一下:</p><ul><li>max-wait: 对应连接池连接等待时间，原先是3000毫秒，有些长了，连接不上应该尽早报错不要占用资源。</li><li>max-active：对应<code>JedisPoolConfig</code>的maxTotal，最大连接数，主要改的就是这个。</li><li>max-idle：最大空闲连接数，保持与maxTotal一致，避免连接池伸缩带来的性能干扰。</li></ul><p>以上设置参考了<a href="https://yq.aliyun.com/articles/236383?spm=5176.8091938.0.0.qVO71y" target="_blank" rel="noopener">JedisPool资源池优化</a>。</p><p>最后附一下JedisPoolConfig关键配置，也是参考以上博客哈：</p><table><thead><tr><th>参数名</th><th>含义</th><th>默认值</th><th>使用建议</th></tr></thead><tbody><tr><td>maxTotal</td><td>资源池中最大连接数</td><td>8</td><td>不能太大，连接太多占用客户端和服务器的资源，建议50</td></tr><tr><td>maxIdle</td><td>资源池允许最大空闲的连接数</td><td>8</td><td>与maxTotal一致</td></tr><tr><td>minIdle</td><td>资源池确保最少空闲的连接数</td><td>0</td><td>根据业务，可设置少量</td></tr><tr><td>blockWhenExhausted</td><td>当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效</td><td>true</td><td>建议默认值</td></tr><tr><td>maxWaitMillis</td><td>当资源池连接用尽后，调用者的最大等待时间(单位为毫秒)</td><td>-1 : 表示永不超时</td><td>不建议默认值，我们是500</td></tr><tr><td>testOnBorrow</td><td>向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td>false</td><td>业务量很大时候建议设置为false(多一次ping的开销)。</td></tr><tr><td>testOnReturn</td><td>向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除</td><td>false</td><td>业务量很大时候建议设置为false(多一次ping的开销)。</td></tr><tr><td>jmxEnabled</td><td>是否开启jmx监控，可用于监控</td><td>true</td><td>建议开启，但应用本身也要开启</td></tr><tr><td>testWhileIdle</td><td>是否开启空闲资源监测</td><td>false</td><td>true</td></tr><tr><td>timeBetweenEvictionRunsMillis</td><td>空闲资源的检测周期(单位为毫秒)</td><td>-1：不检测</td><td>建议设置，周期自行选择，也可以默认也可以使用下面JedisPoolConfig中的配置</td></tr><tr><td>minEvictableIdleTimeMillis</td><td>资源池中资源最小空闲时间(单位为毫秒)，达到此值后空闲资源将被移除</td><td>1000<em>60</em>30 = 30 min</td><td>可根据自身业务决定，大部分默认值即可，也可以考虑使用下面JeidsPoolConfig中的配置</td></tr><tr><td>numTestsPerEvictionRun</td><td>做空闲资源检测时，每次的采样数</td><td>3</td><td>可根据自身应用连接数进行微调,如果设置为-1，就是对所有连接做空闲监测</td></tr></tbody></table><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>这次的问题属于客户端设置参数的问题，还是要检查一下各个服务的配置为好。</p><p>解决了这个问题，根据监控发现还有更多可优化的地方，其次，我们的这次监控没有加上Jedis的异常报错，监控还有待提高，不过我们以及在测试环境上接上了点评的<a href="https://github.com/dianping/cat" target="_blank" rel="noopener">CAT</a>,非常好用，踩完坑后准备接到生产。</p><p>最后感慨一下解决问题真的很有快感。更感谢帮助我解决问题的这些参考的博文:</p><ul><li><a href="https://blog.csdn.net/qq_39954022/article/details/78488935" target="_blank" rel="noopener">Jedis常见异常汇总</a></li><li><a href="https://yq.aliyun.com/articles/236383?spm=5176.8091938.0.0.qVO71y" target="_blank" rel="noopener">JedisPool资源池优化</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;每年双十一，各个互联网企业都会搞一些活动来促销自己公司产品，然而今年对于互联网金融领域的企业来说，可能并不好过，本以为今年公司不搞活动了，然而11月7号被告知11月9号上午发售一批双十一产品搞活动，这对于我们技术人员来说即兴奋又担忧，兴奋的是遇到这种类似秒杀场景的机会不多，担忧的是害怕网站会挂掉，而且留给我们的时间只有两天。&lt;/p&gt;
    
    </summary>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/categories/redis/"/>
    
    
      <category term="essay" scheme="https://www.chenruiwen.cn/tags/essay/"/>
    
      <category term="redis" scheme="https://www.chenruiwen.cn/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>浅析java并发包(六)：线程池那些事儿</title>
    <link href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-ThreadPoolExecutor/"/>
    <id>https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-ThreadPoolExecutor/</id>
    <published>2018-10-28T10:23:51.000Z</published>
    <updated>2018-10-30T13:30:59.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>创建一个线程，最简单的做法是<code>new</code>一个线程，但是当大量请求过来时(类比窗口卖票的场景)，创建这么多个线程的开销就很大了。今天整理下线程池相关知识，相对于传统做法，线程池的优势还是很明显的：<strong>节省了创建和销毁线程的时间，提高了任务执行效率，也就增加了CPU的吞吐能力</strong><a id="more"></a></p><h2 id="线程池的优势"><a href="#线程池的优势" class="headerlink" title="线程池的优势"></a>线程池的优势</h2><p>引用一下方腾飞的话，合理利用线程池能够带来三个好处。</p><ul><li><strong>降低资源消耗</strong>。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li><strong>提高响应速度</strong>。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li><li><strong>提高线程的可管理性</strong>。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。但是要做到合理的利用线程池，必须对其原理了如指掌。</li></ul><h2 id="Executors中的线程池"><a href="#Executors中的线程池" class="headerlink" title="Executors中的线程池"></a>Executors中的线程池</h2><p>j.u.c的Executors中默认提供了一些方便的线程池创建:</p><table><thead><tr><th>静态方法</th><th>线程池类型</th><th>说明</th><th>返回值的实际实现</th></tr></thead><tbody><tr><td>newCachedThreadPool()</td><td>可缓存的线程池</td><td>如果线程池的大小超过了处理任务所需要的线程,那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。</td><td>ThreadPoolExecutor</td></tr><tr><td>newFixedThreadPool(int)</td><td>固定线程池</td><td>每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。</td><td>ThreadPoolExecutor</td></tr><tr><td>newScheduledThreadPool(int)</td><td>定时及周期性线程池</td><td>此线程池支持定时以及周期性执行任务的需求。</td><td>ScheduledThreadPoolExecutor</td></tr><tr><td>newSingleThreadExecutor()</td><td>单线程的线程池</td><td>这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。</td><td>FinalizableDelegatedExecutorService</td></tr></tbody></table><h3 id="线程池的使用"><a href="#线程池的使用" class="headerlink" title="线程池的使用"></a>线程池的使用</h3><pre><code class="java">public static void main(String[] args) {    //ExecutorService pool = Executors. newSingleThreadExecutor();    //ExecutorService pool = Executors.newFixedThreadPool(2);    ExecutorService pool = Executors.newCachedThreadPool();    for (int i = 0; i &lt; 5; i++) {        pool.execute(() -&gt; System.out.println(Thread.currentThread().getName() + &quot;正在执行...&quot;));    }    pool.shutdown();}</code></pre><p>如上述测试程序，如果<code>ExecutorService</code>的实现pool是<code>newSingleThreadExecutor</code>的时，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...pool-1-thread-1正在执行...</code></pre><p>如果<code>ExecutorService</code>的实现pool是<code>newFixedThreadPool</code>的时，参数设置大小为2，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-2正在执行...pool-1-thread-1正在执行...pool-1-thread-2正在执行...pool-1-thread-1正在执行...</code></pre><p>如果<code>ExecutorService</code>的实现pool是<code>newCachedThreadPool</code>的时，输出</p><pre><code>pool-1-thread-1正在执行...pool-1-thread-3正在执行...pool-1-thread-2正在执行...pool-1-thread-4正在执行...pool-1-thread-5正在执行...</code></pre><p>如果是<code>newScheduledThreadPool</code>，则使用方法有些不同:</p><pre><code class="java">public static void main(String[] args) {    ScheduledExecutorService exec = Executors.newScheduledThreadPool(2); // 创建一个可定时的线程池    // 每2秒打印一次    exec.scheduleAtFixedRate(() -&gt; System.out.println(System.currentTimeMillis() / 1000), 1, 2, TimeUnit.SECONDS);    // 线程池中某个线程出错    exec.scheduleAtFixedRate(() -&gt; {        System.out.println(&quot;池中一个线程出错了！&quot;);        throw new RuntimeException();    }, 1, 2, TimeUnit.SECONDS);}</code></pre><p>上述程序输出如下,可见池中的线程是隔离的</p><pre><code>1540794708池中一个线程出错了！154079471015407947121540794714</code></pre><h2 id="核心ThreadPoolExecutor"><a href="#核心ThreadPoolExecutor" class="headerlink" title="核心ThreadPoolExecutor"></a>核心ThreadPoolExecutor</h2><p>无论你从上诉任何一种静态方法进去，其最终都是离不开这个类:<code>ThreadPoolExecutor</code></p><p>构造器：</p><pre><code class="java">public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler)</code></pre><p>解释一下这几个参数:</p><ol><li><code>corePoolSize</code>(核心线程池大小):当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的<code>prestartAllCoreThreads</code>方法，线程池会提前创建并启动所有基本线程。</li><li><code>maximumPoolSize</code>(线程池最大大小，其值=核心线程数+其他线程数):线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。</li><li><code>keepAliveTime</code>(线程活动保持时间):线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率。</li><li><code>TimeUnit</code>(线程活动保持时间的单位)：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。</li><li><code>workQueue</code>(任务队列):用于保存等待执行的任务的阻塞队列。关于阻塞队列，可参考之前写的<a href="https://www.chenruiwen.cn/java-concurrency/java-util-concurrent-BlockingQueue/">浅析java并发包(三)：阻塞队列(BlockingQueue)</a></li><li><code>threadFactory</code>(线程工厂):用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字，Debug和定位问题时非常又帮助。</li><li><code>RejectedExecutionHandler</code>(饱和策略):当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略：<ul><li>AbortPolicy：中止策略，默认。直接抛出异常。</li><li>CallerRunsPolicy：“调用者运行”策略，任务回退到调用者，从而降低了新任务的流量，只用调用者所在线程来运行任务。</li><li>DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。</li><li>DiscardPolicy：不处理，丢弃掉。</li><li>第五种，通过实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。</li></ul></li></ol><h2 id="线程池运行流程"><a href="#线程池运行流程" class="headerlink" title="线程池运行流程"></a>线程池运行流程</h2><p>一图胜前言，直接引用来自方腾飞《聊聊并发》：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwpdng64j1j20dw0850t4.jpg" alt=""></p><p>图码结合，从线程池的执行方法<code>ThreadPoolExecutor.execute</code>分析。分3种，我在代码里用注释标出</p><pre><code class="java">public void execute(Runnable command) {    if (command == null)        throw new NullPointerException();    int c = ctl.get();// 获取线程数    // 1.如果线程数小于核心线程数，则addWorker创建线程执行任务    if (workerCountOf(c) &lt; corePoolSize) {        if (addWorker(command, true))            return;        c = ctl.get();    }    // 2.线程是否RUNNING状态且尝试加入队列    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {        int recheck = ctl.get();        //再检查， 任务队列不在运行且从队列中删除，执行拒绝策略        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        // 运行任务数量为0，则移除核心线程外的线程        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    }    // 3.非RUNNING状态或者加入队列失败，尝试创建非核心线程直到maxPoolSize，如果失败则执行拒绝策略    else if (!addWorker(command, false))        reject(command);}</code></pre><h2 id="配置线程池"><a href="#配置线程池" class="headerlink" title="配置线程池"></a>配置线程池</h2><p>知道了线程池的参数和运行规则，那么如何配置线程池呢?</p><p>一. <strong>线程池的大小</strong>。主要是根据任务类型：计算密集型 or I/O密集型 or 二者皆可？</p><p>计算密集型的任务，通常情况线程池大小=Ncpu+1最优；</p><p>I/O密集型任务，由于线程不会一直执行，通常设置为Ncpu*2。</p><p>混合型，最好因地制宜，拆分为CPU密集型和I/O密集型处理。</p><p>一个通用公式:</p><pre><code>Ncpu:cpu的个数Ucpu:使用cpu的个数W/C:计算时间等待率Nthreads=Ncpu * Ucpu * (1 + W/C)</code></pre><p>二. <strong>阻塞队列的选择</strong>。主要分为3种，有界队列、无界队列、同步移交。</p><p>有界队列有助于避免资源耗尽，大部分情况比较适合。使用有界队列时，队列大小与线程池大小必须一起调节。当线程池较小而队列较大时，有助于减少内存使用量，降低CPU使用率，同时减少上下文切换，但代价是可能会限制吞吐量。</p><p>无界队列可以通过使用SynchronousQueue来避免排队。只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值。</p><p>三.<strong>关于ThreadPoolExecutor的扩展性</strong>。它提供了几个可以在子类改写的方法:<code>beforeExecute</code>,<code>afterExecute</code>,<code>terminated</code>。可以利用这些方法在线程执行前、后、以及销毁时做一些特别操作，比如添加日志、计时、监控、收集统计信息等功能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要参考了：</p><ul><li><a href="https://www.oschina.net/question/565065_86540" target="_blank" rel="noopener">java自带线程池和队列详细讲解</a></li><li><a href="http://ifeve.com/java-threadpool/" target="_blank" rel="noopener">聊聊并发（三）Java线程池的分析和使用</a></li><li>java并发编程实战</li></ul><p>对这些优秀博文书籍进行了一次聚合总结吧，感谢原作者。同时，对java线程池也更加的了解一些。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;创建一个线程，最简单的做法是&lt;code&gt;new&lt;/code&gt;一个线程，但是当大量请求过来时(类比窗口卖票的场景)，
创建这么多个线程的开销就很大了。
今天整理下线程池相关知识，相对于传统做法，线程池的优势还是很明显的：
&lt;strong&gt;节省了创建和销毁线程的时间，提高了任务执行效率，也就增加了CPU的吞吐能力&lt;/strong&gt;
    
    </summary>
    
      <category term="java-concurrency" scheme="https://www.chenruiwen.cn/categories/java-concurrency/"/>
    
    
      <category term="java" scheme="https://www.chenruiwen.cn/tags/java/"/>
    
      <category term="java concurrency" scheme="https://www.chenruiwen.cn/tags/java-concurrency/"/>
    
  </entry>
  
  <entry>
    <title>巴厘岛旅行记</title>
    <link href="https://www.chenruiwen.cn/travel/traveling-all-around-Bali/"/>
    <id>https://www.chenruiwen.cn/travel/traveling-all-around-Bali/</id>
    <published>2018-10-24T15:40:24.000Z</published>
    <updated>2018-10-28T12:23:43.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>过了一个漫长的假期，国庆节七天加上婚假十天，过的都不会上班了。蜜月之行的计划本来打算是去欧洲看看的，但是听说基本都是玩十二天左右，时间太长会很累，其次由于我们第一次出国，很多事情不是很懂，所以跟了个10.09-10.15的七天五晚的旅行团(有出国经验的话建议自由行)，遂主要记录在巴厘岛这几天的行程与游记。<a id="more"></a></p><h2 id="行前准备"><a href="#行前准备" class="headerlink" title="行前准备"></a>行前准备</h2><p>必备：  </p><ul><li>护照</li><li>机票(去机场取，我们坐的从北京直飞登巴萨的东方航空，座位可以从网上提前预约好)</li><li>钱。推荐带美元+印尼盾的组合，各提前准备好。(是可以从当地货币兑换点兑换，但是比较亏。最好提前准备好。)</li><li>打电话与流量(可以直接从支付宝搜索“境外上网”，我们是移动的用户，价格是移动的一半，办了五天流量价格54元。)</li><li>防晒霜(我们是提前在首都机场DFS买好的安耐晒，非常便宜，建议多买)</li><li>户外常用app：google地图，大众点评/飞猪等</li></ul><p>补充一些非必须但是有必要带的物品：</p><ul><li>沙滩裤(毕竟是要沾水的，速干的裤子比较好，巴厘岛那边比较潮湿，棉的衣物在宾馆不容易干)</li><li>泳衣泳裤(不解释)</li><li>拖鞋(不解释，基本告别要穿袜子的鞋)</li><li>沙滩鞋(有些地方比拖鞋好用)</li><li>花露水(防蚊)</li><li>手机防水袋(一些喜欢拍照的朋友请准备好)</li></ul><h2 id="具体行程记录"><a href="#具体行程记录" class="headerlink" title="具体行程记录"></a>具体行程记录</h2><p>行程简记：<br><strong>day0</strong> 首都机场飞到巴厘岛(人家原名叫登巴萨) -&gt; uluwatu的酒店<br><strong>day1</strong> uluwatu的酒店 -&gt; 情人崖 -&gt; 海龟岛 -&gt; 金巴兰海滩 -&gt; uluwatu的酒店<br><strong>day2</strong> uluwatu的酒店 -&gt; 蓝梦岛 -&gt; spa -&gt;  kuta的酒店<br><strong>day3</strong> kuta的酒店 -&gt; 漂流 -&gt; 大秋千 -&gt; 家乐福购物 -&gt; kuta的酒店<br><strong>day4</strong> kuta的酒店 -&gt; kuta沙滩 -&gt; DFS Bali T Galleria -&gt; spa again~ -&gt; kuta的酒店<br><strong>day5</strong> kuta的酒店 -&gt; 海神庙 -&gt; 乌布皇宫，乌布市场 -&gt; 下午茶 -&gt; 洋人街 -&gt; 机场<br><strong>day6</strong> 飞回首都机场</p><h3 id="day0"><a href="#day0" class="headerlink" title="day0"></a>day0</h3><p>由于是4点半的飞机，我们中午就到了首都机场，先是在机场吃了饭(机场的饭价格不用说，一定会贵，但是感谢上帝，这里的全家便利店跟其他地区一样)。然后我们就直接取机票和登机牌，然后办理托运，开开心心去首都机场的DFS了(帮人代购真累:D)。</p><p>4点半飞机起飞，好久没坐过飞机了，再加上第一次出国，着实有些小兴奋。乘坐的是东方航空，之前还担心东方航空的环境不好，其实还可以。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwb884twazj20u01hcthc.jpg" alt="">壮哉我大蚌埠:D，“新中国四大城市”</p><p>飞行七个小时整，晚上11:45到达巴厘岛，巴厘岛与北京没有时差。第一次办理入境，我的方法是，跟着人群走总是对的。好在大部分人是对的。护照盖章和取完托运的行李后便顺利入境了。</p><p>出去后先是找到导游，本来准备在机场办理一张当地的电话卡的，但是很不划算(比首都机场办卡和中国移动还贵)，后来比对了中国移动推出的无忧行app和支付宝的“境外上网”，价格相同，54RMB五天流量不限，所以就采用了支付宝的解决方案。</p><p>与我们一起同行的也是两对来度蜜月的情侣，都是北京本地人，人都很nice，很好相处，社交属性都很max的感觉:D。我们一行人在导游的导航下开了很久，到达离机场比较远的乌鲁瓦图(uluwatu)的酒店——Hillstone Uluwatu Villa。然后洗洗就睡了。</p><p>槽点：住宿虽是独立别墅，并没有想象中的好，唯一的亮点是院内的泳池，其他设施感觉很一般。</p><h3 id="day1"><a href="#day1" class="headerlink" title="day1"></a>day1</h3><p>早上睡到8点就自然醒了，收拾好后，床头放了5RMB的小费(这是必须的，这边的服务都是要收小费的，给大概5~10RMB小费就足够了)。早饭是吃的酒店的自助餐，味道一般，没有国内吃的习惯就是了。</p><p>11点出发去了情人崖。据说那里的小猴子很调皮，会抢游客的东西，如果被抢了东西，需要找当地的人帮忙，大概就是那种一物换一物的样子，也可能换不回来。所以，保护好自己的钱财啊，拍照的时候手机拿紧了。可能因为我们是中午到了，猴子们都比较懒洋洋的。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwb9686np9j23402c0qv7.jpg" alt="">情人崖</p><p>中午的午饭是在黄金咖啡工厂旁边的娘惹私房菜解决，饭馆里面基本都是中国人，问了导游，说本地人在饭店吃饭的很少。关于菜呢，做的虾不错，别的菜就可圈可点了，咖喱味确实吃不习惯。</p><p>我们没有在黄金工厂逗留，听导游说黄金工厂的猫屎咖啡100g大概800块钱(后来对这个导游所言及其不信任，此价格可信度不足5成)。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbh3q7rbej211a0sctd9.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbh408x0jj22c0340npf.jpg" alt="">娘惹私房菜</p><p>然后下一站直接去了金巴兰沙滩。路上听导游介绍了这里一个很奇葩的本地文化。印尼这边女性地位很低，男性地位很高，之前法律可以允许一个男人娶四个老婆，而且男人不干粗活，像搬砖砌瓦这种粗活都是女人来做，男人只多做雕刻等工作。路上有许多可供休息的小亭子，叫发呆亭，专门给男人发呆用的…这里的男人太幸福了…</p><p>我们2点左右到达金巴兰沙滩，首先是去玩一些水上项目，比如飞艇，滑翔伞等。滑翔伞没有想象的那么刺激，但是高度确实可以，看风景真的不错。玩过这些后，我们乘船去了海龟岛。海龟岛上最特色的是大量的海龟，被当地人群圈养着…我以为是沙滩上的，可能我还是太年轻。不止有海龟，还有各种鸟，蜥蜴，蟒蛇，大蝙蝠等…这个岛基本就是小型动物园的样子，不过好玩的是船停在岸边很远，因为还没到雨季的原因，我们沿着海边走了很久，一路上抓了不少寄居蟹和海螺。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj47lsqzj22c0340qva.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj36n4i1j22c0340kjn.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj3h9t4qj22c0340u0z.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbj3u80eaj22c03401l1.jpg" alt=""></p><p>玩到四五点我们又回到了金巴兰沙滩看日出，嗯，没错，金巴兰海滩——世界十大最美落日海滩之一。直接上图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjn0pcmlj23402c0kjn.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjmm2gtgj22c0340hdv.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbjma0f5bj23402c0u0y.jpg" alt=""></p><p>看着日落，吃着烧烤，金巴兰的玉米据说是必吃的，点了一个微辣，实际上也是很辣了，价格7块5RMB，果然景区很贵。这里的烧烤也是出奇的宰人啊，看了菜单，要想吃饱人均至少200+RMB，巴厘岛的人民也不老实啊。烧烤是旅行团提供了，每人一盘，一盘有三只虾，三串鱿鱼，一个螃蟹，一条鱼，啤酒一瓶。(画外音：想念我大中华的烧烤啤酒。)就这价格明显宰人，不能当傻子(怂了)，我们又去便利店看了看当地的人民都吃些什么。嗯，买了泡面和一些零食回去垫垫了…回酒店游了一圈就休息了。</p><h3 id="day2"><a href="#day2" class="headerlink" title="day2"></a>day2</h3><p>这是一个早起的上午，6点半就吃饭了，七点开始出发，今天的目的地是巴厘岛必玩景点之一——蓝梦岛，所以我们坐车先来到Pantai Mertasari，等到八点十几分左右坐上船开往蓝梦岛(Lembongan)。大概坐了四五十分钟左右的船(有点晕船的小伙伴最好准备好口香糖等缓解手段)，来到另一个船上，这个船上先玩一些水上项目，香蕉船，甜甜圈无限玩，玩到过瘾，浮潜，水上跳床等，还有水底漫步，很多热带鱼很好看。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwbkenk1d0j215e0vewhl.jpg" alt="">坐船路线</p><p>中文在蓝梦岛又是吃的自助餐，应该是最难吃的一顿饭了，如果不是饿的厉害，我可能得去买泡面了。</p><p>蓝梦岛最著名的景点是梦幻沙滩和恶魔的眼泪。当时我就想如果是自由行就好了，我一定会在蓝梦岛上住一晚，就住在梦幻沙滩这里。梦幻沙滩必须是住在那个酒店才能进去的。在恶魔的眼泪拍照一定要小心，因为我们是在旱季去的，水位不高，我看网上雨季的巴厘岛水位是可能冲上来的，据说每年能卷走一两百个游客。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwcrigz5rnj23402c0kjo.jpg" alt="">梦幻沙滩</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwcri5z4jxj23402c04qu.jpg" alt="">恶魔的眼泪</p><p>看完恶魔的眼泪，下午4点去做了当地的spa，给幸苦的一天画上一个舒服的句号。晚上的酒店是在库塔(kuta)区的 The Kuta Beach Heritage Hotel 酒店，对面就是库塔沙滩，这条街上基本都是酒吧，沙滩、啤酒与乐队，就会突然感觉很有电影里看到的那种氛围。晚上没事干就去酒店四层(顶层，巴厘岛没有什么高楼大厦，基本最高就四五层)大泳池游了一圈(弥补今夏未游泳之遗憾)。</p><h3 id="day3"><a href="#day3" class="headerlink" title="day3"></a>day3</h3><p>今天是自由行的第一天，我们在昨天晚上一起从飞猪上定了今天的行程(阿勇河漂流和悬崖秋千)，于是一大早便起，七点半吃了酒店的自助餐(吐槽一下，来巴厘岛这几天吃的最好吃的一顿)。八点多坐上了包的车，一路上用中午和师傅谈笑风生大约一个半小时左右，来到目的地，阿勇河漂流。不得不说阿勇河真的是适合团队活动，漂流的时间大概在两个小时左右，漂流是一定会全身湿透的(刚下水就湿透了)，所以要准备泳衣。河水并不深，不必担心掉下水溺水，水流有平缓和湍急之处，有的时候皮划艇还会卡在石头上…至于河里有没有蛇就不知道了，反正看到了树枝上有蛇还有蜥蜴…</p><p>午餐是一如既往的难吃，依旧是景点的自助餐。唯一能让我吃下去的就是依靠当地的辣酱了。</p><p>饭后直接去悬崖秋千。路上经过了一些雕刻和沉香店，下车瞧了瞧，由于并不懂行，并没有买。悬崖秋千，确实是有些刺激的(主要是因为司机路上告诉了我们之前都摔下去摔死的，我心里一直担心绳子会断…)。其次，论拍摄技巧的重要性，被老婆好好教育了一顿，惨痛，有时间一定要系统性学习一下拍摄。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9f6pn6ij23402c0e85.jpg" alt="">坐秋千</p><p>玩完之后又让师傅带着去了当地的一个猫屎咖啡工厂，看了猫屎咖啡的生产过程，尝了尝当地各种品种咖啡和饮料(免费的)，猫屎咖啡是需要付费的(25RMB)，而且喝起来感觉怪怪的，加了两袋白糖喝起来还行。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9jx5j4yj23402c04qr.jpg" alt="">十三种免费饮品</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9jju2tfj22c03407wj.jpg" alt="">制作中的猫屎咖啡豆</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9j92w3gj22c0340u0z.jpg" alt="">磨的猫屎豆</p><p>逛完猫屎咖啡工厂，下一站我们的选择是家乐福…总结一下，家乐福中可带的东西有手工香皂，猫屎咖啡(价格不贵)，当地泡面(难道不想和康师傅汤达人一较高低吗)，Max T奶茶(超级好喝)，Olay空气霜(国内价格的三分之一，这个牌子的基本价格都是国内的一半价格一下)，雕刻手工制品，养乐多才5块钱…总之我们满载而归。</p><h3 id="day4"><a href="#day4" class="headerlink" title="day4"></a>day4</h3><p>自由行的第二天，必须睡到自然醒(其实八点多就醒了)。9点吃了超好吃的早饭，和老婆去酒店对面的库塔沙滩走了走。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwg9vks2fhj23402c0u0z.jpg" alt=""></p><p>天气又好，浪又大，冲浪的人很多，忍不住的我也跃跃欲试，于是人生中第一次冲浪诞生于巴厘岛了。库塔沙滩旁边都是出租冲浪板和教学了，我和同行的游泳爱好者一起冲的，两个人45W印尼盾(大约一个人115RMB)，各有一个教练带着。tips，切记不要刚吃完饭去冲浪，会吐的。总的来说，冲浪真的是很爽就是了(被一浪一浪排在沙滩上)。</p><p>中午，是女人们的专场，巴厘岛当地的DFS。我们打了当地的出租车，号称蓝鸟(Blue Bird)，上车后听见师傅在听布鲁斯，便用我那蹩脚的英文跟司机师傅瞎侃说我也喜欢布鲁斯，我喜欢Jimi Hendrix。司机师傅表示认同，他说他有个自己的乐队，但平时排练比较少等等。。。</p><p>然而，聊的挺愉快，下车的时候就不愉快了。这儿的出租车挺黑的。我从谷歌地图上看司机带我们绕了个大圈，而且就算绕这个大圈，应该也就四五公里不到的路。下册的时候师傅打的表显示160000，合RMB 80块，这是北京的四五倍价格了。(回去的时候我们问了当地七座的私人车，五个人25就回去了。)</p><p>其次，到了目的地也没想象的那么愉快，因为这里的DFS比国内的贵，一件东西没买上。然后又去了家乐福，还是家乐福好啊，把昨天没上的东西再看看咯。</p><p>晚上又想去spa了，这里的spa毕竟很便宜。从大众点评上(巴厘岛大众点评是可以用的)看了离我们最近的有一个五星好评的“哈巴狗spa”，于是我们一路沿着酒吧街走过去，直到到达目的地后着实让我们失望了，原来是小作坊:)。由于这家spa位置有限以及时间原因问题，换了旁边一家小spa点按了一下全身按摩，感觉很一般，没啥手劲，但是我老婆说这家手劲刚好:)。</p><p>遇到一件很酷的事情，在路边的时候，几个老外在酒吧大声合唱起来，一听让人激动，原来是“英国国歌”：Oasis的Don’t Look Back in Anger。让人想到2005年曼城演唱会上的万人大合唱。</p><h3 id="day5"><a href="#day5" class="headerlink" title="day5"></a>day5</h3><p>早上出发的比较早，一大早就去了海神庙。海神庙的海浪很大…<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwij8zix0hj23402c0hdw.jpg" alt="">看不腻的海</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwij9g6btyj23402c0nph.jpg" alt="">浪花与帅男</p><p>中午那会儿又去了乌布皇宫和乌布市场。乌布皇宫，说是皇宫，但是真的好小啊，跟咱故宫比查太远了，没什么意思。有点意思的是乌布市场，这里能淘一些当地的手工工艺品，当然最需要也是最有意思的就是砍价了。(语言采用中西结合的技法，又不缺失肢体语言与计算器这种神奇的辅助，方能砍得合适的价格)。我自己的战利品是尤克里里一把(75RMB价格，真的很便宜了)。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijipl9l1j22c0340b2c.jpg" alt=""><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwiji66q0lj22c0340hdw.jpg" alt="">乌布市场街景(后面还有很大一片)</p><p>中午的午饭吃的是当地有名的脏鸭餐，说实话，味道一般。</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijhqn1r5j22c03401kz.jpg" alt="">脏鸭餐(确实是脏，能感受到上面的毛毛)</p><p>我们吃脏鸭餐的旁边就是Monkey Park，我们出门还碰到几个猴兄，给了一袋薯片一下就抢走了。。。<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwijmh5kp1j22c03407wk.jpg" alt=""></p><p>下午是休闲的下午茶时光(旅行社安排，对于我来说有点浪费时间)，我们来到 Benoa Bay 海湾这里的 Conard Bali酒店吃的下午茶。下午茶平淡无奇，但是这里的住宿是真的比之前住的好(超大泳池，几乎整个花园都是泳池，这里沙滩也好，还有飞艇等娱乐工具)，妈的，要是自己来一定住这里！</p><p><img src="https://ws1.sinaimg.cn/large/87faef88ly1fwjpo7vzuhj22c0340b2e.jpg" alt="">康纳德酒店泳池一角</p><p>晚上去了巴厘岛的洋人街，一听名字就知道很宰人，这里的手工制品比乌布市场的贵将近一半左右，以及商场里的一些品牌比国内的贵。洋人街不适合购物，可以选择去对面的库塔沙滩吹吹海风。</p><p>巴厘岛之行基本上就到这了，晚上我们很早就去了机场，大概11点办理完托运等，第一件事就是再去DFS(万恶的化妆品)再看看。最后1点半坐上回帝都的飞机了。再见，巴厘岛(登巴萨)。</p><h2 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h2><p>在巴厘岛待的时间不长，一共就5天5晚吧，说实话还是想再多玩几天的，还是有些遗憾的，只能暂时先列一下计划了以后再去补上~~：</p><ul><li>看海豚和海上日出</li><li>去火山和温泉</li><li>蓝梦岛住一晚，一定要冲一次梦幻沙滩的浪</li><li>吃一顿猪排饭</li><li>乌布多待两天</li><li>吉利三岛和龙目岛(脱离巴厘岛的范围了:))玩几天</li></ul><p>对巴厘岛印象最深刻的还是这里的交通，路又窄又弯又起伏，这里的摩托车是主要的交通工具，喜欢摩托车的朋友适合在这生活哈~：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fwo7f19fx6j22c0340u0y.jpg" alt=""></p><p>最后，还是想说一句：巴厘岛司机牛逼！巴厘岛司机世界第一！</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;过了一个漫长的假期，国庆节七天加上婚假十天，过的都不会上班了。蜜月之行的计划本来打算是去欧洲看看的，但是听说基本都是玩十二天左右，时间太长会很累，其次由于我们第一次出国，很多事情不是很懂，所以跟了个10.09-10.15的七天五晚的旅行团(有出国经验的话建议自由行)，遂主要记录在巴厘岛这几天的行程与游记。
    
    </summary>
    
      <category term="travel" scheme="https://www.chenruiwen.cn/categories/travel/"/>
    
    
      <category term="travel" scheme="https://www.chenruiwen.cn/tags/travel/"/>
    
      <category term="Bali" scheme="https://www.chenruiwen.cn/tags/Bali/"/>
    
  </entry>
  
  <entry>
    <title>《大型网站技术架构》知识总结</title>
    <link href="https://www.chenruiwen.cn/architecture/large-scale-websites-architecture-note/"/>
    <id>https://www.chenruiwen.cn/architecture/large-scale-websites-architecture-note/</id>
    <published>2018-09-23T15:10:24.000Z</published>
    <updated>2018-09-24T13:04:33.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>又把《大型网站技术架构-核心原理与案例分析》看了一遍，之前走马观花看了一遍，没有体会到精髓。现在具备一定“中型”网站开发经验后再看之，又有些体会，故整理一下这本书的内容。<a id="more"></a></p><h2 id="大型网站架构演化"><a href="#大型网站架构演化" class="headerlink" title="大型网站架构演化"></a>大型网站架构演化</h2><h3 id="大型网站软件的特点"><a href="#大型网站软件的特点" class="headerlink" title="大型网站软件的特点"></a>大型网站软件的特点</h3><ul><li>高并发、大流量</li><li>高可用</li><li>海量数据</li><li>用户分布广泛</li><li>安全环境恶劣</li><li>需求变更快，发布频繁</li><li>渐进式发展</li></ul><h3 id="大型网站架构演化发展历程"><a href="#大型网站架构演化发展历程" class="headerlink" title="大型网站架构演化发展历程"></a>大型网站架构演化发展历程</h3><ol><li><strong>初始阶段的网站架构</strong>：all in one，一台服务器，部署了应用程序，数据库，文件，等所有资源。比如经典的<code>LAMP</code>架构。</li><li><strong>应用和数据服务分离</strong>：应用程序，数据库，文件分别用了3台服务器部署。</li><li><strong>使用缓存改善网站性能</strong>：本地缓存+分布式缓存。</li><li><strong>使用应用服务器集群改善网站并发处理能力</strong>：通过负载均衡调度服务器来将访问请求分发到应用服务器集群中的任何一台机器。</li><li><strong>数据库读写分离</strong>：数据库采用主从热备，写数据在主数据库中，主数据库通过主从复制机制将数据更新同步到从数据库。读数据从从库读取。</li><li><strong>使用反向代理和 CDN 加速网站响应</strong>：这两者基本原理都是缓存。CDN 部署在网络提供商的机房，使用户可从离距离自己最近的提供商机房获取数据;反向代理部署在网站的中心机房，减轻后端负载压力，反向代理服务器命中的静态数据可直接返回。</li><li><strong>使用分布式文件系统和分布式数据库系统</strong>：数据库拆分的最后手段，解决单表特别大的情况。</li><li><strong>使用 NoSQL 和搜索引擎</strong>：对可伸缩的分布式有更好的支持。</li><li><strong>业务拆分</strong>：将整个网站业务拆分成不同的应用，每个应用独立部署维护，应用之间通过超链接建立联系/消息队列进行数据分发/访问同一数据存储系统</li><li><strong>分布式服务</strong>：公共业务提取出来独立部署</li></ol><p>大型网站演化到这里，大多数技术问题都得以解决，如图：<img src="https://ws1.sinaimg.cn/large/87faef88ly1fvjtco0bevj20r20e2mxf.jpg" alt=""></p><h3 id="大型网站架构演化的价值观"><a href="#大型网站架构演化的价值观" class="headerlink" title="大型网站架构演化的价值观"></a>大型网站架构演化的价值观</h3><ul><li>大型网站架构的核心价值是随网站所需灵活应对</li><li>驱动大型网站技术发展的主要力量是网站的业务发展</li></ul><h3 id="网站架构设计误区"><a href="#网站架构设计误区" class="headerlink" title="网站架构设计误区"></a>网站架构设计误区</h3><ul><li>一味追随大公司的解决方案</li><li>为了技术而技术</li><li>企图用技术解决所有问题</li></ul><h2 id="大型网站架构模式"><a href="#大型网站架构模式" class="headerlink" title="大型网站架构模式"></a>大型网站架构模式</h2><ul><li>分层:计算机世界无处不在，操作系统与硬件，网络七层，网站应用MVC分层。</li><li>分割：按业务分割</li><li>分布式：<ul><li>分布式应用和服务</li><li>分布式静态资源</li><li>分布式数据和存储</li><li>分布式计算</li></ul></li><li>集群</li><li>缓存：<ul><li>CDN</li><li>反向代理</li><li>本地缓存</li><li>分布式缓存</li></ul></li><li>异步：<ul><li>提供系统可用性</li><li>加快网站响应速度</li><li>消除高并发访问高峰</li></ul></li><li>冗余：服务器冗余运行，数据库冗余备份（冷热备份）</li><li>自动化：自动化代码管理；自动化发布；自动化测试；自动化安全检测；自动化部署；自动化监控；自动化报警；自动化失效转移；自动化失效恢复；自动化降级；自动化分配资源。</li><li>安全：防止XSS攻击、sql注入。</li></ul><h2 id="大型网站核心架构要素"><a href="#大型网站核心架构要素" class="headerlink" title="大型网站核心架构要素"></a>大型网站核心架构要素</h2><ul><li>性能<ol><li>浏览器端:浏览器缓存，页面压缩，合理布局页面，减少Cookie传输</li><li>CDN：静态内容分发到离用户最近的网络服务商机房。</li><li>应用服务器：缓存+异步。</li><li>代码层面：多线程+改善内存等手段优化。</li><li>数据库：索引，缓存，SQL优化等。</li></ol></li><li>可用性：只要手段是冗余<ol><li>应用服务器：负载均衡组成集群。</li><li>数据库：实时备份。</li><li>软件开发质量保证：预发布验证，自动化测试，自动化发布，灰度发布等。</li></ol></li><li>伸缩性：主要标准是是否可以构成集群，是否容易不断地向服务器集群加服务器<ol><li>应用服务器集群：负载均衡设备。</li><li>缓存服务器集群：改进缓存路由算法保证存储数据的可访问性。</li><li>数据库：路由分区等。</li><li>NoSQL数据库：先天良好支持。</li></ol></li><li>扩展性：指业务上是否可以少有改动快速上线。主要手段是事件驱动架构和分布式服务。<ol><li>事件驱动架构：通常用消息队列实现。</li><li>分布式服务：按业务和可复用性将服务分离。</li></ol></li><li>安全性：标准是针对现存和潜在的各种攻击和窃密手段，是否有可靠的应对策略。</li></ul><h2 id="瞬时响应：网站的高性能架构"><a href="#瞬时响应：网站的高性能架构" class="headerlink" title="瞬时响应：网站的高性能架构"></a>瞬时响应：网站的高性能架构</h2><h3 id="网站性能测试"><a href="#网站性能测试" class="headerlink" title="网站性能测试"></a>网站性能测试</h3><ul><li>不同视角下网站的性能 <ul><li>用户视角网站性能：响应时间。</li><li>开发人员视角的网站性能：响应时间、并发量、吞吐量。</li><li>运维人员视角的网站性能：资源。</li></ul></li><li>性能测试指标 <ul><li>响应时间：直观反映系统快慢。</li><li>并发数：反映系统负载特性。</li><li>吞吐量：反映系统整体处理能力。通过qps,tps,hps测量。</li><li>性能计数器：描述服务器或操作系统的数据指标。包括System Load、对象与线程数、内存使用、CPU使用、磁盘与网络I/O等指标。</li></ul></li><li>性能测试方法 <ul><li>性能测试：验证系统在资源可接受范围内。</li><li>负载测试：测试安全临界值。</li><li>压力测试：测试系统最大压力承受能力。</li><li>稳定性测试：模拟生产环境。</li></ul></li><li>性能测试报告</li><li>性能优化策略 <ul><li>性能分析：1.检测请求各环节日志，分析那个环节响应时间不合理。2.检查监控数据。</li><li>性能优化：<ul><li>Web前端性能优化</li><li>应用服务器性能优化</li><li>存储服务器性能优化</li></ul></li></ul></li></ul><h3 id="web前端性能优化"><a href="#web前端性能优化" class="headerlink" title="web前端性能优化"></a>web前端性能优化</h3><ul><li>浏览器访问优化 <ul><li>减少http请求</li><li>使用浏览器缓存</li><li>启用压缩</li><li>css放在网页最上面 js最下面</li><li>减少cookie传输</li></ul></li><li>CDN加速</li><li>反向代理：安全屏障；缓存静态和热点数据；负载均衡。</li></ul><h3 id="应用服务器性能优化"><a href="#应用服务器性能优化" class="headerlink" title="应用服务器性能优化"></a>应用服务器性能优化</h3><p>优化的主要手段还是：缓存，异步，集群。</p><ul><li>分布式缓存 <ul><li>缓存的基本原理</li><li>合理的使用缓存 <ul><li>频繁修改数据：读写比2：1以上缓存才有意义</li><li>没有热点的访问</li><li>数据不一致与脏读</li><li>缓存可用性</li><li>缓存预热</li><li>缓存穿透</li></ul></li><li>分布式缓存架构</li></ul></li><li>异步操作：削峰</li><li>使用集群</li><li>代码优化<ul><li>多线程：<ul><li>将对象设计为无状态对象</li><li>使用局部对象</li><li>并发访问资源加锁</li></ul></li><li>资源复用：单例和对象池</li><li>数据结构</li><li>垃圾回收</li></ul></li></ul><h3 id="存储性能优化"><a href="#存储性能优化" class="headerlink" title="存储性能优化"></a>存储性能优化</h3><ul><li>机械硬盘 vs. 固态硬盘</li><li>B+ 树 vs. LSM 树</li><li>RAID vs. HDFS</li></ul><h2 id="万无一失：网站的高可用架构"><a href="#万无一失：网站的高可用架构" class="headerlink" title="万无一失：网站的高可用架构"></a>万无一失：网站的高可用架构</h2><h3 id="网站可用性的度量和考核"><a href="#网站可用性的度量和考核" class="headerlink" title="网站可用性的度量和考核"></a>网站可用性的度量和考核</h3><ul><li>网站可行性度量<ul><li>网站不可用时间(故障时间) = 故障修复时间点 - 故障发现时间点</li><li>网站年度可用性指标 = (1 - 网站不可用时间/年度总时间) * 100%</li><li>2个9基本可用，3个9较高可用，4个9具有自动恢复能力的高可用，5个9是极高可用性</li></ul></li><li>网站可用性考核:故障分 = 故障时间 * 故障权重</li></ul><h3 id="高可用的网站架构"><a href="#高可用的网站架构" class="headerlink" title="高可用的网站架构"></a>高可用的网站架构</h3><p>分层+分割+集群</p><h3 id="高可用的应用"><a href="#高可用的应用" class="headerlink" title="高可用的应用"></a>高可用的应用</h3><ul><li>通过负载均衡进行无状态服务的失效转移</li><li>应用服务器集群的session管理 <ul><li>session复制：简单，适用于集群规模较小的情况</li><li>session绑定：粘性session</li><li>利用cookie记录 session：简单易用，可用性高，支持线性伸缩，但是每次响应都会传输cookie，影响性能。</li><li>session服务器：利用分布式缓存。</li></ul></li></ul><h3 id="高可用的应用-1"><a href="#高可用的应用-1" class="headerlink" title="高可用的应用"></a>高可用的应用</h3><ul><li>分级管理：核心应用与服务优先使用更好的硬件；部署上进行隔离。</li><li>超时设置</li><li>异步调用</li><li>服务降级：手段有二：拒绝服务及关闭服务。</li><li>幂等性设计：业务代码层面通过有效性校验等。 <h3 id="高可用的数据"><a href="#高可用的数据" class="headerlink" title="高可用的数据"></a>高可用的数据</h3></li><li>CAP原理 <ul><li>数据持久性</li><li>数据可访问性</li><li>数据一致性 <ul><li>数据强一致性</li><li>数据用户一致性</li><li>数据最终一致性</li></ul></li></ul></li><li>数据备份<ul><li>冷备:简单廉价，成本和技术难度低；但不能保证数据最终一致。恢复时间可能会长，一段时间不可用。</li><li>热备：同步和异步方式</li></ul></li><li>失效转移 <ul><li>失效确认</li><li>访问转移</li><li>数据恢复</li></ul></li></ul><h3 id="高可用软件质量保障"><a href="#高可用软件质量保障" class="headerlink" title="高可用软件质量保障"></a>高可用软件质量保障</h3><ul><li><p>网站发布：脚本发布，流程大致如下</p><ol><li>关闭负载均衡服务器上一台或一小批服务器路由</li><li>关闭这些服务器应用</li><li>同步(复制)软件代码包到这些服务器上</li><li>启动这些服务器</li><li>打开负载均衡服务器这些服务器的路由</li><li>集群所有机器发布完成？是则退出：否则继续1.</li></ol></li><li><p>自动化测试</p></li><li>预发布验证</li><li>代码控制 <ul><li>主干开发，分支发布</li><li>分支开发，主干发布</li></ul></li><li>自动化发布</li><li>灰度发布</li></ul><h3 id="网站运行监控"><a href="#网站运行监控" class="headerlink" title="网站运行监控"></a>网站运行监控</h3><ul><li>监控数据采集 <ul><li>用户行为日志收集</li><li>服务器性能检测</li><li>运行数据报告</li></ul></li><li>监控管理 <ul><li>系统报警</li><li>失效转移</li><li>自动优雅降级</li></ul></li></ul><h2 id="永无止尽：网站的伸缩性架构"><a href="#永无止尽：网站的伸缩性架构" class="headerlink" title="永无止尽：网站的伸缩性架构"></a>永无止尽：网站的伸缩性架构</h2><h3 id="网站伸缩性设计"><a href="#网站伸缩性设计" class="headerlink" title="网站伸缩性设计"></a>网站伸缩性设计</h3><ul><li>不同功能进行物理分离实现伸缩<ul><li>纵向分离(分层后分离)</li><li>横向分离(业务分割后分离)</li></ul></li><li>单一功能通过集群实现伸缩</li></ul><h3 id="应用服务器集群伸缩设计"><a href="#应用服务器集群伸缩设计" class="headerlink" title="应用服务器集群伸缩设计"></a>应用服务器集群伸缩设计</h3><ul><li>http重定向负载均衡：简单，但是浏览器需要两次请求服务器。</li><li>Dns域名解析负载均衡：省掉了管理运维负载均衡服务器的麻烦，能支持基于地理位置的域名解析加速访问；但是生效时间较长，以及无法做更多改善和更强大的管理。</li><li>反向代理负载均衡：发生在http协议层，也叫应用层负载均衡。</li><li>ip负载均衡：发生在网络层，修改请求目标地址进行负载均衡。</li><li>数据链路层负载均衡：发生在通信协议的数据链路层，通过修改mac地址进行负载均衡。广泛使用的一种方式，比如：LVS(Linux Virtual Server)</li><li>负载均衡算法 <ul><li>轮询</li><li>加权轮询</li><li>随机</li><li>最少链接</li><li>源地址散列</li></ul></li></ul><h3 id="分布式缓存集群的伸缩性设计"><a href="#分布式缓存集群的伸缩性设计" class="headerlink" title="分布式缓存集群的伸缩性设计"></a>分布式缓存集群的伸缩性设计</h3><ul><li>Memcached分布式缓存集群的访问模型</li><li>Memcached分布式缓存集群的伸缩性挑战</li><li>分布式缓存的一致性hash算法</li></ul><h3 id="数据存储服务器集群的伸缩性设计"><a href="#数据存储服务器集群的伸缩性设计" class="headerlink" title="数据存储服务器集群的伸缩性设计"></a>数据存储服务器集群的伸缩性设计</h3><ul><li>关系数据库集群的伸缩性设计：从业务上回避分布式关系型数据库的各种缺点：避免事务或利用事务补偿机制代替数据库事务；避免JOIN操作等。</li><li>Nosql数据库的伸缩性设计</li></ul><h2 id="随机应变：网站的可扩展性架构"><a href="#随机应变：网站的可扩展性架构" class="headerlink" title="随机应变：网站的可扩展性架构"></a>随机应变：网站的可扩展性架构</h2><h3 id="构建可扩展性的网站架构"><a href="#构建可扩展性的网站架构" class="headerlink" title="构建可扩展性的网站架构"></a>构建可扩展性的网站架构</h3><p>软件架构师的最大价值不在于掌握多少先进的技术，而在于具有将一个大系统切分层N个低耦合的子模块的能力，这些子模块包含横向的业务模块，也包含纵向的基础技术模块。</p><h3 id="利用分布式消息队列降低系统耦合性"><a href="#利用分布式消息队列降低系统耦合性" class="headerlink" title="利用分布式消息队列降低系统耦合性"></a>利用分布式消息队列降低系统耦合性</h3><ul><li>事件驱动架构</li><li>分布式消息队列</li></ul><h3 id="利用分布式服务打造可复用的业务平台"><a href="#利用分布式服务打造可复用的业务平台" class="headerlink" title="利用分布式服务打造可复用的业务平台"></a>利用分布式服务打造可复用的业务平台</h3><ul><li>web service与企业级分布式服务：缺点有臃肿的注册和发现机制，抵消的XML序列化手段，开销相对较高的HTTP远程通信，复杂的部署与维护手段。</li><li>大型网站分布式服务的需求与特点 <ul><li>负载均衡</li><li>失效转移</li><li>高效的远程通信</li><li>整合异构系统</li><li>对应用最少侵入</li><li>版本控制</li><li>实时监控</li></ul></li><li>分布式服务框架设计</li></ul><h3 id="可扩展的数据结构"><a href="#可扩展的数据结构" class="headerlink" title="可扩展的数据结构"></a>可扩展的数据结构</h3><p>利用NoSQL的ColumnFamily(列族)设计。</p><h3 id="利用开放平台建设网站生态圈"><a href="#利用开放平台建设网站生态圈" class="headerlink" title="利用开放平台建设网站生态圈"></a>利用开放平台建设网站生态圈</h3><ul><li>api接口</li><li>协议转移</li><li>安全</li><li>审计</li><li>路由</li><li>流程</li></ul><h2 id="固若金汤：网站的安全架构"><a href="#固若金汤：网站的安全架构" class="headerlink" title="固若金汤：网站的安全架构"></a>固若金汤：网站的安全架构</h2><h3 id="道高一尺魔高一丈的网站应用攻击与防御"><a href="#道高一尺魔高一丈的网站应用攻击与防御" class="headerlink" title="道高一尺魔高一丈的网站应用攻击与防御"></a>道高一尺魔高一丈的网站应用攻击与防御</h3><p>全球70%的web攻击来自XSS攻击和SQL注入。</p><ul><li>xss攻击 <ul><li>消毒：转移html字符</li><li>httponly：避免攻击脚本窃取</li></ul></li><li>注入攻击 <ul><li>开源</li><li>错误回显</li><li>盲注</li><li>消毒</li><li>参数绑定</li></ul></li><li>csrf攻击：防御的主要手段是识别访问者身份。<ul><li>表单token</li><li>验证码</li><li>referer check</li></ul></li><li>其他攻击和漏洞 <ul><li>error code</li><li>html注释</li><li>文件上传</li><li>路径遍历</li></ul></li><li>web应用防火墙</li><li>网站安全漏洞扫描</li></ul><h3 id="信息加密技术及密钥安全管理"><a href="#信息加密技术及密钥安全管理" class="headerlink" title="信息加密技术及密钥安全管理"></a>信息加密技术及密钥安全管理</h3><ul><li>单向散列加密：MD5,SHA等</li><li>对称加密：DES,RC等</li><li>非对称加密：RSA等</li><li>密钥安全管理</li></ul><h3 id="信息过滤与反垃圾"><a href="#信息过滤与反垃圾" class="headerlink" title="信息过滤与反垃圾"></a>信息过滤与反垃圾</h3><ul><li>文本匹配<ul><li>正则表达式匹配：适用于敏感词较少</li><li>Trie树、双数组Trie树：时间和空间复杂度都较好</li><li>多级hash表：速度较快，但浪费部分空间</li></ul></li><li>分类算法：朴素贝叶斯算法。</li><li>黑名单：布隆过滤器。</li></ul><h3 id="电子商务风险控制"><a href="#电子商务风险控制" class="headerlink" title="电子商务风险控制"></a>电子商务风险控制</h3><ul><li>风险 <ul><li>账号风险</li><li>买家风险</li><li>卖家风险</li><li>交易风险</li></ul></li><li>风控<ul><li>规则引擎</li><li>统计模型</li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>大致总结了李智慧老师的<a href="https://book.douban.com/subject/25723064/" target="_blank" rel="noopener">《大型网站技术架构——核心原理与案例分析》</a>一书中的部分知识点的原理部分，又重新加深了架构演进的过程。建议还是需要购买原书看一看。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;又把《大型网站技术架构-核心原理与案例分析》看了一遍，之前走马观花看了一遍，没有体会到精髓。现在具备一定“中型”网站开发经验后再看之，又有些体会，故整理一下这本书的内容。
    
    </summary>
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/categories/architecture/"/>
    
    
      <category term="architecture" scheme="https://www.chenruiwen.cn/tags/architecture/"/>
    
      <category term="read notes" scheme="https://www.chenruiwen.cn/tags/read-notes/"/>
    
  </entry>
  
</feed>
