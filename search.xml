<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Dubbo路由层之Directory]]></title>
    <url>%2Fdubbo%2Fdubbo-cluster-Directory%2F</url>
    <content type="text"><![CDATA[前言在Dubbo服务引用之ReferenceConfig中看到在引用协议订阅远程服务的过程中涉及到这么一个接口Directory。这个东东是做什么的呢？ 回顾时序图 之前说到了拿到引用配置ReferenceConfig类，并且调用了RegistryProtocol的refer方法，接下来在手撕源码前，先超前的看看后面还要经历哪些环节：Directory,Cluster,Protocol,Invoker。。。(省略)。到这里可以根据源码结构找到关键的接口Directory,Cluster，这俩都是dubbo-cluster下的接口，一起理解会比较方便，在细嚼源码前看看开发者文档有没有给我们一些帮助。 可以找到官网介绍图： 从图中大致了解到各个接口的作用，今天要分析的Directory主要作用是服务目录列表。 Directory看下接口设计： public interface Directory&lt;T&gt; extends Node { /** * get service type. * * @return service type. */ Class&lt;T&gt; getInterface(); /** * list invokers. * * @return invokers */ List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException; } 就俩方法： 获取服务类型 获取invoker列表 看一下其实现的子类： 再结合官网介绍图可知主要实现有StaticDirectory,RegistryDirectory。模板类是AbstractDirectory. AbstractDirectory看名便知，提供了抽象的Directory实现，也是模板方法模式的体现。 doList方法交由具体的子类实现。父类(即此类)实现了模板方法list。 list方法： public List&lt;Invoker&lt;T&gt;&gt; list(Invocation invocation) throws RpcException { if (destroyed) { throw new RpcException(&quot;Directory already destroyed .url: &quot; + getUrl()); } // 从子类的实现中获取调用者列表 List&lt;Invoker&lt;T&gt;&gt; invokers = doList(invocation); List&lt;Router&gt; localRouters = this.routers; // local reference // 路由过滤，获取匹配的调用者列表 if (localRouters != null &amp;&amp; !localRouters.isEmpty()) { for (Router router : localRouters) { try { if (router.getUrl() == null || router.getUrl().getParameter(Constants.RUNTIME_KEY, false)) { invokers = router.route(invokers, getConsumerUrl(), invocation); } } catch (Throwable t) { logger.error(&quot;Failed to execute router: &quot; + getUrl() + &quot;, cause: &quot; + t.getMessage(), t); } } } return invokers; } 可见主要作用就是找到真的匹配的invoker列表。 此处涉及接口Router，之后分析。 StaticDirectory主要还是看doList的实现，这是区分不同Directory的根本方法。 StaticDirectory#doList: @Override protected List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) throws RpcException { return invokers; } 惊不惊喜？意不意外？没错，就是这么简单，因此也和这个实现的名称也想对应了，“静态的服务目录”，调用者列表不会动态改变。它的invokers主要还是通过构造器传入： public StaticDirectory(URL url, List&lt;Invoker&lt;T&gt;&gt; invokers, List&lt;Router&gt; routers) { super(url == null &amp;&amp; invokers != null &amp;&amp; !invokers.isEmpty() ? invokers.get(0).getUrl() : url, routers); if (invokers == null || invokers.isEmpty()) throw new IllegalArgumentException(&quot;invokers == null&quot;); this.invokers = invokers; } 此类的应用本人才疏学浅，暂时没有看到，存在即合理，之后看到再补充吧。 RegistryDirectory这个子类实现应该是应用最广泛的一个了。 RegistryDirectory#doList: public List&lt;Invoker&lt;T&gt;&gt; doList(Invocation invocation) { if (forbidden) { // 下面这个异常简直不要太熟悉了 // 1. No service provider 2. Service providers are disabled throw new RpcException(RpcException.FORBIDDEN_EXCEPTION, &quot;No provider available from registry &quot; + getUrl().getAddress() + &quot; for service &quot; + getConsumerUrl().getServiceKey() + &quot; on consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please check status of providers(disabled, not registered or in blacklist).&quot;); } List&lt;Invoker&lt;T&gt;&gt; invokers = null; Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; localMethodInvokerMap = this.methodInvokerMap; // local reference if (localMethodInvokerMap != null &amp;&amp; localMethodInvokerMap.size() &gt; 0) { String methodName = RpcUtils.getMethodName(invocation); // 获取服务提供者方法名称 Object[] args = RpcUtils.getArguments(invocation); // 获取调用参数 if (args != null &amp;&amp; args.length &gt; 0 &amp;&amp; args[0] != null &amp;&amp; (args[0] instanceof String || args[0].getClass().isEnum())) { invokers = localMethodInvokerMap.get(methodName + &quot;.&quot; + args[0]); // The routing can be enumerated according to the first parameter } if (invokers == null) { invokers = localMethodInvokerMap.get(methodName); } if (invokers == null) { invokers = localMethodInvokerMap.get(Constants.ANY_VALUE); } if (invokers == null) { Iterator&lt;List&lt;Invoker&lt;T&gt;&gt;&gt; iterator = localMethodInvokerMap.values().iterator(); if (iterator.hasNext()) { invokers = iterator.next(); } } } return invokers == null ? new ArrayList&lt;Invoker&lt;T&gt;&gt;(0) : invokers; } 工作流程： 可以看到主要是从methodInvokerMap中获取。 先尝试从map中获取key为方法名.参数0的invokers，没找到再尝试从map中获取key为方法名的invokers。没找到再尝试从map中获取key为*的invokers。都找不到就遍历map找到最后的一个invokers。 那么问题来了，获取invokers是从methodInvokerMap中获取，那么methodInvokerMap是怎么来的呢。 借助IDE找到methodInvokerMap的赋值处，是在refreshInvoker方法中。refreshInvoker又是在notify方法里调用。现在问题来了，notify方法何时何地调用？ 我们可以注意到: public class RegistryDirectory&lt;T&gt; extends AbstractDirectory&lt;T&gt; implements NotifyListener`。 RegistryDirectory实现了NotifyListener，并实现了notify方法。方便起见，利用IDE生成一个类图: 关于在哪里调用又借助一下IDE： 可以确定的是在注册服务处调用的，这里先不细看。 到这里再细看一下notify方法: public synchronized void notify(List&lt;URL&gt; urls) { List&lt;URL&gt; invokerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; routerUrls = new ArrayList&lt;URL&gt;(); List&lt;URL&gt; configuratorUrls = new ArrayList&lt;URL&gt;(); for (URL url : urls) { String protocol = url.getProtocol(); String category = url.getParameter(Constants.CATEGORY_KEY, Constants.DEFAULT_CATEGORY); if (Constants.ROUTERS_CATEGORY.equals(category) || Constants.ROUTE_PROTOCOL.equals(protocol)) { routerUrls.add(url); } else if (Constants.CONFIGURATORS_CATEGORY.equals(category) || Constants.OVERRIDE_PROTOCOL.equals(protocol)) { configuratorUrls.add(url); } else if (Constants.PROVIDERS_CATEGORY.equals(category)) { invokerUrls.add(url); } else { logger.warn(&quot;Unsupported category &quot; + category + &quot; in notified url: &quot; + url + &quot; from registry &quot; + getUrl().getAddress() + &quot; to consumer &quot; + NetUtils.getLocalHost()); } } // configurators if (configuratorUrls != null &amp;&amp; !configuratorUrls.isEmpty()) { this.configurators = toConfigurators(configuratorUrls); } // routers if (routerUrls != null &amp;&amp; !routerUrls.isEmpty()) { List&lt;Router&gt; routers = toRouters(routerUrls); if (routers != null) { // null - do nothing setRouters(routers); } } List&lt;Configurator&gt; localConfigurators = this.configurators; // local reference // merge override parameters this.overrideDirectoryUrl = directoryUrl; if (localConfigurators != null &amp;&amp; !localConfigurators.isEmpty()) { for (Configurator configurator : localConfigurators) { this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl); } } // providers refreshInvoker(invokerUrls); } private void refreshInvoker(List&lt;URL&gt; invokerUrls) { // 清除不存在注册中心的数据 if (invokerUrls != null &amp;&amp; invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) { // 空协议禁止访问 this.forbidden = true; // Forbid to access this.methodInvokerMap = null; // Set the method invoker map to null destroyAllInvokers(); // Close all invokers } else { this.forbidden = false; // Allow to access Map&lt;String, Invoker&lt;T&gt;&gt; oldUrlInvokerMap = this.urlInvokerMap; // local reference // invokerUrls为空，因为通知的url可能只改变了router或者configurator，提供者并没有变化，但是对应invoker配置还是需要被更改的 if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) { invokerUrls.addAll(this.cachedInvokerUrls); // 使用缓存的url } else { // 更新缓存 this.cachedInvokerUrls = new HashSet&lt;URL&gt;(); this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison } if (invokerUrls.isEmpty()) { return; } Map&lt;String, Invoker&lt;T&gt;&gt; newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map Map&lt;String, List&lt;Invoker&lt;T&gt;&gt;&gt; newMethodInvokerMap = toMethodInvokers(newUrlInvokerMap); // Change method name to map Invoker Map // state change // If the calculation is wrong, it is not processed. if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) { logger.error(new IllegalStateException(&quot;urls to invokers error .invokerUrls.size :&quot; + invokerUrls.size() + &quot;, invoker.size :0. urls :&quot; + invokerUrls.toString())); return; } // 是否存在group？是则对method对应的invoker进行cluster伪装 this.methodInvokerMap = multiGroup ? toMergeMethodInvokerMap(newMethodInvokerMap) : newMethodInvokerMap; this.urlInvokerMap = newUrlInvokerMap; try { destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker } catch (Exception e) { logger.warn(&quot;destroyUnusedInvokers error. &quot;, e); } } } notify方法主要就是对url进行分类处理，分为provider，configurators，routers三类url。然后再使用provider类的url调用refreshInvoker进行增量刷新. refreshInvoker主要根据url协议过滤不匹配的提供者url，然后对过滤后的提供者url生成远程对等调用invoker，并且这些invoker会利用缓存防止重复创建。 总结到这里，基本Directory的核心方法都已经研究完，尤其是RegistryDirectory，它涉及动态更新invokerUrls，核心在于注册中心的通知与监听。dubbo的路由层还有Cluster,Router以及LoadBalance。留到明天再看！不知不觉已经凌晨，一看源码就容易上头哈~]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo服务引用之ReferenceConfig]]></title>
    <url>%2Fdubbo%2Fdubbo-ReferenceConfig%2F</url>
    <content type="text"><![CDATA[前言开启RTFSC之旅，先拾起来之前未完成的Dubbo源码解析。Dubbo自今年夏天开始也是变化很大，github上的官方文档也变化了不少次，现在来看也是非常的美观了。话不多说，今天研究一下Dubbo引用服务。 开局一张图老规矩，从文档入手，看看官网介绍。 ps:一图千言 和Dubbo服务调用过程一样，其非常重要的还是Invoker 从图可见，服务调用过程大概经历这两步: 把引用配置(ReferenceConfig)转化为Invoker实例 再把Invoker实例转化为客户端需要的接口代理对象 再补一张时序图： ReferenceConfig准备工作，先启动服务提供者，我们将dubbo-demo模块下的dubbo-demo-provider启动起来即可。 第一个断点打在哪，文档以及告诉你了。即ReferenceConfig类的init方法，重点则是调用Protocol的refer方法。 代码片段分析，直击init方法: private void init() { // 省略代码，判断是否已初始化过 // get consumer&#39;s global configuration checkDefault(); appendProperties(this); // 添加config 配置属性(根据xml或者java bean) // 省略代码，获取到 interfaceClass 以及 检察其属性 String resolve = System.getProperty(interfaceName); String resolveFile = null; if (resolve == null || resolve.length() == 0) { resolveFile = System.getProperty(&quot;dubbo.resolve.file&quot;); // resolveFile 映射路径文件，通常用于开发直连调试 if (resolveFile == null || resolveFile.length() == 0) { File userResolveFile = new File(new File(System.getProperty(&quot;user.home&quot;)), &quot;dubbo-resolve.properties&quot;); // 默认加载 ${user.home}/dubbo-resolve.properties if (userResolveFile.exists()) { resolveFile = userResolveFile.getAbsolutePath(); } } if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) { Properties properties = new Properties(); FileInputStream fis = null; try { fis = new FileInputStream(new File(resolveFile)); properties.load(fis); } catch (IOException e) { throw new IllegalStateException(&quot;Unload &quot; + resolveFile + &quot;, cause: &quot; + e.getMessage(), e); } finally { try { if (null != fis) fis.close(); } catch (IOException e) { logger.warn(e.getMessage(), e); } } resolve = properties.getProperty(interfaceName); // 获取接口的直连地址 } } if (resolve != null &amp;&amp; resolve.length() &gt; 0) { url = resolve; if (logger.isWarnEnabled()) { if (resolveFile != null &amp;&amp; resolveFile.length() &gt; 0) { logger.warn(&quot;Using default dubbo resolve file &quot; + resolveFile + &quot; replace &quot; + interfaceName + &quot;&quot; + resolve + &quot; to p2p invoke remote service.&quot;); } else { logger.warn(&quot;Using -D&quot; + interfaceName + &quot;=&quot; + resolve + &quot; to p2p invoke remote service.&quot;); } } } // 获取 应用配置，模块配置，注册中心(多个)配置，监控配置 if (consumer != null) { if (application == null) { application = consumer.getApplication(); } if (module == null) { module = consumer.getModule(); } if (registries == null) { registries = consumer.getRegistries(); } if (monitor == null) { monitor = consumer.getMonitor(); } } if (module != null) { if (registries == null) { registries = module.getRegistries(); } if (monitor == null) { monitor = module.getMonitor(); } } if (application != null) { if (registries == null) { registries = application.getRegistries(); } if (monitor == null) { monitor = application.getMonitor(); } } checkApplication(); checkStubAndMock(interfaceClass); // 添加调用信息，用于封装为invoker，side=consumer,dubbo=2.0.0,timestamp=xxxxx,pid=xxx Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Map&lt;Object, Object&gt; attributes = new HashMap&lt;Object, Object&gt;(); map.put(Constants.SIDE_KEY, Constants.CONSUMER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) { map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); } if (!isGeneric()) { String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) { map.put(&quot;revision&quot;, revision); } String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) { logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName()); map.put(&quot;methods&quot;, Constants.ANY_VALUE); } else { map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;)); } } map.put(Constants.INTERFACE_KEY, interfaceName); appendParameters(map, application); appendParameters(map, module); appendParameters(map, consumer, Constants.DEFAULT_KEY); appendParameters(map, this); String prefix = StringUtils.getServiceKey(map); if (methods != null &amp;&amp; !methods.isEmpty()) { for (MethodConfig method : methods) { appendParameters(map, method, method.getName()); String retryKey = method.getName() + &quot;.retry&quot;; if (map.containsKey(retryKey)) { String retryValue = map.remove(retryKey); if (&quot;false&quot;.equals(retryValue)) { map.put(method.getName() + &quot;.retries&quot;, &quot;0&quot;); } } appendAttributes(attributes, method, prefix + &quot;.&quot; + method.getName()); checkAndConvertImplicitConfig(method, map, attributes); } } String hostToRegistry = ConfigUtils.getSystemProperty(Constants.DUBBO_IP_TO_REGISTRY); if (hostToRegistry == null || hostToRegistry.length() == 0) { hostToRegistry = NetUtils.getLocalHost(); } else if (isInvalidLocalHost(hostToRegistry)) { throw new IllegalArgumentException(&quot;Specified invalid registry ip from property:&quot; + Constants.DUBBO_IP_TO_REGISTRY + &quot;, value:&quot; + hostToRegistry); } map.put(Constants.REGISTER_IP_KEY, hostToRegistry); //attributes are stored by system context. StaticContext.getSystemContext().putAll(attributes); ref = createProxy(map); ConsumerModel consumerModel = new ConsumerModel(getUniqueServiceName(), this, ref, interfaceClass.getMethods()); ApplicationModel.initConsumerModel(getUniqueServiceName(), consumerModel); // 实际将消费者模块放入缓存中 } 初始化过程: 获取消费者配置并初始赋值。 获取接口类并检查配置中的 interface 属性 和 methods属性。 获取resolveFile映射路径文件，如果文件存则获取属性将接口的值赋给url属性用于直连使用。(不存在则url属性为null) 获取应用配置，模块配置，注册中心(多个)配置。 添加接口调用信息，用于封装为Invoker 创建引用代理(T createProxy(Map&lt;String, String&gt; map))。 创建引用代理过程: private T createProxy(Map&lt;String, String&gt; map) { URL tmpUrl = new URL(&quot;temp&quot;, &quot;localhost&quot;, 0, map); // 初始化url temp://localhost?xxx=xxx // 判断是否是内部调用 final boolean isJvmRefer; if (isInjvm() == null) { if (url != null &amp;&amp; url.length() &gt; 0) { // if a url is specified, don&#39;t do local reference isJvmRefer = false; } else if (InjvmProtocol.getInjvmProtocol().isInjvmRefer(tmpUrl)) { // by default, reference local service if there is isJvmRefer = true; } else { isJvmRefer = false; } } else { isJvmRefer = isInjvm().booleanValue(); } if (isJvmRefer) { URL url = new URL(Constants.LOCAL_PROTOCOL, NetUtils.LOCALHOST, 0, interfaceClass.getName()).addParameters(map); invoker = refprotocol.refer(interfaceClass, url); if (logger.isInfoEnabled()) { logger.info(&quot;Using injvm service &quot; + interfaceClass.getName()); } } else { // 是否是点对点调用（之前的resolveFile配置和获取） if (url != null &amp;&amp; url.length() &gt; 0) { // user specified URL, could be peer-to-peer address, or register center&#39;s address. String[] us = Constants.SEMICOLON_SPLIT_PATTERN.split(url); if (us != null &amp;&amp; us.length &gt; 0) { for (String u : us) { URL url = URL.valueOf(u); if (url.getPath() == null || url.getPath().length() == 0) { url = url.setPath(interfaceName); } if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { urls.add(url.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } else { urls.add(ClusterUtils.mergeUrl(url, map)); } } } } else { // assemble URL from register center&#39;s configuration List&lt;URL&gt; us = loadRegistries(false); // 加载注册中心列表 if (us != null &amp;&amp; !us.isEmpty()) { for (URL u : us) { URL monitorUrl = loadMonitor(u); if (monitorUrl != null) { map.put(Constants.MONITOR_KEY, URL.encode(monitorUrl.toFullString())); } urls.add(u.addParameterAndEncoded(Constants.REFER_KEY, StringUtils.toQueryString(map))); } } if (urls == null || urls.isEmpty()) { throw new IllegalStateException(&quot;No such any registry to reference &quot; + interfaceName + &quot; on the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion() + &quot;, please config &lt;dubbo:registry address=\&quot;...\&quot; /&gt; to your spring config.&quot;); } } if (urls.size() == 1) { invoker = refprotocol.refer(interfaceClass, urls.get(0)); } else { List&lt;Invoker&lt;?&gt;&gt; invokers = new ArrayList&lt;Invoker&lt;?&gt;&gt;(); URL registryURL = null; for (URL url : urls) { invokers.add(refprotocol.refer(interfaceClass, url)); if (Constants.REGISTRY_PROTOCOL.equals(url.getProtocol())) { registryURL = url; // use last registry url } } if (registryURL != null) { // registry url is available // use AvailableCluster only when register&#39;s cluster is available URL u = registryURL.addParameter(Constants.CLUSTER_KEY, AvailableCluster.NAME); invoker = cluster.join(new StaticDirectory(u, invokers)); } else { // not a registry url invoker = cluster.join(new StaticDirectory(invokers)); } } } Boolean c = check; if (c == null &amp;&amp; consumer != null) { c = consumer.isCheck(); } if (c == null) { c = true; // default true } if (c &amp;&amp; !invoker.isAvailable()) { throw new IllegalStateException(&quot;Failed to check the status of the service &quot; + interfaceName + &quot;. No provider available for the service &quot; + (group == null ? &quot;&quot; : group + &quot;/&quot;) + interfaceName + (version == null ? &quot;&quot; : &quot;:&quot; + version) + &quot; from the url &quot; + invoker.getUrl() + &quot; to the consumer &quot; + NetUtils.getLocalHost() + &quot; use dubbo version &quot; + Version.getVersion()); } if (logger.isInfoEnabled()) { logger.info(&quot;Refer dubbo service &quot; + interfaceClass.getName() + &quot; from url &quot; + invoker.getUrl()); } // create service proxy return (T) proxyFactory.getProxy(invoker); } 步骤： 判断是否是内部调用，如果是内部调用，则创建一个内部调用Invoker。比如：injvm://127.0.0.1/interfaceClass?xxx=xxx&amp;xxx=xxx 判断是否是点对点调用，即通过之前resolveFile文件获取到的映射地址。如果有则执行点对点直连调用。 如果以上都不是，则加载注册中心url(多个)，获取到注册中心url并赋值属性refer=之前的接口调用url。 注册中心url如果是单个，则直接通过扩展点机制，引用的协议获取此url的Invoker对象。 注册中心url如果是多个，生成多个Invoker对象，遍历urls获取最后一个registryURL。如果registryURL不为null,则有注册中心，用 AvailableCluster获取invoker对象。 创建服务代理。(这一步之前有介绍过，实际为JavassistProxyFactory.getInvoker通过字节码获取代理对象。) 关于获取Invoker对象，代码里是这么获取的: invoker = refprotocol.refer(interfaceClass, urls.get(0)); 这里的refprotocol又是扩展点机制，在上面这个例子里，他的实现是RegistryProtocol. public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { // 设置url中的协议，将 registry 换为url中的registry属性，默认为dubbo url = url.setProtocol(url.getParameter(Constants.REGISTRY_KEY, Constants.DEFAULT_REGISTRY)).removeParameter(Constants.REGISTRY_KEY); Registry registry = registryFactory.getRegistry(url); if (RegistryService.class.equals(type)) { return proxyFactory.getInvoker((T) registry, type, url); } // group=&quot;a,b&quot; or group=&quot;*&quot; Map&lt;String, String&gt; qs = StringUtils.parseQueryString(url.getParameterAndDecoded(Constants.REFER_KEY)); String group = qs.get(Constants.GROUP_KEY); if (group != null &amp;&amp; group.length() &gt; 0) { if ((Constants.COMMA_SPLIT_PATTERN.split(group)).length &gt; 1 || &quot;*&quot;.equals(group)) { return doRefer(getMergeableCluster(), registry, type, url); } } return doRefer(cluster, registry, type, url); } private &lt;T&gt; Invoker&lt;T&gt; doRefer(Cluster cluster, Registry registry, Class&lt;T&gt; type, URL url) { RegistryDirectory&lt;T&gt; directory = new RegistryDirectory&lt;T&gt;(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String&gt; parameters = new HashMap&lt;String, String&gt;(directory.getUrl().getParameters()); URL subscribeUrl = new URL(Constants.CONSUMER_PROTOCOL, parameters.remove(Constants.REGISTER_IP_KEY), 0, type.getName(), parameters); if (!Constants.ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(Constants.REGISTER_KEY, true)) { registry.register(subscribeUrl.addParameters(Constants.CATEGORY_KEY, Constants.CONSUMERS_CATEGORY, Constants.CHECK_KEY, String.valueOf(false))); } directory.subscribe(subscribeUrl.addParameter(Constants.CATEGORY_KEY, Constants.PROVIDERS_CATEGORY + &quot;,&quot; + Constants.CONFIGURATORS_CATEGORY + &quot;,&quot; + Constants.ROUTERS_CATEGORY)); Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; } 这里的实现涉及的一些内容： 获取Registry对象 Directory接口 向注册中心注册。比如本例的ZookeeperRegistry 服务订阅 cluster集群容错 这里暂时不解释这么多，明天接着按顺序看。 总结看了下Dubbo的ReferenceConfig的源码，更深刻体会了那句话:满眼都是Invoker。 除此之外，还有很多重要的接口需要理解，比如Directory接口… to be contine…]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的反思录]]></title>
    <url>%2Fessay%2Fmy-rethink-on-2018%2F</url>
    <content type="text"><![CDATA[前言眼瞅着2018要过去了，这一年是有不少收获，但是感觉和自己的计划还有一些差距，简而言之就是没有达到自己的目标。 这是一件糟糕的事情，加上已经很久没有写博客了，真的感觉状态不太对，总结一下吧。 回忆问题出在哪有哪些问题呢？ 地铁上耗费的时间太长。 突然的加班导致加班前的正常学习状态被打破。也就是说学习不连贯。 加班耗费了太多精力，回家就想躺下睡大觉。 焦虑于未完成的事情。 分析问题看似问题简单，根本原因是时间，然后又巧妙的甩锅给加班。然而真的是这样的吗？ 我看来，根本原因可能是拖延症，或者说是自己的懒。 解决问题的方法基本就是如何解决掉自己懒的特性。 地铁上的时间可以用来看一下书籍。 加班问题，其实也没有加班到特别晚过，至少还能留有1小时的时间。 加班耗费精力的问题，主要还是要集中解决一下效率问题，效率高了就节约加班时间甚至于不用加班。如何提高效率，在日常工作中尽量多的积累工具经验，写优秀简洁的代码，自然而然效率就高了。 解决了上面的问题也就不焦虑了。 给自己个小目标我的目标最终是要写出高质量简洁高效的代码来提高自己的生产效率，根治加班问题。 那么，如何一步一步完成这个目标呢？ 答案即是 RTFSC：Read The Fucking Source Code。 每天坚持看源码，之前dubbo的源码分析还没有写完，我承认是自己懒了，虽然网上也大把的分析dubbo源码的， 但是应该有输入也有输出才是正确的学习姿势，应该持之以恒。 总结学习之路漫长，走的不快，但是尽量走的远一些，坚持二字确实难但也是一条最正确的路。]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小Tips，加速github访问速度]]></title>
    <url>%2Ftips%2Flittle-tips-optimize-github-access%2F</url>
    <content type="text"><![CDATA[前言访问github的速度真的太慢了。(尤其微软收购之后。:D)。 尤其在git clone等操作上确实影响心情: Receiving objects: 8% (497/5635), 2.89 MiB | 15.00 KiB/s 然而解决的方法非常简单。 解决方案慢的原因在哪？其实并不是因为 http://github.com 的这个域名被限制了。而是 http://github.global.ssl.fastly.Net 这个域名被限制了。 解决方法在于修改hosts文件，增加如下: 151.101.72.249 global-ssl.fastly.Net 192.30.253.112 github.com 成功解决问题，测速如下: Receiving objects: 100% (5635/5635), 46.94 MiB | 2.27 MiB/s, done. 总结国内的编程环境的阻碍还是不少啊~~]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用性能分析工具]]></title>
    <url>%2FLinux%2FLinux-performance-analysis-util%2F</url>
    <content type="text"><![CDATA[前言上周五公司搞了双十一“大促”，虽然时间紧凑，还是引起了团队上下高度重视，在有限的两天时间里，进行了充分的压测和性能分析，最终的结果也是不错的。对于性能分析工具，又做了一次熟悉的过程，这里结合网上优秀博文做了下整理。 性能监控，要看哪些一张表搞定： 检测目标 指标 工具 cpu usr&lt;=70%, sys&lt;=35%, usr+sys&lt;=70% top memory swap in （si） == 0，swap out （so） == 0； 可用空间&gt;=30%；应用程序可用内存/系统物理内存 &lt;= 70% vmstat 1;free; /proc/meminfo io iowait% &lt; 20% sar; iostat -x; network udp：缓冲区不挤压, 无丢包 tcp：重传率 netstat -lunp; netstat -su; /proc/net/snmp 良好状态指标: cpu： CPU利用率：User Time &lt;= 70%，System Time &lt;= 35%，User Time + System Time &lt;= 70% 上下文切换：与CPU利用率相关联，如果CPU利用率状态良好，大量的上下文切换也是可以接受的 可运行队列：每个处理器的可运行队列&lt;=3个线程 memory:swap in(si)==0，swap out(so)==0;应用程序可用内存/系统物理内存 &lt;= 70% io：iowait % &lt; 20% ;提高命中率的一个简单方式就是增大文件缓存区面积，缓存区越大预存的页面就越多，命中率也越高。Linux 内核希望能尽可能产生次缺页中断（从文件缓存区读），并且能尽可能避免主缺页中断（从硬盘读），这样随着次缺页中断的增多，文件缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。 network： 对于UDP，接收、发送缓冲区不长时间有等待处理的网络包； 对于TCP而言，不会出现因为缓存不足而存在丢包的事，因为网络等其他原因，导致丢了包，协议层也会通过重传机制来保证丢的包到达对方。所以，更多的专注重传率。 监控工具列举一些常用且实用的工具。 top命令最常用的命令，每次压测第一使用率的命令。top命令可以实时监控系统运行状态，它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序。 命令格式: top [参数] 命令参数: -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i&lt;时间&gt; 设置间隔时间 -u&lt;用户名&gt; 指定用户名 -p&lt;进程号&gt; 指定进程 -n&lt;次数&gt; 循环显示的次数 使用top命令后，可见如下交互信息： top - 22:44:08 up 667 days, 4:15, 9 users, load average: 4.07, 3.54, 3.30 Tasks: 406 total, 1 running, 405 sleeping, 0 stopped, 0 zombie Cpu(s): 15.3%us, 0.7%sy, 0.0%ni, 84.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 32899876k total, 31996032k used, 903844k free, 337144k buffers Swap: 15624188k total, 1577788k used, 14046400k free, 9132796k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 47210 staging 20 0 13.6g 743m 6224 S 5204 2.3 5128980h java 35314 staging 20 0 16.6g 830m 11m S 4 2.6 243:11.07 java 32098 staging 20 0 10.1g 524m 9208 S 4 1.6 664:05.61 java 12789 staging 20 0 13.7g 635m 18m S 3 2.0 67:37.08 java 3198 staging 20 0 1193m 38m 5016 S 2 0.1 1942:19 PM2 v2.7.2: God 29642 staging 20 0 13.0g 416m 5348 S 2 1.3 1428:13 java 21707 staging 20 0 13.4g 412m 11m S 2 1.3 110:47.28 java 20115 staging 20 0 13.7g 614m 18m S 1 1.9 46:43.89 java 43796 staging 20 0 16.6g 579m 11m S 1 1.8 102:33.21 java 12320 staging 20 0 13.7g 653m 18m S 1 2.0 60:49.53 java 24179 look 20 0 17596 1560 960 R 1 0.0 0:00.16 top 31933 staging 20 0 11.1g 424m 9084 S 1 1.3 208:44.23 java 33717 staging 20 0 1206m 49m 8824 S 1 0.2 3:45.91 node /data/web- 40163 staging 20 0 13.5g 534m 15m S 1 1.7 72:56.82 java 7974 staging 20 0 13.0g 435m 8804 S 1 1.4 259:16.18 java 13487 staging 20 0 13.0g 413m 9084 S 1 1.3 188:53.99 java 15855 root 20 0 9.9g 861m 1524 S 1 2.7 1544:16 java 17886 staging 20 0 12.8g 239m 6396 S 1 0.7 692:52.16 java 18725 staging 20 0 13.5g 519m 15m S 1 1.6 39:54.70 java 27444 root 20 0 10.4g 503m 1280 S 1 1.6 2753:21 java 31900 staging 20 0 8991m 422m 9156 S 1 1.3 136:25.31 java 32034 staging 20 0 10.8g 461m 9376 S 1 1.4 152:14.69 java 上述信息很多，逐个解释。 第一行，任务队列信息，同 uptime 命令的执行结果 参数示例 含义 22:44:08 当前系统时间 up 667 days, 4:15 已经运行667天4小时15分(未重启过) 9 users 当前9个用户登录系统 load average: 4.07, 3.54, 3.30 系统负载，后面三个参数分别是一分钟，五分钟和十五分钟；load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程）： 参数示例 含义 406 total 总进程数，共有206个进程 1 running 正在运行进程数，1个 405 sleeping 休眠状态进程数，405个 0 stopped 停止进程数，0个 0 zombie 僵尸进程数（处于无响应状态），0个 第三行，cpu状态信息： 参数示例 含义 15.3%us 用户空间占用CPU的百分比 0.7%sy 内核空间占用CPU的百分比 0.0%ni 改变过优先级的进程占用CPU的百分比 84.0%id 空闲CPU百分比 0.0%wa IO等待占用CPU的百分比 0.0%hi 硬中断（Hardware IRQ）占用CPU的百分比 0.0%si 软中断（Software Interrupts）占用CPU的百分比 0.0%st 在内存紧张环境下，pagein 强制对不同的页面进行的 steal 操作 第四行，cpu状态信息： 参数示例 含义 32899876k total 物理内存总量（32GB） 31996032k used 使用中的内存总量（31GB） 903844k free 空闲内存总量（903M） 337144k buffers 缓存的内存量 （337M） 第五行，cpu状态信息： 参数示例 含义 15624188k total 交换区总量（15.6GB） 1577788k used 使用的交换区总量（1.5GB） 14046400k free 空闲交换区总量（14GB） 9132796k cached 缓冲的交换区总量（9.1GB） 说明: 第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。 如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。 对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 第六行。空行。 第七行，各进程（任务）的状态监控： PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND参数示例 | 含义 —|— PID | 进程id USER | 进程所有者 PR | 进程优先级 NI | nice值。负值表示高优先级，正值表示低优先级 VIRT | 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES | 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR | 共享内存大小，单位kb S | 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU | 上次更新到现在的CPU时间占用百分比 %MEM | 进程使用的物理内存百分比 TIME+ | 进程使用的CPU时间总计，单位1/100秒 COMMAND | 进程名称（命令名/命令行） top命令下，常用交互操作： h:显示帮助画面 1:显示CPU信息。可监控每个逻辑CPU的状况。(%cpu的值是跟内核数成正比的，如8核cpu的%cpu最大可以800%。) H:显示线程。 排序。 Cpu ： 在top交互界面按shift+p或P。 Mem ：在top交互界面按shift+m或M。 Time ：在top交互界面按shift+t或T。 显示程序名。在top交互界面按c。 监控进程下的线程。在命令行输入top -H -p pid，其中pid为进程id，进入界面后显示的PID为线程ID；或者使用命令top -H -p pid进入界面之后在按shift+h来显示线程。 vmstatvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。不足之处是无法对某个进程进行深入分析。 vmstat工具提供了一种低开销的系统性能观察方式，适合在高负荷的服务器上控系统的健康情况。 命令格式： vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 命令参数： -a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 。 -m：显示slabinfo -n：只在开始时显示一次各字段名称。 -s：显示内存相关统计信息及多种系统活动数量。 delay：刷新时间间隔。如果不指定，只显示一条结果。 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 -d：显示磁盘相关统计信息。 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V：显示vmstat版本信息。 使用示例，1秒输出一次，输出20次，单位为MB： ~$ vmstat 1 20 -S M procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r b swpd free buff cache si so bi bo in cs us sy id wa 2 0 1540 1079 348 8715 0 0 0 6 0 0 5 0 94 0 18 0 1540 1078 348 8715 0 0 0 40 11476 16550 32 1 67 0 1 0 1540 1078 348 8715 0 0 0 0 9431 16197 11 0 89 0 0 0 1540 1079 348 8715 0 0 0 244 8325 15550 1 0 99 0 6 0 1540 1079 348 8715 0 0 0 0 8770 15459 5 0 95 0 0 0 1540 1080 348 8715 0 0 0 100 13954 20077 37 1 62 0 0 0 1540 1080 348 8715 0 0 0 36 8661 16188 1 0 98 0 2 0 1540 1080 348 8715 0 0 0 0 8708 16158 1 0 98 0 1 0 1540 1081 348 8715 0 0 0 68 10946 16001 33 0 66 0 1 0 1540 1080 348 8715 0 0 0 0 9380 17035 1 1 98 0 0 0 1540 1080 348 8715 0 0 0 128 8447 15719 1 0 99 0 20 0 1540 1080 348 8715 0 0 0 44 10066 15924 15 1 84 0 1 0 1540 1081 348 8715 0 0 0 0 11834 16701 41 1 59 0 1 0 1540 1080 348 8715 0 0 0 144 8346 15732 1 1 98 1 2 0 1540 1080 348 8715 0 0 0 0 8378 15545 1 0 98 0 2 0 1540 1080 348 8715 0 0 0 120 16144 21775 36 1 63 0 3 0 1540 1079 348 8715 0 0 0 60 8911 16162 3 1 97 0 1 0 1540 1079 348 8715 0 0 0 0 8645 16013 1 1 99 0 5 0 1540 1079 348 8715 0 0 0 272 9153 15929 6 1 92 1 2 0 1540 1080 348 8715 0 0 0 0 12723 16598 52 1 48 0 procs R 列表示运行和等待 CPU 时间片的进程数，这个值如果长期大于系统 CPU 个数，说明CPU 不足，需要增加 CPU。 B 列表示在等待资源的进程数，比如正在等待 I/O 或者内存交换等。 memory swpd 列表示切换到内存交换区的内存大小（单位 KB），通俗讲就是虚拟内存的大小。如果 swap 值不为 0 或者比较大， 只要 si、so 的值长期为 0，这种情况一般属于正常情况 free 列表示当前空闲的物理内存（单位 KB） 。 buff 列表示 buffers cached 内存大小，也就是缓冲区大小，一般对块设备的读写才需要缓冲。 cache 列表示 page cached 的内存大小，也就是缓存大小，一般作为文件系统进行缓冲，频繁访问的文件都会被缓存，如果 cache 值非常大说明缓存文件比较多，如果此时 io中的 bi 比较小，说明文件系统效率比较好。 swap si 列表示由磁盘调入内存，也就是内存进入内存交换区的内存大小。 so 列表示由内存进入磁盘，也就是有内存交换区进入内存的内存大小。 一般情况下，si、so 的值都为 0，如果 si、so 的值长期不为 0，则说明系统内存不足，需要增加系统内存。 io bi 列表示由块设备读入数据的总量，即读磁盘，单位 kb/s。 bo 列表示写到块设备数据的总量，即写磁盘，单位 kb/s。 如果 bi+bo 值过大，且 wa 值较大，则表示系统磁盘 IO 瓶颈。 system in 列表示某一时间间隔内观测到的每秒设备中断数。 cs 列表示每秒产生的上下文切换次数。 这 2 个值越大，则由内核消耗的 CPU 就越多。 cpu us 列表示用户进程消耗的 CPU 时间百分比，us 值越高，说明用户进程消耗 cpu 时间越多，如果长期大于 50%，则需要考虑优化程序或者算法。 sy 列表示系统内核进程消耗的 CPU 时间百分比，一般来说 us+sy 应该小于 80%，如果大于 80%，说明可能处于 CPU 瓶颈。 id 列表示 CPU 处在空闲状态的时间百分比。 wa 列表示 IP 等待所占的 CPU 时间百分比，wa 值越高，说明 I/O 等待越严重，根据经验 wa 的参考值为 20%，如果超过 20%，说明 I/O 等待严重，引起 I/O 等待的原因可能是磁盘大量随机读写造成的， 也可能是磁盘或者此哦按监控器的贷款瓶颈 （主要是块操作）造成的。 字段 含义 Procs（进程） r: 运行队列中进程数量;b: 等待IO的进程数量 Memory（内存） swpd: 使用虚拟内存大小;free: 可用内存大小;buff: 用作缓冲的内存大小;cache: 用作缓存的内存大小 Swap si: 每秒从交换区写到内存的大小;so: 每秒写入交换区的内存大小 IO：（现在的Linux版本块的大小为1024bytes） bi: 每秒读取的块数; cs: 每秒上下文切换数 system（系统） in: 每秒中断数，包括时钟中断;cs: 每秒上下文切换数 CPU（以百分比表示） us: 用户进程执行时间(user time);sy: 系统进程执行时间(system time);id: 空闲时间(包括IO等待时间),中央处理器的空闲时间,以百分比表示;wa: 等待IO时间 备注： 如果r经常大于4，且id经常少于40，表示cpu的负荷很重。如果pi，po长期不等于0，表示内存不足。如果disk经常不等于0，且在 b中的队列大于3，表示io性能不好。 freefree命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。也是经典常用命令之一。 命令格式： free [参数] 命令参数： -b 以Byte为单位显示内存使用情况。 -k 以KB为单位显示内存使用情况。 -m 以MB为单位显示内存使用情况。 -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 持续观察内存使用状况。 -t 显示内存总和列。 -V 显示版本信息。 使用实例： chenruiwen@ubuntu$ free -m total used free shared buffers cached Mem: 32128 31103 1025 0 348 8739 -/+ buffers/cache: 22014 10114 Swap: 15257 1540 13717 字段解释： Mem：物理内存大小。 total：总计物理内存的大小。 used：已使用多大。 free：可用有多少。 shared：多个进程共享的内存总额。 buffers：缓冲区内存总量。 cached：交换区缓冲区内存总量。 第三行(-/+ buffers/cached)：系统的物理内存真实使用量，可通过used-buffers-cached计算得到，因为buffers和cached也是占用物理内存得来，可以通过释放它们来获得这部分内存。 Swap：交换区总量，也叫虚拟内存。 第二行(Mem)的used/free与第三行(-/+ buffers/cache) used/free的区别： 这两个的区别在于使用的角度来看。 Mem行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是1025MB，已用内存是31103MB，其中包括，内核（OS）使用 + Application(X,oracle,etc)使用的 + buffers + cached. -/+ buffers/cache行是从应用程序角度来看，对于应用程序来说，buffers/cached是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。 例如本机的可用内存为： 22014MB(-/+ buffers/cache: used) = 1025MB(Mem:free) + 348MB(Mem:buffers) + 8739MB(Mem:cached) cache 和 buffer的区别： Cache：高速缓存，是位于CPU与主内存间的一种容量较小但速度很高的存储器。 由于CPU的速度远高于主内存，CPU直接从内存中存取数据要等待一定时间周期，Cache中保存着CPU刚用过或循环使用的一部分数据，当CPU再次使用该部分数据时可从Cache中直接调用,这样就减少了CPU的等待时间,提高了系统的效率。 Cache又分为一级Cache(L1 Cache)和二级Cache(L2 Cache)，L1 Cache集成在CPU内部，L2 Cache早期一般是焊在主板上,现在也都集成在CPU内部，常见的容量有256KB或512KB L2 Cache。 Buffer：缓冲区，一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。 通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。 Free中的buffer和cache：（它们都是占用内存） buffer : 作为buffer cache的内存，是块设备的读写缓冲区 cache: 作为page cache的内存，文件系统的cache 如果 cache 的值很大，说明cache住的文件数很多。如果频繁访问到的文件都能被cache住，那么磁盘的读IO 必会非常小。 /proc/meminfo 文件/proc/meminfo是了解Linux系统内存使用状况的主要接口，我们最常用的free、vmstat等命令就是通过它获取数据的。此信息最为丰富，但是我个人使用不多。 使用示例如下，至于各参数的含义，还是留给Google吧: ~$ cat /proc/meminfo MemTotal: 32899876 kB MemFree: 4919948 kB Buffers: 95612 kB Cached: 1170384 kB SwapCached: 1345120 kB Active: 22391896 kB Inactive: 4236700 kB Active(anon): 21918324 kB Inactive(anon): 3448892 kB Active(file): 473572 kB Inactive(file): 787808 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 15624188 kB SwapFree: 5905244 kB Dirty: 7212 kB Writeback: 0 kB AnonPages: 24023988 kB Mapped: 33772 kB Shmem: 4408 kB Slab: 764240 kB SReclaimable: 598480 kB SUnreclaim: 165760 kB KernelStack: 70024 kB PageTables: 125652 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 32074124 kB Committed_AS: 52714036 kB VmallocTotal: 34359738367 kB VmallocUsed: 342184 kB VmallocChunk: 34342341604 kB HardwareCorrupted: 0 kB AnonHugePages: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 271296 kB DirectMap2M: 25896960 kB DirectMap1G: 7340032 kB sarsar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等，sar命令由sysstat安装包安装。 sar安装直接yum install -y sysstat，然后先执行sar -o 2 3，来生成所需文件，之后使用就正常啦。 命令格式: sar [选项] [&lt;时间间隔&gt; [&lt;次数&gt;]] 命令参数: -A:所有报告的总和 -b:显示I/O和传递速率的统计信息 -B:显示换页状态 -d:输出每一块磁盘的使用信息 -e:设置显示报告的结束时间 -f:从制定的文件读取报告 -i:设置状态信息刷新的间隔时间 -P:报告每个CPU的状态 -R:显示内存状态 –u:输出cpu使用情况和统计信息 –v:显示索引节点、文件和其他内核表的状态 -w:显示交换分区的状态 -x:显示给定进程的装 -r:报告内存利用率的统计信息 sar监控CPU使用示例,输出cpu使用情况和统计信息，每2秒输出一次，输出10次： ~$ sar -u 2 10 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 13时43分03秒 CPU %user %nice %system %iowait %steal %idle 13时43分05秒 all 2.23 0.02 0.93 0.15 0.00 96.67 13时43分07秒 all 1.54 0.00 0.65 0.11 0.00 97.71 13时43分09秒 all 0.99 0.00 0.65 1.12 0.00 97.24 13时43分11秒 all 2.02 0.02 0.92 0.13 0.00 96.91 13时43分13秒 all 1.39 0.00 0.63 0.44 0.00 97.53 13时43分15秒 all 1.85 0.02 1.01 0.06 0.00 97.06 13时43分17秒 all 2.11 0.00 0.70 0.02 0.00 97.17 13时43分19秒 all 1.37 0.00 0.51 0.72 0.00 97.41 13时43分21秒 all 1.62 0.02 0.93 0.06 0.00 97.37 13时43分23秒 all 1.39 0.00 0.59 0.27 0.00 97.75 Average: all 1.65 0.01 0.75 0.31 0.00 97.28 参数说明: %usr：用户进程消耗的 CPU 时间百分比 %nice: 运行正常进程消耗的 CPU 时间百分比 %system：系统进程消耗的 CPU 时间百分比 %iowait：I/O 等待所占 CPU 时间百分比 %steal：在内存紧张环境下，pagein强制对不同的页面进行的steal操作。虚拟服务占用的CPU时间百分比，这个值一般为0. %idle：CPU 空闲状态的时间百分比 在所有的显示中，我们应主要注意%iowait 和%idle。 %iowait 的值过高，表示硬盘存在I/O瓶颈， %idle值高，表示 CPU 较空闲，如果%idle 值高但系统响应慢时，有可能是 CPU 等待分配内存， 此时应加大内存容量。 %idle 值如果持续低于 10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 sar监控内存使用示例,显示内存使用信息： ~$ sar -r 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 14时04分38秒 kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact 14时04分40秒 4984120 27915756 84.85 104060 1157104 52363184 107.91 22343076 4227168 14时04分42秒 4983772 27916104 84.85 104060 1157416 52363184 107.91 22343080 4227344 14时04分44秒 4983516 27916360 84.85 104072 1157584 52363184 107.91 22343148 4227532 Average: 4983803 27916073 84.85 104064 1157368 52363184 107.91 22343101 4227348 kbmemfree： 空闲的物理内存大小。这个值和 free 命令中的 free 值基本一致,所以它不包括 buffer 和 cache 的空间。 kbmemused：使用中的物理内存大小。这个值和 free 命令中的 used 值基本一致,所以它包括 buffer 和 cache 的空间。 %memused：这个值是 kbmemused 和内存总量(不包括 swap)的一个百分比。 kbbuffers 和 kbcached：这两个值就是 free 命令中的 buffer 和 cache。 kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)。 %commit：这个值是 kbcommit 与内存总量(包括 swap)的一个百分比。 使用示例，显示系统内存分页状态： ~$ sar -B 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 14时17分35秒 pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff 14时17分37秒 0.00 16.00 135.00 0.00 395.50 0.00 0.00 0.00 0.00 14时17分39秒 0.00 168.00 26.00 0.00 435.00 0.00 0.00 0.00 0.00 14时17分41秒 0.00 1142.00 517.50 0.00 679.50 0.00 0.00 0.00 0.00 Average: 0.00 442.00 226.17 0.00 503.33 0.00 0.00 0.00 0.00 pgpgin/s：表示每秒从磁盘或 SWAP 置换到内存的字节数(KB)。 pgpgout/s：表示每秒从内存置换到磁盘或 SWAP 的字节数(KB)。 fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)。 majflt/s：每秒钟产生的主缺页数。 使用示例，显示系统虚拟内存分页状态： $ sar -W 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 17时08分41秒 pswpin/s pswpout/s 17时08分43秒 0.00 0.00 17时08分45秒 0.00 0.00 17时08分47秒 0.00 0.00 Average: 0.00 0.00 pswpin/s：每秒系统换入的交换页面（swap page）数量。 pswpout/s：每秒系统换出的交换页面（swap page）数量。 sar监控负载使用示例，查看平均负载： ~$ sar -q 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 21时36分24秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked 21时36分26秒 1 8321 0.92 0.71 0.72 0 21时36分28秒 0 8321 0.92 0.71 0.72 0 21时36分30秒 1 8322 0.92 0.71 0.72 0 Average: 1 8321 0.92 0.71 0.72 0 unq-sz：运行队列的长度（等待运行的进程数） plist-sz：进程列表中进程（processes）和线程（threads）的数量 ldavg-1：最后1分钟的系统平均负载 ldavg-5：过去5分钟的系统平均负载 ldavg-15：过去15分钟的系统平均负载 sar监控I/O使用示例，显示缓冲区使用情况: ~$ sar -b 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 21时40分00秒 tps rtps wtps bread/s bwrtn/s 21时40分02秒 18.50 0.00 18.50 0.00 288.00 21时40分04秒 15.50 0.00 15.50 0.00 240.00 21时40分06秒 5.50 0.00 5.50 0.00 44.00 Average: 13.17 0.00 13.17 0.00 190.67 tps：每秒钟物理设备的 I/O 传输总量。 rtps：每秒钟从物理设备读入的数据总量。 wtps：每秒钟向物理设备写入的数据总量。 bread/s：每秒钟从物理设备读入的数据量，单位为 块/s。 bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s。 使用示例，监控设备使用情况: ~$ sar -d 2 3 Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) 21时50分47秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 21时50分49秒 dev8-0 17.50 0.00 868.00 49.60 0.71 40.57 6.17 10.80 21时50分49秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 21时50分51秒 dev8-0 5.00 0.00 40.00 8.00 0.02 3.60 3.60 1.80 21时50分51秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 21时50分53秒 dev8-0 53.50 0.00 800.00 14.95 4.70 87.89 3.03 16.20 Average: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util Average: dev8-0 25.33 0.00 569.33 22.47 1.81 71.45 3.79 9.60 tps:每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。 rd_sec/s:每秒读扇区的次数。 wr_sec/s:每秒写扇区的次数。 avgrq-sz:平均每次设备 I/O 操作的数据大小(扇区)。 avgqu-sz:磁盘请求队列的平均长度。 await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1 秒=1000 毫秒)。 svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间。 %util:I/O 请求占 CPU 的百分比,比率越大,说明越饱和。 avgqu-sz 的值较低时，设备的利用率较高。 当%util 的值接近 1% 时，表示设备带宽已经占满。 await-svctm=io等待时间。 sar总结sar可监控的太多了，这里做个总结。 要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来 怀疑 CPU 存在瓶颈，可用 sar -u 和 sar -q 等来查看 怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看 怀疑 I/O 存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看 iostat iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。 命令格式： iostat[参数][时间][次数] 命令参数： -C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 显示所有磁盘分区的情况~$ iostat -x Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.56 0.01 2.38 0.17 0.00 94.88 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util sda 0.10 6.61 0.61 8.95 6.79 169.04 36.80 0.04 4.44 10.29 4.04 3.64 3.47 参数说明: rrqm/s：每秒进行 merge 的读操作数目，即 delta(rmerge)/s 。 wrqm/s：每秒进行 merge 的写操作数目，即 delta(wmerge)/s 。 r/s：每秒完成的读 I/O 设备次数，即 delta(rio)/s 。 w/s： 每秒完成的写 I/O 设备次数，即 delta(wio)/s 。 rsec/s：每秒读扇区数，即 delta(rsect)/s。 wsec/s：每秒写扇区数，即 delta(wsect)/s rkB/s：每秒读 K 字节数，是 rsect/s 的一半，因为每扇区大小为 512 字节。 wkB/s：每秒写 K 字节数，是 wsect/s 的一半 avgrq-sz：平均每次设备 I/O 操作的数据大小 (扇区)，即 delta(rsect+wsect)/delta(rio+wio) 。 avgqu-sz：平均 I/O 队列长度，即 delta(aveq)/s/1000 (因为 aveq 的单位为毫秒)。 Await： 平均每次设备 I/O 操作的等待时间 (毫秒)， 即 delta(ruse+wuse)/delta(rio+wio) 。 Svctm：平均每次设备 I/O 操作的服务时间 (毫秒)，即delta(use)/delta(rio+wio) %util：一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为 use 的单位为毫秒) 。 显示所有设备负载情况 ~$ iostat Linux 3.2.0-23-generic (localhost) 2018年11月12日 _x86_64_ (24 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.56 0.01 2.38 0.17 0.00 94.88 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 9.55 6.79 169.04 391806012 9758159776 参数说明： %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 tps：每秒从物理磁盘 I/O 的次数.多个逻辑请求会被合并为一个 I/O 磁盘请求,一次传输的大小是不确定的。磁盘的一次读或者写都是一次 I/O 操作 Blk_read/s：每秒读取的数据块数。 Blk_wrtn/s ：每秒写入的数据块数。 Blk_read：读取的所有块数。 Blk_wrtn ：写入的所有块数。 netstatnetstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 命令格式： netstat [-acCeFghilMnNoprstuvVwx][-A&lt;网络类型&gt;][--ip] 命令参数： -a或–all 显示所有连线中的Socket。 -A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。 -c或–continuous 持续列出网络状态。 -C或–cache 显示路由器配置的快取信息。 -e或–extend 显示网络其他相关信息。 -F或–fib 显示FIB。 -g或–groups 显示多重广播功能群组组员名单。 -h或–help 在线帮助。 -i或–interfaces 显示网络界面信息表单。 -l或–listening 显示监控中的服务器的Socket。 -M或–masquerade 显示伪装的网络连线。 -n或–numeric 直接使用IP地址，而不通过域名服务器。 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。 -o或–timers 显示计时器。 -p或–programs 显示正在使用Socket的程序识别码和程序名称。 -r或–route 显示Routing Table。 -s或–statistice 显示网络工作信息统计表。 -t或–tcp 显示TCP传输协议的连线状况。 -u或–udp 显示UDP传输协议的连线状况。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -w或–raw 显示RAW传输协议的连线状况。 -x或–unix 此参数的效果和指定”-A unix”参数相同。 –ip或–inet 此参数的效果和指定”-A inet”参数相同。 常用的有两个：netstat -plnt和netstat -i. ~$ netstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth1 1500 0 26920306700 0 26842853 0 23410550297 0 0 0 BMRU lo 16436 0 9819751923 0 0 0 9819751923 0 0 0 LRU 字段说明: Iface：表示网络设备的接口名称。 MTU：表示最大传输单元，单位为字节。 RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。 RX-ERR/TX-ERR：表示接收/发送数据包时候产生了多少错误。 RX-DRP/TX-DRP：表示接收/发送数据包时候丢弃了多少数据包。 RX-OVR/TX-OVR：表示由于误差而丢失了多少数据包。 Flg 表示接口标记，其中 B 已经设置了一个广播地址。 L 该接口是一个回送设备。 M 接收所有数据包（混乱模式） 。 N 避免跟踪。 O 在该接口上，禁用 AR P。 P 这是一个点到点链接。 R 接口正在运行。 U 接口处于“活动”状态。 其中 RX-ERR/TX-ERR、 RX-DRP/TX-DRP 和 RX-OVR/TX-OVR 的值应该都为 0，如果不为 0，并且很大，那么网络质量肯定有问题，网络传输性能也一代会下降。 $ netstat -plnt (No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.) Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:2281 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:18889 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:27017 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:30090 0.0.0.0:* LISTEN - tcp 0 0 10.0.0.114:22122 0.0.0.0:* LISTEN - tcp 0 0 10.0.0.114:22123 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:1099 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:9100 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:30060 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:6380 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:48781 0.0.0.0:* LISTEN - 字段说明： Proto ：协议 Recv-Q：表示接收队列。 Send-Q ：表示发送队列。 LocalAddress ：表示本地机器名、端口 Foreign Address ：表示远程机器名、端口 State：表示状态，其中: LISTEN ：在监听状态中。 ESTABLISHED：已建立联机的联机情况。 TIME_WAIT：该联机在目前已经是等待的状态。 PID/Program name:进程id/进程名 总结Linux的性能分析工具非常多，这里只是总结了冰山一角，也是参考了很多优秀的博文: Linux 性能监控 ： CPU 、Memory 、 IO 、Network linux 服务器性能监控 每天一个linux命令]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>Linux</tag>
        <tag>performance analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次jedis连接异常引发的血案]]></title>
    <url>%2Fredis%2FJedisPool-optimize-record%2F</url>
    <content type="text"><![CDATA[前言每年双十一，各个互联网企业都会搞一些活动来促销自己公司产品，然而今年对于互联网金融领域的企业来说，可能并不好过，本以为今年公司不搞活动了，然而11月7号被告知11月9号上午发售一批双十一产品搞活动，这对于我们技术人员来说即兴奋又担忧，兴奋的是遇到这种类似秒杀场景的机会不多，担忧的是害怕网站会挂掉，而且留给我们的时间只有两天。 去年花了一段时间优化了我们网站，从架构层面到代码层面，也做了充分的全链路压测，花费了不少心思。(然而去年，并没有搞活动。)总之，我们还是对我们的代码有信心。 虽说如此，我们还是做了2天的全链路压测，压测数据单机qps大概能达到400+，能撑住五分钟左右然后系统性能下降，但是一分钟后qps又能上来，系统并没有挂掉，说明我们的系统还可以，又增加了自信。 今天上午9点早早到达公司，打开各种监控和日志，实施观察以便处理意外情况。果不其然，产品销售很快，门槛低的产品基本一分钟内卖完，90%的产品八分钟内卖完。我们的系统抗住压力。 app端请求数: app端购买请求数： 问题然而还是出现了一些问题。 运维的同学反馈，基于redis统计并发在线人数有些不正常，有一个突然间的峰值： 老大反馈了一些问题： 总之问题是： 登录后，PC端在产品可购买的瞬间大量用户登出系统了。 购买后反馈结果慢。(这个问题老问题了，原因是对接杭州那边系统反应慢。) 排查问题我们主要是排查为什么大量用户登出？ 开始以为是cookie被删除的原因，但是大量用户登出还是有些不正常，我们的服务监控也没有报警，一度觉得很诧异，总之还是先查日志吧，万一日志确实没有报警呢？ 还真是。Dubbo报错：调用用户服务线程池满了，达到上限200，之后的请求全部拒绝了: 到底什么导致了Dubbo线程池满了？接着看日志找到了具体的报错信息: Caused by: java.util.NoSuchElementException: Timeout waiting for idle object at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449) at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363) at redis.clients.util.Pool.getResource(Pool.java:49) ... 16 more Exception in thread &quot;pool-4-thread-4074&quot; org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:198) at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:345) at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:129) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:92) at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:79) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:191) at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:166) at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:88) at org.springframework.data.redis.core.DefaultValueOperations.set(DefaultValueOperations.java:169) at com.gemantic.wealth.test.controller.RedisController$1.run(RedisController.java:40) at com.gemantic.wealth.test.controller.MyRunnable.run(RedisController.java:84) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Caused by: redis.clients.jedis.exceptions.JedisException: Could not get a resource from the pool at redis.clients.util.Pool.getResource(Pool.java:51) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:99) at redis.clients.jedis.JedisPool.getResource(JedisPool.java:12) at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:191) ... 13 more Caused by: java.util.NoSuchElementException: Timeout waiting for idle object at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:449) at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363) at redis.clients.util.Pool.getResource(Pool.java:49) ... 16 more 那么问题就比较明朗了： jedis获取资源时等待超时，连接不上报错。 看了下生产的redis配置： spring.redis: database: 1 host: redis port: 6379 password: pool: max-wait: 3000 max-idle: 20 问题可能是出在这里，大胆猜测一下：由于没有配置jedisPool的maxTotal，默认连接数为8，当并发数上来时，大量请求过来导致大部分的连接不上redis而直接抛异常了。 Google了一下，也有我们这种情况的先例，但还是先测试一下： 200个并发请求往redis中插入数据，jedis配置与生产一致的情况，发现稳定浮现错误信息。 对比测试，修改测试用例的jedis配置，大致，最大连接数改为100后测试，发现报错少了90%。那么应该就是这个问题了。 解决生产问题，修改redis配置: spring.redis: database: 1 host: redis port: 6379 password: pool: max-wait: 500 max-idle: 50 max-active: 50 解释一下: max-wait: 对应连接池连接等待时间，原先是3000毫秒，有些长了，连接不上应该尽早报错不要占用资源。 max-active：对应JedisPoolConfig的maxTotal，最大连接数，主要改的就是这个。 max-idle：最大空闲连接数，保持与maxTotal一致，避免连接池伸缩带来的性能干扰。 以上设置参考了JedisPool资源池优化。 最后附一下JedisPoolConfig关键配置，也是参考以上博客哈： 参数名 含义 默认值 使用建议 maxTotal 资源池中最大连接数 8 不能太大，连接太多占用客户端和服务器的资源，建议50 maxIdle 资源池允许最大空闲的连接数 8 与maxTotal一致 minIdle 资源池确保最少空闲的连接数 0 根据业务，可设置少量 blockWhenExhausted 当资源池用尽后，调用者是否要等待。只有当为true时，下面的maxWaitMillis才会生效 true 建议默认值 maxWaitMillis 当资源池连接用尽后，调用者的最大等待时间(单位为毫秒) -1 : 表示永不超时 不建议默认值，我们是500 testOnBorrow 向资源池借用连接时是否做连接有效性检测(ping)，无效连接会被移除 false 业务量很大时候建议设置为false(多一次ping的开销)。 testOnReturn 向资源池归还连接时是否做连接有效性检测(ping)，无效连接会被移除 false 业务量很大时候建议设置为false(多一次ping的开销)。 jmxEnabled 是否开启jmx监控，可用于监控 true 建议开启，但应用本身也要开启 testWhileIdle 是否开启空闲资源监测 false true timeBetweenEvictionRunsMillis 空闲资源的检测周期(单位为毫秒) -1：不检测 建议设置，周期自行选择，也可以默认也可以使用下面JedisPoolConfig中的配置 minEvictableIdleTimeMillis 资源池中资源最小空闲时间(单位为毫秒)，达到此值后空闲资源将被移除 10006030 = 30 min 可根据自身业务决定，大部分默认值即可，也可以考虑使用下面JeidsPoolConfig中的配置 numTestsPerEvictionRun 做空闲资源检测时，每次的采样数 3 可根据自身应用连接数进行微调,如果设置为-1，就是对所有连接做空闲监测 结束语这次的问题属于客户端设置参数的问题，还是要检查一下各个服务的配置为好。 解决了这个问题，根据监控发现还有更多可优化的地方，其次，我们的这次监控没有加上Jedis的异常报错，监控还有待提高，不过我们以及在测试环境上接上了点评的CAT,非常好用，踩完坑后准备接到生产。 最后感慨一下解决问题真的很有快感。更感谢帮助我解决问题的这些参考的博文: Jedis常见异常汇总 JedisPool资源池优化]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>essay</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(六)：线程池那些事儿]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-ThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[前言创建一个线程，最简单的做法是new一个线程，但是当大量请求过来时(类比窗口卖票的场景)， 创建这么多个线程的开销就很大了。 今天整理下线程池相关知识，相对于传统做法，线程池的优势还是很明显的： 节省了创建和销毁线程的时间，提高了任务执行效率，也就增加了CPU的吞吐能力 线程池的优势引用一下方腾飞的话， 合理利用线程池能够带来三个好处。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。但是要做到合理的利用线程池，必须对其原理了如指掌。 Executors中的线程池j.u.c的Executors中默认提供了一些方便的线程池创建: 静态方法 线程池类型 说明 返回值的实际实现 newCachedThreadPool() 可缓存的线程池 如果线程池的大小超过了处理任务所需要的线程,那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 ThreadPoolExecutor newFixedThreadPool(int) 固定线程池 每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 ThreadPoolExecutor newScheduledThreadPool(int) 定时及周期性线程池 此线程池支持定时以及周期性执行任务的需求。 ScheduledThreadPoolExecutor newSingleThreadExecutor() 单线程的线程池 这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 FinalizableDelegatedExecutorService 线程池的使用public static void main(String[] args) { //ExecutorService pool = Executors. newSingleThreadExecutor(); //ExecutorService pool = Executors.newFixedThreadPool(2); ExecutorService pool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) { pool.execute(() -&gt; System.out.println(Thread.currentThread().getName() + &quot;正在执行...&quot;)); } pool.shutdown(); } 如上述测试程序，如果ExecutorService的实现pool是newSingleThreadExecutor的时，输出 pool-1-thread-1正在执行... pool-1-thread-1正在执行... pool-1-thread-1正在执行... pool-1-thread-1正在执行... pool-1-thread-1正在执行... 如果ExecutorService的实现pool是newFixedThreadPool的时，参数设置大小为2，输出 pool-1-thread-1正在执行... pool-1-thread-2正在执行... pool-1-thread-1正在执行... pool-1-thread-2正在执行... pool-1-thread-1正在执行... 如果ExecutorService的实现pool是newCachedThreadPool的时，输出 pool-1-thread-1正在执行... pool-1-thread-3正在执行... pool-1-thread-2正在执行... pool-1-thread-4正在执行... pool-1-thread-5正在执行... 如果是newScheduledThreadPool，则使用方法有些不同: public static void main(String[] args) { ScheduledExecutorService exec = Executors.newScheduledThreadPool(2); // 创建一个可定时的线程池 // 每2秒打印一次 exec.scheduleAtFixedRate(() -&gt; System.out.println(System.currentTimeMillis() / 1000), 1, 2, TimeUnit.SECONDS); // 线程池中某个线程出错 exec.scheduleAtFixedRate(() -&gt; { System.out.println(&quot;池中一个线程出错了！&quot;); throw new RuntimeException(); }, 1, 2, TimeUnit.SECONDS); } 上述程序输出如下,可见池中的线程是隔离的 1540794708 池中一个线程出错了！ 1540794710 1540794712 1540794714 核心ThreadPoolExecutor无论你从上诉任何一种静态方法进去，其最终都是离不开这个类:ThreadPoolExecutor 构造器： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 解释一下这几个参数: corePoolSize(核心线程池大小):当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads方法，线程池会提前创建并启动所有基本线程。 maximumPoolSize(线程池最大大小，其值=核心线程数+其他线程数):线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。 keepAliveTime(线程活动保持时间):线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率。 TimeUnit(线程活动保持时间的单位)：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。 workQueue(任务队列):用于保存等待执行的任务的阻塞队列。关于阻塞队列，可参考之前写的浅析java并发包(三)：阻塞队列(BlockingQueue) threadFactory(线程工厂):用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字，Debug和定位问题时非常又帮助。 RejectedExecutionHandler(饱和策略):当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略： AbortPolicy：中止策略，默认。直接抛出异常。 CallerRunsPolicy：“调用者运行”策略，任务回退到调用者，从而降低了新任务的流量，只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 DiscardPolicy：不处理，丢弃掉。 第五种，通过实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。 线程池运行流程一图胜前言，直接引用来自方腾飞《聊聊并发》： 图码结合，从线程池的执行方法ThreadPoolExecutor.execute分析。分3种，我在代码里用注释标出 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get();// 获取线程数 // 1.如果线程数小于核心线程数，则addWorker创建线程执行任务 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } // 2.线程是否RUNNING状态且尝试加入队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); //再检查， 任务队列不在运行且从队列中删除，执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 运行任务数量为0，则移除核心线程外的线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 3.非RUNNING状态或者加入队列失败，尝试创建非核心线程直到maxPoolSize，如果失败则执行拒绝策略 else if (!addWorker(command, false)) reject(command); } 配置线程池知道了线程池的参数和运行规则，那么如何配置线程池呢? 一. 线程池的大小。主要是根据任务类型：计算密集型 or I/O密集型 or 二者皆可？ 计算密集型的任务，通常情况线程池大小=Ncpu+1最优； I/O密集型任务，由于线程不会一直执行，通常设置为Ncpu*2。 混合型，最好因地制宜，拆分为CPU密集型和I/O密集型处理。 一个通用公式: Ncpu:cpu的个数 Ucpu:使用cpu的个数 W/C:计算时间等待率 Nthreads=Ncpu * Ucpu * (1 + W/C) 二. 阻塞队列的选择。主要分为3种，有界队列、无界队列、同步移交。 有界队列有助于避免资源耗尽，大部分情况比较适合。使用有界队列时，队列大小与线程池大小必须一起调节。当线程池较小而队列较大时，有助于减少内存使用量，降低CPU使用率，同时减少上下文切换，但代价是可能会限制吞吐量。 无界队列可以通过使用SynchronousQueue来避免排队。只有当线程池是无界的或者可以拒绝任务时，SynchronousQueue才有实际价值。 三.关于ThreadPoolExecutor的扩展性。它提供了几个可以在子类改写的方法:beforeExecute,afterExecute,terminated。可以利用这些方法在线程执行前、后、以及销毁时做一些特别操作，比如添加日志、计时、监控、收集统计信息等功能。 总结本文主要参考了： java自带线程池和队列详细讲解 聊聊并发（三）Java线程池的分析和使用 java并发编程实战 对这些优秀博文书籍进行了一次聚合总结吧，感谢原作者。同时，对java线程池也更加的了解一些。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[巴厘岛旅行记]]></title>
    <url>%2Ftravel%2Ftraveling-all-around-Bali%2F</url>
    <content type="text"><![CDATA[前言过了一个漫长的假期，国庆节七天加上婚假十天，过的都不会上班了。蜜月之行的计划本来打算是去欧洲看看的，但是听说基本都是玩十二天左右，时间太长会很累，其次由于我们第一次出国，很多事情不是很懂，所以跟了个10.09-10.15的七天五晚的旅行团(有出国经验的话建议自由行)，遂主要记录在巴厘岛这几天的行程与游记。 行前准备必备： 护照 机票(去机场取，我们坐的从北京直飞登巴萨的东方航空，座位可以从网上提前预约好) 钱。推荐带美元+印尼盾的组合，各提前准备好。(是可以从当地货币兑换点兑换，但是比较亏。最好提前准备好。) 打电话与流量(可以直接从支付宝搜索“境外上网”，我们是移动的用户，价格是移动的一半，办了五天流量价格54元。) 防晒霜(我们是提前在首都机场DFS买好的安耐晒，非常便宜，建议多买) 户外常用app：google地图，大众点评/飞猪等 补充一些非必须但是有必要带的物品： 沙滩裤(毕竟是要沾水的，速干的裤子比较好，巴厘岛那边比较潮湿，棉的衣物在宾馆不容易干) 泳衣泳裤(不解释) 拖鞋(不解释，基本告别要穿袜子的鞋) 沙滩鞋(有些地方比拖鞋好用) 花露水(防蚊) 手机防水袋(一些喜欢拍照的朋友请准备好) 具体行程记录行程简记：day0 首都机场飞到巴厘岛(人家原名叫登巴萨) -&gt; uluwatu的酒店day1 uluwatu的酒店 -&gt; 情人崖 -&gt; 海龟岛 -&gt; 金巴兰海滩 -&gt; uluwatu的酒店day2 uluwatu的酒店 -&gt; 蓝梦岛 -&gt; spa -&gt; kuta的酒店day3 kuta的酒店 -&gt; 漂流 -&gt; 大秋千 -&gt; 家乐福购物 -&gt; kuta的酒店day4 kuta的酒店 -&gt; kuta沙滩 -&gt; DFS Bali T Galleria -&gt; spa again~ -&gt; kuta的酒店day5 kuta的酒店 -&gt; 海神庙 -&gt; 乌布皇宫，乌布市场 -&gt; 下午茶 -&gt; 洋人街 -&gt; 机场day6 飞回首都机场 day0由于是4点半的飞机，我们中午就到了首都机场，先是在机场吃了饭(机场的饭价格不用说，一定会贵，但是感谢上帝，这里的全家便利店跟其他地区一样)。然后我们就直接取机票和登机牌，然后办理托运，开开心心去首都机场的DFS了(帮人代购真累:D)。 4点半飞机起飞，好久没坐过飞机了，再加上第一次出国，着实有些小兴奋。乘坐的是东方航空，之前还担心东方航空的环境不好，其实还可以。 壮哉我大蚌埠:D，“新中国四大城市” 飞行七个小时整，晚上11:45到达巴厘岛，巴厘岛与北京没有时差。第一次办理入境，我的方法是，跟着人群走总是对的。好在大部分人是对的。护照盖章和取完托运的行李后便顺利入境了。 出去后先是找到导游，本来准备在机场办理一张当地的电话卡的，但是很不划算(比首都机场办卡和中国移动还贵)，后来比对了中国移动推出的无忧行app和支付宝的“境外上网”，价格相同，54RMB五天流量不限，所以就采用了支付宝的解决方案。 与我们一起同行的也是两对来度蜜月的情侣，都是北京本地人，人都很nice，很好相处，社交属性都很max的感觉:D。我们一行人在导游的导航下开了很久，到达离机场比较远的乌鲁瓦图(uluwatu)的酒店——Hillstone Uluwatu Villa。然后洗洗就睡了。 槽点：住宿虽是独立别墅，并没有想象中的好，唯一的亮点是院内的泳池，其他设施感觉很一般。 day1早上睡到8点就自然醒了，收拾好后，床头放了5RMB的小费(这是必须的，这边的服务都是要收小费的，给大概5~10RMB小费就足够了)。早饭是吃的酒店的自助餐，味道一般，没有国内吃的习惯就是了。 11点出发去了情人崖。据说那里的小猴子很调皮，会抢游客的东西，如果被抢了东西，需要找当地的人帮忙，大概就是那种一物换一物的样子，也可能换不回来。所以，保护好自己的钱财啊，拍照的时候手机拿紧了。可能因为我们是中午到了，猴子们都比较懒洋洋的。 情人崖 中午的午饭是在黄金咖啡工厂旁边的娘惹私房菜解决，饭馆里面基本都是中国人，问了导游，说本地人在饭店吃饭的很少。关于菜呢，做的虾不错，别的菜就可圈可点了，咖喱味确实吃不习惯。 我们没有在黄金工厂逗留，听导游说黄金工厂的猫屎咖啡100g大概800块钱(后来对这个导游所言及其不信任，此价格可信度不足5成)。 娘惹私房菜 然后下一站直接去了金巴兰沙滩。路上听导游介绍了这里一个很奇葩的本地文化。印尼这边女性地位很低，男性地位很高，之前法律可以允许一个男人娶四个老婆，而且男人不干粗活，像搬砖砌瓦这种粗活都是女人来做，男人只多做雕刻等工作。路上有许多可供休息的小亭子，叫发呆亭，专门给男人发呆用的…这里的男人太幸福了… 我们2点左右到达金巴兰沙滩，首先是去玩一些水上项目，比如飞艇，滑翔伞等。滑翔伞没有想象的那么刺激，但是高度确实可以，看风景真的不错。玩过这些后，我们乘船去了海龟岛。海龟岛上最特色的是大量的海龟，被当地人群圈养着…我以为是沙滩上的，可能我还是太年轻。不止有海龟，还有各种鸟，蜥蜴，蟒蛇，大蝙蝠等…这个岛基本就是小型动物园的样子，不过好玩的是船停在岸边很远，因为还没到雨季的原因，我们沿着海边走了很久，一路上抓了不少寄居蟹和海螺。 玩到四五点我们又回到了金巴兰沙滩看日出，嗯，没错，金巴兰海滩——世界十大最美落日海滩之一。直接上图： 看着日落，吃着烧烤，金巴兰的玉米据说是必吃的，点了一个微辣，实际上也是很辣了，价格7块5RMB，果然景区很贵。这里的烧烤也是出奇的宰人啊，看了菜单，要想吃饱人均至少200+RMB，巴厘岛的人民也不老实啊。烧烤是旅行团提供了，每人一盘，一盘有三只虾，三串鱿鱼，一个螃蟹，一条鱼，啤酒一瓶。 (画外音：想念我大中华的烧烤啤酒。) 就这价格明显宰人，不能当傻子(怂了)，我们又去便利店看了看当地的人民都吃些什么。嗯，买了泡面和一些零食回去垫垫了…回酒店游了一圈就休息了。 day2这是一个早起的上午，6点半就吃饭了，七点开始出发，今天的目的地是巴厘岛必玩景点之一——蓝梦岛，所以我们坐车先来到Pantai Mertasari，等到八点十几分左右坐上船开往蓝梦岛(Lembongan)。大概坐了四五十分钟左右的船(有点晕船的小伙伴最好准备好口香糖等缓解手段)，来到另一个船上，这个船上先玩一些水上项目，香蕉船，甜甜圈无限玩，玩到过瘾，浮潜，水上跳床等，还有水底漫步，很多热带鱼很好看。 坐船路线 中文在蓝梦岛又是吃的自助餐，应该是最难吃的一顿饭了，如果不是饿的厉害，我可能得去买泡面了。 蓝梦岛最著名的景点是梦幻沙滩和恶魔的眼泪。当时我就想如果是自由行就好了，我一定会在蓝梦岛上住一晚，就住在梦幻沙滩这里。梦幻沙滩必须是住在那个酒店才能进去的。在恶魔的眼泪拍照一定要小心，因为我们是在旱季去的，水位不高，我看网上雨季的巴厘岛水位是可能冲上来的，据说每年能卷走一两百个游客。 梦幻沙滩 恶魔的眼泪 看完恶魔的眼泪，下午4点去做了当地的spa，给幸苦的一天画上一个舒服的句号。晚上的酒店是在库塔(kuta)区的 The Kuta Beach Heritage Hotel 酒店，对面就是库塔沙滩，这条街上基本都是酒吧，沙滩、啤酒与乐队，就会突然感觉很有电影里看到的那种氛围。晚上没事干就去酒店四层(顶层，巴厘岛没有什么高楼大厦，基本最高就四五层)大泳池游了一圈(弥补今夏未游泳之遗憾)。 day3今天是自由行的第一天，我们在昨天晚上一起从飞猪上定了今天的行程(阿勇河漂流和悬崖秋千)，于是一大早便起，七点半吃了酒店的自助餐(吐槽一下，来巴厘岛这几天吃的最好吃的一顿)。八点多坐上了包的车，一路上用中午和师傅谈笑风生大约一个半小时左右，来到目的地，阿勇河漂流。不得不说阿勇河真的是适合团队活动，漂流的时间大概在两个小时左右，漂流是一定会全身湿透的(刚下水就湿透了)，所以要准备泳衣。河水并不深，不必担心掉下水溺水，水流有平缓和湍急之处，有的时候皮划艇还会卡在石头上…至于河里有没有蛇就不知道了，反正看到了树枝上有蛇还有蜥蜴… 午餐是一如既往的难吃，依旧是景点的自助餐。唯一能让我吃下去的就是依靠当地的辣酱了。 饭后直接去悬崖秋千。路上经过了一些雕刻和沉香店，下车瞧了瞧，由于并不懂行，并没有买。悬崖秋千，确实是有些刺激的(主要是因为司机路上告诉了我们之前都摔下去摔死的，我心里一直担心绳子会断…)。其次，论拍摄技巧的重要性，被老婆好好教育了一顿，惨痛，有时间一定要系统性学习一下拍摄。 坐秋千 玩完之后又让师傅带着去了当地的一个猫屎咖啡工厂，看了猫屎咖啡的生产过程，尝了尝当地各种品种咖啡和饮料(免费的)，猫屎咖啡是需要付费的(25RMB)，而且喝起来感觉怪怪的，加了两袋白糖喝起来还行。 十三种免费饮品 制作中的猫屎咖啡豆 磨的猫屎豆 逛完猫屎咖啡工厂，下一站我们的选择是家乐福…总结一下，家乐福中可带的东西有手工香皂，猫屎咖啡(价格不贵)，当地泡面(难道不想和康师傅汤达人一较高低吗)，Max T奶茶(超级好喝)，Olay空气霜(国内价格的三分之一，这个牌子的基本价格都是国内的一半价格一下)，雕刻手工制品，养乐多才5块钱…总之我们满载而归。 day4自由行的第二天，必须睡到自然醒(其实八点多就醒了)。9点吃了超好吃的早饭，和老婆去酒店对面的库塔沙滩走了走。 天气又好，浪又大，冲浪的人很多，忍不住的我也跃跃欲试，于是人生中第一次冲浪诞生于巴厘岛了。库塔沙滩旁边都是出租冲浪板和教学了，我和同行的游泳爱好者一起冲的，两个人45W印尼盾(大约一个人115RMB)，各有一个教练带着。tips，切记不要刚吃完饭去冲浪，会吐的。总的来说，冲浪真的是很爽就是了(被一浪一浪排在沙滩上)。 中午，是女人们的专场，巴厘岛当地的DFS。我们打了当地的出租车，号称蓝鸟(Blue Bird)，上车后听见师傅在听布鲁斯，便用我那蹩脚的英文跟司机师傅瞎侃说我也喜欢布鲁斯，我喜欢Jimi Hendrix。司机师傅表示认同，他说他有个自己的乐队，但平时排练比较少等等。。。 然而，聊的挺愉快，下车的时候就不愉快了。这儿的出租车挺黑的。我从谷歌地图上看司机带我们绕了个大圈，而且就算绕这个大圈，应该也就四五公里不到的路。下册的时候师傅打的表显示160000，合RMB 80块，这是北京的四五倍价格了。(回去的时候我们问了当地七座的私人车，五个人25就回去了。) 其次，到了目的地也没想象的那么愉快，因为这里的DFS比国内的贵，一件东西没买上。然后又去了家乐福，还是家乐福好啊，把昨天没上的东西再看看咯。 晚上又想去spa了，这里的spa毕竟很便宜。从大众点评上(巴厘岛大众点评是可以用的)看了离我们最近的有一个五星好评的“哈巴狗spa”，于是我们一路沿着酒吧街走过去，直到到达目的地后着实让我们失望了，原来是小作坊:)。由于这家spa位置有限以及时间原因问题，换了旁边一家小spa点按了一下全身按摩，感觉很一般，没啥手劲，但是我老婆说这家手劲刚好:)。 遇到一件很酷的事情，在路边的时候，几个老外在酒吧大声合唱起来，一听让人激动，原来是“英国国歌”：Oasis的Don’t Look Back in Anger。让人想到2005年曼城演唱会上的万人大合唱。 day5早上出发的比较早，一大早就去了海神庙。海神庙的海浪很大… 看不腻的海 浪花与帅男 中午那会儿又去了乌布皇宫和乌布市场。乌布皇宫，说是皇宫，但是真的好小啊，跟咱故宫比查太远了，没什么意思。有点意思的是乌布市场，这里能淘一些当地的手工工艺品，当然最需要也是最有意思的就是砍价了。(语言采用中西结合的技法，又不缺失肢体语言与计算器这种神奇的辅助，方能砍得合适的价格)。我自己的战利品是尤克里里一把(75RMB价格，真的很便宜了)。 乌布市场街景(后面还有很大一片) 中午的午饭吃的是当地有名的脏鸭餐，说实话，味道一般。 脏鸭餐(确实是脏，能感受到上面的毛毛) 我们吃脏鸭餐的旁边就是Monkey Park，我们出门还碰到几个猴兄，给了一袋薯片一下就抢走了。。。 下午是休闲的下午茶时光(旅行社安排，对于我来说有点浪费时间)，我们来到 Benoa Bay 海湾这里的 Conard Bali酒店吃的下午茶。下午茶平淡无奇，但是这里的住宿是真的比之前住的好(超大泳池，几乎整个花园都是泳池，这里沙滩也好，还有飞艇等娱乐工具)，妈的，要是自己来一定住这里！ 康纳德酒店泳池一角 晚上去了巴厘岛的洋人街，一听名字就知道很宰人，这里的手工制品比乌布市场的贵将近一半左右，以及商场里的一些品牌比国内的贵。洋人街不适合购物，可以选择去对面的库塔沙滩吹吹海风。 巴厘岛之行基本上就到这了，晚上我们很早就去了机场，大概11点办理完托运等，第一件事就是再去DFS(万恶的化妆品)再看看。 最后1点半坐上回帝都的飞机了。 再见，巴厘岛(登巴萨)。 后话在巴厘岛待的时间不长，一共就5天5晚吧，说实话还是想再多玩几天的，还是有些遗憾的，只能暂时先列一下计划了以后再去补上~~： 看海豚和海上日出 去火山和温泉 蓝梦岛住一晚，一定要冲一次梦幻沙滩的浪 吃一顿猪排饭 乌布多待两天 吉利三岛和龙目岛(脱离巴厘岛的范围了:))玩几天 对巴厘岛印象最深刻的还是这里的交通，路又窄又弯又起伏，这里的摩托车是主要的交通工具，喜欢摩托车的朋友适合在这生活哈~： 最后，还是想说一句：巴厘岛司机牛逼！巴厘岛司机世界第一！]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
        <tag>Bali</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《大型网站技术架构》知识总结]]></title>
    <url>%2Farchitecture%2Flarge-scale-websites-architecture-note%2F</url>
    <content type="text"><![CDATA[前言又把《大型网站技术架构-核心原理与案例分析》看了一遍，之前走马观花看了一遍，没有体会到精髓。现在具备一定“中型”网站开发经验后再看之，又有些体会，故整理一下这本书的内容。 大型网站架构演化大型网站软件的特点 高并发、大流量 高可用 海量数据 用户分布广泛 安全环境恶劣 需求变更快，发布频繁 渐进式发展 大型网站架构演化发展历程 初始阶段的网站架构：all in one，一台服务器，部署了应用程序，数据库，文件，等所有资源。比如经典的LAMP架构。 应用和数据服务分离：应用程序，数据库，文件分别用了3台服务器部署。 使用缓存改善网站性能：本地缓存+分布式缓存。 使用应用服务器集群改善网站并发处理能力：通过负载均衡调度服务器来将访问请求分发到应用服务器集群中的任何一台机器。 数据库读写分离：数据库采用主从热备，写数据在主数据库中，主数据库通过主从复制机制将数据更新同步到从数据库。读数据从从库读取。 使用反向代理和 CDN 加速网站响应：这两者基本原理都是缓存。CDN 部署在网络提供商的机房，使用户可从离距离自己最近的提供商机房获取数据;反向代理部署在网站的中心机房，减轻后端负载压力，反向代理服务器命中的静态数据可直接返回。 使用分布式文件系统和分布式数据库系统：数据库拆分的最后手段，解决单表特别大的情况。 使用 NoSQL 和搜索引擎：对可伸缩的分布式有更好的支持。 业务拆分：将整个网站业务拆分成不同的应用，每个应用独立部署维护，应用之间通过超链接建立联系/消息队列进行数据分发/访问同一数据存储系统 分布式服务：公共业务提取出来独立部署 大型网站演化到这里，大多数技术问题都得以解决，如图： 大型网站架构演化的价值观 大型网站架构的核心价值是随网站所需灵活应对 驱动大型网站技术发展的主要力量是网站的业务发展 网站架构设计误区 一味追随大公司的解决方案 为了技术而技术 企图用技术解决所有问题 大型网站架构模式 分层:计算机世界无处不在，操作系统与硬件，网络七层，网站应用MVC分层。 分割：按业务分割 分布式： 分布式应用和服务 分布式静态资源 分布式数据和存储 分布式计算 集群 缓存： CDN 反向代理 本地缓存 分布式缓存 异步： 提供系统可用性 加快网站响应速度 消除高并发访问高峰 冗余：服务器冗余运行，数据库冗余备份（冷热备份） 自动化：自动化代码管理；自动化发布；自动化测试；自动化安全检测；自动化部署；自动化监控；自动化报警；自动化失效转移；自动化失效恢复；自动化降级；自动化分配资源。 安全：防止XSS攻击、sql注入。 大型网站核心架构要素 性能 浏览器端:浏览器缓存，页面压缩，合理布局页面，减少Cookie传输 CDN：静态内容分发到离用户最近的网络服务商机房。 应用服务器：缓存+异步。 代码层面：多线程+改善内存等手段优化。 数据库：索引，缓存，SQL优化等。 可用性：只要手段是冗余 应用服务器：负载均衡组成集群。 数据库：实时备份。 软件开发质量保证：预发布验证，自动化测试，自动化发布，灰度发布等。 伸缩性：主要标准是是否可以构成集群，是否容易不断地向服务器集群加服务器 应用服务器集群：负载均衡设备。 缓存服务器集群：改进缓存路由算法保证存储数据的可访问性。 数据库：路由分区等。 NoSQL数据库：先天良好支持。 扩展性：指业务上是否可以少有改动快速上线。主要手段是事件驱动架构和分布式服务。 事件驱动架构：通常用消息队列实现。 分布式服务：按业务和可复用性将服务分离。 安全性：标准是针对现存和潜在的各种攻击和窃密手段，是否有可靠的应对策略。 瞬时响应：网站的高性能架构网站性能测试 不同视角下网站的性能 用户视角网站性能：响应时间。 开发人员视角的网站性能：响应时间、并发量、吞吐量。 运维人员视角的网站性能：资源。 性能测试指标 响应时间：直观反映系统快慢。 并发数：反映系统负载特性。 吞吐量：反映系统整体处理能力。通过qps,tps,hps测量。 性能计数器：描述服务器或操作系统的数据指标。包括System Load、对象与线程数、内存使用、CPU使用、磁盘与网络I/O等指标。 性能测试方法 性能测试：验证系统在资源可接受范围内。 负载测试：测试安全临界值。 压力测试：测试系统最大压力承受能力。 稳定性测试：模拟生产环境。 性能测试报告 性能优化策略 性能分析：1.检测请求各环节日志，分析那个环节响应时间不合理。2.检查监控数据。 性能优化： Web前端性能优化 应用服务器性能优化 存储服务器性能优化 web前端性能优化 浏览器访问优化 减少http请求 使用浏览器缓存 启用压缩 css放在网页最上面 js最下面 减少cookie传输 CDN加速 反向代理：安全屏障；缓存静态和热点数据；负载均衡。 应用服务器性能优化优化的主要手段还是：缓存，异步，集群。 分布式缓存 缓存的基本原理 合理的使用缓存 频繁修改数据：读写比2：1以上缓存才有意义 没有热点的访问 数据不一致与脏读 缓存可用性 缓存预热 缓存穿透 分布式缓存架构 异步操作：削峰 使用集群 代码优化 多线程： 将对象设计为无状态对象 使用局部对象 并发访问资源加锁 资源复用：单例和对象池 数据结构 垃圾回收 存储性能优化 机械硬盘 vs. 固态硬盘 B+ 树 vs. LSM 树 RAID vs. HDFS 万无一失：网站的高可用架构网站可用性的度量和考核 网站可行性度量 网站不可用时间(故障时间) = 故障修复时间点 - 故障发现时间点 网站年度可用性指标 = (1 - 网站不可用时间/年度总时间) * 100% 2个9基本可用，3个9较高可用，4个9具有自动恢复能力的高可用，5个9是极高可用性 网站可用性考核:故障分 = 故障时间 * 故障权重 高可用的网站架构分层+分割+集群 高可用的应用 通过负载均衡进行无状态服务的失效转移 应用服务器集群的session管理 session复制：简单，适用于集群规模较小的情况 session绑定：粘性session 利用cookie记录 session：简单易用，可用性高，支持线性伸缩，但是每次响应都会传输cookie，影响性能。 session服务器：利用分布式缓存。 高可用的应用 分级管理：核心应用与服务优先使用更好的硬件；部署上进行隔离。 超时设置 异步调用 服务降级：手段有二：拒绝服务及关闭服务。 幂等性设计：业务代码层面通过有效性校验等。 高可用的数据 CAP原理 数据持久性 数据可访问性 数据一致性 数据强一致性 数据用户一致性 数据最终一致性 数据备份 冷备:简单廉价，成本和技术难度低；但不能保证数据最终一致。恢复时间可能会长，一段时间不可用。 热备：同步和异步方式 失效转移 失效确认 访问转移 数据恢复 高可用软件质量保障 网站发布：脚本发布，流程大致如下 关闭负载均衡服务器上一台或一小批服务器路由 关闭这些服务器应用 同步(复制)软件代码包到这些服务器上 启动这些服务器 打开负载均衡服务器这些服务器的路由 集群所有机器发布完成？是则退出：否则继续1. 自动化测试 预发布验证 代码控制 主干开发，分支发布 分支开发，主干发布 自动化发布 灰度发布 网站运行监控 监控数据采集 用户行为日志收集 服务器性能检测 运行数据报告 监控管理 系统报警 失效转移 自动优雅降级 永无止尽：网站的伸缩性架构网站伸缩性设计 不同功能进行物理分离实现伸缩 纵向分离(分层后分离) 横向分离(业务分割后分离) 单一功能通过集群实现伸缩 应用服务器集群伸缩设计 http重定向负载均衡：简单，但是浏览器需要两次请求服务器。 Dns域名解析负载均衡：省掉了管理运维负载均衡服务器的麻烦，能支持基于地理位置的域名解析加速访问；但是生效时间较长，以及无法做更多改善和更强大的管理。 反向代理负载均衡：发生在http协议层，也叫应用层负载均衡。 ip负载均衡：发生在网络层，修改请求目标地址进行负载均衡。 数据链路层负载均衡：发生在通信协议的数据链路层，通过修改mac地址进行负载均衡。广泛使用的一种方式，比如：LVS(Linux Virtual Server) 负载均衡算法 轮询 加权轮询 随机 最少链接 源地址散列 分布式缓存集群的伸缩性设计 Memcached分布式缓存集群的访问模型 Memcached分布式缓存集群的伸缩性挑战 分布式缓存的一致性hash算法 数据存储服务器集群的伸缩性设计 关系数据库集群的伸缩性设计：从业务上回避分布式关系型数据库的各种缺点：避免事务或利用事务补偿机制代替数据库事务；避免JOIN操作等。 Nosql数据库的伸缩性设计 随机应变：网站的可扩展性架构构建可扩展性的网站架构软件架构师的最大价值不在于掌握多少先进的技术，而在于具有将一个大系统切分层N个低耦合的子模块的能力，这些子模块包含横向的业务模块，也包含纵向的基础技术模块。 利用分布式消息队列降低系统耦合性 事件驱动架构 分布式消息队列 利用分布式服务打造可复用的业务平台 web service与企业级分布式服务：缺点有臃肿的注册和发现机制，抵消的XML序列化手段，开销相对较高的HTTP远程通信，复杂的部署与维护手段。 大型网站分布式服务的需求与特点 负载均衡 失效转移 高效的远程通信 整合异构系统 对应用最少侵入 版本控制 实时监控 分布式服务框架设计 可扩展的数据结构利用NoSQL的ColumnFamily(列族)设计。 利用开放平台建设网站生态圈 api接口 协议转移 安全 审计 路由 流程 固若金汤：网站的安全架构道高一尺魔高一丈的网站应用攻击与防御全球70%的web攻击来自XSS攻击和SQL注入。 xss攻击 消毒：转移html字符 httponly：避免攻击脚本窃取 注入攻击 开源 错误回显 盲注 消毒 参数绑定 csrf攻击：防御的主要手段是识别访问者身份。 表单token 验证码 referer check 其他攻击和漏洞 error code html注释 文件上传 路径遍历 web应用防火墙 网站安全漏洞扫描 信息加密技术及密钥安全管理 单向散列加密：MD5,SHA等 对称加密：DES,RC等 非对称加密：RSA等 密钥安全管理 信息过滤与反垃圾 文本匹配 正则表达式匹配：适用于敏感词较少 Trie树、双数组Trie树：时间和空间复杂度都较好 多级hash表：速度较快，但浪费部分空间 分类算法：朴素贝叶斯算法。 黑名单：布隆过滤器。 电子商务风险控制 风险 账号风险 买家风险 卖家风险 交易风险 风控 规则引擎 统计模型 总结大致总结了李智慧老师的《大型网站技术架构——核心原理与案例分析》一书中的部分知识点的原理部分， 又重新加深了架构演进的过程。建议还是需要购买原书看一看。]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>read notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(五)：Callable、Future和FutureTask]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-callable-future-futureTask%2F</url>
    <content type="text"><![CDATA[前言创建一个线程，最熟悉的做法是集成Thread类或者实现Runnable接口重新run()。 但是这两种创建方式在一些场景比如想要获取线程的执行结果时却不那么好用。J.U.C满足了这种需求。 今天说一下不得不知的Callable、Future和FutureTask Callable比对Runnable接口与Callable接口： public interface Runnable { public abstract void run(); } public interface Callable&lt;V&gt; { V call() throws Exception; } 可以看到，Callable接口代表一种能返回结果并可能引发异常的任务。 实现者只要实现call()并返回任务结果即可。 Callable接口类似于Runnable，但是，Runnable不返回结果，也不能抛出被检查的异常。 一个好的事实是，无论是Callable还是Runnable，都可以很好的与Executor框架结合使用： &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); Futurefuture,单从语义上就知道代表未来，实际上也是如此。 先看接口定义： public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } Future提供了5个方法: cancel(boolean mayInterruptIfRunning):尝试取消执行此任务。 isCancelled():如果此任务在正常完成之前被取消，则返回 true 。 isDone():如果任务已完成返回 true。 get():一直阻塞直至获取执行结果。 get(long timeout, TimeUnit unit)：在指定时间内获取执行结果，获取不到抛出TimeoutException FutureTaskFutureTask实现了RunnableFuture接口，看下RunnableFuture接口： public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; { void run(); } 可以看到它即实现了Runnable接口，也实现了Future接口，因此FutureTask可以作为Runnable的实现， 也可以作为Future来获取Callable的返回。看其构造器便知如何选择： public FutureTask(Callable&lt;V&gt; callable) { } public FutureTask(Runnable runnable, V result) { } 推荐的使用方式开发中建议使用线程池+Callable返回Future的方式来获取异步结果,最好给予超时时间： ExecutorService es = Executors.newSingleThreadExecutor(); Future&lt;Integer&gt; future = es.submit(() -&gt; { try { System.out.println(&quot;开始执行计算任务...&quot;); Thread.sleep(5000L); } catch (InterruptedException e) { e.printStackTrace(); } return 100; }); es.shutdown(); // Integer integer = future.get(); // System.out.println(&quot;get() 获取异步任务结果:&quot; + integer); Integer integer; try { integer = future.get(2, TimeUnit.SECONDS); } catch (TimeoutException e) { System.out.println(&quot;调用超时，返回错误结果&quot;); integer = -1; } System.out.println(&quot;get(timeout) 获取异步任务结果:&quot; + integer); } 返回的结果值: 开始执行计算任务... 调用超时，返回错误结果 get(timeout) 获取异步任务结果:-1]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(四)：闭锁与栅栏]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-latch-and-barrier%2F</url>
    <content type="text"><![CDATA[前言闭锁(CountDownlatch)和栅栏(CyclicBarrier)功能看起来相似，都是同步工具类， 看起来都是可以阻塞一个操作，等待其依赖的一组操作完成之后再执行。但是害死有所区别。 闭锁闭锁(CountDownlatch)：允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。 注意这里有两种线程，一种是等待的线程，一种是执行线程。 它的应用场景比如： 确保某个计算在其需要的所有资源都初始化后继续执行。即，这个计算依赖于资源初始化，必须等待所有依赖资源初始化后执行。 确保某个服务在其依赖的所有其他服务启动之后才能启动。 等待直到某个操作的所有参与者都就绪后再继续执行。 闭锁示例举例说明，比如有三个玩家，游戏开始必须在三个玩家就绪后才能开始。 这里用两个类来模拟这种情况，分别是玩家(Player)和游戏(Game). 玩家： public class Player implements Runnable { private CountDownLatch downLatch; private String name; public Player(CountDownLatch downLatch, String name) { this.downLatch = downLatch; this.name = name; } @Override public void run() { System.out.println(&quot;玩家:&quot; + name + &quot;正来赶来游戏场地的路上！&quot;); try { Thread.sleep(new Random().nextInt(10000)); } catch (InterruptedException ie) { } System.out.println(&quot;玩家:&quot; + name + &quot;已准备就绪！&quot;); this.downLatch.countDown(); } } 游戏： public class Game implements Runnable { private CountDownLatch downLatch; public Game(CountDownLatch downLatch) { this.downLatch = downLatch; } @Override public void run() { System.out.println(&quot;游戏尚未开始，正在等待玩家就绪...&quot;); try { this.downLatch.await(); } catch (InterruptedException ie) { } System.out.println(&quot;所有玩家已就绪，游戏开始&quot;); this.downLatch.countDown(); } } 运行测试程序： public static void main(String[] args) { ExecutorService executor = Executors.newCachedThreadPool(); CountDownLatch latch = new CountDownLatch(3); Player p1 = new Player(latch, &quot;A&quot;); Player p2 = new Player(latch, &quot;B&quot;); Player p3 = new Player(latch, &quot;C&quot;); Game game = new Game(latch); executor.execute(p1); executor.execute(p2); executor.execute(p3); executor.execute(game); executor.shutdown(); } 结果： 玩家:A正来赶来游戏场地的路上！ 玩家:C正来赶来游戏场地的路上！ 游戏尚未开始，正在等待玩家就绪... 玩家:B正来赶来游戏场地的路上！ 玩家:C已准备就绪！ 玩家:A已准备就绪！ 玩家:B已准备就绪！ 所有玩家已就绪，游戏开始 可见，Game线程和所有Player都持有同一把闭锁，Game线程等待所有Player闭锁释放后才能继续执行，否则则一直等待。 关键方法浅析原理分析：CountDownLatch里初始化会存有一个正数计算器，每次做countDown()操作时会把计算器减1，await()需要等待 计数器为0时才能释放，否则一直阻塞。 构造器给定一个初始化的计数值： public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count); } Sync是闭锁内部类，继承了AQS，并重写了tryAcquireShared(int acquires)和tryReleaseShared(int releases)方法， 可见其采用共享锁实现。 await()内部使用AQS的acquireSharedInterruptibly(int arg)： public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } AQS中的acquireSharedInterruptibly(int arg)： public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); } 关键点在这个tryAcquireShared方法中，闭锁内部类Sync重写了这个方法： protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } 这里的getState就是计数器的个数，当个数为0时可以获取到共享锁。 再看countDown()，其目的是减少计数器个数。 public void countDown() { sync.releaseShared(1); } 其内部也是调用AQS的releaseShared(int arg)方法来释放共享锁同步状态： public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 这里的tryReleaseShared是内部类Sync重写的： protected boolean tryReleaseShared(int releases) { for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; } } 可见此处计算器进行了减1操作，知道状态为0时释放锁。 栅栏栅栏(CyclicBarrier)类似于闭锁，但其还是不同。 api中介绍： 允许一组线程全部等待彼此达到共同屏障点的同步辅助。 循环阻塞在涉及固定大小的线程方的程序中很有用，这些线程必须偶尔等待彼此。 屏障被称为循环 ，因为它可以在等待的线程被释放之后重新使用。 再引用java并发编程实战里的解释： 栅栏类似于闭锁，它能阻塞一组线程直到某个事件发生。 栅栏与闭锁的关键区别在于，所有的线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。 所以关注点在于”栅栏”(共同屏障点)这个位置，这一组线程必须都到达栅栏以后才可以都继续执行。 栅栏示例比如三个人共同商议6点钟去麦当劳碰头，等到三个人都到达以后，一起商讨去干什么。 这里用栅栏实现，只需要一个Person类： public class Persion implements Runnable { private CyclicBarrier cyclicBarrier; private String name; public Persion(CyclicBarrier cyclicBarrier, String name) { this.name = name; this.cyclicBarrier = cyclicBarrier; } @Override public void run() { System.out.println(name + &quot;正来赶来麦当劳的路上...&quot;); try { Thread.sleep(new Random().nextInt(10000)); System.out.println(name + &quot;到达麦当劳...&quot;); cyclicBarrier.await(); } catch (BrokenBarrierException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(name + &quot;说：大家都到齐了，开始商量干什么吧！&quot;); } } 运行程序： public static void main(String[] args) { ExecutorService executor = Executors.newCachedThreadPool(); CyclicBarrier barrier = new CyclicBarrier(3); Persion p1 = new Persion(barrier, &quot;A&quot;); Persion p2 = new Persion(barrier, &quot;B&quot;); Persion p3 = new Persion(barrier, &quot;C&quot;); executor.execute(p1); executor.execute(p2); executor.execute(p3); executor.shutdown(); } 运行结果： A正来赶来麦当劳的路上... C正来赶来麦当劳的路上... B正来赶来麦当劳的路上... B到达麦当劳... A到达麦当劳... C到达麦当劳... C说：大家都到齐了，开始商量干什么吧！ B说：大家都到齐了，开始商量干什么吧！ A说：大家都到齐了，开始商量干什么吧！ 可见，所有线程都等到了其栅栏点才可以继续执行。 可能有时候需要我们的执行线程希望做到类似闭锁的情况，即到达栅栏点时，只执行一次处理。 CyclicBarrier有个这么个构造器(public CyclicBarrier(int parties, Runnable barrierAction))可以实现： 修改上面的Persion类： public class Persion implements Runnable { private CyclicBarrier cyclicBarrier; private String name; public Persion(CyclicBarrier cyclicBarrier, String name) { this.name = name; this.cyclicBarrier = cyclicBarrier; } @Override public void run() { System.out.println(name + &quot;正来赶来麦当劳的路上...&quot;); try { Thread.sleep(new Random().nextInt(10000)); System.out.println(name + &quot;到达麦当劳...&quot;); cyclicBarrier.await(); } catch (BrokenBarrierException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } } } 执行程序： public static void main(String[] args) { ExecutorService executor = Executors.newCachedThreadPool(); CyclicBarrier barrier = new CyclicBarrier(3, new Runnable() { @Override public void run() { System.out.println(&quot;大家都到齐了，开始商量干什么吧！&quot;); } }); Persion p1 = new Persion(barrier, &quot;A&quot;); Persion p2 = new Persion(barrier, &quot;B&quot;); Persion p3 = new Persion(barrier, &quot;C&quot;); executor.execute(p1); executor.execute(p2); executor.execute(p3); executor.shutdown(); } 运行结果： A正来赶来麦当劳的路上... C正来赶来麦当劳的路上... B正来赶来麦当劳的路上... C到达麦当劳... A到达麦当劳... B到达麦当劳... 大家都到齐了，开始商量干什么吧！ 关键方法浅析构造器有两个： public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } public CyclicBarrier(int parties) { this(parties, null); } parties是拦截的线程数，当拦截的线程数达到这个值之前，线程会一直等待。 barrierAction是当拦截的线程数达到parties时，由最后一个进入的线程执行此操作。 await()方法，所有的参与者在此等待： public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L);//不超时等待 } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; lock.lock(); try { final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } // 每次进度的线程，此count值减1，减到0时，触发barrierCommand任务 int index = --count; if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; nextGeneration(); // 此处唤醒所有等待线程 return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { breakBarrier(); throw ie; } else { // We&#39;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); } } 简单的说，dowait方法使得最后一个到达的线程到达之后，index == 0，执行Runnable任务，唤醒所有等待的线程。 总结闭锁和栅栏是实现并发同步操作的两把利器，有所相似又各有不同，抓住其原理关键点就很好理解了。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(三)：阻塞队列(BlockingQueue)]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-BlockingQueue%2F</url>
    <content type="text"><![CDATA[前言阻塞队列 (BlockingQueue)是j.u.c下重要的数据结构，BlockingQueue提供了线程安全的队列访问方式： 当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。 接口 BlockingQueue提供的方法API从API文档上看，BlockingQueue定义的方法有四种形式，具有不同的操作方式，不能立即满足，但可能在将来的某个时间点满足： 一个抛出异常，第二个返回一个特殊值（ null或false ，具体取决于操作），第三个程序将无限期地阻止当前线程，直到操作成功为止， 而第四个程序块在放弃之前只有给定的最大时限。 这些方法总结在下表中： method\way Throws exception Special value Blocks Times out Insert add(e) offer(e) put(e) offer(e, time, unit) Remove remove() poll() take() poll(time, unit) Examine element() peek() not applicable not applicable 简单解释一下四种行为方式： 抛异常(Throws exception)：如果试图的操作无法立即执行，抛一个异常。 特定值(Special value)：如果试图的操作无法立即执行，返回一个特定的值(常常是 true / false)。 阻塞(Blocks)：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时(Times out)：如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是true / false)。 使用场景阻塞队列的典型使用场景就是生产者 - 消费者场景，它可以安全的与多个生产者和多个消费者一起使用。 引用API文档里的例子： class Producer implements Runnable { private final BlockingQueue queue; Producer(BlockingQueue q) { queue = q; } public void run() { try { while (true) { queue.put(produce()); } } catch (InterruptedException ex) { ... handle ...} } Object produce() { ... } } class Consumer implements Runnable { private final BlockingQueue queue; Consumer(BlockingQueue q) { queue = q; } public void run() { try { while (true) { consume(queue.take()); } } catch (InterruptedException ex) { ... handle ...} } void consume(Object x) { ... } } class Setup { void main() { BlockingQueue q = new SomeQueueImplementation(); Producer p = new Producer(q); Consumer c1 = new Consumer(q); Consumer c2 = new Consumer(q); new Thread(p).start(); new Thread(c1).start(); new Thread(c2).start(); } } 其他特性 不接受null元素。当尝试对一个阻塞队列执行add,put或offer一个null对象时，会抛出NullPointerException。 BlockingQueue实现是线程安全的。 所有排队方法使用内部锁或其他形式的并发控制在原子上实现其效果。 BlockingQueue常见实现类与介绍 有界阻塞队列：ArrayBlockingQueue,LinkedBlockingQueue… 无界阻塞队列：PriorityBlockingQueue,DelayQueue… 优先级阻塞队列：PriorityBlockingQueue 延迟阻塞队列：DelayQueue ArrayBlockingQueue有界阻塞队列，FIFO队列，内部是通过数组实现的，大小固定，创建后容量无法修改。尝试put成满的队列的元件将导致在操作阻挡; 尝试take从空队列的元件将类似地阻塞。 举个栗子： public class BlockingQueueTest { /** * 实例化一个队列，队列中的容量为10 */ private static BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10); public static void main(String[] args) { ScheduledExecutorService product = Executors.newScheduledThreadPool(1); Random random = new Random(); product.scheduleAtFixedRate(() -&gt; { int value = random.nextInt(101); try { blockingQueue.offer(value); //offer()方法就是往队列的尾部设置值 System.out.println(&quot;已经往队列里加入数据:&quot; + value); } catch (Exception ex) { ex.printStackTrace(); } }, 0, 100, TimeUnit.MILLISECONDS); //每100毫秒执行线程 new Thread(() -&gt; { while (true) { try { Thread.sleep(1000); Integer poll = blockingQueue.poll();// 弹出 System.out.println(&quot;已经从队列里取出数据:&quot; + poll); } catch (InterruptedException e) { e.printStackTrace(); } } }).start(); } } 以上实现一个固定队列的例子，容量为10，可以通过构造器创建容量大小为n的阻塞队列。 LinkedBlockingQueue有界阻塞队列，FIFO队列，基于链表实现，创建时可以不指定容量，不指定时默认容量Integer.MAX_VALUE。队列的节点可以动态扩展，只是不能超过容量。 这一点上与ArrayBlockingQueue区别在于ArrayBlockingQueue创建后不能再扩展队列的元素了。 使用方式，将上面的BlockingQueueTest里的阻塞队列的实现改为LinkedBlockingQueue即可。 PriorityBlockingQueue无界阻塞队列，优先级排序。 PriorityBlockingQueue只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容。 所以，虽然这个队列逻辑上无界，但是可能会耗尽资源导致OOM的问题。 PriorityBlockingQueue的内部排序默认是自然排序，也可通过omparator指定排序规则，便于自定义优先级逻辑。 PriorityBlockingQueue内部也是通过数组实现，数组的容量可以动态扩展，源码如下： /** * Tries to grow array to accommodate at least one more element * (but normally expand by about 50%), giving up (allowing retry) * on contention (which we expect to be rare). Call only while * holding lock. * * @param array the heap array * @param oldCap the length of the array */ private void tryGrow(Object[] array, int oldCap) { lock.unlock(); // must release and then re-acquire main lock Object[] newArray = null; if (allocationSpinLock == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) { try { int newCap = oldCap + ((oldCap &lt; 64) ? (oldCap + 2) : // grow faster if small (oldCap &gt;&gt; 1)); if (newCap - MAX_ARRAY_SIZE &gt; 0) { // possible overflow int minCap = oldCap + 1; if (minCap &lt; 0 || minCap &gt; MAX_ARRAY_SIZE) throw new OutOfMemoryError(); newCap = MAX_ARRAY_SIZE; } if (newCap &gt; oldCap &amp;&amp; queue == array) newArray = new Object[newCap]; } finally { allocationSpinLock = 0; } } if (newArray == null) // back off if another thread is allocating Thread.yield(); lock.lock(); if (newArray != null &amp;&amp; queue == array) { queue = newArray; System.arraycopy(array, 0, newArray, 0, oldCap); } } DelayQueue无界阻塞队列，其元素是一个Delayed元素，其元素只能在其延迟到期时才被使用。 在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。 其使用场景： 定时任务调度。通过DelayQueue保存执行的任务和执行时间，当从DelayQueue中获取到任务时立即执行，从而实现定时调度。 缓存有效期。缓存元素的有效期，当循环获取队列的元素时，只要获取到就说明缓存有效期过了。 其他队列除了常用的队列以外，jdk还提供了一些其他的实现，比如：SynchronousQueue，LinkedTransferQueue，LinkedBlockingDeque等， 各有特色与其使用场景。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(二)：并发容器类]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-collections%2F</url>
    <content type="text"><![CDATA[前言jdk1.5之前，线程安全的容器类有HashTable,Vector等实现。但是其内部使用的是synchronized内置锁这样重量级的实现，在高并发的情况下大大影响性能。 jdk1.5之后，j.u.c中有了基于CAS实现的更加高并发的实现来极大的提高伸缩性。 ConcurrentHashMapConcurrentHashMap是当前最常使用的并发容器之一，它同样也实现了AbstractMap接口，所以使用它就像是使用HashMap等线程不安全的容器一样使用。 存储结构static final class HashEntry&lt;K,V&gt; { final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; } 和HashMap类似，也是基于哈希桶的结构，最主要的区别在于，ConcurrentHashMap采用了分段锁Segment来加锁，并不是整个结构都加锁，使得多个线程可以访问不同分段锁上的桶，从而实现更高的并发。 关于并发等级，即分段锁的个数，在源码里默认的并发等级是16： /** * The default concurrency level for this table. Unused but * defined for compatibility with previous versions of this class. */ private static final int DEFAULT_CONCURRENCY_LEVEL = 16; Segment的结构: /** * Stripped-down version of helper class used in previous version, * declared for the sake of serialization compatibility */ static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable { private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) { this.loadFactor = lf; } } 所以其大致的结构是这样的: 重要的方法put(K key, V value)public V put(K key, V value) { return putVal(key, value, false); } 如果key存在也替换value值： /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 简诉以上代码逻辑： 判断key,value均不能为null。 计算key的hash值。 开始遍历整个table。 table为null时初始化table 计算节点位置，如果该位置没有别的节点则直接插入，不需要加锁 (fh = f.hash) == MOVED，如果有线程正在扩容，则先帮助扩容 4 如果该节点位置有别的节点，加锁处理。 如果该节点位置上目前fh &gt;= 0，则为链表结构，遍历链表，如果key节点相同则替换value，否则插入链表尾部。 如果该位置节点上是TreeBin类型，则以红黑树的方式赠加节点。 ConcurrentHashMap 的 size + 1。 get(Object key)public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null; } 简诉以上代码逻辑： 计算key的hash值。 判断table是否有值，没值直接返回null。 获取table中的node节点，如果是链表则遍历查找到相同key的value，如果是红黑树则调用e.find(h, key)找到value。 size()size()操作是一个费劲的操作，在1.7以及之前的版本中，size()是需要获取每个Segment中的count值累加获取的，由于可能存在size的同时有线程正在put或者remove操作， 所以其返回的值可能不精确。 而1.8之后，ConcurrentHashMap提供了baseCount、counterCells两个辅助变量和一个CounterCell辅助内部类来计算size()。 具体代码暂不展示了，在实际操作中实际上很少用到size()方法。 CopyOnWriteArrayListCopyOnWriteArrayList是用于替代同步List,它提供了更好的并发性。同理的CopyOnWriteArrayList是替代同步Set。 写入时复制(Copy-On-Write)，这一类容器的特点是，访问该对象时不需要再进行一次同步，但每次修改时都会创建并重新发布一个新的容器副本从而实现可变性。 读写分离，写在一个新的副本数组上执行，此处需加锁；读操作直接读原始数组。写操作完成后会把原始数组指向新数组： public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); } } final void setArray(Object[] a) { array = a; } 因此，增删元素等都是花费很大的开销，典型的空间换时间的方式，只有当迭代操作远远多于修改操作时，才应当使用Copy-On-Write容器。 总结除此之外，还有一些有各自应用场景的并发集合类比如ConcurrentSkipListMap和ConcurrentSkipListSet。 最主要的重点集合类便是ConcurrentHashMap了，其代码在jdk1.7和1.8之间还有不同。建议阅读源码顺序：1.7的HashMap-&gt;1.7的ConcurrentHashMap-&gt;1.8的HashMap-&gt;1.8的ConcurrentHashMap。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析java并发包(一)：原子类和锁]]></title>
    <url>%2Fjava-concurrency%2Fjava-util-concurrent-atomic-and-locks%2F</url>
    <content type="text"><![CDATA[前言jdk 1.5开始，新增了java.util.concurrent包（以下简称j.u.c），是一系列关于并发的工具类，是java并发编程必知必会的内容。今儿准备简单介绍一些常用的工具类。 原子类java.util.concurrent.atomic包提供了一些专门为线程安全设计的java操作原子类。 见名知意，类名基本以 Atomic 开头，表示这些类都是线程安全的。 明明提供线程安全的锁，为什么还要提供这些基础的类呢？ 这就必须说明，这些原子类与通过synchronized加锁实现的对象不同，以往通过synchronized等加锁的实现我们认为是一种悲观锁的体现， 即不论谁来操作，都假设最坏的情况，必须加锁独占，让其他需要操作的线程挂起等待锁释放。这种情况是具有比较大的开销的，线程抢占锁的花费的时间代价非常高。 所以这里就体现了原子类存在的强大意义。原子类的底层代码是利用了现代CPU的CAS指令来完成赋值操作的。 CAS是乐观锁技术，原称:Compare and Swap,比较并交换。操作之前会比较内存值V与预期值A是否一致，并且仅当V == A时，才会把V赋值为新值B。 举个例子，AtomicInteger的incrementAndGet操作: public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } 其调用了sun.misc.Unsafe的方法，这里的compareAndSwapInt是一个本地方法，起调用了CPU的CAS指令。 public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } 锁java.util.concurrent.locks包下提供了很方方便加锁的工具。其下最知名的应该是ReentrantLock，但是提到ReentrantLock之前，最需要提的是AbstractQueuedSynchronizer。 AQSAbstractQueuedSynchronizer简称AQS，见名知意，抽象的基于队列的同步器，本质上是提供并定义了一套多线程访问共享资源的模板。 这个模板应用广泛，大部分锁的实现都基于此： 源码中的描述: The wait queue is a variant of a “CLH” (Craig, Landin, and Hagersten) lock queue. CLH是一种自旋锁，提供先来先服务的公平性，其基于链表，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。 AQS提供了两种资源共享方式:Exclusive(独占) 和 Shared(共享)。 我们开发中自定义队列同步器很少，更多的实现都在jdk中。 ReentrantLockReentrantLock是开发中比较常用的显示锁。其性能在jdk1.5的时候是比synchronized关键字高出许多的，但是jdk1.6之后二者实际上不分伯仲。 但是ReentrantLock还是有其独特的特性：轮询锁、定时锁、可中断锁、公平锁等，并且使用更加灵活。 其基本使用方式: Lock lock = new ReentrantLock(); ... lock.lock(); // 上锁 try { // 处理共享资源 } finally { lock.unlock(); // 解锁 } 轮询锁与定时锁轮询锁与定时锁是由tryLock方法实现的，与无条件的锁获取方式相比，它具有跟完善的错误回复机制。 轮询锁之转账问题假设在银行系统把账户A的钱转给账户B，必须保证多线程并发安全，加锁是必不可少的，但是在获取多个锁的情况下，如果通过内置锁，很可能发生死锁问题。 解决方式：通过tryLock尝试同时获取多个锁，如果不能同时获取，就回退重试。 账户类，每个账户都持有一把锁： @Data @Builder class Account { private BigDecimal balance; // 账户余额 private String name; // 账户名称 public Lock lock; void debit(BigDecimal amount) { balance = balance.subtract(amount); } void credit(BigDecimal amount) { balance = balance.add(amount); } @Override public String toString() { return new StringBuilder(name).append(&quot;的余额为:&quot;).append(balance).toString(); } } 使用tryLock尝试获取锁，进行两个账户的转账: public class TransferService { public boolean transferAccount(Account fromAcct, Account toAcct, BigDecimal amount, long timeout) throws InterruptedException { long stopTime = System.currentTimeMillis() + timeout; while (true) { if (fromAcct.lock.tryLock()) { try { if (toAcct.lock.tryLock()) { try { if (fromAcct.getBalance().compareTo(amount) &lt; 0) { throw new RuntimeException(&quot;转账账户余额不足&quot;); } else { fromAcct.debit(amount); toAcct.credit(amount); System.out.println(&quot;转账人:&quot; + fromAcct.toString()); System.out.println(&quot;被转账人:&quot; + toAcct.toString()); return true; } } finally { toAcct.lock.unlock(); } } else { System.out.println(&quot;toAcct.lock.tryLock() false&quot;); } } finally { fromAcct.lock.unlock(); } } else { System.out.println(&quot;fromAcct.lock.tryLock() false&quot;); } if (System.currentTimeMillis() &gt; stopTime) { return false; } Thread.sleep(1000L); } } public static void main(String[] args) { Lock lock1 = new ReentrantLock(); Lock lock2 = new ReentrantLock(); final Account fromAcct = Account.builder().lock(lock1).name(&quot;老王&quot;).balance(new BigDecimal(1000)).build(); final Account toAcct = Account.builder().lock(lock2).name(&quot;老李&quot;).balance(new BigDecimal(1000)).build(); TransferService service = new TransferService(); Runnable runnable = new Runnable() { @Override public void run() { try { service.transferAccount(fromAcct, toAcct, new BigDecimal(50), 1000); } catch (InterruptedException e) { e.printStackTrace(); } } }; for (int i = 0; i &lt; 10; i++) { new Thread(runnable).start(); } } } 如下运行结果，可以看到尝试获取锁多次。如果修改调用参数里的timeout 值，可能会出现转账失败的情况。 fromAcct.lock.tryLock() false 转账人:老王的余额为:950 被转账人:老李的余额为:1050 转账人:老王的余额为:900 fromAcct.lock.tryLock() false 被转账人:老李的余额为:1100 转账人:老王的余额为:850 被转账人:老李的余额为:1150 fromAcct.lock.tryLock() false 转账人:老王的余额为:800 被转账人:老李的余额为:1200 fromAcct.lock.tryLock() false 转账人:老王的余额为:750 被转账人:老李的余额为:1250 fromAcct.lock.tryLock() false fromAcct.lock.tryLock() false 转账人:老王的余额为:700 被转账人:老李的余额为:1300 fromAcct.lock.tryLock() false fromAcct.lock.tryLock() false 转账人:老王的余额为:650 被转账人:老李的余额为:1350 fromAcct.lock.tryLock() false fromAcct.lock.tryLock() false 转账人:老王的余额为:600 被转账人:老李的余额为:1400 fromAcct.lock.tryLock() false 转账人:老王的余额为:550 被转账人:老李的余额为:1450 转账人:老王的余额为:500 被转账人:老李的余额为:1500 定时锁的使用关键方法tryLock(long timeout, TimeUtil unit)，即申请获取锁设置等待时间，在此等待时间内尝试获取锁，如果锁被其他线程占有，则返回false. 这种方式可以有效的避免死锁的发生。 public class Service { public ReentrantLock lock = new ReentrantLock(); public void waitMethod() { try { if (lock.tryLock(3, TimeUnit.SECONDS)) { System.out.println(Thread.currentThread().getName() + &quot;获得锁的时间:&quot; + System.currentTimeMillis()); Thread.sleep(10000); } else { System.out.println(Thread.currentThread().getName() + &quot;没有获得锁&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } finally { if (lock.isHeldByCurrentThread()) { lock.unlock(); } } } } public class Run_tryLock_param { public static void main(String[] args) { final Service service = new Service(); Runnable runnable = new Runnable() { public void run() { System.out.println(Thread.currentThread().getName() + &quot; 调用waitMethod时间:&quot; + System.currentTimeMillis()); service.waitMethod(); } }; Thread threadA = new Thread(runnable); threadA.setName(&quot;A&quot;); threadA.start(); Thread threadB = new Thread(runnable); threadB.setName(&quot;B&quot;); threadB.start(); } } 如上所示，运行结果: A 调用waitMethod时间:1534690399458 B 调用waitMethod时间:1534690399458 A获得锁的时间:1534690399459 B没有获得锁 可中断锁java的内置锁synchronized就是不可中断的锁， 其不可中断的阻塞机制使得实现可取消的任务变得复杂。 Lock是可中断锁，lockInterruptibly可以使得在获得锁的同时保持对中断的响应。 lockInterruptibly基本使用方式: public void method() throws InterruptedException { lock.lockInterruptibly(); try { //do something } finally { lock.unlock(); } } 读写锁ReentrantReadWriteLock读写锁，它除了实现了Lock接口外，同时也实现了ReadWriteLock接口。 public interface ReadWriteLock { /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock(); } 总所周知，ReentrantLock是排它锁，无论什么操作（read or write），其同一时间只能一个线程访问。但是实际应用中，读操作往往是占据最多的场景，那么绝大部分读取的场景能否采用共享锁呢？ReentrantReadWriteLock就能满足这一点，它允许读读共享，但是读写，写写是排他的操作。 应用场景，见java doc api提供了一个读写锁的生动的使用范例： Here is a code sketch showing how to perform lock downgrading after updating a cache (exception handling is particularly tricky when handling multiple locks in a non-nested fashion): `java class CachedData { Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() { rwl.readLock().lock(); // 1.加读锁 if (!cacheValid) { // Must release read lock before acquiring write lock rwl.readLock().unlock(); // 2.释放读锁，因为要加写锁，不支持锁升级，只能先解读锁再加写锁 rwl.writeLock().lock();// 3.加写锁 try { // Recheck state because another thread might have // acquired write lock and changed state before we did. if (!cacheValid) { // 见上面英文解释，简单的说避免重复写入数据 data = … cacheValid = true; } // Downgrade by acquiring read lock before releasing write lock rwl.readLock().lock();// 4.锁降级，写锁变读锁 } finally { rwl.writeLock().unlock(); // Unlock write, still hold read 5.见英文，解写锁，仍然能读 } } try { use(data); } finally { rwl.readLock().unlock(); // 6.最终释放读锁 } } } ` 为什么要有锁降级？因为锁降级的过程能避免在写锁释放，加读锁的过程中，此时读取的数据不会被其他线程竞争到写锁更新数据导致脏读问题。 总结j.u.c是实现java高并发必知必会的重要内容。在很多web相关框架中都有体现，也是java程序猿进阶的必备技能之一，多学多用。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，艾泽拉斯]]></title>
    <url>%2Fessay%2FGoodbye-Azeroth%2F</url>
    <content type="text"><![CDATA[再见终于，这一刻还是来了。2018年8月13日开始，彻底AFK了。虽然玩的菜，但好歹是玩的最久的游戏，就此告别，很开心有生之年去过艾泽拉斯。 AFK的原因直接原因，是月卡的推出的这两年。官方公告： 《魔兽世界》已于2016年8月4日从分钟付费模式转为包月畅玩模式。此后的两年内，账号里仍有剩余分钟时间的玩家可以选择继续消耗分钟进行游戏，也可通过游戏内的兑换功能，按以下比例将分钟换为包月模式下的天数： 150分钟=1天；不足150分钟的部分按150分钟计算 自2018年8月4日起，玩家将无法使用分钟时间继续登录游戏。我们将通过专题网站为这部分玩家提供如下的兑换选项： 150分钟=1天；不足150分钟的部分按150分钟计算 或以90分钟=1点的比例退还暴雪游戏点数至游戏账号关联的暴雪游戏通行证，小数部分向上取整，如7.1点计为8点。 注：账号冻结期间不能参与兑换；而通过战友招募等途径获取的免费时间将无法转为暴雪游戏点数，仅可换成包月天数。 2016年的8月4日之前得到了官方公告，2016年8月4日后将不再支持点卡。于是乎大批休闲玩家(没时间一直玩)的玩家大批量囤游戏时间。没错，包括我，我囤了十张点卡。 时间过得真的飞快，得到官方公告后才发现自那以后居然已经过了两年时间了… 这两年的时间总共的游戏时间还不到24小时。 根本原因，则是时间。 今天，又重新把时间兑换成了战网点数。感觉青春突然又走了一些。 初识艾泽拉斯那是2008年的夏天，那年初中刚毕业，和磊少顺子去常州找好哥们猴子玩。猴子算是我对电脑的”启蒙老师”，他教会了我电脑是如何用来玩游戏的。。。 猴子初中的时候离开了我们。。。不是永久的那种，跟他父母移居到常州去了，每年还是能回蚌埠来玩几天的。 在常州度过了难忘的几天，我们宅在家里玩游戏，第一次接触魔兽是那时候看猴子和他朋友打22竞技场，他们是战德组合，猴子就是德，所以就打德。 炫酷的界面，复杂的技能栏，各种监控插件，最重要的是种族好多啊，牛头人真的很可爱，仅次于兽人妹纸。 后来上了高一后，上网吧成了周末的必备活动，好孩子表示周一到周五不能上网吧，原因是没时间。 那时候的周末总是那么美好，周六上午包个早机，中午回家吃饭后上一会儿网接着去打球，简单而充实的快乐。 高一那年，认识了鸣鸣，一个活逗比。那会儿开号也是要花一张大卡的，我俩分表练了侏儒盗贼和侏儒法师。为什么玩侏儒，可能是比较符合我们猥琐的气质吧。 那会儿印象最深的是艾尔文森林的鱼人族们，嗯，让我们跑尸的那群哇啦啦们。 然后是杀霍格，第一个小BOSS，年轻的我以为同级的怪都能打过，没想到是还得靠磊少的大号SS带了把。吐槽一下磊少的术士， ID:囡囡不坏。嗯，非常接地气。 第一个FB，西部荒野的地下矿井。还是靠磊少的SS。套用磊少一句话：火石法杖，极品。 后来记得很清楚，17级的时候，号被盗了。那时候的盗号还是非常疯狂的，用密保吧太费事，不用密保稳被盗，没想到的是我的不到20级的号都能被盗。于是乎，我的第一个侏儒贼算是折戟了。 再识艾泽拉斯很长一段时间没有玩了，后来猴子给了个号，44级人类盗贼，又让我重新回到艾泽拉斯。不得不说，人类盗贼潜行的样子真的很猥琐。 第一次荣誉击杀，是在塔纳瑞斯，野外遇到一个部落的猎人，第一反应，潜行。嗯，盗贼就得有盗贼的样子。悄悄潜过去，偷袭，背刺，肾击。总之就是一顿技能上去追着干。职业优势了也是，拿下艾泽拉斯一血。 【得睡觉了，未完待续…】]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS解决pycurl安装的坑]]></title>
    <url>%2Fpython%2Fmacos-fix-problem-about-pycurl-install%2F</url>
    <content type="text"><![CDATA[前言记录macos安装pycurl过程中的爬坑过程。 爬坑过程记录本来目的是安装pyspider的, 安装pyspider必须依赖pycurl。 本人环境： Python 3.6.4 MacOS 10.12 Sierra 初次安装 pycurl第一次安装pycurl。直接 pip 安装 pip install pycurl 可是安装并不顺利。安装报错: ... File &quot;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-y_b53n5l/pycurl/setup.py&quot;, line 316, in configure_unix specify the SSL backend manually.&#39;&#39;&#39;) __main__.ConfigurationError: Curl is configured to use SSL, but we have not been able to determine which SSL backend it is using. Please see PycURL documentation for how to specify the SSL backend manually. ---------------------------------------- Command &quot;python setup.py egg_info&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-y_b53n5l/pycurl/ 可以看到报错应该是因为 使用ssl配置的原因。查看官方PycURL Installation¶，可以不使用ssl安装。 第二次安装 pycurl第二次安装，配置不使用ssl安装。 # upgrade pip if necessary pip install --upgrade pip # remove current pycurl pip uninstall pycurl # set PYCURL_SSL_LIBRARY export PYCURL_SSL_LIBRARY=nss # recompile and install pycurl pip install --compile pycurl 可是还是报错: ... build/temp.macosx-10.12-x86_64-3.6/src/stringcompat.o build/temp.macosx-10.12-x86_64-3.6/src/threadsupport.o build/temp.macosx-10.12-x86_64-3.6/src/util.o -lssl3 -lcurl -o build/lib.macosx-10.12-x86_64-3.6/pycurl.cpython-36m-darwin.so ld: library not found for -lssl3 clang: error: linker command failed with exit code 1 (use -v to see invocation) error: command &#39;clang&#39; failed with exit status 1 ---------------------------------------- Command &quot;/Users/chenruiwen/.pyenv/versions/3.6.4/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&#39;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-syesb72n/pycurl/setup.py&#39;;f=getattr(tokenize, &#39;open&#39;, open)(__file__);code=f.read().replace(&#39;\r\n&#39;, &#39;\n&#39;);f.close();exec(compile(code, __file__, &#39;exec&#39;))&quot; install --record /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-record-ch2zxgp5/install-record.txt --single-version-externally-managed --compile&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-syesb72n/pycurl/ 二次吐血。 第三次安装pycurl还是根据官网，nss不可以，配置成openssl试试吧。 pip uninstall pycurl export PYCURL_SSL_LIBRARY=openssl pip install --compile pycurl 还是那个熟悉的味道: ... clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/Cellar/openssl/1.0.2o_1/include -DPYCURL_VERSION=&quot;7.43.0.2&quot; -DHAVE_CURL_SSL=1 -DHAVE_CURL_OPENSSL=1 -DHAVE_CURL_SSL=1 -I/Users/chenruiwen/.pyenv/versions/3.6.4/include/python3.6m -c src/docstrings.c -o build/temp.macosx-10.12-x86_64-3.6/src/docstrings.o In file included from src/docstrings.c:4: src/pycurl.h:164:13: fatal error: &#39;openssl/ssl.h&#39; file not found # include &lt;openssl/ssl.h&gt; ^~~~~~~~~~~~~~~ 1 error generated. error: command &#39;clang&#39; failed with exit status 1 ---------------------------------------- Command &quot;/Users/chenruiwen/.pyenv/versions/3.6.4/bin/python3.6 -u -c &quot;import setuptools, tokenize;__file__=&#39;/private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-aavrg23s/pycurl/setup.py&#39;;f=getattr(tokenize, &#39;open&#39;, open)(__file__);code=f.read().replace(&#39;\r\n&#39;, &#39;\n&#39;);f.close();exec(compile(code, __file__, &#39;exec&#39;))&quot; install --record /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-record-l0npewt_/install-record.txt --single-version-externally-managed --compile&quot; failed with error code 1 in /private/var/folders/nx/khfvbh1d6vg334173fsxzb9r0000gn/T/pip-install-aavrg23s/pycurl/ 三次吐血。可以看到引入 openssl/ssl.h失败了。继续google解决一下。 第四次安装pycurl从 stackoverflow 搜到一个解决方案,准备尝试一下。 pip uninstall pycurl export PYCURL_SSL_LIBRARY=openssl export LDFLAGS=-L/usr/local/opt/openssl/lib export CPPFLAGS=-I/usr/local/opt/openssl/include pip install pycurl --compile --no-cache-dir 果然安装成功了！可喜可贺！可是我们用python导入pycurl试试： &gt;&gt;&gt; import pycurl Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; ImportError: pycurl: libcurl link-time ssl backend (none/other) is different from compile-time ssl backend (openssl) 四次吐血。 不过这次的问题应该是系统版本问题，刚刚 stackoverflow上的解决方案要求是系统OSX 10.13，于是乎备份系统，升级到macOS 10.13 High Sierra。 大胆的童鞋可以不备份升级，比如我(:D)。 升级完成后尝试一下导入pycurl: &gt;&gt;&gt; import pycurl &gt;&gt;&gt; 成功解决问题。吐血完毕。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pycurl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis“冷门”知识点：HyperLogLog]]></title>
    <url>%2Fredis%2Fredis-hyperloglog%2F</url>
    <content type="text"><![CDATA[前言前几天，我司大牛分享redis知识点，讲到redis数据结构的时候，抛出一个问题：如果要统计网站uv，你准备怎么实现？ 和大多数普通开发人员一样，想到的第一个想法是存到set集合里。可是这样真的好吗？ 后来找到了更好的方式，redis“冷门”数据结构:HyperLogLog。（说是“冷门”，可能只是我不知道罢了:D） 问题回顾 你准备如何实现统计大型网站的网页UV数据？ uv数据不像pv数据，pv可能只需要在redis中使用一个计数器，每次访问incrby一次即可。uv数据需要根据用户id来标识唯一来统计，集合中的数据需要去重，那么set是一个最容易想到的数据结构。 现在的问题是，大型网站，可能这是一个爆款商品的秒杀页面，用户访问量非常大，假如有上千万的uv估计，那么占用的空间就非常大，而我仅仅只是想要一个set的size，岂不是杀鸡用了宰牛刀了？ 而且，uv数据一定要精确吗？uv数据存在一些误差可不可以？有没有更好的解决方案？ uv数据当然可以存在误差，更好的解决方案当然有。那就是redis的HyperLogLog。 HyperLogLog本文主角HyperLogLog，redis的一种数据结构，可能不被大多数人知道，但却是非常有用的数据。 HyperLogLog是什么Redis 在 2.8.9 版本添加了HyperLogLog结构。 Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 但是，因为HyperLogLog只会根据输入元素来计算基数，而不会储存输入元素本身，所以HyperLogLog 不能像集合那样，返回输入的各个元素。 可见，专业的人做专业的事，HyperLogLog在做基数统计方面是一流的。 HyperLogLog怎么玩HyperLogLog的三个指令: 命令 描述 PFADD key element [element …] 添加指定元素到 HyperLogLog 中。 PFCOUNT key [key …] 返回给定 HyperLogLog 的基数估算值。 PFMERGE destkey sourcekey [sourcekey …] 将多个 HyperLogLog 合并为一个 HyperLogLog 小试牛刀以计算uv为例，假如统计网站首页uv人数，路径/index，我们使用pfadd增加计数，pfcount统计人数。使用方式类似于set集合的sadd和scard。 127.0.0.1:6379[1]&gt; pfadd /index user_1 (integer) 1 127.0.0.1:6379[1]&gt; pfadd /index user_2 (integer) 1 127.0.0.1:6379[1]&gt; pfcount /index (integer) 2 127.0.0.1:6379[1]&gt; pfadd /index user_3 (integer) 1 127.0.0.1:6379[1]&gt; pfcount /index (integer) 3 127.0.0.1:6379[1]&gt; pfadd /index user_4 (integer) 1 127.0.0.1:6379[1]&gt; pfcount /index (integer) 4 127.0.0.1:6379[1]&gt; pfadd /index user_1 (integer) 0 127.0.0.1:6379[1]&gt; pfcount /index (integer) 4 127.0.0.1:6379[1]&gt; pfadd /index user_5 user_6 user_7 (integer) 1 127.0.0.1:6379[1]&gt; pfcount /index (integer) 7 目前看数值都是正确的，我们用程序加大user数据看看精确度怎么样。 此处用Python实现吧，你懂的，毕竟人生苦短。 # coding: utf-8 import redis def start_test(): r = redis.Redis(host=&#39;localhost&#39;, port=6379, decode_responses=True) client = redis.StrictRedis() for i in range(100000): client.pfadd(&quot;/index&quot;, &quot;user%d&quot; % i) print(&quot;用户真实人数:&quot;, 100000, &quot;,统计uv数:&quot; , client.pfcount(&quot;/index&quot;)) if __name__ == &#39;__main__&#39;: start_test(); 输出结果: 用户真实人数: 100000 ,统计uv数: 99723 可见正确率有99.723%，误差可以接受的范围 HyperLogLog的底层原理建议阅读文章：神奇的HyperLogLog算法 其底层的实现原理还是比较复杂，感兴趣的童鞋可以多多了解。 结论在统计不是很要求精确的统计计数时，可以考虑使用redis的HyperLogLog数据结构。它的占用内存非常小，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。当数值非常大时，它的优势就越发明显。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java SE1.6中的Synchronized]]></title>
    <url>%2Fjava-concurrency%2Fjava-concurrency-se-16-synchronized%2F</url>
    <content type="text"><![CDATA[前言多线程并发，你最先想到的加锁使用方式是什么？我想几乎百分百会想到这个关键字:Synchronized。 关于Synchronized的底层原理，可能大部分java程序猿都没有太多的了解。本文将洞悉Synchronized那些小细节。 本文摘自 infoq 上阿里巴巴的技术专家方腾飞老师的文章。 原文地址：聊聊并发（二）Java SE1.6中的Synchronized 引言在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，有些情况下它并不那么重了，本文详细介绍了Java SE1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 术语定义 术语 英文 说明 CAS Compare and Swap 比较并设置。用于在硬件层面上提供原子性操作。在 Intel 处理器中，比较并交换通过指令cmpxchg实现。比较是否和给定的数值一致，如果一致则修改，不一致则不修改。 同步的基础Java中的每一个对象都可以作为锁。 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁存在哪里呢？锁里面会存储什么信息呢？ 同步的原理JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。 Java对象头锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。 长度 内容 说明 32/64bit Mark Word 存储对象的hashCode或锁信息等。 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/64bit Array length 数组的长度（如果当前对象是数组） Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下： 25 bit 4bit 1bit是否是偏向锁 2bit锁标志位 无锁状态 对象的hashCode 对象分代年龄 0 01 在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据： 锁状态 25 bit 4bit 1bit 2bit 23bit 2bit 是否是偏向锁 锁标志位 轻量级锁 指向栈中锁记录的指针 00 重量级锁 指向互斥量（重量级锁）的指针 10 GC标记 空 11 偏向锁 线程ID Epoch 对象分代年龄 1 01 在64位虚拟机下，Mark Word是64bit大小的，其存储结构如下： 锁状态 25 bit 31bit 1bit 4bit 1bit 2bit cms_free 分代年龄 偏向锁 锁标志位 无锁 unused hashCode 0 01 偏向锁 ThreadID(54bit) Epoch(2bit) 1 01 锁的升级Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。 偏向锁Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX:BiasedLockingStartupDelay=0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 轻量级锁轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 锁的优缺点对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。 参考源码本文一些内容参考了HotSpot源码 。对象头源码markOop.hpp。偏向锁源码biasedLocking.cpp。以及其他源码ObjectMonitor.cpp和BasicLock.cpp。 参考资料 偏向锁 java-overview-and-java-se6 Synchronization Optimization章节 Dave Dice “Synchronization in Java SE 6” Java SE 6 Performance White Paper 2.1章节 JVM规范（Java SE 7） Java语言规范（JAVA SE7） 周志明的《深入理解Java虚拟机》 Java偏向锁实现原理 hotspot Synchronization 个人总结java中锁的四种状态:无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态。各有千秋，并且锁会随着竞争情况逐渐升级，且不会降级，好处是提高获得锁和释放锁的效率。 关于四种锁的使用，还是要分场景和尽量多的测试性能。 关于synchronized，早起的版本效率很低，从java6开始有了较多的优化。如果生成环境的jdk版本较低,低于1.5，建议尽量少使用，同步尽量使用ReentrantLock。如果jdk版本比较高，java8以后还是可以考虑synchronized的，效率并不差。 致谢最后，还是非常感谢本文的原创作者: 方腾飞，阿里巴巴资深软件开发工程师，致力于高性能网络和并发编程，目前在公司从事询盘管理和长连接服务器OpenComet的开发工作。 博客地址：https://ifeve.com 微博地址：https://weibo.com/kirals]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>转载摘抄</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot优雅使用redis集中式缓存]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-cache-redis%2F</url>
    <content type="text"><![CDATA[前言之前的文章spring-boot优雅的使用缓存介绍了使用spring3开始的cache功能， 并使用guava实现完成一次示例。但是在分布式环境下，进程内的本地缓存是独立的，在一些场景并不使用。 在现在互联网企业中广泛使用了一些中间件比如memcache,redis等来实现分布式环境下的集中式缓存。 本文将介绍spring-boot下集成redis做缓存的实现细节。 redisredis是开源免费的、高性能key-value数据库。 它的特点主要有： 高性能，基于内存内的数据结构，读写性能都很好 支持持久化，数据支持写进磁盘 数据结构有五种形式，string,list，set，zset，hash，各有特点，使用场景广泛。 高可用，支持集群 支持发布/订阅 现如今大多公司使用redis，大有替代memcache的意思(具体根据业务场景选型)。 集成redis依旧三步完成redis缓存： maven依赖 配置redis和缓存 代码使用及测试 maven依赖1.4.x版本的spring-boot可依赖如下: &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;/dependency&gt; 但是从1.5.x开始已经被废弃，请依赖如下: &lt;!-- redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 配置文件application.yml添加redis相关配置，以及缓存开启为redis.spring: # redis redis: database: 2 host: 127.0.0.1 port: 6379 password: pool: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 timeout: 0 # cache cache: type: redis 代码使用及单元测试redis的配置类在spring-boot-autoconfigure包中的RedisAutoConfiguration类中有自动装配了RedisConnectionFactory,RedisTemplate,无需多配置即可完成直接调用即可。 但是此处我们想要定制RedisTemplate,因为默认的RedisTemplate的keySerializer和valueSerializer都是默认的JdkSerializationRedisSerializer。由于业务的需要(强迫症+颜控)，我们希望key是字符串类型，value是json格式。如下修改RedisTemplate的序列化格式即可: @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate&lt;Object, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); // 使用Jackson2JsonRedisSerialize 替换默认序列化 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); // 设置value的序列化规则和 key的序列化规则 redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; } cache配置使用redis当application.yml指定为spring.cache.type=redis时，即已经会自动加载spring-boot-autoconfigure包中的RedisCacheConfiguration,从源码中可以看到它自动装配了RedisCacheManager，原则上无需配置直接使用即可。 但是此处默认的RedisCacheManager不没有设置过期时间，即不过期。这显然不合理。因此需要自定义RedisCacheManager。 有两种方式自定义RedisCacheManager: 直接装配RedisCacheManager 装配CacheManagerCustomizer 方式一. 直接手动装配RedisCacheManager方式如下: @Bean public CacheManager redisCacheManager(RedisTemplate redisTemplate) { RedisCacheManager redisCacheManager = new RedisCacheManager(redisTemplate); redisCacheManager.setDefaultExpiration(60L); // 默认缓存 1 分钟 redisCacheManager.setUsePrefix(true); Map&lt;String, Long&gt; expires = new ConcurrentHashMap&lt;String, Long&gt;(2); expires.put(&quot;userCache&quot;, 90L); // 指定 cacheName 缓存时间 redisCacheManager.setExpires(expires); return redisCacheManager; } 方式二. spring boot添加了可扩展RedisCacheManager的方式，即CacheManagerCustomizer接口。可通过装配CacheManagerCustomizer的实现，实现其customize(T cacheManager)方法即可实现自定义： @Bean public CacheManagerCustomizer redisCacheManagerCustomizer() { return (CacheManagerCustomizer&lt;RedisCacheManager&gt;) cacheManager -&gt; { cacheManager.setDefaultExpiration(60L);// 默认过期时间，单位秒 Map&lt;String, Long&gt; expires = new ConcurrentHashMap&lt;&gt;(2); expires.put(&quot;userCache&quot;, 2000L); // 指定 cacheName 缓存时间 cacheManager.setExpires(expires); }; } 测试redis操作首先测试通过redisTemplate来操作redis。测试用例: @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) public class RedisTemplateTest { @Autowired private StringRedisTemplate redisTemplate; @Test public void test() { redisTemplate.opsForValue().set(&quot;key1&quot;, &quot;value1&quot;); String value1 = redisTemplate.opsForValue().get(&quot;key1&quot;); Assert.assertEquals(&quot;value1&quot;, value1); } } 调用正常结束，查看redis库中有此缓存。 测试redis缓存比如我们有个User服务，代码如下: @Service @CacheConfig(cacheNames = &quot;userCache&quot;) public class SbpUserServiceImpl implements SbpUserService { @Resource private SbpUserMapper sbpUserMapper; @Override @CachePut(key = &quot;&#39;id:&#39;+ #p0.id&quot;) public SbpUser insert(SbpUser user) { sbpUserMapper.insert(user); return user; } @Override @CachePut(key = &quot;&#39;id:&#39;+ #p0.id&quot;) public SbpUser update(SbpUser user) { sbpUserMapper.updateByPrimaryKey(user); return user; } @Override @CacheEvict(allEntries = true, beforeInvocation = true)// 清空 userCache 缓存 public int insertList(List&lt;SbpUser&gt; list) { return sbpUserMapper.insertList(list); } @Override public Page&lt;SbpUser&gt; getListPageInfo(int pageNo, int pageSize) { // 开启分页 Page&lt;SbpUser&gt; page = PageHelper.startPage(pageNo, pageSize); sbpUserMapper.getAll(); return page; } @Override @CacheEvict(key = &quot;&#39;id:&#39;+#id&quot;, beforeInvocation = true) public boolean deleteById(Long id) { return sbpUserMapper.deleteByPrimaryKey(id) &gt; 0; } @Override @Cacheable(key = &quot;&#39;id:&#39;+ #id&quot;) public SbpUser getObjectById(Long id) { return sbpUserMapper.selectByPrimaryKey(id); } } 说明: @CacheConfig(cacheNames = &quot;userCache&quot;)注解表示SbpUserServiceImpl服务下的所有缓存的前缀加上了”userCache”。注意前提是RedisCacheManager配置的usePrefix为true时才生效。 @CachePut注解使得数据更新时放入缓存，此处在insert和update方法时都使用了此注解更新缓存。 @CacheEvict注解用在delete方法上，并配置了删除时清空”userCache”里的缓存。 @Cacheable设置了查询缓存。 单元测试用例: @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) @Slf4j public class SbpUserServiceTest { @Autowired private SbpUserService sbpUserService; @Autowired private RedisTemplate redisTemplate; @Test public void testRedisCache() { long now = System.currentTimeMillis(); SbpUser user1 = SbpUser.builder().id(666L).mobile(&quot;11100006666&quot;) .nickName(&quot;老A&quot;).password(&quot;111111&quot;) .createAt(now).updateAt(now).build(); sbpUserService.insert(user1); log.info(&quot;~~~~~~~~~~~~~insert data~~~~~~~~~~~~~~~~~~~~~~&quot;); log.info(&quot;=============first select start===============&quot;); SbpUser user2 = sbpUserService.getObjectById(666L); log.info(&quot;=============first select end=================,user:{}&quot;, user2); user2.setNickName(&quot;老B&quot;); sbpUserService.update(user2); log.info(&quot;~~~~~~~~~~~~~update data~~~~~~~~~~~~~~~~~~~~~~&quot;); log.info(&quot;=============second select start===============&quot;); SbpUser user3 = sbpUserService.getObjectById(666L); log.info(&quot;=============second select end=================,user:{}&quot;, user3); sbpUserService.deleteById(666L); log.info(&quot;~~~~~~~~~~~~~delete data~~~~~~~~~~~~~~~~~~~~~~&quot;); log.info(&quot;=============third select start===============&quot;); SbpUser user4 = sbpUserService.getObjectById(666L); log.info(&quot;=============third select end=================,user:{}&quot;, user4); assert 666L == sbpUserService.insert(SbpUser.builder().id(666L).mobile(&quot;11100006666&quot;) .nickName(&quot;老A&quot;).password(&quot;111111&quot;) .createAt(now).updateAt(now).build()).getId(); redisTemplate.delete(&quot;userCache:id:666&quot;); // 手动删除redis缓存 log.info(&quot;~~~~~~~~~~~~~insert data and delete cache~~~~~~~~~~~~~~~~~~~~~~&quot;); log.info(&quot;=============fourth select start===============&quot;); SbpUser user5 = sbpUserService.getObjectById(666L); log.info(&quot;=============fourth select end=================,user:{}&quot;, user5); } } 控制台输出: JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: insert into sbp_user (id, nick_name, password, mobile, create_at, update_at ) values (?, ?, ?, ?, ?, ? ) ==&gt; Parameters: 666(Long), 老A(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@552ffa44] 2018-07-24 21:45:02.196 [main] INFO com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~insert data~~~~~~~~~~~~~~~~~~~~~~ 2018-07-24 21:45:02.199 [main] INFO com.crw.service.SbpUserServiceTest - =============first select start=============== 2018-07-24 21:45:02.280 [main] INFO com.crw.service.SbpUserServiceTest - =============first select end=================,user:SbpUser(id=666, nickName=老A, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401) Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@578198d9] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: update sbp_user set nick_name = ?, password = ?, mobile = ?, create_at = ?, update_at = ? where id = ? ==&gt; Parameters: 老B(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long), 666(Long) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@578198d9] 2018-07-24 21:45:02.286 [main] INFO com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~update data~~~~~~~~~~~~~~~~~~~~~~ 2018-07-24 21:45:02.287 [main] INFO com.crw.service.SbpUserServiceTest - =============second select start=============== 2018-07-24 21:45:02.289 [main] INFO com.crw.service.SbpUserServiceTest - =============second select end=================,user:SbpUser(id=666, nickName=老B, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401) Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3ff53704] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: delete from sbp_user where id = ? ==&gt; Parameters: 666(Long) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@3ff53704] 2018-07-24 21:45:02.298 [main] INFO com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~delete data~~~~~~~~~~~~~~~~~~~~~~ 2018-07-24 21:45:02.298 [main] INFO com.crw.service.SbpUserServiceTest - =============third select start=============== Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@31b289da] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: select id, nick_name, password, mobile, create_at, update_at from sbp_user where id = ? ==&gt; Parameters: 666(Long) &lt;== Total: 0 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@31b289da] 2018-07-24 21:45:02.326 [main] INFO com.crw.service.SbpUserServiceTest - =============third select end=================,user:null Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58a7ca42] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: insert into sbp_user (id, nick_name, password, mobile, create_at, update_at ) values (?, ?, ?, ?, ?, ? ) ==&gt; Parameters: 666(Long), 老A(String), 111111(String), 11100006666(String), 1532439901401(Long), 1532439901401(Long) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@58a7ca42] 2018-07-24 21:45:02.332 [main] INFO com.crw.service.SbpUserServiceTest - ~~~~~~~~~~~~~insert data and delete cache~~~~~~~~~~~~~~~~~~~~~~ 2018-07-24 21:45:02.332 [main] INFO com.crw.service.SbpUserServiceTest - =============fourth select start=============== Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@16890f00] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@759f45f1] will not be managed by Spring ==&gt; Preparing: select id, nick_name, password, mobile, create_at, update_at from sbp_user where id = ? ==&gt; Parameters: 666(Long) &lt;== Columns: id, nick_name, password, mobile, create_at, update_at &lt;== Row: 666, 老A, 111111, 11100006666, 1532439901401, 1532439901401 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@16890f00] 2018-07-24 21:45:02.338 [main] INFO com.crw.service.SbpUserServiceTest - =============fourth select end=================,user:SbpUser(id=666, nickName=老A, password=111111, mobile=11100006666, createAt=1532439901401, updateAt=1532439901401) 2018-07-24 21:45:02.343 [Thread-4] INFO org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@1556f2dd: startup date [Tue Jul 24 21:44:55 CST 2018]; root of context hierarchy Disconnected from the target VM, address: &#39;127.0.0.1:51531&#39;, transport: &#39;socket&#39; Process finished with exit code 0 输出结果分析： 第一次查询在插入数据之后，并没有打印查询sql表明是从缓存查询。即insert操作的@CachePut注解其效果。 第二次查询在修改数据之后，也没有打印查询sql表明从缓存查询。继续观察输出的user对象，nickName已经从“老A”变为“老B”了。即update操作的@CachePut注解其效果。 第三次查询在删除数据之后，打印sql说明未从缓存查询。继续观察输出的user对象为null,说明delete操作的@CacheEvict注解其效果。 第四次查询在插入数据并删除缓存的情况下，打印sql了说明从数据库查询。再连接redis可以看到： 图上，redis已有缓存，说明select操作也会增加redis缓存。并且输出格式正如RedisTemplate配置的那样，key为字符串,value为json格式。同时设置的缓存时间为2000秒。]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>cache</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot优雅的使用缓存]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-cache-guava%2F</url>
    <content type="text"><![CDATA[前言如果说如何优化你的网站或者应用，大部分同学第一的反应可能就是缓存。缓存不是万能的，但是当用户和访问量加大的情况下，缓存是提高应用吞吐量非常有效的手段。 本文主要介绍如果通过spring-boot使用本地缓存，以guava cache为例。其实从spring3开始就已经提供了基于注解的缓存支持，其原理还是基于aop的思想，降低了缓存代码对我们应用代码的侵入。 spring cache相关接口及注解从spring3开始，spring支持基于注解的缓存组件。其核心接口俩个，在spring-context包中: Cache CacheManager spring中实现优雅使用缓存的方式还是基于注解的方式，其中常用的一些注解也是在spring-context包中。 接下来分别看下这些接口。 Cache 接口Cache接口，提供操作缓存的定义(比如放入、读取、清理等。 其中Cache接口Spring也提供了很多默认的实现，它们在spring-context包和spring-context-support包中: Cache接口: public interface Cache { // cacheName，缓存的名字，默认实现中一般是CacheManager创建Cache的bean时传入cacheName String getName(); // 获取实际使用的缓存，如：RedisTemplate、com.github.benmanes.caffeine.cache.Cache&lt;Object, Object&gt;。暂时没发现实际用处，可能只是提供获取原生缓存的bean，以便需要扩展一些缓存操作或统计之类的东西 Object getNativeCache(); // 通过key获取缓存值，注意返回的是ValueWrapper，为了兼容存储空值的情况，将返回值包装了一层，通过get方法获取实际值 ValueWrapper get(Object key); // 通过key获取缓存值，返回的是实际值，即方法的返回值类型 &lt;T&gt; T get(Object key, Class&lt;T&gt; type); // 通过key获取缓存值，可以使用valueLoader.call()来调使用@Cacheable注解的方法。当@Cacheable注解的sync属性配置为true时使用此方法。因此方法内需要保证回源到数据库的同步性。避免在缓存失效时大量请求回源到数据库 &lt;T&gt; T get(Object key, Callable&lt;T&gt; valueLoader); // 将@Cacheable注解方法返回的数据放入缓存中 void put(Object key, Object value); // 当缓存中不存在key时才放入缓存。返回值是当key存在时原有的数据 ValueWrapper putIfAbsent(Object key, Object value); // 删除缓存 void evict(Object key); // 删除缓存中的所有数据。需要注意的是，具体实现中只删除使用@Cacheable注解缓存的所有数据，不要影响应用内的其他缓存 void clear(); // 缓存返回值的包装 interface ValueWrapper { // 返回实际缓存的对象 Object get(); } // 当{@link #get(Object, Callable)}抛出异常时，会包装成此异常抛出 @SuppressWarnings(&quot;serial&quot;) class ValueRetrievalException extends RuntimeException { private final Object key; public ValueRetrievalException(Object key, Callable&lt;?&gt; loader, Throwable ex) { super(String.format(&quot;Value for key &#39;%s&#39; could not be loaded using &#39;%s&#39;&quot;, key, loader), ex); this.key = key; } public Object getKey() { return this.key; } } } CacheManager 接口主要负责缓存Cache接口的管理，提供了根据cacheName获取缓存的接口以及获取所有cacheName的接口。 public interface CacheManager { // 通过cacheName创建Cache的实现bean，具体实现中需要存储已创建的Cache实现bean，避免重复创建，也避免内存缓存对象（如Caffeine）重新创建后原来缓存内容丢失的情况 Cache getCache(String name); // 返回所有的cacheName Collection&lt;String&gt; getCacheNames(); } cache 相关注解@EnableCaching启用Cache注解支持的总开关。 @CachePut应用到写数据的方法上，如新增/修改方法，调用方法时会自动把相应的数据放入缓存。 Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface CachePut { // cacheNames，CacheManager就是通过这个名称创建对应的Cache实现bean @AliasFor(&quot;cacheNames&quot;) String[] value() default {}; // 含义与`cacheNames`别名一样，等价于value() @AliasFor(&quot;value&quot;) String[] cacheNames() default {}; // 缓存的key，支持SpEL表达式。默认是使用所有参数及其计算的hashCode包装后的对象（SimpleKey） String key() default &quot;&quot;; // 缓存key生成器，spring4开始默认实现是SimpleKeyGenerator String keyGenerator() default &quot;&quot;; // 指定使用的cacheManager String cacheManager() default &quot;&quot;; // 缓存解析器 String cacheResolver() default &quot;&quot;; // 缓存的条件，支持SpEL表达式，当达到满足的条件时才缓存数据。在调用方法前后都会判断 String condition() default &quot;&quot;; // 满足条件时不更新缓存，支持SpEL表达式，只在调用方法后判断 String unless() default &quot;&quot;; } @CacheEvict应用到移除数据的方法上，如删除方法，调用方法时会从缓存中移除相应的数据。 大部分定义可参考上面@CachePut注解，新增了2个属性: @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface CacheEvict { // 此处省略大部分与CachePut相同的属性... // 是否要清除所有缓存的数据，为false时调用的是Cache.evict(key)方法；为true时调用的是Cache.clear()方法 boolean allEntries() default false; // 是否在调用方法之前清除缓存 boolean beforeInvocation() default false; } @Cacheable应用到读取数据的方法上，即可缓存的方法，如查找方法：先从缓存中读取，如果没有再调用方法获取数据，然后把数据添加到缓存中。 大部分定义可参考上面@CachePut注解，新增了1个属性: @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface Cacheable { // 此处省略大部分与CachePut相同的属性... // 回源到实际方法获取数据时，是否要保持同步，如果为false，调用的是Cache.get(key)方法；如果为true，调用的是Cache.get(key, Callable)方法 boolean sync() default false; } @Caching提供了注解的组合模式，可以在此注解中配置多个Cache注解。 @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface Caching { // @Cacheable 数组，可以配置多个Cacheable注解，实现同时查询多个缓存 Cacheable[] cacheable() default {}; // @CachePut 数组，可以配置多个CachePut注解，实现同时存放多个缓存 CachePut[] put() default {}; // @CacheEvict 数组，可以配置多个CacheEvict注解，实现同时删除多个缓存 CacheEvict[] evict() default {}; } guava cacheguava是Google提供的开源的java核心工具类库。其中包含很多好用的工具类，我们这里主要使用guava中的cache包。 为什么要使用guava的cache而不是简单的使用ConcurrentMap呢？或者说这二者的区别在哪？ 答：Guava Cache与ConcurrentMap很相似，它们之间的一个根本区别在于缓存可以回收存储的元素。 guava提供了不同方式的缓存回收策略： 基于容量的回收 定时回收 基于引用的回收 在spring-boot中使用guava cache三步完成在spring-boot中使用guava cache: maven依赖 配置缓存类型 代码中使用guava cache并单元测试 maven依赖maven依赖特别少，由于spring-boot-starter默认并没有依赖上spring-context-support包，所以我们需要依赖上它。如下，引入spring-boot-starter-cache即可。以及引入本地缓存要用到的guava。 &lt;!-- cache --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- guava --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt; &lt;/dependency&gt; 配置缓存类型由于我们使用guava作为缓存，只需要指明缓存类型为 guava即可。 spring: cache: type: guava 使用guava cache一. 配置 CacheManager，并开启缓存功能。 @EnableCaching @Configuration public class CacheConfig { @Bean public CacheManager cacheManager() { GuavaCacheManager cacheManager = new GuavaCacheManager(); cacheManager.setCacheBuilder(CacheBuilder.newBuilder() .expireAfterWrite(10, TimeUnit.SECONDS).maximumSize(1000)); return cacheManager; } } 如上，我配置了缓存写入后保持10秒 二. 使用注解优雅给接口加上缓存。在访问接口上加上注解。 @Service @CacheConfig(cacheNames = &quot;product&quot;) public class ProductServiceImpl implements ProductService { @Resource private ProductMapper productMapper; @Override @Cacheable public Product getObjectById(Long id) { return productMapper.selectByPrimaryKey(id); } } 三. 测试本地缓存。 首先开启mybatis的sql输出打印，修改application.yml的配置，增加如下: mybatis: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 测试本地缓存是否起效，以及缓存时间是否其效果。 @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) @Slf4j public class SbpProductServiceTest { @Autowired private ProductService productService; @Test @Rollback public void getObjectById() throws InterruptedException { Product product1 = productService.getObjectById(1L); log.info(&quot;time:{} , first get product:{}&quot;, System.currentTimeMillis(), product1); Product product2 = productService.getObjectById(1L); log.info(&quot;time:{} , second get product:{}&quot;, System.currentTimeMillis(), product2); Thread.sleep(15000); Product product3 = productService.getObjectById(1L); log.info(&quot;time:{} , third get product:{}&quot;, System.currentTimeMillis(), product3); } } 输出如下： ==&gt; Preparing: select id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at from sbp_product where id = ? ==&gt; Parameters: 1(Long) &lt;== Columns: id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at &lt;== Row: 1, BK100001, 1, java编程思想, thinking in java, 86.00, 75.00, 300, 1532260305712, 1532260305712 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@25791d40] 2018-07-22 19:53:05.534 [main] INFO com.crw.service.SbpProductServiceTest - time:1532260385532 , first get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712) 2018-07-22 19:53:05.537 [main] INFO com.crw.service.SbpProductServiceTest - time:1532260385537 , second get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712) Creating a new SqlSession SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6812c8cc] was not registered for synchronization because synchronization is not active JDBC Connection [com.mysql.jdbc.JDBC4Connection@6075b369] will not be managed by Spring ==&gt; Preparing: select id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at from sbp_product where id = ? ==&gt; Parameters: 1(Long) &lt;== Columns: id, code, type, full_name, alias_name, original_price, vip_price, storage, create_at, update_at &lt;== Row: 1, BK100001, 1, java编程思想, thinking in java, 86.00, 75.00, 300, 1532260305712, 1532260305712 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6812c8cc] 2018-07-22 19:53:20.547 [main] INFO com.crw.service.SbpProductServiceTest - time:1532260400547 , third get product:SbpProduct(id=1, code=BK100001, type=1, fullName=java编程思想, aliasName=thinking in java, originalPrice=86.00, vipPrice=75.00, storage=300, createAt=1532260305712, updateAt=1532260305712) 2018-07-22 19:53:20.553 [Thread-4] INFO org.springframework.web.context.support.GenericWebApplicationContext - Closing org.springframework.web.context.support.GenericWebApplicationContext@6853425f: startup date [Sun Jul 22 19:53:01 CST 2018]; root of context hierarchy 可以看到结果: 第一次调用打印了sql，此时还没有缓存。 第二次调用没打印sql，此时有本地缓存了。 第三次调用又打印sql，此时本地缓存失效。 结束语再来回顾一下，本文介绍了： spring cache的使用，它是AOP理念的一个很好的应用 guava的使用。by the way,从Spring5开始变不再支持guava的实现了，从spring-boot 1.5.x版本你就可以看到autoconfgure包下的GuavaCacheConfiguration以及被注解为@Deprecated了。推荐更好的实现是caffeine。 spring-boot使用哦cache非常方便，三步完成。 本文参考了： Spring Cache抽象详解]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>cache</tag>
        <tag>guava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot集成ActiveMQ]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-activemq%2F</url>
    <content type="text"><![CDATA[前言之前的文章spring-boot集成RabbitMQ介绍了spring-boot如何集成RabbitMQ。本篇文章是spring-boot集成MQ的姊妹篇，看看spring-boot如何集成常用的ActiveMQ. JMSJMS是什么百度百科： JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。 简单的说，JMS是j2ee技术中的提供了访问消息中间件的规范。它的常见实现如ActiveMQ。 JMS API简介JMS 规范和 javax.jms 包定义一组可供 Java 应用程序用于执行消息传递操作的接口。以下列表概括了主要的 JMS 接口： Destination： Destination 对象是应用程序将消息发往的位置和/或应用程序从其接收消息的源。 ConnectionFactory： ConnectionFactory 对象包括连接的一组配置属性。应用程序使用连接工厂来创建连接。 Connection： Connection 对象包括应用程序与消息传递服务器的活动连接。应用程序使用连接来创建会话。 Session： Session 对象是用于发送和接收消息的单个线程上下文。应用程序使用会话来创建消息、消息生产者和消息使用者。会话是事务性或非事务性会话。 Message： Message 对象包括应用程序发送或接收的消息。 MessageProducer： 应用程序使用消息生产者将消息发送到目标。 MessageConsumer： 应用程序使用消息使用者来接收已发送到目标的消息。 JMS对象及其关系: ActiveMQ介绍ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。 特性： 支持多种语言和协议。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP。 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务) 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA 设计上保证了高性能的集群，客户端-服务器，点对点 ActiveMQ安装通过国外地址下载通常比较慢，所以我们一般通过国内的镜像地址下载。 一些常用的apache其下的国内镜像地址： https://mirrors.hust.edu.cn/apache/ https://mirrors.shu.edu.cn/apache/ https://mirrors.tuna.tsinghua.edu.cn/apache/ 通过国内镜像地址下载 wget http://mirror.bit.edu.cn/apache/activemq/5.14.5/apache-activemq-5.14.5-bin.tar.gz 解压： tar xf apache-activemq-5.14.5-bin.tar.gz 启动： cd apache-activemq-5.14.5\bin\ 注意：如果一台机器启动RabbitMQ以及ActiveMQ,要注意端口冲突问题。 修改ActiveMQ端口,找到..\apache-activemq-5.x.x\conf\目录下的activemq.xml,修改&lt;transportConnectors&gt;标签下的uri属性，比如： &lt;transportConnectors&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;amqp&quot; uri=&quot;amqp://0.0.0.0:5673?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;stomp&quot; uri=&quot;stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;mqtt&quot; uri=&quot;mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;ws&quot; uri=&quot;ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;/transportConnectors&gt; 如何查看RabbitMQ的端口号？打开web控制台查看即可。 集成置ActiveMQ使用过程与RabbitMQ类似，三步完成： maven依赖 配置ActiveMQ 编写代码及单元自测 maven依赖&lt;!-- activemq --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;/dependency&gt; 配置ActiveMQ在application.yml里添加几行即可: spring: activemq: broker-url: tcp://127.0.0.1:61616 #activeMQ地址 user: admin #用户名 password: admin #密码 in-memory: true #是否启用内存模式（也就是不安装MQ，项目启动时同时也启动一个MQ实例 pool: enabled: false #是否替换默认的connectionFactory packages: trust-all: true #信任所有的包 编写代码及单元自测一. 配置一个hello队列： @Configuration public class MessageQueueConfig { @Bean public javax.jms.Queue helloQueueByActiveMQ() { return new ActiveMQQueue(&quot;hello&quot;); } } 二. 消息推送端，向hello队列发送一条消息: @Component @Slf4j public class HelloActiveMQSender { @Autowired private JmsMessagingTemplate jmsMessagingTemplate; public void send(String content) { log.info(&quot;ActiveMQ send : {}&quot;, content); this.jmsMessagingTemplate.convertAndSend(&quot;hello&quot;, content); } } 三. 消息消费端，消费一条hello队列里的消息: @Slf4j @Component @EnableJms public class HelloActiveMQConsumer { @JmsListener(destination = &quot;hello&quot;) public void process(String hello) { log.info(&quot;ActiveMQ receiver : {}&quot;, hello); } } 四. 单元测试发送一条消息: @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) public class HelloActiveMQSenderTest { @Autowired private HelloActiveMQSender sender; @Test public void sendHello() { sender.send(&quot;Hello &quot; + new Date()); } } 输出结果，可以确认消息发送并且被消费了： 2018-07-17 16:56:16.320 [main] INFO com.crw.mq.HelloActiveMQSender - ActiveMQ send : Hello Tue Jul 17 16:56:16 CST 2018 2018-07-17 16:56:16.355 [DefaultMessageListenerContainer-1] INFO com.crw.mq.HelloActiveMQConsumer - ActiveMQ receiver : Hello Tue Jul 17 16:56:16 CST 2018]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>ActiveMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot集成RabbitMQ]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-rabbitmq%2F</url>
    <content type="text"><![CDATA[前言消息队列是日常开发中非常常用的工具，当调用方不需要关心执行结果时，你可以使用它来解耦。 本文简单介绍下spring-boot中快速使用RabbitMQ完成队列的发送与消费。 AMQPAMQP协议AMQP，即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。 消息代理消息代理（message brokers）从发布者（publishers）亦称生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。 由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以存在于不同的设备上。 AMQP协议模型这里推荐直接查看 AMQP 0-9-1 模型解析。 RabbitMQ与AMQP的关系RabbitMQ采用Erlang语言开发。是AMQP协议的一个实现。 安装rabbitMQ根据RabbitMQ文档 Installing on Debian and Ubuntu进行安装。 Windows安装一. 下载并安装Erlang。官网下载页：http://www.erlang.org/downloads。 二. 下载并安装RabbitMQ。官网下载页：https://www.rabbitmq.com/download.html。安装完成后会自动注册到服务中启动。 Mac OS X安装一. 安装Erlang，执行命令：brew install erlang。 二. 安装RabbitMQ，执行命令：brew install rabbitmq。 Ubuntu安装一. 安装Erlang，执行命令：apt-get install erlang erlang-nox。 二. 在系统中加入RabbitMQ apt 仓库: echo &#39;deb http://www.rabbitmq.com/debian/ testing main&#39; | sudo tee /etc/apt/sources.list.d/rabbitmq.list 三. 添加signing key，执行命令: wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add -。 四. 更新APT仓库的package list，执行命令:apt-get update 五. 安装Rabbit Server，执行命令：apt-get install rabbitmq-server。 web控制台RabbitMQ内置提供了Web管理插件。 开启RabbitMQ web管理 Windows系统：进入插件目录:D:\rabbitmq\rabbitmq_server-3.7.7\sbin，运行命令：rabbitmq-plugins.bat enable rabbitmq_management Linux和Mac系统: 运行命令：rabbitmq-plugins enable rabbitmq_management。 通过浏览器访问web管理界面：http://localhost:15672/，默认登录用户:guest,密码:guest。 spring-boot中使用RabbitMQ三步完成集成: maven依赖 配置RabbitMQ 代码使用及测试 maven依赖仅需添加 &lt;!-- amqp,用于支持RabbitMQ --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 配置rabbitMQ配置非常简单，在application.yml添加rabbitMQ相关: # rabbitMQ spring: rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest 代码中使用及测试一. 在配置类中创建一个hello队列： @Configuration public class MessageQueueConfig { @Bean public org.springframework.amqp.core.Queue helloQueueByRabbitMQ() { return new org.springframework.amqp.core.Queue(&quot;hello&quot;); } } 二. 消息推送端，向hello队列发送一条消息: @Component @Slf4j public class HelloRabbitMQSender { @Autowired private AmqpTemplate rabbitTemplate; public void send(String content) { log.info(&quot;RabbitMQ send : {}&quot;, content); this.rabbitTemplate.convertAndSend(&quot;hello&quot;, content); } } 三. 消息消费端，消费一条hello队列里的消息: @Component @RabbitListener(queues = &quot;hello&quot;) @Slf4j public class HelloRabbitMQConsumer { @RabbitHandler public void process(String hello) { log.info(&quot;RabbitMQ receiver : {}&quot;, hello); } } 四. 单元测试发送一条消息: @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) public class HelloRabbitMQSenderTest { @Autowired private HelloRabbitMQSender sender; @Test public void sendHello() { sender.send(&quot;Hello &quot; + new Date()); } } 输出结果，可以确认消息发送并且被消费了： 2018-07-16 14:23:09.844 [main] INFO com.crw.mq.HelloRabbitMQSender - RabbitMQ send : Hello Mon Jul 16 14:23:09 CST 2018 2018-07-16 14:23:09.872 [SimpleAsyncTaskExecutor-1] INFO com.crw.mq.HelloRabbitMQConsumer - RabbitMQ receiver : Hello Mon Jul 16 14:23:09 CST 2018 这里仅仅简单介绍了使用RabbitMQ基于队列完成简单的点对点的使用，这也是在web开发中最常用的方式(易于系统解耦、消峰)。更多的使用还是参考官方文档。]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis集成分页插件pageHelper]]></title>
    <url>%2Fspring-boot%2Fmybatis-plugins-pagehelper%2F</url>
    <content type="text"><![CDATA[前言web开发少不了分页，本文将简单介绍使用基于spring-boot + mybatis + pageHelper技术实现数据库分页。 本文算是对上一篇spring-boot集成mybatis的一个补充。 pageHelper简介使用MyBatis作为数据访问层进行对sql语句分页的最好用的插件。 建议去pageHelper官网看一看。 特点： 物理分页：支持常见的12种数据库。Oracle,MySql,MariaDB,SQLite,DB2,PostgreSQL,SqlServer等。 支持多种分页方式：支持常见的RowBounds(PageRowBounds)，PageHelper.startPage 方法调用，Mapper 接口参数调用。 QueryInterceptor 规范：使用 QueryInterceptor 规范，开发插件更轻松。 集成pageHelper三步完成集成： maven依赖 配置pageHelper 代码使用及测试 maven依赖此处依赖在集成了mybatis的基础上增加: &lt;!-- pagehelper --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; 配置pageHelper在application.yml里增加: # 分页配置 pagehelper: helper-dialect: mysql reasonable: &quot;true&quot; support-methods-arguments: &quot;true&quot; params: count=countSql 代码使用及测试根据官网之如何在代码中使用中的推荐，我们使用静态方法PageHelper.startPage来实现分页。 首先是SbpUserMapper接口增加方法： public interface SbpUserMapper { List&lt;SbpUser&gt; getAll(); } 对应的SbpUserMapper.xml增加sql: &lt;select id=&quot;getAll&quot; resultMap=&quot;BaseResultMap&quot;&gt; SELECT * FROM sbp_user &lt;/select&gt; 代码使用，传参当前页为1，每页条数显示5条: @Test @Rollback public void pageByPageHelper() throws Exception { PageHelper.startPage(1, 5); List&lt;SbpUser&gt; users = sbpUserMapper.getAll(); Page&lt;SbpUser&gt; page = (Page&lt;SbpUser&gt;) users; System.out.println(&quot;total count :&quot; + page.getTotal()); System.out.println(&quot;pages :&quot; + page.getPages()); System.out.println(&quot;data :&quot; + page.getResult()); } 输出: total count :21 pages :5 data :Page{count=true, pageNum=1, pageSize=5, startRow=0, endRow=5, total=21, pages=5, reasonable=true, pageSizeZero=false} 还有更多的用法请参考官方文档。 结束语pageHelper还是非常好用的，简单，集成方便，是和mybatis搭配的分页插件首选。除此之外，大家一定要会自行写分页接口，除此之外还要 知其然，知其所以然。看其源码实现与设计理念，得到的不仅仅是分页。]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot集成Log4j2]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-log4j2%2F</url>
    <content type="text"><![CDATA[前言在企业级项目里，日志框架种类杂乱不一，尤其是接手一些有些年头的老项目时，各种各样的日志框架依赖和使用让人看的头大。 如何解决各种各样日志框架的大一统呢？神器Slf4j。 spring-boot如何利用Slf4j集成其他日志框架？本文将以Log4j2为例。 Slf4j简单介绍去Slf4j官网瞧一瞧: The Simple Logging Facade for Java (SLF4J) serves as a simple facade or abstraction for various logging frameworks (e.g. java.util.logging, logback, log4j) allowing the end user to plug in the desired logging framework at deployment time. Slf4j:Simple Logging Facade for Java.它并不是一个类似java.util.logging, logback, log4j等的日志框架实现，而是作为一个门面服务于这些各种日志框架。如同字面含义，类似外观设计模式，提供了一组简单统一的API接口，隐藏了各种日志不一致的复杂性。 日志框架选型几种日志框架简单对比: log4j:元老级日志框架。它定义的Logger、Appender、Level等概念如今已经被广泛使用，里程碑式的日志框架 java.util.logging:简称j.u.l。java1.4版本引入，功能不如log4j，性能和可用性有限。 logback：log4j升级版。它比log4j增加了不少功能，比如：原生实现了Slf4J,支持XML、Groovy方式配置等，主要是性能比log4j提升不少。 log4j2:同样是log4j升级版。也比log4j添加不少功能，比如多线程下的异步日志等。性能也提升不少。 至于logback和log4j2性能比对，可以参考网上博文： logback log4j log4j2 性能实测 看log4j2如何秒杀一切日志组件 根据官方推荐是Slf4j+logback，此处我使用Slf4j2+log4j2来集成日志框架。 集成Log4j2三步完成Log4j2的集成: maven依赖 配置日志文件 测试日志 maven依赖pom.xml： &lt;!-- 需要排除logback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- log4j2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; 配置日志文件classpath下添加log4j2.xml: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration status=&quot;OFF&quot;&gt; &lt;properties&gt; &lt;property name=&quot;LOG_HOME&quot;&gt;../logs/&lt;/property&gt; &lt;property name=&quot;STDOUT_FILE_NAME&quot;&gt;stdout&lt;/property&gt; &lt;/properties&gt; &lt;appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;RollingRandomAccessFile name=&quot;stdout-log&quot; fileName=&quot;${LOG_HOME}/${STDOUT_FILE_NAME}.log&quot; filePattern=&quot;${LOG_HOME}/$${date:yyyy-MM}/${STDOUT_FILE_NAME}-%d{yyyy-MM-dd}-%i.log.gz&quot;&gt; &lt;PatternLayout pattern=&quot;%date{yyyy-MM-dd HH:mm:ss.SSS} %level [%thread][%file:%line] - %msg%n&quot;/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;100 MB&quot;/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max=&quot;20&quot;/&gt; &lt;/RollingRandomAccessFile&gt; &lt;/appenders&gt; &lt;loggers&gt; &lt;root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;stdout-log&quot;/&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/root&gt; &lt;logger name=&quot;com.crw&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;AppenderRef ref=&quot;stdout-log&quot;/&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/logger&gt; &lt;/loggers&gt; &lt;/configuration&gt; 修改应用日志文件路径，application.yml: logging.config: classpath:log4j2.xml 测试日志增加一个EchoController: @RestController @Slf4j public class EchoController { @GetMapping(&quot;/echo/hello&quot;) public String echo(String msg) { log.debug(&quot;DEBUG ----&gt; echo:{}&quot;, msg); log.info(&quot;INFO ----&gt; echo:{}&quot;, msg); log.warn(&quot;WARN ----&gt; echo:{}&quot;, msg); log.error(&quot;ERROR ----&gt; echo:{}&quot;, msg); return &quot;hello, &quot; + msg; } } 调用接口地址： curl http://127.0.0.1:8080/echo/hello?msg=world 页面输出： hello, world stdout.log文件输出： 2018-07-12 22:56:04.023 INFO [http-nio-8080-exec-3][EchoController.java:17] - INFO ----&gt; echo:world 2018-07-12 22:56:04.024 WARN [http-nio-8080-exec-3][EchoController.java:18] - WARN ----&gt; echo:world 2018-07-12 22:56:04.024 ERROR [http-nio-8080-exec-3][EchoController.java:19] - ERROR ----&gt; echo:world debug级别的日志并未输出和打印在控制台，info级别以上日志打印并输出控制台。可见日志测试成功。 结束语本文简单介绍了日志框架的种类已经统一日志API框架Slf4j,除此之外，apache下也有与Slf4j同一职能的框架commons-logging。之后可自行研究一下。]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot集成mybatis]]></title>
    <url>%2Fspring-boot%2Fspring-boot-use-mybatis%2F</url>
    <content type="text"><![CDATA[前言如果你是一个j2ee开发工程师，你一定不能不会spring，你一定不能不了解spring-boot，你一定不能不知道最火的orm框架Mybatis。 本文使用spring-boot集成mybatis，体会下spring-boot + mybatis实现效率开发数据层代码。 一分钟创建工程通过idea创建spring-boot项目，File-&gt;New-&gt;Project...: 点击Next配置你的项目的基础信息，再点击Next，勾选需要的依赖: 创建完毕。耗时不到半分钟。 对于非idea使用的用户，可以直接登录https://start.spring.io,用同样的方式打包你的程序即可。 mybatis自动生成代码通过mybatis-generator技术来自动生成数据库层相关代码。 大致分为三步： 创建表结构。 配置 generatorConfig.xml 依赖 mybatis-generator-maven-plugin 并运行创建 创建表结构创建一个简单的用户表： CREATE TABLE `sbp_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `nick_name` varchar(50) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;昵称&#39;, `password` varchar(50) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;密码&#39;, `mobile` varchar(15) DEFAULT NULL COMMENT &#39;手机号码&#39;, `create_at` bigint(20) NOT NULL, `update_at` bigint(20) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=100 DEFAULT CHARSET=utf8; 配置 generatorConfig.xml以下配置文件都放置在classpath下： generator.properties文件： ## jdbc jdbc.driverClassName=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://10.0.0.20:3306/spring-boot-practice?useUnicode=true&amp;amp;characterEncoding=utf-8 jdbc.username=root jdbc.password=root ## model model.targetPackage=com.crw.model ## DAO dao.targetPackage=com.crw.mapper dao.type=XMLMAPPER ## table.name=product_honor table.name=sbp_user generatorConfig.xml文件: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt; &lt;generatorConfiguration&gt; &lt;properties resource=&quot;generator.properties&quot;&gt;&lt;/properties&gt; &lt;context id=&quot;mysql&quot; defaultModelType=&quot;flat&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;property name=&quot;javaFileEncoding&quot; value=&quot;UTF-8&quot;/&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt; &lt;/commentGenerator&gt; &lt;jdbcConnection driverClass=&quot;${jdbc.driverClassName}&quot; connectionURL=&quot;${jdbc.url}&quot; userId=&quot;${jdbc.username}&quot; password=&quot;${jdbc.password}&quot;/&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;javaModelGenerator targetPackage=&quot;${model.targetPackage}&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;immutable&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;javaClientGenerator targetPackage=&quot;${dao.targetPackage}&quot; targetProject=&quot;src/main/java&quot; type=&quot;${dao.type}&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;&quot;/&gt; &lt;property name=&quot;exampleMethodVisibility&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;methodNameCalculator&quot; value=&quot;&quot;/&gt; &lt;property name=&quot;rootInterface&quot; value=&quot;&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;table tableName=&quot;${table.name}&quot; schema=&quot;wealth&quot; enableUpdateByExample=&quot;true&quot;&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; 附录：mybatis generator 配置详解，参考资料：http://www.jianshu.com/p/e09d2370b796 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt; &lt;!-- 配置生成器 --&gt; &lt;generatorConfiguration&gt; &lt;!-- 可以用于加载配置项或者配置文件，在整个配置文件中就可以使用${propertyKey}的方式来引用配置项 resource：配置资源加载地址，使用resource，MBG从classpath开始找，比如com/myproject/generatorConfig.properties url：配置资源加载地质，使用URL的方式，比如file:///C:/myfolder/generatorConfig.properties. 注意，两个属性只能选址一个; 另外，如果使用了mybatis-generator-maven-plugin，那么在pom.xml中定义的properties都可以直接在generatorConfig.xml中使用 &lt;properties resource=&quot;&quot; url=&quot;&quot; /&gt; --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包 location属性指明加载jar/zip包的全路径 &lt;classPathEntry location=&quot;/Program Files/IBM/SQLLIB/java/db2java.zip&quot; /&gt; --&gt; &lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG --&gt; &lt;context id=&quot;mysql&quot; defaultModelType=&quot;hierarchical&quot; targetRuntime=&quot;MyBatis3Simple&quot; &gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name=&quot;autoDelimitKeywords&quot; value=&quot;false&quot;/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name=&quot;javaFileEncoding&quot; value=&quot;UTF-8&quot;/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name=&quot;javaFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultJavaFormatter&quot;/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name=&quot;xmlFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultXmlFormatter&quot;/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;property name=&quot;beginningDelimiter&quot; value=&quot;`&quot;/&gt; &lt;property name=&quot;endingDelimiter&quot; value=&quot;`&quot;/&gt; &lt;!-- 必须要有的，使用这个配置链接数据库 @TODO:是否可以扩展 --&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql:///pss&quot; userId=&quot;root&quot; password=&quot;admin&quot;&gt; &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 --&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type=&quot;org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl&quot;&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage=&quot;com._520it.mybatis.domain&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;false&quot;/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;property name=&quot;immutable&quot; value=&quot;false&quot;/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;property name=&quot;rootClass&quot; value=&quot;com._520it.mybatis.domain.BaseDomain&quot;/&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成SQL map的XML文件生成器， 注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口）， 或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置 targetPackage/targetProject:同javaModelGenerator --&gt; &lt;sqlMapGenerator targetPackage=&quot;com._520it.mybatis.mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;javaClientGenerator targetPackage=&quot;com._520it.mybatis.mapper&quot; type=&quot;ANNOTATEDMAPPER&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name=&quot;rootInterface&quot; value=&quot;&quot;/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的&quot;&quot;把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers=&quot;true&quot;即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName=&quot;userinfo&quot; &gt; &lt;!-- 参考 javaModelGenerator 的 constructorBased属性--&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;false&quot;/&gt; &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； --&gt; &lt;property name=&quot;ignoreQualifiersAtRuntime&quot; value=&quot;false&quot;/&gt; &lt;!-- 参考 javaModelGenerator 的 immutable 属性 --&gt; &lt;property name=&quot;immutable&quot; value=&quot;false&quot;/&gt; &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 --&gt; &lt;property name=&quot;modelOnly&quot; value=&quot;false&quot;/&gt; &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 &lt;property name=&quot;rootClass&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 参考javaClientGenerator 的 rootInterface 属性 &lt;property name=&quot;rootInterface&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog &lt;property name=&quot;runtimeCatalog&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema &lt;property name=&quot;runtimeSchema&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename &lt;property name=&quot;runtimeTableName&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 注意，该属性只针对MyBatis3Simple有用； 如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； --&gt; &lt;property name=&quot;selectAllOrderByClause&quot; value=&quot;age desc,username asc&quot;/&gt; &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN_DATE，生成的属性名字就是BORN_DATE,而不会是bornDate --&gt; &lt;property name=&quot;useActualColumnNames&quot; value=&quot;false&quot;/&gt; &lt;!-- generatedKey用于生成生成主键的方法， 如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选 column:主键的列名； sqlStatement：要生成的selectKey语句，有以下可选项： Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2 :相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2_MF :相当于selectKey的SQL为：SELECT IDENTITY_VAL_LOCAL() FROM SYSIBM.SYSDUMMY1 Derby :相当于selectKey的SQL为：VALUES IDENTITY_VAL_LOCAL() HSQLDB :相当于selectKey的SQL为：CALL IDENTITY() Informix :相当于selectKey的SQL为：select dbinfo(&#39;sqlca.sqlerrd1&#39;) from systables where tabid=1 MySql :相当于selectKey的SQL为：SELECT LAST_INSERT_ID() SqlServer :相当于selectKey的SQL为：SELECT SCOPE_IDENTITY() SYBASE :相当于selectKey的SQL为：SELECT @@IDENTITY JDBC :相当于在生成的insert元素上添加useGeneratedKeys=&quot;true&quot;和keyProperty属性 &lt;generatedKey column=&quot;&quot; sqlStatement=&quot;&quot;/&gt; --&gt; &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候， 比如列名为：CUST_ID,CUST_NAME,CUST_EMAIL,CUST_ADDRESS等； 那么就可以设置searchString为&quot;^CUST_&quot;，并使用空白替换，那么生成的Customer对象中的属性名称就不是 custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email； 注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的， 如果使用了columnOverride元素，该属性无效； &lt;columnRenamingRule searchString=&quot;&quot; replaceString=&quot;&quot;/&gt; --&gt; &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性； column:要重新设置的列名； 注意，一个table元素中可以有多个columnOverride元素哈~ --&gt; &lt;columnOverride column=&quot;username&quot;&gt; &lt;!-- 使用property属性来指定列要生成的属性名称 --&gt; &lt;property name=&quot;property&quot; value=&quot;userName&quot;/&gt; &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名 &lt;property name=&quot;javaType&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- jdbcType用于指定该列的JDBC类型 &lt;property name=&quot;jdbcType&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名 注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler 只会生成类似：where id = #{id,jdbcType=BIGINT,typeHandler=com._520it.mybatis.MyTypeHandler}的参数描述 &lt;property name=&quot;jdbcType&quot; value=&quot;&quot;/&gt; --&gt; &lt;!-- 参考table元素的delimitAllColumns配置，默认为false &lt;property name=&quot;delimitedColumnName&quot; value=&quot;&quot;/&gt; --&gt; &lt;/columnOverride&gt; &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 column:指定要忽略的列的名字； delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false 注意，一个table元素中可以有多个ignoreColumn元素 &lt;ignoreColumn column=&quot;deptId&quot; delimitedColumnName=&quot;&quot;/&gt; --&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; 通过mybatis-generator-maven-plugin插件生产代码配置maven依赖： &lt;build&gt; &lt;plugins&gt; ... &lt;!-- mybatis generator--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 运行命令： mvn mybatis-generator:generate 即可生成相应的代码至相应的配置目录。 集成mybatis三步完成集成： 添加maven依赖 配置数据源和Mybatis 单元测试 添加maven依赖依赖spring-boot相关以及jdbc相关： &lt;dependencies&gt; &lt;!-- spring-boot相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置数据源和Mybatis配置spring-boot的application.yml(如果喜欢用application.properties)的改成相应的格式即可。 如下创建连接池和mybatis配置： # jdbc-DruidDataSource连接池配置 sbp.datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/spring-boot-practice?useUnicode=true&amp;amp;characterEncoding=utf8mb4&amp;amp;useSSL=false&amp;amp;autoReconnect=true username: root password: root # mybatis mybatis: mapperLocations: classpath:mapper/*.xml configuration.mapUnderscoreToCamelCase: true 创建DataSource,映射配置文件内容，扫描mapper接口： @Configuration @MapperScan(basePackages = &quot;com.crw.mapper&quot;) public class DataSourceConfig { @Bean @ConfigurationProperties(prefix = &quot;sbp.datasource&quot;) public DataSource datasource() { return new DruidDataSource(); } } 单元测试测试mybatis是否正常: @RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = App.class) public class SbpUserMapperTest { @Autowired private SbpUserMapper sbpUserMapper; @Test @Rollback public void insert() throws Exception { long now = System.currentTimeMillis(); int id = sbpUserMapper.insert(new SbpUser(1L, &quot;张三&quot;, &quot;111111&quot;, &quot;11100001001&quot;, now, now)); Assert.assertEquals(id, 1L); } @Test @Rollback public void selectByPrimaryKey() throws Exception { SbpUser user = sbpUserMapper.selectByPrimaryKey(1L); Assert.assertEquals(&quot;张三&quot;, user.getNickName()); } @Test @Rollback public void update() throws Exception { long now = System.currentTimeMillis(); sbpUserMapper.updateByPrimaryKey(new SbpUser(1L, &quot;张三改&quot;, &quot;111111&quot;, &quot;11100001001&quot;, now, now)); SbpUser user = sbpUserMapper.selectByPrimaryKey(1L); Assert.assertEquals(&quot;张三改&quot;, user.getNickName()); } @Test @Rollback public void selectByExample() throws Exception { SbpUserExample example = new SbpUserExample(); SbpUserExample.Criteria criteria = example.createCriteria(); criteria.andMobileEqualTo(&quot;11100001001&quot;); List&lt;SbpUser&gt; users = sbpUserMapper.selectByExample(example); Assert.assertEquals(users.size(), 1); } } 运行之后正常CRUD，完成spring-boot与Mybatis的集成。 结束语本篇文章从创建spring-boot项目开始介绍了集成mybatis的过程。 可以见到spring-boot是多么的高效： 一分钟(半分钟)创建spring-boot项目 三步完成myybatis代码自动生成 三步配置集成mybatis 前后大概10分钟时间绰绰有余了。效率是不是不差于世界上最好的PHP呢？(:D)]]></content>
      <categories>
        <category>spring-boot</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发修行之基础篇：线程安全]]></title>
    <url>%2Fjava-concurrency%2Fjava-concurrency-base-threadsafe%2F</url>
    <content type="text"><![CDATA[前言在互联网应用广泛的今天，软件并发已经成为目前软件开发的必备基础。java作为一门成熟的语言，其拥有着极其高效的并发机制，是目前大中型企业的常用开发语言。想要开发大规模应用，java并发已成为java程序猿们的必备基础技能。 从今天开始，开启java并发修行之路。 什么是线程安全性线程的安全性总是难以定义的。 在阅读《java并发编程实战》的过程中觉得说的很好： 在线程安全性的定义中，最核心的概念就是正确性。 何为正确性？ 某个类的行为与其规范完全一致。 通常我们并不规定类的规范，于是我们通俗对正确性的理解是，单线程的类的行为是按照我们“所见”来运行的，我们确保其可信，“所见即所知”。 于是给出线程安全性的定义： 当多个线程访问某个类时，这个类始终都能表现出正确的行为。 某个对象保证多线程环境下共享、可修改的状态的正确性，那么即是线程安全。 换个角度分析： 当某个类单线程条件都不是正确的，那么其肯定不是线程安全的。 无状态对象一定线程安全 状态不共享或不可修改，即不存在线程安全问题。 如何做到线程安全线程安全要保证： 原子性。保证一组相关操作在竞态条件下保证结果可靠。 可见性。当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性。避免指令重排序。 解释一下上面三个安全特性： 原子性关键词：一组相关操作、竞态条件。 先解释竞态条件： 当某个计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。 简单的说，其本质就是基于了一个错误的状态去判断或执行计算。 上代码举例。比如一个多线程累加并打印偶数的程序。 程序A：典型的竞态条件无处理: public class EchoEvenNumService implements Runnable { private int num; @Override public void run() { if (num % 2 == 0) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(num + &quot;\t&quot;); } num++; } } 运行main程序: public static void main(String[] args) { EchoEvenNumService service = new EchoEvenNumService(); for (int i = 0; i &lt; 100; i++) { new Thread(service).start(); } } 结果是可想而知的，奇数偶数都有： 0 1 1 2 4 3 2 1 1 9 9 10 9 9 9 9 10 9 18 18 18 20 21 22 20 20 19 ... 程序B有些同学会觉得，num改成线程安全的类型(AtomicInteger)就可以了，可是事实是这样吗？修改程序A: public class EchoEvenNumService implements Runnable { private AtomicInteger num = new AtomicInteger(0); @Override public void run() { if (num.get() % 2 == 0) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(num.get() + &quot;\t&quot;); } num.incrementAndGet(); } } 运行main方法后，你会发现还是奇数偶数都有： 0 0 2 3 4 5 5 5 5 7 9 6 6 13 14 14 14 15 18 14 17 20 20 17 21 25 25 26 28 28 29 30 ... 这么写是因为没有理解一组相关操作。在上面的程序中，实际上需要做到三个操作：1.num.get() % 2 == 0判断。2.打印偶数。3.num递增。 即时上面三个操作各做各的做到了原子性，但是整体并不是原子性，程序依旧会错误。 程序C做到整体的原子性，加锁同步。修改程序A： public class EchoEvenNumService implements Runnable { private int num; private ReentrantLock lock = new ReentrantLock(); @Override public void run() { try { lock.lock(); if (num % 2 == 0) { try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print(num + &quot;\t&quot;); } num++; } finally { lock.unlock(); } } } 运行main方法后，程序终于保证了正确性: 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 可见性保证共享变量有效。 这里需要简单提一下Java的内存模型: 看图说话: 主内存(Main Memory),存储所有变量。 工作内存(Working Memory),保存了该线程使用到的变量的主存副本拷贝。 线程、工作内存、主存三者关系：线程对变量的所有操作(读写等)都必须在工作内存中进行，而不能之间读写主内存中的变量。 如此可见，如果程序没有保证可见性，会使一部分线程读取到的是工作内存中的值(并不一定准确)，导致程序不正确执行。 如何保证可见性？手段：加锁，volatile修饰。 有序性解释下“重排序”现象： 在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。 比如赋值两个变量: private int a; private int b; 线程A对a,b进行赋值,代码中的逻辑是这样的: a = 1; b = 2; 线程A在运行时，对a变量赋值发现a变量在主存中被其他线程加锁不能访问，线程A并不会等待锁释放，它会去尝试获取b变量，当b变量没有被占用时，线程A的执行过程就会变成这样: b = 2; a = 1; 这就是JVM内部优化导致的“指令重排序”。 重排序可能导致一些重要的状态值的读取顺序改变导致程序异常甚至会死循环发生OOM。 比如如下程序： public class NoVisibility { private static boolean ready; private static int number; private static class ReaderThread extends Thread { public void run() { while (!ready) Thread.yield(); System.out.println(number); } } public static void main(String[] args) { new ReaderThread().start(); number = 42; ready = true; } } 这个程序的诡异之处在于，ReaderThread可能永远看不到ready值，更诡异的是ReaderThread的输出可能是0，ReaderThread只读到了ready的值但没有读到number值。这一切“归功于”神奇的“重排序”。 解决方式:同步。 总结本文java并发修行的第一篇，重在基础。本文简单讲解了线程安全的“定义”，以及线程安全的一些基础概念。核心在于线程并发处理共享变量时的三点保证：原子性，可见性，有序性。细细体会之，后续准备从源码层面详细对这三点进行分析。]]></content>
      <categories>
        <category>java-concurrency</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从一份配置清单详解Nginx服务器配置]]></title>
    <url>%2Fnginx%2Fexplain-nginx-server-config%2F</url>
    <content type="text"><![CDATA[前言Nginx是现在企业上用的比较多的高性能的HTTP和反向代理服务器。入门Nginx一定少不了学习它的配置文件。本文将比较详细的介绍一下Nginx的各个配置项。 本文转载自CodeSheep的技术博文。 原文地址:https://my.oschina.net/hansonwang99/blog/1835408 概述在前面《Nginx服务器开箱体验》 一文中我们从开箱到体验，感受了一下Nginx服务器的魅力。Nginx是轻量级的高性能Web服务器，提供了诸如HTTP代理和反向代理、负载均衡、缓存等一系列重要特性，因而在实践之中使用广泛，笔者也在学习和实践之中。 在本文中，我们继续延续前文，从前文给出的一份示例配置清单开始，详解一下Nginx服务器的各种配置指令的作用和用法。 看到了下文中的包含了 “小猪佩琪色” 的配图了吗，嘿嘿，我们开始吧！ Nginx配置文件的整体结构 从图中可以看出主要包含以下几大部分内容： 1. 全局块该部分配置主要影响Nginx全局，通常包括下面几个部分： 配置运行Nginx服务器用户（组） worker process数 Nginx进程PID存放路径 错误日志的存放路径 配置文件的引入 2. events块该部分配置主要影响Nginx服务器与用户的网络连接，主要包括： 设置网络连接的序列化 是否允许同时接收多个网络连接 事件驱动模型的选择 最大连接数的配置 3. http块 定义MIMI-Type 自定义服务日志 允许sendfile方式传输文件 连接超时时间 单连接请求数上限 4. server块 配置网络监听 于名称的虚拟主机配置 基于IP的虚拟主机配置 5. location块 location配置 请求根目录配置 更改location的URI 网站默认首页配置 一份配置清单例析笔者按照文章：《Nginx服务器开箱体验》 中的实验，给出了一份简要的清单配置举例： 配置代码如下： user nobody nobody; worker_processes 3; error_log logs/error.log; pid logs/nginx.pid; events { use epoll; worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; server { listen 8088; server_name codesheep; access_log /codesheep/webserver/server1/log/access.log; error_page 404 /404.html; location /server1/location1 { root /codesheep/webserver; index index.server2-location1.htm; } location /server1/location2 { root /codesheep/webserver; index index.server2-location2.htm; } } server { listen 8089; server_name 192.168.31.177; access_log /codesheep/webserver/server2/log/access.log; error_page 404 /404.html; location /server2/location1 { root /codesheep/webserver; index index.server2-location1.htm; } location /srv2/loc2 { alias /codesheep/webserver/server2/location2/; index index.server2-location2.htm; } location = /404.html { root /codesheep/webserver/; index 404.html; } } } 接下来就来详细剖析以下配置文件中各个指令的含义⬇️ 配置文件指令配置运行Nginx服务器用户（组）指令格式:user user [group]; user：指定可以运行Nginx服务器的用户 group：可选项，可以运行Nginx服务器的用户组 如果user指令不配置或者配置为 user nobody nobody ，则默认所有用户都可以启动Nginx进程 worker process数配置Nginx服务器实现并发处理服务的关键，指令格式：worker_processes number | auto; number：Nginx进程最多可以产生的worker process数 auto：Nginx进程将自动检测 按照上文中的配置清单的实验，我们给worker_processes配置的数目是：3，启动Nginx服务器后，我们可以后台看一下主机上的Nginx进程情况： ps -aux | grep nginx 很明显，理解 worker_processes 这个指令的含义就很容易了 Nginx进程PID存放路径Nginx进程是作为系统守护进程在运行，需要在某文件中保存当前运行程序的主进程号，Nginx支持该保存文件路径的自定义 指令格式：pid file; file：指定存放路径和文件名称 如果不指定默认置于路径 logs/nginx.pid 错误日志的存放路径指定格式：error_log file | stderr; file：日志输出到某个文件file stderr：日志输出到标准错误输出 配置文件的引入指令格式：include file; 该指令主要用于将其他的Nginx配置或者第三方模块的配置引用到当前的主配置文件中 设置网络连接的序列化指令格式：accept_mutex on | off; 该指令默认为on状态，表示会对多个Nginx进程接收连接进行序列化，防止多个进程对连接的争抢。 说到该指令，首先得阐述一下什么是所谓的 “惊群问题”，可以参考 WIKI百科的解释。就Nginx的场景来解释的话大致的意思就是：当一个新网络连接来到时，多个worker进程会被同时唤醒，但仅仅只有一个进程可以真正获得连接并处理之。如果每次唤醒的进程数目过多的话，其实是会影响一部分性能的。 所以在这里，如果accept_mutex on，那么多个worker将是以串行方式来处理，其中有一个worker会被唤醒；反之若accept_mutex off，那么所有的worker都会被唤醒，不过只有一个worker能获取新连接，其它的worker会重新进入休眠状态 这个值的开关与否其实是要和具体场景挂钩的。 是否允许同时接收多个网络连接指令格式：multi_accept on | off; 该指令默认为off状态，意指每个worker process 一次只能接收一个新到达的网络连接。若想让每个Nginx的worker process都有能力同时接收多个网络连接，则需要开启此配置 事件驱动模型的选择指令格式：use model; model模型可选择项包括：select、poll、kqueue、epoll、rtsig等…… 最大连接数的配置指令格式：worker_connections number; number默认值为512，表示允许每一个worker process可以同时开启的最大连接数 定义MIME-Type指令格式： include mime.types; default_type mime-type; MIME-Type指的是网络资源的媒体类型，也即前端请求的资源类型 include指令将mime.types文件包含进来 cat mime.types 来查看mime.types文件内容，我们发现其就是一个types结构，里面包含了各种浏览器能够识别的MIME类型以及对应类型的文件后缀名字，如下所示： 自定义服务日志指令格式：access_log path [format]; path：自定义服务日志的路径 + 名称 format：可选项，自定义服务日志的字符串格式。其也可以使用 log_format 定义的格式 允许sendfile方式传输文件指令格式： sendfile on | off; sendfile_max_chunk size; 前者用于开启或关闭使用sendfile()传输文件，默认off 后者指令若size&gt;0，则Nginx进程的每个worker process每次调用sendfile()传输的数据了最大不能超出此值；若size=0则表示不限制。默认值为0 连接超时时间配置指令格式：keepalive_timeout timeout [header_timeout]; timeout 表示server端对连接的保持时间，默认75秒 header_timeout 为可选项，表示在应答报文头部的 Keep-Alive 域设置超时时间：“Keep-Alive : timeout = header_timeout” 单连接请求数上限指令格式：keepalive_requests number; 该指令用于限制用户通过某一个连接向Nginx服务器发起请求的次数 配置网络监听指令格式： 第一种：配置监听的IP地址：listen IP[:PORT]; 第二种：配置监听的端口：listen PORT; 基于名称和IP的虚拟主机配置指令格式：server_name name1 name2 ... name可以有多个并列名称，而且此处的name支持正则表达式书写 实际举例： server_name ~^www\d+\.myserver\.com$ 此时表示该虚拟主机可以接收类似域名 www1.myserver.com 等的请求而拒绝 www.myserver.com 的域名请求，所以说用正则表达式可以实现更精准的控制。 至于基于IP的虚拟主机配置比较简单，不再太赘述： 指令格式：server_name IP地址 location配置指令格式为：location [ = | ~ | ~* | ^~ ] uri {...} 这里的uri分为标准uri和正则uri，两者的唯一区别是uri中是否包含正则表达式 uri前面的方括号中的内容是可选项，解释如下： “=”：用于标准uri前，要求请求字符串与uri严格匹配，一旦匹配成功则停止 “~”：用于正则uri前，并且区分大小写 “~*”：用于正则uri前，但不区分大小写 “^~”：用于标准uri前，要求Nginx找到标识uri和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配 请求根目录配置指令格式：root path; path：Nginx接收到请求以后查找资源的根目录路径 当然，还可以通过alias指令来更改location接收到的URI请求路径，指令为： 设置网站的默认首页指令格式：index file ...... file可以包含多个用空格隔开的文件名，首先找到哪个页面，就使用哪个页面响应请求 结束语非常感谢CodeSheep的的分享！ 通过本文并结合官方文档，并加以加以使用，多多去体验Nginx的神奇吧。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>转载摘抄</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo扩展机制实现(三)之扩展点特性]]></title>
    <url>%2Fdubbo%2Fdubbo-spi-extension-feature%2F</url>
    <content type="text"><![CDATA[前言上一篇简单分析了Dubbo的扩展点机制的实现，以及其与java spi的区别与改进。 本篇文章准备从扩展点特性的角度分析一下源码。 扩展点自动装配 加载扩展点时，自动注入依赖的扩展点。加载扩展点时，扩展点实现类的成员如果为其它扩展点类型，ExtensionLoader 在会自动注入依赖的扩展点。ExtensionLoader 通过扫描扩展点实现类的所有 setter 方法来判定其成员。即 ExtensionLoader 会执行扩展点的拼装操作。 上一篇提到了Dubbo的ExtensionLoader提供了三种获取扩展点实现类的方式，其中的一种是根据名字获取扩展点实现: public T getExtension(String name) { if (name == null || name.length() == 0) throw new IllegalArgumentException(&quot;Extension name == null&quot;); if (&quot;true&quot;.equals(name)) { // 判断是否是获取默认实现 return getDefaultExtension(); } Holder&lt;Object&gt; holder = cachedInstances.get(name); // 从缓存中取 if (holder == null) { cachedInstances.putIfAbsent(name, new Holder&lt;Object&gt;()); holder = cachedInstances.get(name); } Object instance = holder.get(); if (instance == null) { synchronized (holder) { instance = holder.get(); if (instance == null) { instance = createExtension(name); // 创建缓存实例 holder.set(instance); } } } return (T) instance; } 还是用到了缓存，先是判断是否取默认实例，再是从缓存取和设置缓存。接下来看一下创建扩展点的方法createExtension(name): private T createExtension(String name) { Class&lt;?&gt; clazz = getExtensionClasses().get(name); // 加载当前Extension的所有实现, 并从中获取指定name的Extension if (clazz == null) { throw findException(name); } try { T instance = (T) EXTENSION_INSTANCES.get(clazz); // 从Extension实例缓存中获取实例 if (instance == null) { EXTENSION_INSTANCES.putIfAbsent(clazz, (T) clazz.newInstance()); instance = (T) EXTENSION_INSTANCES.get(clazz); } injectExtension(instance); // 注入扩展点信息 Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } return instance; } catch (Throwable t) { throw new IllegalStateException(&quot;Extension instance(name: &quot; + name + &quot;, class: &quot; + type + &quot;) could not be instantiated: &quot; + t.getMessage(), t); } } 如上代码所示，createExtension(name)创建一个扩展点实例大致做了两件事： 调用getExtensionClasses()加载了扩展点类，并通过名字获取到扩展点的Class类对象 创建扩展点的Class类对象的实例，并调用injectExtension(instance) 注入扩展点信息 getExtensionClasses()暂且不说，比较重要的一个方法，在获取自适应扩展点的时候也会用到此方法。 injectExtension(instance) 注入扩展点信息，这里便展示了扩展点自动装配的特性。private T injectExtension(T instance) { try { if (objectFactory != null) { for (Method method : instance.getClass().getMethods()) { // 处理所有set方法 if (method.getName().startsWith(&quot;set&quot;) &amp;&amp; method.getParameterTypes().length == 1 &amp;&amp; Modifier.isPublic(method.getModifiers())) { Class&lt;?&gt; pt = method.getParameterTypes()[0]; try { // 获取setter对应的property名称 String property = method.getName().length() &gt; 3 ? method.getName().substring(3, 4).toLowerCase() + method.getName().substring(4) : &quot;&quot;; // 根据参数类型和属性名称，从 ExtensionFactory 里获取扩展点 Object object = objectFactory.getExtension(pt, property); if (object != null) { // 如果不为空，则 setter 方法的参数是扩展点类型，那么进行注入 method.invoke(instance, object); } } catch (Exception e) { logger.error(&quot;fail to inject via method &quot; + method.getName() + &quot; of interface &quot; + type.getName() + &quot;: &quot; + e.getMessage(), e); } } } } } catch (Exception e) { logger.error(e.getMessage(), e); } return instance; } 这里可以看到，扩展点自动注入就是根据setter方法对应的参数类型和property名称从ExtensionFactory中查询，如果有返回扩展点实例，那么就进行注入操作。 扩展点自适应Dubbo扩展点有一个非常重要的概念：Adaptive. ExtensionLoader 注入的依赖扩展点是一个 Adaptive 实例，直到扩展点方法执行时才决定调用是一个扩展点实现。 Dubbo 使用 URL 对象（包含了Key-Value）传递配置信息。 扩展点方法调用会有URL参数（或是参数有URL成员） 这样依赖的扩展点也可以从URL拿到配置信息，所有的扩展点自己定好配置的Key后，配置信息从URL上从最外层传入。URL在配置传递上即是一条总线。 来看看Dubbo获取自适应扩展点的方法:getAdaptiveExtension(): public T getAdaptiveExtension() { Object instance = cachedAdaptiveInstance.get(); // 从缓存中获取自适应实例 if (instance == null) { if (createAdaptiveInstanceError == null) { synchronized (cachedAdaptiveInstance) { instance = cachedAdaptiveInstance.get(); if (instance == null) { try { instance = createAdaptiveExtension(); // 创建自适应实例并缓存 cachedAdaptiveInstance.set(instance); } catch (Throwable t) { createAdaptiveInstanceError = t; throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + t.toString(), t); } } } } else { throw new IllegalStateException(&quot;fail to create adaptive instance: &quot; + createAdaptiveInstanceError.toString(), createAdaptiveInstanceError); } } return (T) instance; } 又是缓存，看看如何创建一个自适应扩展点:createAdaptiveExtension() private T createAdaptiveExtension() { try { return injectExtension((T) getAdaptiveExtensionClass().newInstance()); } catch (Exception e) { throw new IllegalStateException(&quot;Can not create adaptive extension &quot; + type + &quot;, cause: &quot; + e.getMessage(), e); } } injectExtension(instance)方法上面说明过了，是对扩展点自动装配。主要看getAdaptiveExtensionClass()方法： private Class&lt;?&gt; getAdaptiveExtensionClass() { getExtensionClasses(); // 加载当前Extension的所有实现 if (cachedAdaptiveClass != null) { return cachedAdaptiveClass; } return cachedAdaptiveClass = createAdaptiveExtensionClass(); // 动态创建自适应扩展类 Class 对象 } getExtensionClasses()是个很重要的方法，三种获取扩展点实现的方法都会用到这个方法，这个稍后说明一下。这里主要看createAdaptiveExtensionClass(): private Class&lt;?&gt; createAdaptiveExtensionClass() { String code = createAdaptiveExtensionClassCode(); // 自适应扩展类拼装代码 ClassLoader classLoader = findClassLoader(); com.alibaba.dubbo.common.compiler.Compiler compiler = ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.common.compiler.Compiler.class).getAdaptiveExtension(); return compiler.compile(code, classLoader); // 动态编译 } 这里也是获取了Compiler接口的自适应扩展点AdaptiveCompiler的实现，由于实现里又compiler = loader.getDefaultExtension()获取了默认的扩展点，即JavassistCompiler的实例，来实现了动态编译。通过断点看一下通过 javassist 生成的实现类长啥样，以Protocol的自适应扩展点来看(debug打印后格式化并做了注释方便看): package com.alibaba.dubbo.rpc; import com.alibaba.dubbo.common.extension.ExtensionLoader; public class Protocol$Adaptive implements com.alibaba.dubbo.rpc.Protocol { public void destroy() { throw new UnsupportedOperationException(&quot;method public abstract void com.alibaba.dubbo.rpc.Protocol.destroy() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); } public int getDefaultPort() { throw new UnsupportedOperationException(&quot;method public abstract int com.alibaba.dubbo.rpc.Protocol.getDefaultPort() of interface com.alibaba.dubbo.rpc.Protocol is not adaptive method!&quot;); } public com.alibaba.dubbo.rpc.Exporter export(com.alibaba.dubbo.rpc.Invoker arg0) throws com.alibaba.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument == null&quot;); if (arg0.getUrl() == null) throw new IllegalArgumentException(&quot;com.alibaba.dubbo.rpc.Invoker argument getUrl() == null&quot;);com.alibaba.dubbo.common.URL url = arg0.getUrl(); // 从url中获取扩展点名称,如果没有就赋值为默认的值 String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); // 通过名字获取扩展点实现 com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); } public com.alibaba.dubbo.rpc.Invoker refer(java.lang.Class arg0, com.alibaba.dubbo.common.URL arg1) throws com.alibaba.dubbo.rpc.RpcException { if (arg1 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg1; // 从url中获取扩展点名称,如果没有就赋值为默认的值 String extName = ( url.getProtocol() == null ? &quot;dubbo&quot; : url.getProtocol() ); if(extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.alibaba.dubbo.rpc.Protocol) name from url(&quot; + url.toString() + &quot;) use keys([protocol])&quot;); // 通过名字获取扩展点实现 com.alibaba.dubbo.rpc.Protocol extension = (com.alibaba.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(com.alibaba.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); } } 从上可以看到，确实正如Dubbo所描述的那样，通过url传递配置信息。 扩展点自动包装在官方文档中有如下说明： 自动包装扩展点的 Wrapper 类。ExtensionLoader 在加载扩展点时，如果加载到的扩展点有拷贝构造函数，则判定为扩展点 Wrapper 类。 在源码里的体现，在加载扩展点文件 loadFile(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) 里会根据构造器函数进行判断是否是 Wrapper类： try { clazz.getConstructor(type); // 判断是否 Wrapper 类型 Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) { cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; } wrappers.add(clazz); } catch (NoSuchMethodException e) { // 非 Wrapper 类型 ... } 其次在创建扩展点实例的时候也会根据是否是 Wrapper 类来创建相应的扩展点，这在createExtension(String name)中的体现: Set&lt;Class&lt;?&gt;&gt; wrapperClasses = cachedWrapperClasses; // 获取缓存的Wrapper类集合 // 如果是包装类则创建包装类扩展点实例 if (wrapperClasses != null &amp;&amp; !wrapperClasses.isEmpty()) { for (Class&lt;?&gt; wrapperClass : wrapperClasses) { instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance)); } } return instance; 那么，为什么要使用 Wrapper 类呢？ Wrapper 类同样实现了扩展点接口，但是 Wrapper 不是扩展点的真正实现。它的用途主要是用于从 ExtensionLoader返回扩展点时，包装在真正的扩展点实现外。即从 ExtensionLoader 中返回的实际上是 Wrapper 类的实例，Wrapper 持有了实际的扩展点实现类。 扩展点的 Wrapper 类可以有多个，也可以根据需要新增。 通过 Wrapper 类可以把所有扩展点公共逻辑移至 Wrapper 中。新加的 Wrapper 在所有的扩展点上添加了逻辑，有些类似 AOP，即 Wrapper 代理了扩展点。 从这里看 Dubbo 的aop实际上是装饰者设计模式 + 自适应特性的动态代理。 举个例子，在之前写Dubbo暴露过程的源码中对Protocol接口的调用过程进行了分析，在ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();获取Protocol自适应扩展点的时序是ProtocolListenerWrapper-&gt;ProtocolFilterWrapper-&gt;DubboProtocol。 在真正暴露服务之前，对此进行了一些额外的扩展操作，通过这些层层包装使得各个类逻辑分明，代码维护性高。 扩展点自动激活先看官方文档： 对于集合类扩展点，比如：Filter, InvokerListener, ExportListener, TelnetHandler, StatusChecker 等，可以同时加载多个实现，此时，可以用自动激活来简化配置。 Dubbo实现自动激活的核心关键词:Activate。 @Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.TYPE, ElementType.METHOD}) public @interface Activate { /** * 根据group匹配当前扩展点 * * @return 匹配的group名称 */ String[] group() default {}; /** * 当URL上的参数包含指定的keys时，激活当前的扩展点 * &lt;p&gt; * 举个栗子, 当使用 &lt;code&gt;@Activate(&quot;cache, validation&quot;)&lt;/code&gt;, 当URL参数上包含&lt;code&gt;cache&lt;/code&gt; 或 &lt;code&gt;validation&lt;/code&gt; 时，当前扩展点才会被激活 * &lt;/p&gt; * * @return URL 参数上的key值 */ String[] value() default {}; /** * 相对排序信息, 可选 * * @return 应当放在当前扩展点之前的扩展点列表 */ String[] before() default {}; /** * 相对排序信息, 可选 * * @return 应当放在当前扩展点之前的扩展点列表 */ String[] after() default {}; /** * 绝对排序信息, 可选 * * @return 绝对排序信息 */ int order() default 0; } 总之就是根据注解的 value 和 group 两个属性来决定是否激活。比如CacheFilter： @Activate(group = {Constants.CONSUMER, Constants.PROVIDER}, value = Constants.CACHE_KEY) public class CacheFilter implements Filter {} 当满足条件: 服务提供者 和 服务消费者 url上的参数包含cache 则激活 CacheFilter 那么，Dubbo如何使用 Activate 呢？没错，一定还记得那个方法:getActivateExtension。 getActivateExtension有多个重写的方法，但实际最终会调用到如下： public List&lt;T&gt; getActivateExtension(URL url, String[] values, String group) { List&lt;T&gt; exts = new ArrayList&lt;T&gt;(); List&lt;String&gt; names = values == null ? new ArrayList&lt;String&gt;(0) : Arrays.asList(values); if (!names.contains(Constants.REMOVE_VALUE_PREFIX + Constants.DEFAULT_KEY)) { getExtensionClasses(); // 此处缓存了 cachedActivates for (Map.Entry&lt;String, Activate&gt; entry : cachedActivates.entrySet()) { String name = entry.getKey(); // 获取 可激活的扩展点的spi扩展名 Activate activate = entry.getValue(); if (isMatchGroup(group, activate.group())) { // 如果group匹配 T ext = getExtension(name); // 根据扩展点名称获取扩展点实例 // name不在 values 指定的列，且没排除name，且url上有activate的value，则激活 if (!names.contains(name) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name) &amp;&amp; isActive(activate, url)) { exts.add(ext); } } } Collections.sort(exts, ActivateComparator.COMPARATOR); // 排序 } List&lt;T&gt; usrs = new ArrayList&lt;T&gt;(); for (int i = 0; i &lt; names.size(); i++) { // 指定使用values的时候 String name = names.get(i); // 所有未被排除的扩展名 if (!name.startsWith(Constants.REMOVE_VALUE_PREFIX) &amp;&amp; !names.contains(Constants.REMOVE_VALUE_PREFIX + name)) { if (Constants.DEFAULT_KEY.equals(name)) { if (!usrs.isEmpty()) { exts.addAll(0, usrs); usrs.clear(); } } else { T ext = getExtension(name); usrs.add(ext); } } } if (!usrs.isEmpty()) { exts.addAll(usrs); } return exts; } 关于Activate的使用场景：当需要提供一组需要指定条件的扩展点并使用的时候。比如在ProtocolFilterWrapper的buildInvokerChain里构建一组Filter时，Dubbo是这么处理的: List&lt;Filter&gt; filters = ExtensionLoader.getExtensionLoader(Filter.class).getActivateExtension(invoker.getUrl(), key, group); 扩展点的一些核心方法在整个扩展点源码里，有一些核心的方法贯穿整个ExtensionLoader。 首先是之前常见得getExtensionClasses() 这个方法里进行了： 缓存扩展点Class 从指定文件路径加载扩展点文件 创建扩展点 getExtensionClasses()里的核心方法是loadExtensionClasses. private Map&lt;String, Class&lt;?&gt;&gt; loadExtensionClasses() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); // 先获取 @SPI 注解中的默认值 if (defaultAnnotation != null) { // 如果 @SPI 注解存在 value 默认值, 赋值给 cachedDefaultName 属性 String value = defaultAnnotation.value(); if (value != null &amp;&amp; (value = value.trim()).length() &gt; 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length &gt; 1) { // 每个扩展点实现只能配置一个名字 throw new IllegalStateException(&quot;more than 1 default extension name on extension &quot; + type.getName() + &quot;: &quot; + Arrays.toString(names)); } if (names.length == 1) cachedDefaultName = names[0]; } } // 从配置路径中加载扩展实现类 Map&lt;String, Class&lt;?&gt;&gt; extensionClasses = new HashMap&lt;String, Class&lt;?&gt;&gt;(); loadFile(extensionClasses, DUBBO_INTERNAL_DIRECTORY); loadFile(extensionClasses, DUBBO_DIRECTORY); loadFile(extensionClasses, SERVICES_DIRECTORY); return extensionClasses; } 真正开始加载扩展点文件的方法:loadFile.下面，简单粗暴的贴源码： private void loadFile(Map&lt;String, Class&lt;?&gt;&gt; extensionClasses, String dir) { String fileName = dir + type.getName(); // 获取文件路径名 try { Enumeration&lt;java.net.URL&gt; urls; ClassLoader classLoader = findClassLoader(); // 获取了类加载器 if (classLoader != null) { urls = classLoader.getResources(fileName); } else { urls = ClassLoader.getSystemResources(fileName); } if (urls != null) { while (urls.hasMoreElements()) { java.net.URL url = urls.nextElement(); try { BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream(), &quot;utf-8&quot;)); // 也是以utf-8方式读取配置文件 try { String line = null; while ((line = reader.readLine()) != null) { // 解析每行数据 final int ci = line.indexOf(&#39;#&#39;); if (ci &gt;= 0) line = line.substring(0, ci); line = line.trim(); if (line.length() &gt; 0) { // 非注释内容 try { String name = null; int i = line.indexOf(&#39;=&#39;); if (i &gt; 0) { name = line.substring(0, i).trim(); // 配置中的 key line = line.substring(i + 1).trim(); // 配置中的 value } if (line.length() &gt; 0) { Class&lt;?&gt; clazz = Class.forName(line, true, classLoader); // 获取class对象 if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(&quot;Error when load extension class(interface: &quot; + type + &quot;, class line: &quot; + clazz.getName() + &quot;), class &quot; + clazz.getName() + &quot;is not subtype of interface.&quot;); } if (clazz.isAnnotationPresent(Adaptive.class)) { // 如果注解了@Adaptive if (cachedAdaptiveClass == null) { cachedAdaptiveClass = clazz; // 缓存 cachedAdaptiveClass } else if (!cachedAdaptiveClass.equals(clazz)) { // 只允许一个 Adaptive 实现 throw new IllegalStateException(&quot;More than 1 adaptive class found: &quot; + cachedAdaptiveClass.getClass().getName() + &quot;, &quot; + clazz.getClass().getName()); } } else { try { clazz.getConstructor(type); // 判断是否 Wrapper 类型 Set&lt;Class&lt;?&gt;&gt; wrappers = cachedWrapperClasses; if (wrappers == null) { cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?&gt;&gt;(); wrappers = cachedWrapperClasses; } wrappers.add(clazz); } catch (NoSuchMethodException e) { // 非 Wrapper 类型 clazz.getConstructor(); // 获取class对象的无参构造器 if (name == null || name.length() == 0) { name = findAnnotationName(clazz); if (name == null || name.length() == 0) { if (clazz.getSimpleName().length() &gt; type.getSimpleName().length() &amp;&amp; clazz.getSimpleName().endsWith(type.getSimpleName())) { name = clazz.getSimpleName().substring(0, clazz.getSimpleName().length() - type.getSimpleName().length()).toLowerCase(); } else { throw new IllegalStateException(&quot;No such extension name for the class &quot; + clazz.getName() + &quot; in the config &quot; + url); } } } String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length &gt; 0) { Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) { cachedActivates.put(names[0], activate); // 缓存 cachedActivates } for (String n : names) { if (!cachedNames.containsKey(clazz)) { cachedNames.put(clazz, n); // 缓存 cachedNames ,每个class只对应一个名称 } Class&lt;?&gt; c = extensionClasses.get(n); if (c == null) { extensionClasses.put(n, clazz); // 放入到extensionClasses中,多个 name 可能对应一个Class } else if (c != clazz) { // 重复抛异常 throw new IllegalStateException(&quot;Duplicate extension &quot; + type.getName() + &quot; name &quot; + n + &quot; on &quot; + c.getName() + &quot; and &quot; + clazz.getName()); } } } } } } } catch (Throwable t) { IllegalStateException e = new IllegalStateException(&quot;Failed to load extension class(interface: &quot; + type + &quot;, class line: &quot; + line + &quot;) in &quot; + url + &quot;, cause: &quot; + t.getMessage(), t); exceptions.put(line, e); } } } // end of while read lines } finally { reader.close(); } } catch (Throwable t) { logger.error(&quot;Exception when load extension class(interface: &quot; + type + &quot;, class file: &quot; + url + &quot;) in &quot; + url, t); } } // end of while urls } } catch (Throwable t) { logger.error(&quot;Exception when load extension class(interface: &quot; + type + &quot;, description file: &quot; + fileName + &quot;).&quot;, t); } } 文件加载完成后，几个实例被缓存了: cachedAdaptiveClass(自适应扩展点) cachedWrapperClasses(扩展点包装类) cachedActivates(扩展点激活类) cachedNames(Class-&gt;name映射) 在获取扩展点的三个方法中会常使用缓存了的数据，由此可见Dubbo在这里的缓存优化。 结束语至此，扩展点机制大致介绍完毕，自己从源码中也体会了在扩展设计上原来还可以这么玩，收益匪浅了。 最后做个总结： 从代码层面上对扩展点的四个特性进行了分析 三种获取扩展点的方式相互结合，分别体现了不同的扩展点特点 代码层面合理的设计模式(装饰器模式，动态代理)对代码分层解耦]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA神器那些让人爱不释手的小技巧]]></title>
    <url>%2FIntellij-IDEA%2FIntellij-idea-skills-two%2F</url>
    <content type="text"><![CDATA[前言Intellij IDEA，一个开发者甚爱的IDE，用了这么多年，其中有些小Tips你真的了解吗？Intellij IDEA神器小技巧第二弹来了！ 本文转载自Sam哥哥聊技术的技术博文。 原文地址:https://blog.csdn.net/linsongbin1/article/details/80560332 概述在2018年5月6日写了一篇介绍IntellIJ IDEA的文章,Intellij IDEA神器居然还有这些小技巧,主要是列出一些平时大家可能没用过或者没怎么用，但是又非常好用的IntellIJ IDEA小技巧。由于篇幅原因，只是列出了一小部分，那么接下来的这篇文章，会继续补充一些IntellIJ IDEA的小技巧。 别轻易自定义快捷键有蛮多操作，IntellIJ IDEA并没有给我们设置默认快捷键，需要使用者自己去定义快捷键。比如说： Rebuild Project Compare With Branch 为了能在IntellIJ IDEA里进行无鼠标编程，很多程序员都会自定义快捷键，但是有三个地方你可能需要注意一下。 经常会出现快捷键与其他应用的快捷键冲突的情况； 自定义太多快捷键了，你也不太好记住； 使用其他同事的IDEA时(比如说帮忙定位问题)，你自定义的快捷键没法用。 其实在IntellIJ IDEA里的每个操作，都可以看出一个action。我们可以使用ctrl+shift+a来输入我们要使用的操作。比如说，上面提到的Rebuild Project。你可以先使用ctrl+shift+a快捷键，然后输入Rebuild Project并回车,即可执行你要的操作。 对我自己来说，除了基础的快捷键，ctrl+shift+a是我用最频繁的快捷键了。 使用ctrl+alt+h要小心ctrl+alt+h非常好用,但是有个坑,当同一个方法里,调用某个方法多次的时候,比如说下面的代码： public class TestService { public void test1() { System.out.println(&quot;aa&quot;); } public void test2() { test1(); } public void test3() { test1(); //无数业务操作后,再次电影test1()方法 test1(); } } 如果我们想知道有哪些地方调用了test1()方法，使用ctrl+alt+h无法正确列出来的。因为ctrl+alt+h只能告诉你调用的层次。 ctrl+alt+h只是会在某个隐蔽的地方，告诉你，test3() 方法调用了 test1() 方法两次。这样就很容易坑到开发者，因为大部分人可能不太注意后面的调用次数，导致改bug的时候，以为全部都改了呢？ 如果你想精确的列出到底哪些地方调用了test1() 方法，你需要使用alt+f7这个快捷键。 尤其是我们在阅读极其复杂的业务代码时，使用alt+f7就非常合适。 当然alt+f7也可以作用在变量上，列出某个类里，哪些地方使用了该变量。 ctrl+alt+h被问的最多的两个问题经常有同事和网友问我。 Sam哥，使用ctrl+alt+h怎么跳转到源代码，又如何重新回到ctrl+alt+h对应的视图里面。 调转到源代码 其实很简单，当你使用ctrl+alt+h后，使用向下或者向上箭头，选择某个调用，然后按下f4即可跳转到源代码。 如何回到ctrl+alt+h视图这个真心被问了好几百遍，其实很简单，当你使用f4跳转到源代码后，直接使用 alt+8 就可以跳回去了。就又可以继续看下一个调用的地方了。 快速找到Controller方法如果你的项目里有非常多的 controller，里面有非常多的 http 或者 resful 方法。如何快速找到这些方法呢？这个时候，ctrl+alt+shift+n 就可以派上用场了。 比如说，你依稀记得入账单相关的接口，都有个bill的url路径，那么使用 ctrl+alt+shift+n 后，直接输入/bill即可。 当你在成千上万的Controller里寻找方法时，这一招就可以大大提高效率。 了解项目关键业务流程方法的利器-bookmark在一些创业公司里，很多核心的模块都是放置在同一个项目里的。比如说，订单相关的接口，支付相关的接口，商品相关的接口。这个时候，你可以将这些关键业务方法，使用 bookmark 统一放置到某个地方，方便你阅读。 那么如何使用快捷键来达到上面的效果呢？ public class TestService { public void test1() { System.out.println(&quot;aa&quot;); } public void test2() { test1(); } public void test3() { test1(); test1(); } } 比如像上面的方法，我想将test1()方法放置到bookmark里，可以通过如下操作来完成： 使用 ctrl+f12 ,列出该类的所有方法，然后输入 test1，将光标定位在 test1 上； 按下 f11 ,将 test1() 加入到 bookmark； 按下 shift+f11，将 bookmark 列表弹出来; 按下 ctrl+enter 修改 bookmark 名字。 只留下一个tab这个是我目前正在用的，就是整个工程里面，只有一个代码 tab。也即是说，无论你打开多少个文件，都是在同一个tab里面显示。如果这样设置了，有些网友可能会问,我想看看我最近操作哪些类了，怎么看？ 可以直接使用 ctrl+e 来显示最近操作的文件。 我是比较推荐只是保留一个代码tab的，非常简洁。如果每打开一个文件，就是一个新的tab，很快你就会乱掉，而且还得关闭部分tab。 可以通过下面的方式来设置成用一个tab显示代码。按下 ctrl+shif+a ,然后输入Editor Tabs，然后回车进入编辑页面。 然后在 Placement 那里,选择 None 如何阅读又长又臭的代码由于历史原因，项目里总会存在那种无法理解的，又长又臭的业务代码。阅读这种代码，简直就是一种煎熬。但是 在IntellIJ IDEA 里，只要使用 5 个小技巧，便可大大提高阅读质量和速度。 创建任意代码折叠块 像上面的for循环，我想直接将其折叠起来，因为代码太长的时候，使用折叠块，可以帮助你快速理清代码的主脉络。 可以将光标定位在for循环的左大括号里，然后使用 ctrl+shift+. 即可。 如果你想让这个折叠快消失，直接使用ctrl 加上一个+即可。 大括号匹配这个也非常有用，因为代码太长，某个for循环，可能已经撑满整个屏幕了。这个时候，找到某个大括号对应的另外一边就很费劲。你可以将光标定位在某个大括号一边，然后使用 ctrl+] 或者 ctrl+[ 来回定位即可。 ctrl+shift+f7结合f3ctrl+shift+f7 可以高亮某个变量，而且随着鼠标的移动，这个高亮是不会消失的(这个很重要)。然后使用f3找到下一个使用该变量的地方。 在这个代码块里，你想看看 TestTemp 类的定义，那么将光标定位在 TestTemp 上，然后直接使用 ctrl+shift+i，就会弹出如下的窗口。 按下 esc，可以关闭这个窗口。 使用alt+f7这个我在上面已经介绍过了。可以列出变量在哪些地方被使用了。 结合这5个技巧，相信可以大大提高长段代码的阅读效率。 跳到父类接口我们经常会定义一 个service 接口，比如说 UserService,然后使用一个 UserServiceImpl 类去实现 UserService 里面的接口。 public interface UserService { void test1(); } public class UserServiceImpl implements UserService { @Override public void test1() { } } 那么在UserServiceImpl里的 test1() 方法上，如何跳转到 UserService 的 test1() ,直接使用 ctrl+u 即可。 后悔药如果修改了部分代码，突然觉得不合适，使用 ctrl+z 回滚掉后。突然又觉得刚才的修改是可以的。那你可以使用 ctr+shift+z 再次恢复你刚才修改的内容。 切换皮肤最快的方式可以直接使用 ctrl,然后加上一个 ` ,就可以立刻弹出如下界面： 选择 Color Scheme，然后回车，就可以弹出修改皮肤的窗口。 结束语同样来自于 Sam哥哥聊技术 的分享，这里非常感谢！ 此篇文章同样是收藏级别的文章，多学多用，才能使coding效率大大的提高。]]></content>
      <categories>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>转载摘抄</tag>
        <tag>Intellij IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo扩展机制实现(二)之浅析ExtensionLoader]]></title>
    <url>%2Fdubbo%2Fdubbo-spi-extensionloader%2F</url>
    <content type="text"><![CDATA[前言之前的文章有介绍jdk SPI一些基本的使用和源码分析，既然dubbo也想使用SPI机制，为什么不直接使用jdk的SPI呢？ 上篇文章开头也提到了： Dubbo 的扩展点加载从 JDK 标准的 SPI (Service Provider Interface) 扩展点发现机制加强而来。 看看官方文档上Dubbo加强了哪些地方： 本文简单分析下Dubbo实现扩展点机制的ExtensionLoader类,分析其对比java的spi是怎么改进的。 Dubbo扩展点约定 在扩展类的 jar 包内 ，放置扩展点配置文件 META-INF/dubbo/接口全限定名，内容为：配置名=扩展实现类全限定名，多个实现类用换行符分隔。 注意：这里的配置文件是放在你自己的 jar 包内，不是 dubbo 本身的 jar 包内，Dubbo 会全 ClassPath 扫描所有 jar 包内同名的这个文件，然后进行合并 ↩ 一个自定义扩展点小例子第一步：新建一个jar包，我这里是在原先的dubbo源码包里的dubbo-rpc模块新增了一个实现 [dubbo-rpc-myrpc]： &lt;parent&gt; &lt;artifactId&gt;dubbo-rpc&lt;/artifactId&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;dubbo-rpc-myrpc&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;${project.artifactId}&lt;/name&gt; &lt;description&gt;The my rpc module of dubbo project&lt;/description&gt; &lt;properties&gt; &lt;skip_maven_deploy&gt;false&lt;/skip_maven_deploy&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-rpc-api&lt;/artifactId&gt; &lt;version&gt;${project.parent.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 第二步：以实现Protocol扩展为例，新建自定义实现: /** * MyRpcProtocol */ public class MyRpcProtocol extends AbstractProtocol implements Protocol { public static final int DEFAULT_PORT = 0; @Override public int getDefaultPort() { return DEFAULT_PORT; } @Override public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { System.out.println(&quot;my rpc export...&quot;); return null; } @Override public &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException { System.out.println(&quot;my rpc refer...&quot;); return null; } } 第三步：在jar包里定义扩展点：META-INF/dubbo/internal/com.alibaba.dubbo.rpc.Protocol myrpc=com.alibaba.dubbo.rpc.protocol.myrpc.MyRpcProtocol 大工完成，是不是so easy… 第四步：测试。接下来测试一下，写一个提供者使用我们的自定义协议。pom.xml里引用我们的自定义包 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-rpc-myrpc&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; 提供者xml里注册我们的协议: &lt;dubbo:protocol name=&quot;myrpc&quot; port=&quot;66666&quot;/&gt; 然后启动服务: public class Provider { public static void main(String[] args) throws Exception { //Prevent to get IPV6 address,this way only work in debug mode //But you can pass use -Djava.net.preferIPv4Stack=true,then it work well whether in debug mode or not System.setProperty(&quot;java.net.preferIPv4Stack&quot;, &quot;true&quot;); ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]{&quot;META-INF/spring/dubbo-demo-provider.xml&quot;}); context.start(); System.in.read(); // press any key to exit } } 可以看到控制台打印了: ... [11/06/18 11:12:16:016 CST] main INFO config.AbstractConfig: [DUBBO] Export dubbo service com.alibaba.dubbo.demo.DemoService to local registry, dubbo version: 2.0.0, current host: 172.16.192.43 [11/06/18 11:12:16:016 CST] main INFO config.AbstractConfig: [DUBBO] Export dubbo service com.alibaba.dubbo.demo.DemoService to url myrpc://172.16.192.43:66666/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider2&amp;bind.ip=172.16.192.43&amp;bind.port=66666&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;pid=25280&amp;qos.port=22222&amp;side=provider&amp;timestamp=1528686736167, dubbo version: 2.0.0, current host: 172.16.192.43 [11/06/18 11:12:16:016 CST] main INFO config.AbstractConfig: [DUBBO] Register dubbo service com.alibaba.dubbo.demo.DemoService url myrpc://172.16.192.43:66666/com.alibaba.dubbo.demo.DemoService?anyhost=true&amp;application=demo-provider2&amp;bind.ip=172.16.192.43&amp;bind.port=66666&amp;dubbo=2.0.0&amp;generic=false&amp;interface=com.alibaba.dubbo.demo.DemoService&amp;methods=sayHello&amp;pid=25280&amp;qos.port=22222&amp;side=provider&amp;timestamp=1528686736167 to registry registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider2&amp;dubbo=2.0.0&amp;pid=25280&amp;qos.port=22222&amp;registry=zookeeper&amp;timestamp=1528686735588, dubbo version: 2.0.0, current host: 172.16.192.43 my rpc export... Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: exporter == null at com.alibaba.dubbo.rpc.listener.ListenerExporterWrapper.&lt;init&gt;(ListenerExporterWrapper.java:40) at com.alibaba.dubbo.rpc.protocol.ProtocolListenerWrapper.export(ProtocolListenerWrapper.java:59) ... 至此说明了我们的自定义扩展点可以使用。这样以后如果需要实现自定义的一些其他扩展点，使用起来也是非常easy.这里可以体现出Dubbo的设计理念: API 与 SPI 分离 微核插件式，平等对待第三方 ExtensionLoader中的缓存Dubbo官方文档也说了，扩展点的实例化并非一次性全部加载的。所以它可能是懒加载的，用到哪个实例化哪个扩展点，其次官方文档也说了Dubbo的扩展点性能提升不少，说到性能提升下意识就是想到万能的缓存。来看看 Dubbo的扩展点加载器 ExtensionLoader是怎么实现的提高性能的。 ExtensionLoader各式各样的缓存： public class ExtensionLoader&lt;T&gt; { private static final ConcurrentMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt; EXTENSION_LOADERS = new ConcurrentHashMap&lt;Class&lt;?&gt;, ExtensionLoader&lt;?&gt;&gt;(); private static final ConcurrentMap&lt;Class&lt;?&gt;, Object&gt; EXTENSION_INSTANCES = new ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt;(); private final ConcurrentMap&lt;Class&lt;?&gt;, String&gt; cachedNames = new ConcurrentHashMap&lt;Class&lt;?&gt;, String&gt;(); private final Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt; cachedClasses = new Holder&lt;Map&lt;String, Class&lt;?&gt;&gt;&gt;(); private final Map&lt;String, Activate&gt; cachedActivates = new ConcurrentHashMap&lt;String, Activate&gt;(); private final ConcurrentMap&lt;String, Holder&lt;Object&gt;&gt; cachedInstances = new ConcurrentHashMap&lt;String, Holder&lt;Object&gt;&gt;(); private final Holder&lt;Object&gt; cachedAdaptiveInstance = new Holder&lt;Object&gt;(); private volatile Class&lt;?&gt; cachedAdaptiveClass = null; private String cachedDefaultName; private volatile Throwable createAdaptiveInstanceError; private Set&lt;Class&lt;?&gt;&gt; cachedWrapperClasses; private Map&lt;String, IllegalStateException&gt; exceptions = new ConcurrentHashMap&lt;String, IllegalStateException&gt;(); ... } ExtensionLoader并没有提供public的构造器，获取一个ExtensionLoader实例是通过私有静态方法 getExtensionLoader(Class type) 法获取。 private ExtensionLoader(Class&lt;?&gt; type) { this.type = type; /** * 这里会存在递归调用,ExtensionFactory的objectFactory为null,其他则为AdaptiveExtensionFactory * AdaptiveExtensionFactory的factories中有SpiExtensionFactory,SpringExtensionFactory * getAdaptiveExtension()来获取一个拓展装饰类对象 * objectFactory是一个 ExtensionFactory 对象，扩展点工厂类，暂且不分析 */ objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); } @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; ExtensionLoader&lt;T&gt; getExtensionLoader(Class&lt;T&gt; type) { if (type == null) //拓展点类型非空判断 throw new IllegalArgumentException(&quot;Extension type == null&quot;); if (!type.isInterface()) { // 拓展点类型只能是接口 throw new IllegalArgumentException(&quot;Extension type(&quot; + type + &quot;) is not interface!&quot;); } if (!withExtensionAnnotation(type)) { // 必须使用@spi注解,否则抛异常 throw new IllegalArgumentException(&quot;Extension type(&quot; + type + &quot;) is not extension, because WITHOUT @&quot; + SPI.class.getSimpleName() + &quot; Annotation!&quot;); } // 使用了缓存，从缓存EXTENSION_LOADERS中获取,如果不存在则创建后加入缓存，每个扩展点有且仅有一个ExtensionLoader实例与之对应。 ExtensionLoader&lt;T&gt; loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); if (loader == null) { EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader&lt;T&gt;(type)); loader = (ExtensionLoader&lt;T&gt;) EXTENSION_LOADERS.get(type); } return loader; } Dubbo处理缓存的一些值得学习的小细节：对线程安全方面的细节做得很好。 比如缓存都使用 ConcurrentMap 而不使用 HashMap. volatile关键字的使用。 private volatile Class&lt;?&gt; cachedAdaptiveClass = null; public class Holder&lt;T&gt; { private volatile T value; public void set(T value) { this.value = value; public T get() { return value; } } Dubbo如何改进获取spi的问题问题一：JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 答：Dubbo的ExtensionLoader提供了三种获取扩展点实现类的方式： public T getExtension(String name)根据名称获取当前扩展的指定实现 public T getAdaptiveExtension()获取当前扩展点的自适应实现 public List getActivateExtension(URL url, String[] values, String group)获取可激活的扩展点集合 这三个地方准备在下一篇扩展点自适应自动激活的分析时一并讲解一下。 这里可以看到Dubbo可以直接根据key就能获取到spi对象，而java的spi只能通过遍历然后根据if判断才能获取制定的spi对象。时间复杂度O(1) 比 O(n)快不少。而且用到了就加到缓存里，不用就不需要实例化，节约资源。 问题二：如果扩展点加载失败，连扩展点的名称都拿不到了。会把真正失败的原因吃掉 答: Dubbo并不会这样，当拿不到扩展点的名字时，Dubbo会直接抛出异常： public T getExtension(String name) { if (name == null || name.length() == 0) throw new IllegalArgumentException(&quot;Extension name == null&quot;); ... } 其次，Dubbo非常好的一点，增加了默认值的设置。 比如： @SPI(&quot;dubbo&quot;) public interface Protocol {} 这样就默认提供了dubbo=xxx.xxx.XxxProtocol的s实现。如果使用默认的扩展点，可以这么做： Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getDefaultExtension(); 这里的protocol对象即是com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol 问题三：增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点 答：这个之后分析。 总结 实现一个Dubbo自定义扩展点只需要三步。 Dubbo中的缓存设计在线程安全方面非常值得学习。 Dubbo是如何加强java的spi的，java的spi上哪些的不足被Dubbo巧妙实现了。 后记本文只是简单介绍了一下扩展点加载器ExtensionLoader。之后还有更多的源码分析它。我会从Dubbo官方文档上写的四个特性分析它并借鉴其中的一些理念。 下一篇就说说扩展点的四个特性： 扩展点自动包装，扩展点自动装配，扩展点自适应，扩展点自动激活。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo扩展机制实现(一)之java SPI]]></title>
    <url>%2Fdubbo%2Fdubbo-spi-java%2F</url>
    <content type="text"><![CDATA[前言在之前的文章Dubbo暴露服务过程中提出了问题：@SPI这些东西究竟是什么?在Dubbo开发手册之扩展点加载中有这么解释过： Dubbo 的扩展点加载从 JDK 标准的 SPI (Service Provider Interface) 扩展点发现机制加强而来。 所以在分析Dubbo扩展机制前，先看看jdk的SPI。 什么是SPISPI 全称为 (Service Provider Interface) ,是JDK内置的一种服务提供发现机制。 在面向对象设计里，我们不会针对实现编程，模块间面向接口编程来防止强耦合。java spi机制实现了一种放在程序以外的方式去动态装配模块，这就是java的服务发现。类似于ioc的思想，将模块装配放在程序外，比如xml等方式。 Dubbo框架就是借鉴了这种机制，在jdk的基础上进行了改进。 java SPI机制约定java的spi是通过ServiceLoader来加载，根据官方文档来看一下SPI机制的约定： Service实现类必须有一个无参构造器 在META-INF/services/目录中提供一个文件名称为Service接口全限定名的文件，文件内容为Service接口实现类全限定名，编码格式为UTF-8 使用java.util.ServiceLoader来动态加载Service接口的实现类。 SPI示例代码地址传送门目录结构如下:接口定义： public interface HelloWorld { void sayHello(); } 两个实现： public class HelloWorldENimpl implements HelloWorld { @Override public void sayHello() { System.out.println(&quot;hello,world!&quot;); } } public class HelloWorldCNimpl implements HelloWorld { @Override public void sayHello() { System.out.println(&quot;你好，世界！&quot;); } } 配置服务发现，在META-INF/service目录下创建文件：com.crw.demo.spi.HelloWorld，内容为接口实现类全名： com.crw.demo.spi.impl.HelloWorldENimpl com.crw.demo.spi.impl.HelloWorldCNimpl 编写调用端： public class Run { public static void main(String[] args) { ServiceLoader&lt;HelloWorld&gt; loads = ServiceLoader.load(HelloWorld.class); for (HelloWorld load : loads) { load.sayHello(); } } } 运行结果如下： ServiceLoader源码分析从 ServiceLoader.load(Class\&lt;S> service) 方法点进去看一下 public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { ClassLoader cl = Thread.currentThread().getContextClassLoader(); // 获取类加载器 return ServiceLoader.load(service, cl); } private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) { service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); // 开始加载 } public void reload() { providers.clear(); // 清空提供者缓存 lookupIterator = new LazyIterator(service, loader); // 创建一个懒加载的提供者发现器 } 可以看到，实际上是交给了一个私有静态内部类处理new LazyIterator(service, loader); 通过名字就像是懒加载，所以我们看看什么时候类加载器会加载SPI实现服务。 答案是遍历的时候。 ServiceLoader实现了iterator接口: public Iterator&lt;S&gt; iterator() { return new Iterator&lt;S&gt;() { Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() { if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); // 实际上是调用LazyIterator.hasNext()方法。 } public S next() { if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); // 实际上是调用LazyIterator.next()方法。 } public void remove() { throw new UnsupportedOperationException(); } }; } 在客户端遍历的时候，首先调用了hasNext()方法，hasNext调用了LazyIterator.hasNext(),其实际上又调用了内部方法 hasNextService() : private boolean hasNextService() { if (nextName != null) { // 如果有服务提供者名称，直接返回 return true; } if (configs == null) { try { String fullName = PREFIX + service.getName(); // META-INF/services/xxx.xxx.xxx.XxxImpl // 获取配置文件加载路径 if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); } catch (IOException x) { fail(service, &quot;Error locating configuration files&quot;, x); } } while ((pending == null) || !pending.hasNext()) { if (!configs.hasMoreElements()) { return false; } pending = parse(service, configs.nextElement()); //解析配置路径，用utf-8格式读取配置 } nextName = pending.next(); // 服务提供者名称赋值 return true; } 看一眼解析完的结构，在遍历的时候会读取配置，把服务提供者名称一次性获取： 接着，在客户端遍历的时候调用了next()方法， LazyIterator.next()方法里做了如下事情 private S nextService() { if (!hasNextService()) // 如果配置里没有服务，则会抛异常 throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try { c = Class.forName(cn, false, loader); // 反射创建了配置文件里的实现类 } catch (ClassNotFoundException x) { fail(service, &quot;Provider &quot; + cn + &quot; not found&quot;); } if (!service.isAssignableFrom(c)) { fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); } try { S p = service.cast(c.newInstance()); // 创建了一个实现类的实例 providers.put(cn, p); // 放入提供者缓存中 return p; } catch (Throwable x) { fail(service, &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;, x); } throw new Error(); // This cannot happen } 返回了一个服务提供者实例，就这样完成了一次SPI调用。 总结这篇文章主要介绍了jdk SPI机制： java如何编写一个SPI服务的。 ServiceLoader源码如何实现SPI服务。 本篇主要是为了Dubbo实现spi而做了铺垫。在看ServiceLoader的源码时，主要还是利用了java的类加载器 ClassLoader ，这些之后会单独写一写。鉴于鄙人才疏学浅，以上文章如有不对的地方希望大家予以指出，共同进步。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL查询性能优化]]></title>
    <url>%2Fmysql%2Fmysql-select-performance-optimize%2F</url>
    <content type="text"><![CDATA[目的 查询优化的基本原则 了解MySQL执行过程 浅析MySQL优化器 MySQL语句优化小tips 理解MySQL如何查询，明白高效和低效的原因 优化数据访问分两步分析是否是低效的查询： 是否向数据库请求了不需要的数据？比如查询了过多的行，查询过多的列(select * …)，以及重复的查询。 Mysql是否在扫描额外的记录？三个指标衡量查询开销： 响应时间 扫描行数 返回的行数 重构查询的方式 一个复杂查询or多个简单查询? 切分查询(比如在删改操作时，将全量语句改成批量执行) 分解关联查询(把一条复杂的关联查询分解为多条简单查询，可以让缓存效率更高，减少锁竞争) 一张图看Mysql执行过程 客户端将查询发送到服务器； 服务器检查查询缓存，如果找到了，就从缓存中返回结果，否则进行下一步。 服务器解析，预处理和优化查询，生成执行计划。 执行引擎调用存储引擎API执行查询。 服务器将结果发送回客户端。 1.客户端服务端通信协议通信协议工作机制：“抛球”游戏。任意时刻，要么是客户端发送数据，要么是服务端发送数据。一旦一端发送数据(抛球),另一端只能完整的接受消息才能响应。 所以，我们需要限制发送信息的大小。客户端：查询语句尽量少，否则可能会抛错误异常(“MySQL server has gone away”)。 # 查看你的服务器所允许传送的最大数据 SHOW VARIABLES LIKE &#39;max_allowed_packet&#39; 服务端：当服务端开始响应客户端请求时，客户端必须完整接受整个返回结果。所以要限制查询条数，必要时查询语句用“LIMIT”限制。 通过 “SHOW [FULL] PROCESSLIST” 命令查询mysql连接时线程状态:MySQL5.7通用线程状态 2.查询缓存如果开启了缓存，MySql会检查查询缓存，进行大小写敏感的哈希查找。如果命中，判断权限没问题后会跳过所有其他阶段直接返回。 # 查看是否开启查询 SHOW VARIABLES LIKE &#39;query_cache_type&#39;; 3.解析器解析器通过关键字解析SQL，然后生成一颗对应的“解析树”，然后它使用MySQL语法规则验证和解析语句，比如关键字是否错误，顺序等。 4.预处理进一步检查解析树的合法性。比如检查数据表列是否存在，名字和别名等。最后，预处理器检查权限。 5.查询优化器(重点)优化器负责将预处理合格的语法树转化为执行计划。 MySQL使用基于成本的优化器，它将尝试预测一个查询使用某种执行计划的成本，并选择成本最小的一个。 # 查询当前会话的当前查询成本 SHOW VARIABLES LIKE &#39;Last_query_cost&#39;; Q: 那么，MySQL是如何预测成本的呢？A: MySQL根据一系列统计信息计算得来:每个表或页面个数，索引基数，索引和数据行的长度，索引分布情况等。评估成本不考虑缓存，假设读取任何数据需要一次磁盘I/O。 可惜MySQL优化器并不是万能的，有诸多因素会导致MySQL选择错误的执行计划，比如统计信息可能不准确，成本估算和实际成有差距等。 更多的了解查询优化器是怎么处理查询语句的，查看MySQL查询优化器 6.查询执行引擎MySQL根据解析优化阶段生成的执行计划给出的指令逐步执行。 7.返回结果给客户端 查询结果返回给客户端，即时查询不需要返回结果集给客户端，也亏返回一些这个查询信息，比如影响的行数。 如果查询可以被缓存，这一阶段也会存放结果入缓存。 MySQL结果集返回是一个增量、逐步返回的过程。一旦处理开始产生第一条结果时，MySQL就开始逐步返回结果集了。这样的好处是，服务器无须存储太多结果而消耗太多内存，二是客户端可以第一时间获得返回结果。 总结 当发现MySQL查询效率不高时，考虑两个因素：1.是否请求了不需要的数据？2.是否查询了额外的记录？ 对待效率不高的语句，考虑语句适当拆分成多个简单的语句。 MySQL执行过程，看图]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL查询优化器]]></title>
    <url>%2Fmysql%2Fmysql-optimizer%2F</url>
    <content type="text"><![CDATA[目的 了解查询优化器的优化策略 了解和查看查询优化器优化后的执行计划 了解优化器是怎么优化的 了解优化器在关联语句中的处理 了解一些查询优化器的提示 MySQL查询优化器的优化策略简单分为 静态优化 和 动态优化。 一、静态优化(“编译时优化”): 可以直接对解析树进行分析并完成优化。 优化器通过一些简单的代叔变换将WHERE条件转化为另一种等价形式。 静态优化不依赖特别的数值，比如WHERE条件里带一些常数等。 静态优化在第一次完成后一直有效，即使使用不同的参数值执行查询也不会发生变化。 二、动态优化(“运行时优化”): 动态优化和查询上下文有关或者其他因素有关，比如WHERE条件中的取值，索引中条目对应的数据行数等。 每次查询都需要重新评估。 MySQL能够处理的优化类型先说一点，MySQL优化器使用了很多复杂的优化技巧把查询转化为执行计划。“不要试着比优化器更聪明”，通常都应让MySQL按照自己优化的方式执行语句，绝大多数情况优化器都是更优的。你也可以通过EXPLAIN EXTENDED SELECT … … ; SHOW WARNINGS; 查看最终优化后的执行sql。如何使用“EXPLAIN EXTENDED”可参考官方文档上的Extended EXPLAIN Output Format 重新定义关联表顺序。数据表的关联并不总是按照查询中指定顺序进行的。 将外链接转化为内连接。优化器可以根据某些因素(比如WHERE条件，库表结构等)，使得一个外连接等价于一个内连接。 等价变换规则。MySQL通过等价变换来简化并规范表达式。MySQL可以合并和减少比较。比如 (5=5 AND a&gt;5)会被改写为a&gt;5。(a &lt; b AND b=c) AND a=5会被改写为(b&gt;5 AND b=c AND a=5) 优化 COUNT()、MIN()、MAX()。查找某列最大/最小值，该列又有索引，查找最大值，则会直接找最后一行；最小值，则直接找第一行。因为索引已经排好序了。可以从EXPLAIN中看到：“Select tables optimized away”。这说明已经从执行计划中移除该表并用常数取代。 预估并转化为常数表达式如果一个表达式可以被简化为一个常量，那么这个表达式就会被转换。 在WHERE 、USING、ON这些连接条件强制值相等的条件中，常量具有传递性 ` EXPLAIN SELECT table_a.id, table_b.id FROM table_b INNER JOIN table_a ON table_a.tb_id = table_b.id WHERE table_b.id = 1 ![](https://ww1.sinaimg.cn/large/87faef88ly1fqnue0bqrbj20r102ut8o.jpg) 6. &lt;font face=&quot;华文新魏&quot; size=&quot;3&quot;&gt;覆盖索引&lt;/font&gt; 当索引包含查询需要的列时，MySql就可以使用索引来避免读取行数据。 7. &lt;font face=&quot;华文新魏&quot; size=&quot;3&quot;&gt;子查询优化&lt;/font&gt; MySQL可以将某些类型的子查询转换成相等的效率更高的形式。 8. &lt;font face=&quot;华文新魏&quot; size=&quot;3&quot;&gt;提前终止查询&lt;/font&gt; - MySQL在发现已经满足查询需求时，会立刻终止查询。 - MySQL检测一个不成立的条件也会立刻返回空结果。 EXPLAIN SELECT * FROM table_a WHERE id = - 1; ![](https://ww1.sinaimg.cn/large/87faef88ly1fqongff9j4j20sx01rjra.jpg) 9. &lt;font face=&quot;华文新魏&quot; size=&quot;3&quot;&gt;等值传播&lt;/font&gt; 如果两个列的值通过等式关联，那么MySQL能把其中一个列的WHERE条件传递到另一个列。 比如： SELECT table_a.id, table_b.id FROM table_b INNER JOIN table_a ON table_a.tb_id = table_b.id WHERE table_b.id &lt; 100; MySQL会判断把WHERE后面的关联作用于table_a表，等价于 SELECT table_a.id, table_b.id FROM table_b INNER JOIN table_a ON table_a.tb_id = table_b.id WHERE table_b.id &lt; 100 AND table_a.tb_id &lt; 100; 10. &lt;font face=&quot;华文新魏&quot; size=&quot;3&quot;&gt;列表IN()的比较&lt;/font&gt; MySql会对IN()里面的数据进行排序，然后用二分法查找某个值是否在列表中，这个算法的效率是O(Log n)。这其他数据库等价转换为多个OR条件连接的复杂度O(n)来说，IN()里大量取值时会更快。 ## MySQL如何关联查询 MySQL关联查询策略: 其实就是嵌套循环查询。MySQL先从第一个表循环读，然后再嵌套循环到下一个表寻找匹配，如此反复，直到找到所有表的匹配的行为止。 举个栗子： - 内连接sql SELECT tbl_user.name, tbl_bankcard.bankcard FROM tbl_user INNER JOIN tbl_bankcard ON tbl_user.id = tbl_bankcard.user_id WHERE tbl_user.moblie in (‘18611112222’,’18611113333’) MySQL在查询这条SQL时，用伪代码表示查询过程如下: ```ruby outer_iter = iterator over tbl_user where moblie in (&#39;18611112222&#39;,&#39;18611113333&#39;); outer_row = outer_iter.next; while outer_row: inner_iter = iterator over tbl_bankcard where user_id = outer_row.id; inner_row = inner_iter.next; while inner_row: output [outer_row.name, inner_row.bankcard] inner_row = inner_iter.next; end outer_row = outer_iter.next; end 再看这个SQL左外连接版本：SELECT tbl_user.name, tbl_bankcard.bankcard FROM tbl_user LEFT JOIN tbl_bankcard ON tbl_user.id = tbl_bankcard.user_id WHERE tbl_user.moblie in (&#39;18611112222&#39;,&#39;18611113333&#39;) MySQL在查询这条SQL时，用伪代码表示查询过程如下:outer_iter = iterator over tbl_user where moblie in (&#39;18611112222&#39;,&#39;18611113333&#39;); outer_row = outer_iter.next; while outer_row: inner_iter = iterator over tbl_bankcard where user_id = outer_row.id; inner_row = inner_iter.next; if inner_row: while inner_row: output [outer_row.name, inner_row.bankcard] inner_row = inner_iter.next; end else output [outer_row.name, NULL] end outer_row = outer_iter.next; end 基本上MySQL所有类型的查询都是这种方式运行。包括子查询，也是生成一张临时表，被当做普通表进行循环嵌套。以及右外链接也是会改写成等价的左外连接。 多表关联的一种方式： graph TD B(Join) --&gt; A[Join] C(Join) --&gt; A D(tbl1) --&gt; B E(tbl2) --&gt; B F(tbl3) --&gt; C G(tbl4) --&gt; C 但是MySQL是通过从一个表开始一直嵌套循环的方式： graph TD B(Join) --&gt; A[Join] C(tbl4) --&gt; A D[Join] --&gt; B E[tbl3] --&gt; B F[tbl1] --&gt; D G[tbl2] --&gt; D 关联查询优化器 MySQL查询优化器中最重要的一部分。它决定了多表查询的顺序。它评估不同顺序的成本选择成本最小的一个。 有时优化器给出的并不是最优的关联顺序，可使用STRAIGHT_JOIN关键字替换JOIN关键字重写查询。还是那句，“不要试着比优化器更聪明”。 不过，如果有超过n个表的关联，那么需要检查n的阶乘种关联顺序。我们称之为所有可能的执行计划的“搜索空间”。实际上，当需要关联的表超过 optimizer_search_depth 的限制的时候，就会选择“贪婪”搜索模式。 查询优化器的提示(hint)用于控制查询执行计划。列举一些课使用的提示： HIGH_PRIORITY 和 LOW_PRIORITY 当多条语句同时访问数据库时，设置语句优先级。HIGH_PRIORITY会使语句放在表的队列的最前面，LOW_PRIORITY则相反。这两个提示只对使用表锁的存储引擎有效。 DELAYED 这个提示用于INSERT和REPLACE。使用该提示会将插入的行数据放入缓冲区，然后在表空闲时批量写入数据。适合于日志插入等场景。但并不是所有存储引擎都支持，还会导致函数 LAST_INSERT_ID()无法正常工作。 STRAIGHT_JOIN 这个提示可用于SELECT语句中SELECT关键字之后，也可放置于两个关联表之间。该提示作用一是让查询中的表按语句出现的顺序关联。作用二是固定前后两个表的关联顺序。 SQL_SMALL_RESULT 和 SQL_BIG_RESULT 这个提示只对SELECT有效。它告诉优化器对GROUP BY或者DISTINCT查询如果使用临时表和排序。SQL_SMALL_RESULT会让优化器认为结果集很小，将结果放在内存中的索引临时表中，避免排序。SQL_BIG_RESULT 则告诉优化器结果集很大，在磁盘临时表进行排序。 SQL_BUFFER_RESULT 这个提示告诉优化器将结果放在临时表中，并且尽快释放掉表锁。 SQL_CACHE 和 SQL_NO_CACHE 这个提示告诉MySQL是否将结果集放在查询缓存中。 USING INDEX、IGNORE INDEX 和 FORCE INDEX 这几个提示分别告诉优化器 使用或者不使用或者强制使用索引。 控制优化器的一些参数SHOW VARIABLES LIKE &quot;optimizer_%&quot;; optimizer_search_depth控制穷举执行计划的限度。 optimizer_prune_level默认打开的，让优化器根据需要扫描的行数来决定是否跳过某些执行计划 optimizer_switch此变量包含了一些开关优化器特性的标志位。 总结 MySQL优化器做了很多工作把SQL语句变成更优的查询方式 使用 EXPLAIN EXTENDED … SHOW WARNINGS关键字查看优化后的指令 MySQL的关联查询是“嵌套循环”的 可使用查询优化提示控制查询执行计划，但是，“不要试着比优化器更聪明”。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo暴露服务过程]]></title>
    <url>%2Fdubbo%2Fdubbo-service-export-process%2F</url>
    <content type="text"><![CDATA[前言dubbo框架也用了有一年了，一直没有详细的研究过dubbo源码。所以趁有时间好好学习体会dubbo的博大精深。本人才疏学浅，如有不对，请大神指点。这里使用的dubbo版本是2.6.1。 如何看源码？跟着Dubbo开发手册(中文)来喽。带着目的看源码，这次看dubbo是怎么暴露服务的。 先瞜一眼启动日志一般像这种大型的开源框架，都会有健全的启动日志，看看日志输出利于我们理解dubbo启动流程。 日志输出从上往下看，dubbo做了哪些事： 暴露本地服务 暴露远程服务 启动Netty，绑定和暴露地址 连接zookeeper zookeeper订阅服务 监听zookeeper 先瞜一眼官方手册这段内容来自dubbo开发手册之实现细节 再来一段暴露服务时序图 接下来，从官方文档开始，分析dubbo服务暴露过程。 第一步， ServiceConfig分析前，先利用IDE生成类图看看ServiceConfig的继承关系。 问题一：这么多的配置是啥？凭借感觉像是和dubbo.xml里的配置属性有关系。先不管，留个坑。 根据时序图，我们先定位到 ServiceConfig 的 export()方法 ServiceConfig#export public synchronized void export() { ... // 延迟暴露接口 if (delay != null &amp;&amp; delay &gt; 0) { delayExportExecutor.schedule(new Runnable() { public void run() { doExport(); } }, delay, TimeUnit.MILLISECONDS); } else { doExport(); // 此处调用开始暴露 } } 暴露服务是调用 ServiceConfig#doExport方法 protected synchronized void doExport() { if (unexported) { throw new IllegalStateException(&quot;Already unexported!&quot;); } if (exported) { return; } exported = true; if (interfaceName == null || interfaceName.length() == 0) { throw new IllegalStateException(&quot;&lt;dubbo:service interface=\&quot;\&quot; /&gt; interface not allow null!&quot;); } checkDefault();// 创建了 ProviderConfig 对象并赋值 setter is属性，提供者的缺省值设置 /** * provider已经配置的情况下，application、module、registries、monitor、protocol中未配置的值均可以从provider获取 */ if (provider != null) { if (application == null) { application = provider.getApplication(); } if (module == null) { module = provider.getModule(); } if (registries == null) { registries = provider.getRegistries(); } if (monitor == null) { monitor = provider.getMonitor(); } if (protocols == null) { protocols = provider.getProtocols(); } } if (module != null) { if (registries == null) { registries = module.getRegistries(); } if (monitor == null) { monitor = module.getMonitor(); } } if (application != null) { if (registries == null) { registries = application.getRegistries(); } if (monitor == null) { monitor = application.getMonitor(); } } if (ref instanceof GenericService) { interfaceClass = GenericService.class; if (StringUtils.isEmpty(generic)) { generic = Boolean.TRUE.toString(); } } else { try { interfaceClass = Class.forName(interfaceName, true, Thread.currentThread() .getContextClassLoader()); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } checkInterfaceAndMethods(interfaceClass, methods); // 检查配置中的 interface 属性 和 methods属性 checkRef(); // 检查 ref 属性 generic = Boolean.FALSE.toString(); } // 如果配置 local 属性， 是否服务接口客户端本地代理 if (local != null) { if (&quot;true&quot;.equals(local)) { local = interfaceName + &quot;Local&quot;; } Class&lt;?&gt; localClass; try { localClass = ClassHelper.forNameWithThreadContextClassLoader(local); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } if (!interfaceClass.isAssignableFrom(localClass)) { throw new IllegalStateException(&quot;The local implementation class &quot; + localClass.getName() + &quot; not implement interface &quot; + interfaceName); } } // 如果配置 stub 属性， 是否本地存根 if (stub != null) { if (&quot;true&quot;.equals(stub)) { stub = interfaceName + &quot;Stub&quot;; } Class&lt;?&gt; stubClass; try { stubClass = ClassHelper.forNameWithThreadContextClassLoader(stub); } catch (ClassNotFoundException e) { throw new IllegalStateException(e.getMessage(), e); } if (!interfaceClass.isAssignableFrom(stubClass)) { throw new IllegalStateException(&quot;The stub implementation class &quot; + stubClass.getName() + &quot; not implement interface &quot; + interfaceName); } } checkApplication(); // 检查 application 属性 checkRegistry(); // 检查 registry 属性 checkProtocol(); // 检查 protocol 属性 appendProperties(this); // 赋值 ServiceConfig setter is 属性 checkStubAndMock(interfaceClass); // 检查是否 使用 local,stub,mock 代理 if (path == null || path.length() == 0) { path = interfaceName; } doExportUrls(); // 开始暴露远程服务了 ProviderModel providerModel = new ProviderModel(getUniqueServiceName(), this, ref); ApplicationModel.initProviderModel(getUniqueServiceName(), providerModel); } ServiceConfig#doExportUrls暴露多个远程地址 private void doExportUrls() { // dubbo支持多注册中心，所以这一步把 registry 配置信息封装为多个url,比如 registry://127.0.0.1:2181/com.alibaba.dubbo.registry.RegistryService?application=demo-provider... List&lt;URL&gt; registryURLs = loadRegistries(true); // dubbo是支持多协议的，将所有注册的url上对应的协议暴露出来 for (ProtocolConfig protocolConfig : protocols) { doExportUrlsFor1Protocol(protocolConfig, registryURLs); } } ServiceConfig#doExportUrlsFor1Protocol暴露单个地址 private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List&lt;URL&gt; registryURLs) { String name = protocolConfig.getName(); if (name == null || name.length() == 0) { name = &quot;dubbo&quot;; } // map存放所有配置参数，下面生成url用 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(Constants.SIDE_KEY, Constants.PROVIDER_SIDE); map.put(Constants.DUBBO_VERSION_KEY, Version.getVersion()); map.put(Constants.TIMESTAMP_KEY, String.valueOf(System.currentTimeMillis())); if (ConfigUtils.getPid() &gt; 0) { map.put(Constants.PID_KEY, String.valueOf(ConfigUtils.getPid())); } appendParameters(map, application); appendParameters(map, module); appendParameters(map, provider, Constants.DEFAULT_KEY); appendParameters(map, protocolConfig); appendParameters(map, this); // method子标签配置规则解析，暂时不管 if (methods != null &amp;&amp; !methods.isEmpty()) { for (MethodConfig method : methods) { ... } // end of methods for } // 获取所有方法添加到map中，体现在url里 if (ProtocolUtils.isGeneric(generic)) { // 如果是泛化实现，generic属性为true，method=*表示任意方法 map.put(&quot;generic&quot;, generic); map.put(&quot;methods&quot;, Constants.ANY_VALUE); } else { String revision = Version.getVersion(interfaceClass, version); if (revision != null &amp;&amp; revision.length() &gt; 0) { map.put(&quot;revision&quot;, revision); } String[] methods = Wrapper.getWrapper(interfaceClass).getMethodNames(); if (methods.length == 0) { logger.warn(&quot;NO method found in service interface &quot; + interfaceClass.getName()); map.put(&quot;methods&quot;, Constants.ANY_VALUE); } else { map.put(&quot;methods&quot;, StringUtils.join(new HashSet&lt;String&gt;(Arrays.asList(methods)), &quot;,&quot;)); } } // 如果配置了token属性，如果配为default则随机UUID，否则使用配置中的token，作令牌验证用 if (!ConfigUtils.isEmpty(token)) { if (ConfigUtils.isDefault(token)) { map.put(&quot;token&quot;, UUID.randomUUID().toString()); } else { map.put(&quot;token&quot;, token); } } // 如果协议是 injvm，就不注册服务， notify设置为false if (&quot;injvm&quot;.equals(protocolConfig.getName())) { protocolConfig.setRegister(false); map.put(&quot;notify&quot;, &quot;false&quot;); } // export service String contextPath = protocolConfig.getContextpath(); // 如果 protocol配置没有配置contextPath属性，就从provider配置中取 if ((contextPath == null || contextPath.length() == 0) &amp;&amp; provider != null) { contextPath = provider.getContextpath(); } String host = this.findConfigedHosts(protocolConfig, registryURLs, map); Integer port = this.findConfigedPorts(protocolConfig, name, map); // 根据上面的参数创建url对象 URL url = new URL(name, host, port, (contextPath == null || contextPath.length() == 0 ? &quot;&quot; : contextPath + &quot;/&quot;) + path, map); // 如果url使用的协议存在扩展，调用对应的扩展来修改原url。 if (ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .hasExtension(url.getProtocol())) { url = ExtensionLoader.getExtensionLoader(ConfiguratorFactory.class) .getExtension(url.getProtocol()).getConfigurator(url).configure(url); } String scope = url.getParameter(Constants.SCOPE_KEY); // 如果scope属性没有配置为 none if (!Constants.SCOPE_NONE.toString().equalsIgnoreCase(scope)) { // 如果scope属性没有配置为 remote， 暴露本地服务 if (!Constants.SCOPE_REMOTE.toString().equalsIgnoreCase(scope)) { exportLocal(url); } // // 如果scope属性没有配置为 local， 暴露远程服务 if (!Constants.SCOPE_LOCAL.toString().equalsIgnoreCase(scope)) { if (logger.isInfoEnabled()) { logger.info(&quot;Export dubbo service &quot; + interfaceClass.getName() + &quot; to url &quot; + url); } if (registryURLs != null &amp;&amp; !registryURLs.isEmpty()) { for (URL registryURL : registryURLs) { url = url.addParameterIfAbsent(Constants.DYNAMIC_KEY, registryURL.getParameter(Constants.DYNAMIC_KEY)); URL monitorUrl = loadMonitor(registryURL); if (monitorUrl != null) { // 如果有monitor信息，则在url上增加monitor配置 url = url.addParameterAndEncoded(Constants.MONITOR_KEY, monitorUrl.toFullString()); } if (logger.isInfoEnabled()) { logger.info(&quot;Register dubbo service &quot; + interfaceClass.getName() + &quot; url &quot; + url + &quot; to registry &quot; + registryURL); } // 重要的第二步了，创建 invoker 对象（这里暴露远程协议里，在远程协议里增加了属性 export=url,url默认dubbo协议暴露地址） Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); // 第三步，官方文档加重点的一步，invoker转化为 exporter Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); } } else { Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, url); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); exporters.add(exporter); } } } this.urls.add(url); } 第二步，ProxyFactory.getInvoker在ServiceConfig#doExportUrlsFor1Protocol暴露单个地址中的调用: Invoker&lt;?&gt; invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); 接下来看看这一行代码里做了什么。 问题二：这个 ProxyFactory$Adaptive是什么东东？ 看看 proxyFactory 是怎么来的。 private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension(); 看来是和这个 ExtensionLoader 有关。看看接口: @SPI(&quot;javassist&quot;) public interface ProxyFactory { @Adaptive({Constants.PROXY_KEY}) &lt;T&gt; T getProxy(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive({Constants.PROXY_KEY}) &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) throws RpcException; } @SPI 看起来和java SPI机制有关哦。先留个坑，回头再解决。 但是通过我们debug发现，默认情况下 ProxyFactory的实现是 JavassistProxyFactory。 public &lt;T&gt; Invoker&lt;T&gt; getInvoker(T proxy, Class&lt;T&gt; type, URL url) { // TODO Wrapper cannot handle this scenario correctly: the classname contains &#39;$&#39; final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf(&#39;$&#39;) &lt; 0 ? proxy.getClass() : type); return new AbstractProxyInvoker&lt;T&gt;(proxy, type, url) { @Override protected Object doInvoke(T proxy, String methodName, Class&lt;?&gt;[] parameterTypes, Object[] arguments) throws Throwable { return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments); } }; } 正如官方文档所说: 首先 ServiceConfig 类拿到对外提供服务的实际类 ref(如：HelloWorldImpl),然后通过 ProxyFactory 类的 getInvoker 方法使用 ref 生成一个 AbstractProxyInvoker 实例，到这一步就完成具体服务到 Invoker 的转化。 JavassistProxyFactory的getInvoker实现是先创建一个包装类Wrapper ，包装类来实现远程调用。简单看下这个包装类是什么吧，Wapper.makeWrapper(Class&lt;?&gt; c): 结果大致如下 public class Wrapper1 extends Wrapper { public static String[] pns; public static Map pts; public static String[] mns; // all method name array. public static String[] dmns; public static Class[] mts0; public String[] getPropertyNames() { return pns; } public boolean hasProperty(String n) { return pts.containsKey($1); } public Class getPropertyType(String n) { return (Class) pts.get($1); } public String[] getMethodNames() { return mns; } public String[] getDeclaredMethodNames() { return dmns; } public void setPropertyValue(Object o, String n, Object v) { dubbo.provider.hello.service.impl.HelloServiceImpl w; try { w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); } catch (Throwable e) { throw new IllegalArgumentException(e); } throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); } public Object getPropertyValue(Object o, String n) { dubbo.provider.hello.service.impl.HelloServiceImpl w; try { w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); } catch (Throwable e) { throw new IllegalArgumentException(e); } throw new com.alibaba.dubbo.common.bytecode.NoSuchPropertyException(&quot;Not found property \&quot;&quot; + $2 + &quot;\&quot; filed or setter method in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); } public Object invokeMethod(Object o, String n, Class[] p, Object[] v) throws java.lang.reflect.InvocationTargetException { dubbo.provider.hello.service.impl.HelloServiceImpl w; try { w = ((dubbo.provider.hello.service.impl.HelloServiceImpl) $1); } catch (Throwable e) { throw new IllegalArgumentException(e); } try { if (&quot;sayHello&quot;.equals($2) &amp;&amp; $3.length == 0) { w.sayHello(); return null; } } catch (Throwable e) { throw new java.lang.reflect.InvocationTargetException(e); } throw new com.alibaba.dubbo.common.bytecode.NoSuchMethodException(&quot;Not found method \&quot;&quot; + $2 + &quot;\&quot; in class dubbo.provider.hello.service.impl.HelloServiceImpl.&quot;); } } 第三步，invoker转化为 exporter在ServiceConfig#doExportUrlsFor1Protocol暴露单个地址中的调用: Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker); 由代码可知，这里的 protocol 和第二步里的proxyFactory 一样 private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 我们再看看 Protocol接口，也是SPI机制： @SPI(&quot;dubbo&quot;) public interface Protocol { int getDefaultPort(); @Adaptive &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException; @Adaptive &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException; void destroy(); } 凭感觉会使用dubbo协议调用到DubboProtocol。先debug,果不其然。看一眼调用栈： 从ServiceConfig之后，有两次协议调用，先是调用RegistryProtocol，然后RegistryProtocol里调用了DubboProtocol。 两次暴露协议前，都会调用到 ProtocolListenerWrapper 和 ProtocolFilterWrapper，看看这两个地方。ProtocolListenerWrapper#export方法 public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { // registry类型的Invoker，直接暴露 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) { return protocol.export(invoker); } // 非Registry类型的Invoker，需要被监听器包装 // 这里的protocol是ProtocolFilterWrapper return new ListenerExporterWrapper&lt;T&gt;(protocol.export(invoker), Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), Constants.EXPORTER_LISTENER_KEY))); } ProtocolFilterWrapper#export方法 public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { // registry类型的Invoker，直接暴露 if (Constants.REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) { return protocol.export(invoker); } //非Registry类型的Invoker需要先构建调用链，然后再暴露 return protocol.export(buildInvokerChain(invoker, Constants.SERVICE_FILTER_KEY, Constants.PROVIDER)); } 这里构建调用链，控制invoker调用执行顺序，默认的filters如下图：暂且不谈Filter接口相关。 按照调用顺序，先调用 RegistryProtocol#export public &lt;T&gt; Exporter&lt;T&gt; export(final Invoker&lt;T&gt; originInvoker) throws RpcException { //export invoker final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker); // 本地暴露 URL registryUrl = getRegistryUrl(originInvoker); // 获取注册地址，默认是dubbo，我这里使用zookeeper //registry provider final Registry registry = getRegistry(originInvoker); // 获取注册中心， 我这里的是ZookeeperRegistry对象 final URL registedProviderUrl = getRegistedProviderUrl(originInvoker);// 获取注册的提供者地址 //to judge to delay publish whether or not boolean register = registedProviderUrl.getParameter(&quot;register&quot;, true); ProviderConsumerRegTable.registerProvider(originInvoker, registryUrl, registedProviderUrl);// 注册提供者消费者。 if (register) { register(registryUrl, registedProviderUrl); // 注册服务 ProviderConsumerRegTable.getProviderWrapper(originInvoker).setReg(true); // 标记为已注册 } // Subscribe the override data // FIXME When the provider subscribes, it will affect the scene : a certain JVM exposes the service and call the same service. Because the subscribed is cached key with the name of the service, it causes the subscription information to cover. final URL overrideSubscribeUrl = getSubscribedOverrideUrl(registedProviderUrl); final OverrideListener overrideSubscribeListener = new OverrideListener(overrideSubscribeUrl, originInvoker); overrideListeners.put(overrideSubscribeUrl, overrideSubscribeListener); registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener); //保证每次暴露服务返回一个新的exporter return new DestroyableExporter&lt;T&gt;(exporter, originInvoker, overrideSubscribeUrl, registedProviderUrl); } 然后，上面的本地暴露 doLocalExport(originInvoker) 实际上是暴露的dubbo协议，看下DubboProtocol： public &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException { URL url = invoker.getUrl(); // export service. String key = serviceKey(url); // 获取dubbo协议服务key，serviceGroup/serviceName:serviceVersion:port DubboExporter&lt;T&gt; exporter = new DubboExporter&lt;T&gt;(invoker, key, exporterMap); exporterMap.put(key, exporter); //export an stub service for dispatching event Boolean isStubSupportEvent = url.getParameter(Constants.STUB_EVENT_KEY, Constants.DEFAULT_STUB_EVENT); // 是否是stub事件？ dubbo.stub.event属性 Boolean isCallbackservice = url.getParameter(Constants.IS_CALLBACK_SERVICE, false); // 是否回调服务？ is_callback_service属性 if (isStubSupportEvent &amp;&amp; !isCallbackservice) { // TODO 这里暂时不分析，此处demo场景为false String stubServiceMethods = url.getParameter(Constants.STUB_EVENT_METHODS_KEY); if (stubServiceMethods == null || stubServiceMethods.length() == 0) { if (logger.isWarnEnabled()) { logger.warn(new IllegalStateException(&quot;consumer [&quot; + url.getParameter(Constants.INTERFACE_KEY) + &quot;], has set stubproxy support event ,but no stub methods founded.&quot;)); } } else { stubServiceMethodsMap.put(url.getServiceKey(), stubServiceMethods); } } openServer(url); // 开启服务(这里默认使用netty方式) optimizeSerialization(url);// 优化序列化 return exporter; } 至此返回 exporter 之后，就完成了 invoker到exporter的转化。返回到ServiceConfig后服务发布过程到此结束。 补充先看看之前遗留的两个问题：问题一：AbstractConfig 衍生的子类(ServiceConfig,ProviderConfig,RegistryConfig等) ，这么多的配置类是啥？ 问题二：这个 ProxyFactory$Adaptive是什么东东？ 看看 proxyFactory 是怎么来的。 回答问题一：在dubbo-config模块中，代码里的解释已经很清楚了。这里简单介绍几个抽象配置: AbstractConfig：配置模板，配置解析的工具方法、公共方法，提供几个主要的方法（appendAnnotation，appendProperties，appendParameters，appendAttributes等）。 AbstractMethodConfig：封装了一些方法级别的相关属性 AbstractInterfaceConfig：封装了接口需要的属性 AbstractReferenceConfig：主要是引用实例的配置 再看一下dubbo-config-spring模块，与spring如何整合的：spring.handlers文件里如是写道： http\://code.alibabatech.com/schema/dubbo=com.alibaba.dubbo.config.spring.schema.DubboNamespaceHandler dubbo的schema标签的定义就在DubboNamespaceHandler类中: public class DubboNamespaceHandler extends NamespaceHandlerSupport { static { Version.checkDuplicate(DubboNamespaceHandler.class); } public void init() { registerBeanDefinitionParser(&quot;application&quot;, new DubboBeanDefinitionParser(ApplicationConfig.class, true)); registerBeanDefinitionParser(&quot;module&quot;, new DubboBeanDefinitionParser(ModuleConfig.class, true)); registerBeanDefinitionParser(&quot;registry&quot;, new DubboBeanDefinitionParser(RegistryConfig.class, true)); registerBeanDefinitionParser(&quot;monitor&quot;, new DubboBeanDefinitionParser(MonitorConfig.class, true)); registerBeanDefinitionParser(&quot;provider&quot;, new DubboBeanDefinitionParser(ProviderConfig.class, true)); registerBeanDefinitionParser(&quot;consumer&quot;, new DubboBeanDefinitionParser(ConsumerConfig.class, true)); registerBeanDefinitionParser(&quot;protocol&quot;, new DubboBeanDefinitionParser(ProtocolConfig.class, true)); registerBeanDefinitionParser(&quot;service&quot;, new DubboBeanDefinitionParser(ServiceBean.class, true)); registerBeanDefinitionParser(&quot;reference&quot;, new DubboBeanDefinitionParser(ReferenceBean.class, false)); registerBeanDefinitionParser(&quot;annotation&quot;, new AnnotationBeanDefinitionParser()); } } 所以，一目了然。 回答问题二：这确实和dubbo插件机制有关，后面再单独写一篇文章分析。 提出问题三:dubbo怎么启动的？本文的分析是直接从dubbo文档和启动日志起手的，那么dubbo是怎么从加载spring容器到ServiceConfig暴露服务的呢？ 再回顾看下dubbo暴露服务调用栈： 还记得上面的 AbstractConfig家族的类图吗。ServiceBean继承自ServiceConfig。 ServiceBean实现了pplicationListener接口，实现方法: public void onApplicationEvent(ContextRefreshedEvent event) { if (isDelay() &amp;&amp; !isExported() &amp;&amp; !isUnexported()) { if (logger.isInfoEnabled()) { logger.info(&quot;The service ready on spring started. service: &quot; + getInterface()); } export(); // 调用父类ServiceConfig的export() } } 可见，在spring容器实例化bean完成后，发布ContextRefreshedEvent事件时调用ServiceConfig的export()方法。看看日志是不是有“The service ready on spring started. service:xxx”且在服务暴露日志前呢~ 后言至此，初步完成了dubbo服务暴露过程的解析（ServiceConfig-&gt; Invoker-&gt;Exporter），但是上面服务暴露过程有些内容并没有详细分析，比如 本地暴露与远程暴露的细枝末节 dubbo的扩展机制 获取注册中心注册服务（zookeeper）的过程 开启服务过程(Netty服务)… 这些后面一点点剖析。 总结 dubbo暴露服务过程总体分为三步：ServiceConfig-&gt; Invoker-&gt;Exporter. AbstractConfig家族是spring与dubbo整合的核心配置 ServiceBean中开启spring容器加载完成后的暴露服务过程]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>dubbo</tag>
        <tag>RTFSC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Bean Validation 解决业务中参数校验]]></title>
    <url>%2Fjava%2Fuse-bean-validation-solve-params%2F</url>
    <content type="text"><![CDATA[目的精简业务中的代码校验。 痛点及现状代码中常常见到如下代码： if (Objects.equal(0L ,repertory)){ return ApiResultMap.errorResult(-1 ,&quot;操作数量不可为0&quot;) ; } 这种参数校验写在模块里有如下缺点： 代码冗余 影响代码可读性 需要通过注释来知道每个入参的约束是什么。 每个程序员做参数验证的方式不一样，参数验证不通过抛出的异常也不一样。 抛出问题：那么有没有一种方式可以简化代码呢？ JSR 303 - Bean ValidationBean Validation是一个通过配置注解来验证参数的框架，它包含两部分Bean Validation API和Hibernate Validator。 Bean Validation API是Java定义的一个验证参数的规范。 Hibernate Validator是Bean Validation API的一个实现。 QUICK START 引入pom &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.3.1.Final&lt;/version&gt; &lt;/dependency&gt; dto入参对象属性加入注解 ` @Data public class ValidDemo { @Size(min = 3, max = 12, message = “用户名必须的长度必须是3到12个字母之间”) @Pattern(regexp = “^[a-z]+$”, message = “用户名必须是a-z小字母”) private String name; @Size(min = 6, max = 6, message = “密码必须是6位数字”) @Pattern(regexp = “^[0-9]+$”, message = “密码必须是6位数字”) private String password; @Range(min = 1, max = 9, message = “范围只能1到9”) private Integer range; @NotNull(message = “邮箱不能为Null”) @Email(regexp = “(?:[a-z0-9!#$%&amp;’+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&amp;’+/=?^_`{|}~-]+)|\”(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])\”)@(?:(?:a-z0-9?\.)+a-z0-9?|\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])”, message = &quot;邮箱格式有误&quot;) private String email; } 3. controller方法入参加入校验(@Valid) @GetMapping(“/validdemo”) public Map&lt;String,Object&gt; demo(@Valid ValidDemo validDemo){ return ApiResultMap.successResult(validDemo); } 4. 精简出参，加入全局异常处理 @ExceptionHandler(value = { BindException.class }) public Map&lt;String, Object&gt; validationException(BindException ex) { log.error(ex.getBindingResult().getFieldError().getDefaultMessage()); return ApiResultMap.errorResult(ex.getBindingResult().getFieldError().getDefaultMessage()); } 5. 测试结果： $curl http://localhost:8080/validdemo?email=xxxxx { “message”: { “code”: -1, “message”: “邮箱格式有误” } } **另一种方式，使用 spring 的 @Validated 注解:** 1. 配置 MethodValidationPostProcessor @Bean public MethodValidationPostProcessor methodValidationPostProcessor() { return new MethodValidationPostProcessor(); } 2. 使用@Validated注解： @Validated @RestController public class DemoController {} 3. 方法上加上校验 @GetMapping(“/validdemo3”) public Map&lt;String,Object&gt; demo3(@NotNull String str, @NotNull @Range(min = 0, max = 10) Integer a){ return ApiResultMap.successResult(str + a); } 4. 测试 $curl http://localhost:8080/validdemo?str=1&amp;a=15 { “message”: { “code”: 202, “message”: “需要在0和10之间” } } ` 应用场景java程序员张三和ios程序员李四开发某一需求，明天就要demo了，今天得抓紧联调。李四:三哥，地址发下，调试绑卡。张三启动服务…李四：三哥，帮忙看下，这个接口报错 -1，看下上面错误呗。张三打开控制台，看了一下日志与排查，数据库报错，身份证字段没传导致插入身份证为空报错。张三：李四你身份证没传。…张三一边埋怨着一边加入一行if else，同时在思考别的接口是不是也有这种情况，也给加上if else.没过一会儿，李四：三哥，帮我看下有报错-1了。张三又去查看，同样的，这次是银行卡号没传。张三重复着以上操作可没过一会儿李四又….就这样一天过去，伴随着晚霞下班的张三，心情却没那么高兴… 抛出问题：是什么导致张三忙碌一天却觉得碌碌无为？是道德的沦丧还是人性的丧失？ 如果张三整合Bean Validation的话，可能就没有那么不愉快了。他只需要一次在入参model里加入校验，之后在控制器的通过轻松的 @Valid 注解，就可以省去李四重复的提问，也省去的检查其他接口是否也需要添加代码校验，代码又可以少些几行了，何乐而不为。 常用注解Bean Validation 中内置的 constraint： @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint： @Email 被注释的元素必须是电子邮箱地址 @Length 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range 被注释的元素必须在合适的范围内 优势 代码整洁 代码可读性强 解决不同开发者的不同的校验方式 总结推荐使用 Bean Validation 的方式解决业务中参数校验； 这里只给出了一些基本的参数校验constraint，在实际业务中可根据业务情形自定义业务constraint。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij IDEA神器居然还有这些小技巧]]></title>
    <url>%2FIntellij-IDEA%2FIntellij-idea-skills-one%2F</url>
    <content type="text"><![CDATA[前言Intellij IDEA，一个开发者甚爱的IDE，用了这么多年，其中有些小Tips你真的了解吗？ 本文转载自Sam哥哥聊技术的技术博文。 原文地址:https://blog.csdn.net/linsongbin1/article/details/80211919 概述Intellij IDEA真是越用越觉得它强大，它总是在我们写代码的时候，不时给我们来个小惊喜。出于对Intellij IDEA的喜爱，我决定写一个与其相关的专栏或者系列，把一些好用的Intellij IDEA技巧分享给大家。本文是这个系列的第一篇，主要介绍一些你可能不知道的但是又实用的小技巧。 我最爱的【演出模式】我们可以使用【Presentation Mode】，将IDEA弄到最大，可以让你只关注一个类里面的代码，进行毫无干扰的coding。 可以使用Alt+V快捷键，弹出View视图，然后选择Enter Presentation Mode。效果如下： 这个模式的好处就是，可以让你更加专注，因为你只能看到特定某个类的代码。可能读者会问，进入这个模式后，我想看其他类的代码怎么办？这个时候，就要考验你快捷键的熟练程度了。你可以使用CTRL+E弹出最近使用的文件。又或者使用CTRL+N和CTRL+SHIFT+N定位文件。 如何退出这个模式呢？很简单，使用ALT+V弹出view视图，然后选择Exit Presentation Mode 即可。但是我强烈建议你不要这么做，因为你是可以在Enter Presentation Mode模式下在IDEA里面做任何事情的。当然前提是，你对IDEA足够熟练。 神奇的Inject language如果你使用IDEA在编写JSON字符串的时候，然后要一个一个\去转义双引号的话，就实在太不应该了，又烦又容易出错。在IDEA可以使用Inject language帮我们自动转义双引号。 先将焦点定位到双引号里面，使用alt+enter快捷键弹出inject language视图，并选中 Inject language or reference。 选择后,切记，要直接按下enter回车键，才能弹出inject language列表。在列表中选择json组件。 选择完后。鼠标焦点自动会定位在双引号里面，这个时候你再次使用alt+enter就可以看到 选中Edit JSON Fragment并回车，就可以看到编辑JSON文件的视图了。 可以看到IDEA确实帮我们自动转义双引号了。如果要退出编辑JSON信息的视图，只需要使用ctrl+F4快捷键即可。 Inject language可以支持的语言和操作多到你难以想象，读者可以自行研究。 使用快捷键移动分割线假设有下面的场景，某个类的名字在project视图里被挡住了某一部分。 你想完整的看到类的名字，该怎么做。一般都是使用鼠标来移动分割线，但是这样子效率太低了。可以使用alt+1把鼠标焦点定位到project视图里，然后直接使用ctrl+shift+左右箭头来移动分割线。 ctrl+shift+enter不只是用来行尾加分号的ctrl+shift+enter其实是表示为您收尾的意思，不只是用来给代码加分号的。比如说： 这段代码，我们还需要为if语句加上大括号才能编译通过，这个时候你直接输入ctrl+shift+enter，IDEA会自动帮你收尾，加上大括号的。 不要动不动就使用IDEA的重构功能IDEA的重构功能非常强大，但是也有时候，在单个类里面，如果只是想批量修改某个文本，大可不必使用到重构的功能。比如说： 上面的代码中，有5个地方用到了rabbitTemplate文本，如何批量修改呢？ 首先是使用ctrl+w选中rabbitTemplate这个文本,然后依次使用5次alt+j快捷键，逐个选中，这样五个文本就都被选中并且高亮起来了，这个时候就可以直接批量修改了。 去掉导航栏去掉导航栏，因为平时用的不多。 可以把红色的导航栏去掉，让IDEA显得更加干净整洁一些。使用alt+v，然后去掉Navigation bar即可。去掉这个导航栏后，如果你偶尔还是要用的，直接用alt+home就可以临时把导航栏显示出来。 如果想让这个临时的导航栏消失的话，直接使用esc快捷键即可。 把鼠标定位到project视图里当工程里的包和类非常多的时候，有时候我们想知道当前类在project视图里是处在哪个位置。 上面图中的DemoIDEA里，你如何知道它是在spring-cloud-config工程里的哪个位置呢？ 可以先使用alt+F1，弹出Select in视图，然后选择Project View中的Project，回车，就可以立刻定位到类的位置了。 那如何从project跳回代码里呢？可以直接使用esc退出project视图，或者直接使用F4,跳到代码里。 强大的symbol如果你依稀记得某个方法名字几个字母，想在IDEA里面找出来，可以怎么做呢？ 直接使用ctrl+shift+alt+n，使用symbol来查找即可。比如说： 你想找到checkUser方法。直接输入user即可。 如果你记得某个业务类里面有某个方法，那也可以使用首字母找到类,然后加个 . ，再输入方法名字也是可以的。 如何找目录使用ctrl+shift+n后，使用 /，然后输入目录名字即可。 自动生成not null判断语句自动生成not null这种if判断，在IDEA里有很多种办法，其中一种办法你可能没想到。 当我们使用rabbitTemplate. 后，直接输入notnull并回车，IDEA就好自动生成if判断了。 按照模板找内容这个也是我非常喜欢的一个功能，可以根据模板来找到与模板匹配的代码块。比如说： 想在整个工程里面找到所有的try catch语句,但是catch语句里面没有做异常处理的。 catch语句里没有处理异常，是极其危险的。我们可以IDEA里面方便找到所有这样的代码。 首先使用ctrl+shift+A快捷键弹出action框，然后输入Search Struct 。 选择Search Structurally后，回车，跳转到模板视图。 点击Existing Templates按钮，选择try模板。为了能找出catch里面没有处理异常的代码块，我们需要配置一下CatchStatement的Maximum count的值，将其设置为1。 点击Edit Variables按钮，在界面修改Maximum count的值。 最后点击find按钮，就可以找出catch里面没有处理异常的代码了。 结束语感谢 Sam哥哥聊技术 的分享！ 此篇文章是收藏级别的文章，多学多用，才能使coding效率大大的提高。]]></content>
      <categories>
        <category>Intellij IDEA</category>
      </categories>
      <tags>
        <tag>转载摘抄</tag>
        <tag>Intellij IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu自定义安装Mysql全记录]]></title>
    <url>%2Fmysql%2Fubuntu-install-mysql-options%2F</url>
    <content type="text"><![CDATA[前言记录一下MySQL 5.7版本的安装过程。 MySQL安装零. 参考：官方文档 一. 下载mysql二进制文件，进入页面： https://dev.mysql.com/downloads/mysql/Select Operating System: Linux-Generic 并下载 二. 切换到root用户创建group和user root@chenruiwen:/data/mysql# groupadd mysql root@chenruiwen:/data/mysql# useradd -r -g mysql dba -s /bin/false mysql 三. 解压下载的Mysql,重命名 root@chenruiwen:/data/mysql# tar -xf mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz root@chenruiwen:/data/mysql# mv mysql-5.7.21-linux-glibc2.12-x86_64 mysql-5.7.21 四. 赋予mysql操作权限 root@chenruiwen:/data/mysql/mysql-5.7.21# chown -R dba /data/mysql/mysql-5.7.21 root@chenruiwen:/data/mysql/mysql-5.7.21# chgrp -R mysql /data/mysql/mysql-5.7.21 root@chenruiwen:/data/mysql/mysql-5.7.21# mkdir mysql-files root@chenruiwen:/data/mysql/mysql-5.7.21# chown dba:mysql mysql-files/ root@chenruiwen:/data/mysql/mysql-5.7.21# chmod 750 mysql-files 五. 初始化Mysql root@chenruiwen:/data/mysql/mysql-5.7.21# bin/mysqld --initialize --user=dba mysqld: Can&#39;t create directory &#39;/usr/local/mysql/data/&#39; (Errcode: 2 - No such file or directory) 2018-04-08T15:25:22.856110Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details). 2018-04-08T15:25:22.856195Z 0 [ERROR] Can&#39;t find error-message file &#39;/usr/local/mysql/share/errmsg.sys&#39;. Check error-message file location and &#39;lc-messages-dir&#39; configuration directive. 2018-04-08T15:25:22.856935Z 0 [ERROR] Aborting root@chenruiwen:/data/mysql/mysql-5.7.21# 提示目录不存在，因为我的mysql目录是在/data/mysql/mysql-5.7.21 所以，要指定数据目录和basedir并初始化。 root@chenruiwen:/data/mysql/mysql-5.7.21# mkdir data root@chenruiwen:/data/mysql/mysql-5.7.21# bin/mysqld --user=dba --basedir=/data/mysql/mysql-5.7.21 --datadir=/data/mysql/mysql-5.7.21/data/ --initialize-insecure 2018-04-28T03:12:52.827802Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details). 2018-04-28T03:12:53.883717Z 0 [Warning] InnoDB: New log files created, LSN=45790 2018-04-28T03:12:54.084754Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2018-04-28T03:12:54.150087Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 0aca257d-4a92-11e8-af3b-00163e089ff5. 2018-04-28T03:12:54.153185Z 0 [Warning] Gtid table is not ready to be used. Table &#39;mysql.gtid_executed&#39; cannot be opened. 2018-04-28T03:12:54.153653Z 1 [Warning] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option. 这里我使用了 –initialize-insecure 参数，不设置root密码。如果是 –initialize ，会随机生成一个密码。 六. 开启SSL，生成密钥文件 root@chenruiwen:/data/mysql/mysql-5.7.21# bin/mysql_ssl_rsa_setup 2018-04-28 11:21:57 [ERROR] Failed to access directory pointed by --datadir. Please make sure that directory exists and is accessible by mysql_ssl_rsa_setup. Supplied value : /usr/local/mysql/data 报错,需要修改配置文件。修改 /etc/my.cnf –datadir 属性,创建 my.cnf root@chenruiwen:/data/mysql/mysql-5.7.21# vi /etc/my.cnf MySQL配置文件简单版： [mysqld] # GENERAL character-set-server=utf8 symbolic-links=0 basedir=/data/mysql/mysql-5.7.21 datadir=/data/mysql/mysql-5.7.21/data socket=/tmp/mysql.sock user=dba port=3306 pid-file=/data/mysql/mysql-5.7.21/data/mysql.pid default_storage_engine=InnoDB #LOGGING log_error=/data/mysql/mysql-5.7.21/log/mysql-error.log #OTHER open_files_limit=65535 [client] socket=/tmp/mysql.sock port=3306 [mysqld_safe] log-error=/data/mysql/mysql-5.7.21/log/mysql-error.log pid-file=/data/mysql/mysql-5.7.21/data/mysql.pid 定义的日志目录和文件手工创建一下，然后重新运行： root@chenruiwen:/data/mysql/mysql-5.7.21# bin/mysql_ssl_rsa_setup Generating a 2048 bit RSA private key ............................................+++ ........................+++ writing new private key to &#39;ca-key.pem&#39; ----- Generating a 2048 bit RSA private key ....................................+++ .................+++ writing new private key to &#39;server-key.pem&#39; ----- Generating a 2048 bit RSA private key ..............................................................................+++ ..........................................+++ writing new private key to &#39;client-key.pem&#39; ----- root@chenruiwen:/data/mysql/mysql-5.7.21# 更多开启SSL相关请参考官方文档: Creating SSL and RSA Certificates and Keys 七. 安全启动MySQL服务 root@chenruiwen:/data/mysql/mysql-5.7.21# bin/mysqld_safe --user=dba &amp; 查看MySQL服务进程 root@chenruiwen:/data/mysql/mysql-5.7.21# ps -ef|grep mysql root 14899 11849 0 15:20 pts/0 00:00:00 /bin/sh bin/mysqld_safe --user=dba dba 15135 14899 0 15:20 pts/0 00:00:00 /data/mysql/mysql-5.7.21/bin/mysqld --basedir=/data/mysql/mysql-5.7.21 --datadir=/data/mysql/mysql-5.7.21/data --plugin-dir=/data/mysql/mysql-5.7.21/lib/plugin --user=dba --log-error=/data/mysql/mysql-5.7.21/log/mysql-error.log --open-files-limit=65535 --pid-file=/data/mysql/mysql-5.7.21/data/mysql.pid --socket=/tmp/mysql.sock --port=3306 root 15201 11849 0 15:27 pts/0 00:00:00 grep --color=auto mysql 启动成功。 八. (可选项)加到系统服务 root@chenruiwen:/data/mysql/mysql-5.7.21# cp support-files/mysql.server /etc/init.d/mysql.server 修改 mysqld 文件里的 basedir，datadir， mysqld_pid_file_path属性 连接MySQLroot@chenruiwen:/data/mysql/mysql-5.7.21# mysql -uroot -p The program &#39;mysql&#39; can be found in the following packages: * mysql-client-core-5.7 * mariadb-client-core-10.0 Try: apt install &lt;selected package&gt; 安装客户端 root@chenruiwen:/data/mysql/mysql-5.7.21# apt-get update root@chenruiwen:/data/mysql/mysql-5.7.21# apt-get install mysql-client-core-5.7 安装完成后重新连接MySQL，输入密码时直接回车，登录成功。 修改 root 密码： mysql&gt; use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql&gt; update user set authentication_string = password(&#39;123456&#39;), password_expired = &#39;N&#39;, password_last_changed = now() where user = &#39;root&#39;; Query OK, 1 row affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 1 退出，重启即可。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8实战学习总结]]></title>
    <url>%2Fjava%2Fjava8-in-action%2F</url>
    <content type="text"><![CDATA[前言java8作为一次大的升级，语法层面上有很大的改变，于是，来尝尝Java8的鲜。(ps: 哈哈，java10都出了，java8还不熟咋办呢~ 学学吧~) 为什么要用Java8 elasticsearch: Elasticsearch requires Java 8 or later. Use the official Oracle distribution or an open-source distribution such as OpenJDK. dubbo: Requires JDK1.8+, if you use lower version, see 1.6+, use 2.5.5 spring: JDK 8+ for Spring Framework 5.x…… 很多主流框架已经使用java8进行升级开发，java8是趋势，是时候一起拥抱java8了. java8语言新特性 函数式编程 Lambda表达式 接口的默认方法和静态方法 stream API 新的类库：Optional,Streams,Date/Time API (JSR 310)… JVM新特性 1.Lambda表达式Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中），或者把代码看成数据。 1.1 lambda的基本语法是：(parameters) -&gt; expression 或者 (parameters) -&gt; { statements; } eg:java8中有效的lambda表达式： 一个String类型的参数并返回一个int。Lambda中没有return语句，因为已经隐含了return。 (String s) -&gt; s.length() 两个int类型的参数而没有返回值。 (int x, int y) -&gt; { System.out.println(&quot;Result:&quot;); System.out.println(x+y); } 没有参数，返回一个int() -&gt; 1 1.2 函数式接口 函数式接口(函数式接口就是只定义一个抽象方法的接口) 函数描述符(函数式接口的抽象方法的签名 就是 lambda表达式的签名) java8中接口的变化:Java 8用默认方法与静态方法这两个新概念来扩展接口的声明。此功能是为了向后兼容性增加，使旧接口可用于利用JAVA8，lambda表达式的能力 默认方法与抽象方法不同之处在于抽象方法必须要求实现，但是默认方法则没有这个要求。 在实际使用过程中，函数式接口是容易出错的：如有某个人在接口定义中增加了另一个方法，这时，这个接口就不再是函数式的了，并且编译过程也会失败。为了克服函数式接口的这种脆弱性并且能够明确声明接口作为函数式接口的意图，Java 8增加了一种特殊的注解@FunctionalInterface（Java 8中所有类库的已有接口都添加了@FunctionalInterface注解）。 目前已存在的函数式接口有：Comparable、Runnable和Callable等。java8在java.util.function中有引入了很多个新的函数式接口: Predicate 输入参数为类型T， 输出为类型boolean， 记作 T -&gt; boolean Consumer 输入参数为类型T， 输出为void， 记作 T -&gt; void Function&lt;T,R&gt; 输入参数为类型T， 输出为类型R， 记作 T -&gt; R Supplier 没有输入参数， 输出为类型T， 记作 void -&gt; T… 1.3方法引用方法引用让你可以重复使用现有的方法定义，并像Lambda一样传递它们。当你需要使用方法引用时，目标引用放在分隔符::前，方法的名称放在后面。 三种方法引用： 指向静态方法的方法引用。lambda表达式: (args) -&gt; ClassName.staticMethod(args)方法引用: ClassName::staticMethod 比如 s -&gt; Integer.valueOf(s) 等价于 Integer::valueOf 指向任意类型实例方法的方法引用。lambda表达式: (arg0, rest) -&gt; arg0.instanceMethod(rest) 方法引用: ClassName::instanceMethod(上面args0是ClassName类型的) 比如 (str, integer) -&gt; str.substring(integer) 等价于 String::substring 指向现有对象的实例方法的方法引用。lambda表达式: (args) -&gt; expr.instanceMethod(args) 方法引用: expr::instanceMethod 比如 (Apple arg) -&gt; appleExpr.compareAppleWight(arg) 等价于 appleExpr::compareAppleWight 构造函数的方法引用。对于一个现有构造函数，你可以利用它的名称和关键字new来创建它的一个引用： ClassName::new。它的功能与指向静态方法的引用类似。 比如创建一个Apple对象。空参构造器Apple()： Supplier&lt;Apple&gt; c1 = Apple::new; Apple a1 = c1.get(); 等价于 Supplier&lt;Apple&gt; c1 = () -&gt; new Apple(); Apple a1 = c1.get(); 两个参数的构造函数Apple(String color, Integer weight)： BiFunction&lt;Integer, String, Apple&gt; biFunction = Apple::new; Apple apple2 = biFunction.apply(155, &quot;green&quot;); 等价于 BiFunction&lt;Integer, String, Apple&gt; biFunction = (weight, color) -&gt; new Apple(weight, color); Apple apple2 = biFunction.apply(155, &quot;green&quot;); 1.4 复合lambda表达式 比较器(Comparator)复合(reversed(),thenComparing()) 谓词(Predicate)复合(negate(),and(),or()) 函数(Function&lt;T, V&gt;)复合(compose(),andThen(),identity()) 2.Stream APIJava 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。 Stream API(java.util.stream.*)可以让你的代码具备： 声明性：更简洁，更易读 可复合：更灵活 可并行：性能更好 2.1 什么是流流不是一种数据结构，而是处理集合元素的相关计算，更像一个高级的 Iterator。单向，不可往复，数据只能遍历一次。 如何使用流？ 一个数据源（如集合）来执行一个查询； 一个中间操作链，形成一条流的流水线； 一个终端操作，执行流水线，并能生成结果。 2.2 使用流 筛选、切片和匹配 查找、匹配和归约 使用数值范围等数值流 从多个源创建流 无限流 2.2.1 筛选，切片 filter (筛选过滤) distinct (去重) limit (截取) skip (跳过) 2.2.2 映射 map (映射:接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素) flatMap (flatmap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。) 2.2.3 查找和匹配 anyMatch (检查谓词是否至少匹配一个元素) allMatch (检查谓词是否匹配所有元素) noneMatch (检查是否没有任何元素与给定的谓词匹配) findAny (返回当前流中的任意元素Optional。它可以与其他流操作结合使用。) findFirst (返回流中第一个元素Optional) 2.2.4 reduce这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。 Optional reduce(BinaryOperator accumulator); T reduce(T identity, BinaryOperator accumulator); U reduce(U identity,BiFunction&lt;U, ? super T, U&gt; accumulator,BinaryOperator&lt; U &gt; combiner); 2.2.5 数值流 IntStream DoubleStream LongStream 2.2.6 创建流 由值创建流(Stream.of) 由数组创建流(Arrays.stream(array)) 由文件生成流(java.nio.file.Files) 由函数生成流：创建无限流(Stream.iterate和Stream.generate) 2.3 收集器 用Collectors类创建和使用收集器 将数据流归约为一个值 汇总：归约的特殊情况 数据分组和分区 自定义收集器 2.3.1 归约和汇总Stream.reduce 与 Stream.collect的区别：Stream.reduce，常用的方法有average, sum, min, max, and count，返回单个的结果值，并且reduce操作每处理一个元素总是创建一个新值。Stream.collect修改现存的值，而不是每处理一个元素，创建一个新值。 2.3.2 数据分组 一级分组Map&lt;Dish.Type, List&lt;Dish&gt;&gt; groupByType = menuList.stream().collect(groupingBy(Dish::getType)); 多级分组Map&lt;Dish.Type, Map&lt;CaloricLevel, List&lt;Dish&gt;&gt;&gt; groupByTypeAndCalories = menuList.stream().collect( groupingBy(Dish::getType, groupingBy(dish -&gt; { if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; })) ); 按子组收集数据Map&lt;Dish.Type, Long&gt; groupByTypeToCount = menuList.stream().collect(groupingBy(Dish::getType, counting())); 分区(分区是一种特殊的分组，结果map至少包含两个不同的分组——一个true，一个false。)Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionByVegeterian = menuList.stream().collect(partitioningBy(Dish::isVegetarian)); 2.3.3 Collector接口 public interface Collector&lt;T, A, R&gt; { Supplier&lt;A&gt; supplier() BiConsumer&lt;A, T&gt; accumulator() Function&lt;A, R&gt; finisher() BinaryOperator&lt;A&gt; combiner() Set&lt;Characteristics&gt; characteristics() } Collector接口的三个泛型： T：stream在调用collect方法收集前的数据类型 A：A是T的累加器，遍历T的时候，会把T按照一定的方式添加到A中，换句话说就是把一些T通过一种方式变成A R：R可以看成是A的累加器，是最终的结果，是把A汇聚之后的数据类型，换句话说就是把一些A通过一种方式变成R 通过自定义ToList收集器理解接口方法： Supplier supplier()怎么创建一个累加器（这里对应的是如何创建一个List） BiConsumer&lt;A, T&gt; accumulator()怎么把一个对象添加到累加器中（这里对应的是如何在List里添加一个对象，当然是调用add方法） Function&lt;A, R&gt; finisher()其实就是怎么把A转化为R，由于是toList，所以A和R是一样的类型，这里其实用就是Function.identity BinaryOperator combiner()它定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器要如何合并（这里对应的是如何把List和List合并起来，当然是调用addAll，这里由于最终要返回List，所以A和R是一个类型，都是List所以才调用addAll） Set characteristics()会返回一个不可变的Characteristics集合，它定义 了收集器的行为——尤其是关于流是否可以并行归约，以及可以使用哪些优化的提示，toList这里只用了Characteristics.IDENTITY_FINISH 2.4 并行数据处理并行流：可以通过对收集源调用parallelStream方法来把集合转换为并行流。并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。 问题:并行流用的线程是从哪儿来的？有多少个？怎么自定义这个过程呢？并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量，这个值是由Runtime.getRuntime().available-Processors()得到的。 但是你可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism 来改变线程池大小，如下所示： System.setProperty(“java.util.concurrent.ForkJoinPool.common.parallelism”,”12”);这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。 使用并行流：本地测试的过程中，并行流比顺序流效果差。原因可能与机器，处理的数据量，使用并行流的方式等有关系。 是否使用并行流需考虑如下几种情况： 留意装箱。(使用（IntStream、LongStream、DoubleStream来避免装箱拆箱) 有些操作本身在并行流上的性能就比顺序流差。(limit,findFirst等依赖于元素顺序的操作) 考虑流的操作流水线的总计算成本。设N是要处理的元素的总数，Q是一个元素通过流水线的大致处理成本，则N*Q就是这个对成本的一个粗略的定性估计。Q值较高就意味着使用并行流时性能好的可能性比较大。 数据量较小的情况不适合并行流。 考虑流背后的数据结构是否易于分解。 流自身的特点，以及流水线中的中间操作修改流的方式，都可能会改变分解过程的性能。 考虑终端操作中合并步骤的代价是大是小（例如Collector中的combiner方法）。 流的数据源 源 | 可分解性 —|— ArrayList | 极佳 LinkedList | 差 IntStream.range | 极佳 Stream.iterate | 差 HashSet | 好 TreeSet | 好 3.Optional使用 使用Optional避免null引用 整洁代码中对null的检查 Optional的使用 java中的null带来了种种问题：典型常见，使代码膨胀，自身无意义等等等。 方法 描述 empty 返回一个空的Optional 实例 filter 如果值存在并且满足提供的谓词，就返回包含该值的Optional 对象；否则返回一个空的Optional 对象 flatMap 如果值存在，就对该值执行提供的mapping函数调用，返回一个Optional 类型的值，否则就返回一个空的Optional 对象 get 如果该值存在，将该值用Optional封装返回，否则抛出一个NoSuchElementException 异常 ifPresent 如果值存在，就执行使用该值的方法调用，否则什么也不做 isPresent 如果值存在就返回true，否则返回false map 如果值存在，就对该值执行提供的mapping 函数调用 of 将指定值用Optional封装之后返回，如果该值为null，则抛出一个NullPointerException异常 ofNullable 将指定值用Optional封装之后返回，如果该值为null，则返回一个空的Optional 对象 orElse 如果有值则将其返回，否则返回一个默认值 orElseGet 如果有值则将其返回，否则返回一个由指定的Supplier接口生成的值 orElseThrow 如果有值则将其返回，否则抛出一个由指定的Supplier接口生成的异常 注意：Optional 无法序列化 4.新的日期和时间API新的 java.time 中包含了所有关于：时钟（Clock）、本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。 历史悠久的 Date 类新增了 toInstant() 方法，用于把 Date 转换成新的表示形式。这些新增的本地化时间日期 API 大大简化了了日期时间和本地化的管理。 目前Java8新增了java.time包定义的类表示日期-时间概念的规则，很方便使用；最重要的一点是值不可变，且线程安全。 本地日期时间API: LocalDate(年月日) LocalTime(时分秒) localDateTime(年月日时分秒) 时区API： ZonedDateTime 时钟API： Clock 计算日期时间差API： Period(处理有关基于时间的日期数量。) Duration(处理有关基于时间的时间量。) 时间格式化API DateTimeFormatter(DateTimeFormatter实例都是线程安全 的) 5. 其他 java类库标准base64编码使用方式: `java final String text = “测试Abc123!!￥￥”; final String encoded = Base64.getEncoder().encodeToString(text.getBytes(StandardCharsets.UTF_8)); System.out.println(encoded); // 5rWL6K+VQWJjMTIzISHvv6Xvv6U= final String decoded = new String(Base64.getDecoder().decode(encoded), StandardCharsets.UTF_8); System.out.println(decoded); // 测试Abc123!!￥￥ // url encode final String url = “https://www.chenruiwen.cn/abc?foo=中文&amp;￥%&amp;bar=hello123&amp;baz=https://abc/def123&quot;; final String encoded2 = Base64.getUrlEncoder().encodeToString(url.getBytes(StandardCharsets.UTF_8)); System.out.println(encoded2); // aHR0cDovL3d3dy5qaW5odWkzNjUuY29tL2FiYz9mb2895Lit5paHJu-_pSUmYmFyPWhlbGxvMTIzJmJhej1odHRwOi8vYWJjL2RlZjEyMw== final String decoded2 = new String(Base64.getUrlDecoder().decode(encoded2), StandardCharsets.UTF_8); System.out.println(decoded2); // https://www.chenruiwen.cn/abc?foo=中文&amp;￥%&amp;bar=hello123&amp;baz=https://abc/def123 ` jvm的变化:PermGen空间被移除了，取而代之的是Metaspace（JEP 122）。 JVM选项 -XX:PermSize与-XX:MaxPermSize分别被-XX:MetaSpaceSize与-XX:MaxMetaspaceSize所代替。 最后Java8 作为 Java 语言的一次重大发布，包含语法上的更改、新的方法与数据类型，以及一些能默默提升应用性能的隐性改善。而且java8有利于提高开发生产力，对于开发者来说是好事，也是趋势。但是生产中使用java8可能存在风险，在正式使用Java8之前，不妨先体验一下java8的神奇。 附《java8 in action》源码:https://github.com/java8/Java8InAction.git]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微博图床插件打包]]></title>
    <url>%2Ftips%2Fpackage-weibo-drawing-plugin%2F</url>
    <content type="text"><![CDATA[前言寻找一个免费的图床软件，微博图床真的是太好不过了~~（手动感谢微博图床！）。之前安装微博图床的chrome插件，本人手贱删了，现在暂时也没翻到墙外，一时间需要重新安装微博图床的chrome插件，甚是着急。网上提供的一些插件也都没用，只能另求他路。 通过自己打包安装微博图床插件 链接到微博图床github地址并下载。url如下： https://github.com/suxiaogang/WeiboPicBed 打开chrome扩展程序 打开chrome浏览器，输入如下地址： chrome://extensions/ 打开开发者模式，点击 打包扩展程序 打包扩展程序， 扩展程序目录选择 github上 clone下来的目录，点击打包即可。 会在同级目录下生成 .crx 和 .pem结尾文件，其中 .crx结尾文件即是扩展程序 安装微博图床插件直接拖动微博图床插件(WeiboPicBed.crx)至chrome扩展程序即可。然后你就可以肆意上传图片了~]]></content>
      <categories>
        <category>tips</category>
      </categories>
      <tags>
        <tag>tool</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于hexo+nginx快速建站]]></title>
    <url>%2Fblog%2Fhexo-and-nginx-build-site%2F</url>
    <content type="text"><![CDATA[前言跟公司大神学习技术知识，发现大神们都有自己的技术博客，拥有个人网站，感觉很酷。所以趁着一波阿里云打折，开启自己个人网站之路。准备着手从个人博客网站开始，无奈自己是一个小小后端程序猿，前端技术了解不多，难道要开始先积累前端技术栈再建站吗？orz。当然不，网上有大量博客框架和教程可以快速建站，比如Hexo,Wordpress等。本人博客 1.0版本就准备用hexo开始。本文并非部署到github上，想要部署到github另行参考。 Hexo特点不妨登录Hexo官网瞧一瞧。 Blazing Fast Markdown Support One-Command Deployment Various Plugins 总之就是很快，支持markdown，简单到一键部署，拥有多样性插件。 快速搭建博客前提条件一台阿里云ECS，环境安装有: Node.js, Git Nginx Ubuntu安装Node.js # 安装依赖包python-software-properties apt-get install python-software-properties curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash - apt-get install nodejs Ubuntu安装Git add-apt-repository ppa:git-core/ppa apt update apt install git Ubuntu安装Nginx（略） 安装 Hexo npm install -g hexo-cli 建站创建博客需要文件 cd /data midir hexo-blog cd hexo-blog hexo init $ npm install 配置网站信息修改 _config.yml 文件, 仅修改了站点信息和地址信息, 更多的配置信息参考官网 # Site title: 陈瑞文的个人网站 subtitle: description: 你好，旅行者 keywords: author: 陈瑞文 language: zh-Hans timezone: # URL ## If your site is put in a subdirectory, set url as &#39;http://yoursite.com/child&#39; and root as &#39;/child/&#39; url: http://www.chenruiwen.cn root: / permalink: :year/:month/:day/:title/ permalink_defaults: 顺便下载了github上比较高排名的hexo主题：Next. git clone https://github.com/iissnan/hexo-theme-next 将文件夹拷贝到Hexo博客目录的themes文件夹下，并修改站点主题 theme: next 剩下的个性化配置参考：https://theme-next.iissnan.com/getting-started.html进行配置。此外，参考了大佬们的文章： 打造个性超赞博客Hexo+NexT+GithubPages的超深度优化 hexo高阶教程next主题优化 hexo的next主题个性化教程:打造炫酷网站 Hexo搭建博客的个性化设置 通过Nginx发布Nginx下载安装略。 部署静态站点生成静态文件: ➜ hexo-blog hexo g ➜ hexo-blog ls _config.yml node_modules public themes db.json package-lock.json scaffolds debug.log package.json source 生成好的静态文件在public 文件夹内。 修改nginx配置文件修改nginx配置文件: vi /usr/local/nginx/conf/nginx.conf 仅需修改http模块的server配置： server { listen 80; server_name www.chenruiwen.cn; charset utf-8; root /data/hexo-blog/public;# 这里是静态文件地址 location / { index index.html; } } 重新加载nginx： nginx -s reload 至此，网站已初步建成。 部署到github上通过git部署 创建GitHub Repository(略) 修改配置文件_config.ymldeploy: type: git repo: https://github.com/crrrrrw/hexo_static_page.git branch: master 安装hexo git插件 npm install hexo-deployer-git --save 部署hexo generate hexo deploy 这样，所有文件就都提交到github库上了。 服务器上，克隆静态文件 cd /data git clone https://github.com/crrrrrw/hexo_static_page.git git pull origin master 即可实现静态文件的更新。然后nginx重新指向这个静态文件目录即可。 自动化部署思路a:脚本定时更新github地址。 思路b:基于git hooks实现push后的自动化部署。 总结总之，搭建博客环境很简单，不过还有很多的工作要做，比如优化自己博客的样式，增加一些有意思的功能等，以后会慢慢优化的。当然，最重要的是写出好的有用的博文分享出去。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu安装Nginx全记录]]></title>
    <url>%2Fnginx%2Fubuntu-install-nginx-options%2F</url>
    <content type="text"><![CDATA[前言记录下nginx安装过程。本文只演示源码包编译安装。个人比较喜欢自定义安装，灵活。 nginx下载相关官方下载页面：https://nginx.org/en/download.html configure配置文件详解：https://nginx.org/en/docs/configure.html 安装编译工具及库文件安装gcc g++的依赖库 root@chenruiwen:~# apt-get install build-essential root@chenruiwen:~# apt-get install libtool 安装pcre依赖库（https://www.pcre.org/） root@chenruiwen:~# apt-get update root@chenruiwen:~# apt-get install libpcre3 libpcre3-dev 安装zlib依赖库（https://www.zlib.net） root@chenruiwen:~# apt-get install zlib1g-dev 安装SSL依赖库（16.04默认已经安装了） root@chenruiwen:~# apt-get install openssl 安装nginx下载nginx root@chenruiwen:/data/nginx# wget http://nginx.org/download/nginx-1.6.2.tar.gz 解压 root@chenruiwen:/data/nginx# tar xf nginx-1.6.2.tar.gz 进入解压目录 root@chenruiwen:/data/nginx# cd nginx-1.6.2/ 配置 root@chenruiwen:/data/nginx/nginx-1.6.2# ./configure --prefix=/usr/local/nginx 编译,安装 root@chenruiwen:/data/nginx/nginx-1.6.2# make root@chenruiwen:/data/nginx/nginx-1.6.2# make install 测试 root@chenruiwen:/data/nginx/nginx-1.6.2# /usr/local/nginx/sbin/nginx -v nginx version: nginx/1.6.2 nginx安装完成 配置软链接 root@chenruiwen:/data/nginx/nginx-1.6.2# ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx 现在就可以不用路径直接输入nginx启动。 启动 root@chenruiwen:/data/nginx/nginx-1.6.2# nginx -c /usr/local/nginx/conf/nginx.conf Nginx 配置跳转Nginx配置文件详解]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件详解]]></title>
    <url>%2Fnginx%2Fexplain-nginx-config-file%2F</url>
    <content type="text"><![CDATA[前言参考了网上一些博文和文档，总结了一下，方便日后查阅。 参考文献: https://nginx.org/en/docs/ https://docs.nginx.com/ https://blog.csdn.net/hzsunshine/article/details/63687054 https://blog.csdn.net/field_yang/article/details/52278390 Nginx 工作原理Nginx由内核和模块组成，完成工作是通过查找配置文件将客户端请求映射到一个location block(location是用于URL匹配的命令)，location配置的命令会启动不同模块完成工作。 Nginx模块分为核心模块，基础模块和第三方模块。 核心模块：HTTP模块、EVENT模块(事件)、MAIL模块。 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块、HTTP Rewrite模块。 第三方模块：HTTP Upstream Request Hash模块、Notice模块、HTTP Access Key模块。 Nginx 配置文件结构配置文件主要由四部分组成：main(全区设置)，server(主机配置)，upstream(负载均衡服务器设置)，和location(URL匹配特定位置设置). main events { .... } http { server { location { ... } location { ... } } server { ... } upstream A { ... } upstream B { ... } } Nignx配置文件详解全局变量#Nginx的worker进程运行用户以及用户组，默认为nobody账号 user nobody nobody; #Nginx开启的进程数，每个nginx平均耗内存10~12MB，一般指定一个进程就足够了，建议指定和CPU数目相同的进程数即可。 worker_processes 1; #worker_processes auto; #以下参数指定了哪个cpu分配给哪个进程，一般来说不用特殊指定。如果一定要设的话，用0和1指定分配方式. #这样设就是给1-4个进程分配单独的核来运行，出现第5个进程是就是随机分配了。eg: #worker_processes 4 #4核CPU #worker_cpu_affinity 0001 0010 0100 1000 #定义全局错误日志定义类型，[debug|info|notice|warn|crit] #error_log logs/error.log info; #指定进程ID存储文件位置 #pid logs/nginx.pid; #一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n的值保持一致。worker_rlimit_nofile用于绑定worker进程和CPU，Linux内核2.4以上使用 worker_rlimit_nofile 65535; 修改ulimit -n 值#vim /etc/security/limits.conf # * soft nproc 65535 # * hard nproc 65535 # * soft nofile 65535 # * hard nofile 65535 事件配置 event指令用来设置nginx的工作模式及连接数上限。 #use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; #use是个事件模块指令，用于指定工作模式，nginx支持的工作模式有select、poll、kqueue、epoll、rtsig、和/dev/poll，其中select和poll都是标准的工作模式。kqueue和epoll是高效的工作模式，其中kqueue用于BSD系统，而epoll用于Linux系统，对于Linux系统，epoll是首选。 use epoll; # worker_connections时间模块指令，用于定义进程的最大连接数，默认为1024,。 #最大客户连接数由worker_connections和worker_processes决定，即max_client=worker_processes*worker_connections,在作为反向代理时变为：max_client= worker_processes*worker_connections/4。 #进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit –n 65536”后worker_connections的设置才生效。 worker_connections 65536; #worker工作方式：串行（一定程度降低负载，但服务器吞吐量大时，关闭使用并行方式） #multi_accept on; http参数http{ #文件扩展名与文件类型映射表,可以减少主配置文件的复杂度。 include mime.types; #默认文件类型,默认为二进制流 default_type application/octet-stream; #nginx的httplog模块指令，用于指定nginx的日志输出格式，main为此日志输出格式的名称，可以在下面access_log指令中使用。 log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39; &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;; #连接日志的路径，指定的日志格式放在最后。 #access_log logs/access.log main; #只记录更为严重的错误日志，减少IO压力 error_log logs/error.log crit; #默认编码 #charset utf-8; #服务器名字的hash表大小 server_names_hash_bucket_size 128; #客户端请求单个文件的最大字节数 client_max_body_size 8m; #指定来自客户端请求头的hearerbuffer大小 client_header_buffer_size 32k; #指定客户端请求中较大的消息头的缓存最大数量和大小。 large_client_header_buffers 4 64k; #开启高效传输模式。 sendfile on; #防止网络阻塞 tcp_nopush on; tcp_nodelay on; #设置客户端连续保持活动的超时时间。 keepalive_timeout 65; #keepalive_timeout 0; #设置客户端请求头读取超时时间，超过该时间客户端还没发送任何数据，nginx将返回“request time out（408）”错误。 client_header_timeout 10; #设置客户端请求主体读取超时时间，默认时间为602s，超过该时间客户端还没发送任何数据，nginx将返回“request timeout（408）”错误。 client_body_timeout 10; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 #开启gzip压缩输出 gzip on; #最小压缩文件大小 gzip_min_length 1k; #压缩缓冲区 gzip_buffers 4 16k; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_http_version 1.0; #压缩等级 1-9 等级越高，压缩效果越好，节约宽带，但CPU消耗大 gzip_comp_level 2; #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn gzip_types text/plain application/x-javascript text/css application/xml; #前端缓存服务器缓存经过压缩的页面 gzip_vary on; } 虚拟主机基本设置server{ #监听端口 listen 80; #访问域名,多个域名之间用空格隔开 server_name www.example.com; #编码格式，若网页格式与此不同，将被自动转码 #charset koi8-r; #虚拟主机访问日志定义 #access_log logs/host.access.log main; #对URL进行匹配 location / { #访问路径，可相对也可绝对路径 root html; #首页文件。以下按顺序匹配 index index.html index.htm index.jsp; } #错误信息返回页面 #error_page 404 /404.html; # redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } #php脚本请求全部转发给FastCGI处理 # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} #禁止访问.ht页面 （需ngx_http_access_module模块） # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\.ht { # deny all; #} } #HTTPS虚拟主机定义 # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} 反向代理#以下配置追加在HTTP的全局变量中 #该部分亦可以使用写进proxy.conf文件中，再使用include指令包含进来，从而使配置显得更简练 #用法：include /opt/nginx/conf/proxy.conf #client_body_buffer_size：用于指定客户端请求主体缓冲区大小，意思就是先保存到本地再传给用户。 client_max_body_size 10m; client_body_buffer_size 128k; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 5; #后端服务器数据回传时间(代理发送超时) proxy_send_timeout 5; #连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 60; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 16k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; #反向代理缓存目录 proxy_cache_path /data/proxy/cache levels=1:2 keys_zone=cache_one:500m inactive=1d max_size=1g; #levels=1:2 设置目录深度，第一层目录是1个字符，第2层是2个字符 #keys_zone:设置web缓存名称和内存缓存空间大小 #inactive:自动清除缓存文件时间。 #max_size:硬盘空间最大可使用值。 #指定临时缓存文件的存储路径(路径需和上面路径在同一分区) proxy_temp_path /data/proxy/temp #服务配置 server { #侦听的80端口 listen 80; server_name localhost; location / { #反向代理缓存设置命令(proxy_cache zone|off,默认关闭所以要设置) proxy_cache cache_one; #对不同的状态码缓存不同时间 proxy_cache_valid 200 304 12h; #设置以什么样参数获取缓存文件名 proxy_cache_key $host$uri$is_args$args; #后7端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #代理设置 proxy_pass http://IP; #文件过期时间控制 expires 1d; } #配置手动清楚缓存(实现此功能需第三方模块 ngx_cache_purge) #http://www.123.com/2017/0316/17.html访问 #http://www.123.com/purge/2017/0316/17.html清楚URL缓存 location ~ /purge(/.*) { allow 127.0.0.1; deny all; proxy_cache_purge cache_one $host$1$is_args$args; } #设置扩展名以.jsp、.php、.jspx结尾的动态应用程序不做缓存 location ~.*\.(jsp|php|jspx)?$ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://http://IP; } } 负载均衡upstream是nginx的http upstream模块，这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。 #设置负载均衡器。任意名称命名，使用时调用即可。 upstream my_server_pool { #调度算法 #1.轮循（默认）（weight轮循权值） #2.ip_hash：根据每个请求访问IP的hash结果分配。（会话保持） #3.fair:根据后端服务器响应时间最短请求。（upstream_fair模块） #4.url_hash:根据访问的url的hash结果分配。（需hash软件包） #参数： #down：表示不参与负载均衡 #backup:备份服务器 #max_fails:允许最大请求错误次数 #fail_timeout:请求失败后暂停服务时间。 server 192.168.1.109:80 weight=1 max_fails=2 fail_timeout=30; server 192.168.1.108:80 weight=2 max_fails=2 fail_timeout=30; } #负载均衡调用 server { ... location / { proxy_pass http://my_server_pool; } } URL配置与重写location支持正则表达式和条件判断匹配，可以通过location指令实现nginx对动静态网页的过滤处理。 # URL配置 #所有扩展名为gif|jpg|jpeg|bmp|png|ico|txt|js|css的静态文件都交给nginx处理 location ~ * \.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ { root /web/wwwroot/html; #expires指定静态文件的过期时间 expires 30d; } #将upload和html下的所有文件都交给nginx来处理，当然upload和html目录包含在/web/wwwroot/html目录中 location ~^/(upload|html)/ { root /web/wwwroot/html; expires 30d; } #location对此虚拟机下动态网页的过滤处理，也就是将所有.jsp为后缀的文件都交给本机8080端口处理。 location ~ .*.jsp$ { index index.jsp; proxy_pass http://localhost:8080; } # URL重写 #根据不同的浏览器URL重写 if($http_user_agent ~ Firefox){ rewrite ^(.*)$ /firefox/$1 break; } if($http_user_agent ~ MSIE){ rewrite ^(.*)$ /msie/$1 break; } #实现域名跳转 location / { rewrite ^/(.*)$ https://web8.example.com$1 permanent; } IP限制#限制IP访问 location / { deny 192.168.0.2； allow 192.168.0.0/24; allow 192.168.1.1; deny all; } Nignx状态监控#Nginx运行状态，StubStatus模块获取Nginx自启动的工作状态（编译时要开启对应功能） #location /NginxStatus { # #启用StubStatus的工作访问状态 # stub_status on; # #指定StubStaus模块的访问日志文件 # access_log logs/Nginxstatus.log; # #Nginx认证机制（需Apache的htpasswd命令生成） # #auth_basic &quot;NginxStatus&quot;; # #用来认证的密码文件 # #auth_basic_user_file ../htpasswd; #} #nginx的auth_basic采用的是与Apache兼容的密码文件，所以需要采用Apache的htpasswd命令来生成密码文件 #如添加一个fieldyang 用户可以用该方式生成密码文件:/usr/local/apache/bin/htpasswd –c /opt/nginx/conf/htpasswd fieldyang #访问：http://IP/NginxStatus(测试就不加密码验证相关)]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇]]></title>
    <url>%2Fessay%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[2018年，对我来说不平凡的一年。 过去的一年收获很多，在新公司认识了很多让我敬佩的大牛和可爱的小伙伴们，遇到了让我有些敬畏的领导，严格的要求又让我体验到曾经上学时的感觉。 为什么要建立个人网站？因为coooooooool! 在工作和学习中经常要查询文档和资料，就经常看到某些大牛们的个人网站，博文的质量很高，网站简介又好看，记录下自己走过的坎和分享技术，让我萌生了做个人网站的想法。终于赶上了一次阿里云特价(错过了腾讯云的特价~~)。所以这篇文章就作为我个人网站的开篇了~ 你好2018，开始折腾。]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>essay</tag>
      </tags>
  </entry>
</search>
